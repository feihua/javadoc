{"./":{"url":"./","title":"前言","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"automation/":{"url":"automation/","title":"一、互联网专题","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"automation/git/":{"url":"automation/git/","title":"Git版本控制","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"automation/git/git-base-use.html":{"url":"automation/git/git-base-use.html","title":"1.Git基本概念与核心命令掌握","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.GIT体系概述 1.1GIT 与 svn 主要区别： 1.1.1存储方式区别 1.1.2使用方式区别 1.1.3版本管理模式区别 2.GIT 核心命令使用 2.1安装git客户端安装 2.2认识git的基本使用 快捷提交至本地仓库 2.3分支管理 2.4远程仓库管理 2.5tag 管理 2.6日志管理 3.git 底层原理 3.1GIT存储对像(hashMap) 3.2GIT树对像 3.3git提交对象 3.4GIT引用 4.基于 gogs 快速搭建企业私有 GIT 服务 4.1gogs 介绍安装 前台运行 后台运行 4.2gogs 基础配置 4.3gogs 定时备份与恢复 查看备份相关参数 默认备份,备份在当前目录 参数化备份 --target 输出目录 --database-only 只备份 db 恢复。执行该命令前要先删除 custom.bak 自动备份脚本 !/bin/sh -e 执行备份命令 查找并删除 7 天前的备份 添加定时任务 每天 4：00 执行备份 打开任务编辑器 输入如下命令 00 04 * * * 每天凌晨 4 点执行 do-backup.sh 并输出日志至 #backup.log 4、客户端公钥配置与添加 Git 安装完之后，需做最后一步配置。打开 git bash，分别执行以下两句命令 git 自动记住用户和密码操作 概要： GIT体系概述 GIT 核心命令使用 GIT 底层原理 基于 gogs 搭建 WEB 管理服务1.GIT体系概述 提问： 大家公司是用什么工具来管理代码版本？SVN、CVS、GIT GIT 和 SVN 有什么区别呢？ 1.1GIT 与 svn 主要区别： 存储方式不一样 使用方式不一样 管理模式不一样1.1.1存储方式区别 GIT 把内容按元数据方式存储类似k/v 数据库，而 SVN 是按文件(新版 svn 已改成元数据存储) 1.1.2使用方式区别 从本地把文件推送远程服务，SVN 只需要commint而 GIT 需要add、commint、push 三个步骤 SVN 基本使用过程 Git 基本使用过程 1.1.3**版本管理模式区别** git 是一个分布式的版本管理系统，而要 SVN 是一个远程集中式的管理系统 集中式 分布式 2.GIT 核心命令使用 主要内容: git 客户端安装配置 整体认识 GIT 的基本使用 分支管理 标签管理 远程仓库配置2.1安装git客户端安装 官方客户端： httpsd://git-scm.com/downloads 其它客户端： https://tortoisegit.org/download/ 2.2认识git的基本使用 git 项目创建与克隆 文件提交与推送 完整模拟从项目添加到 push 过程 创建项目 初始化 git 仓库 提交文件 远程关联 push 至远程仓库 本地初始化 GIT 仓库: 基于远程仓库克隆至本地 git clone 当前目录初始化为 git 本地仓库 git init 基于 mvn 模板创建项目 mvn archetype:generate 本地添加 添加指定文件至暂存区 git add 添加指定目录至暂存区 git add 添加所有 git add -A 将指定目录及子目录移除出暂存区 git rm --cached target -r 添加勿略配置文件 .gitignore 本地提交 提交至本地仓库 git commit file -m '提交评论' 快捷提交至本地仓库 git commit -am '快添加与提交' 2.3分支管理 查看当前分支 git branch [-avv] 基于当前分支新建分支 git branch 基于提交新建分支 git branch git branch -d {dev} 切换分支 git checkout 合并分支 git merge 解决冲突，如果因冲突导致自动合并失败，此时 status 为 mergeing 状态. 需要手动修改后重新提交（commit） 2.4远程仓库管理 查看远程配置 git remote [-v] 添加远程地址 git remote add origin http:xxx.xxx 删除远程地址 git remote remove origin 上传新分支至远程 git push --set-upstream origin master 将本地分支与远程建立关联 git branch --track --set-upstream-to=origin/test test 2.5tag 管理 查看当前 git tag 创建分支 git tag 删除分支 git tag -d 2.6日志管理 查看当前分支下所有提交日志 git log 查看当前分支下所有提交日志 git log {branch} 单行显示日志 git log --oneline 比较两个版本的区别 git log master..experiment 以图表的方式显示提交合并网络 git log --pretty=format:'%h %s' --graph 3.git 底层原理 GIT 存储对像 GIT 树对像 GIT 提交对像 GIT 引用3.1GIT存储对像(hashMap) Git 是一个内容寻址文件系统，其核心部分是一个简单的键值对数据库（key-value data store），你可以向数据库中插入任意内容，它会返回一个用于取回该值的 hash 键。 git 键值库中插入数据 echo 'luban is good man' | git hash-object -w --stdin 79362d07cf264f8078b489a47132afbc73f87b9a 基于键获取指定内容 git cat-file -p 79362d07cf264f8078b489a47132afbc73f87b9a Git 基于该功能 把每个文件的版本中内容都保存在数据库中，当要进行版本回滚的时候就通过其中一个键将期取回并替换。 模拟演示 git 版写入与回滚过程 查找所有的 git 对像 find .git/objects/ -type f 写入版本 1 echo 'version1' > README.MF; git hash-object -w README.MF; 写入版本 2 echo 'version2' > README.MF; git hash-object -w README.MF; 写入版本 3 echo 'version3' > README.MF; git hash-object -w README.MF; 回滚指定版本 git cat-file -p c11e96db44f7f3bc4c608aa7d7cd9ba4ab25066e > README.MF 所以我们平常用的 git add 其实就是把修改之后的内容 插入到键值库中。当我们执行git add README.MF等同于执行了git hash-object -w README.MF把文件写到数据库中。 我们解决了存储的问题，但其只能存储内容同并没有存储文件名，如果要进行回滚 怎么知道哪个内容对应哪个文件呢？接下要讲的就是树对象，它解决了文件名存储的问题 。 3.2GIT树对像 树对像解决了文件名的问题，它的目的将多个文件名组织在一起，其内包含多个文件名称与其对应的 Key 和其它树对像的用引用，可以理解成操作系统当中的文件夹，一个文件夹包含多个文件和多个其它文件夹。 每一个分支当中都关联了一个树对像，他存储了当前分支下所有的文件名及对应的 key. 通过以下命令即可查看 查看分支树 git cat-file -p master^{tree} 3.3git提交对象 一次提交即为当前版本的一个快照，该快照就是通过提交对像保存，其存储的内容为：一个顶级树对象、上一次提交的对像啥希、提交者用户名及邮箱、提交时间戳、提交评论。 git cat-file -p b2395925b5f1c12bf8cb9602f05fc8d580311836 tree 002adb8152f7cd49f400a0480ef2d4c09b060c07 parent 8be903f5e1046b851117a21cdc3c80bdcaf97570 author tommy 1532959457 +0800 committer tommy 1532959457 +0800 通过上面的知识，我们可以推测出从修改一个文件到提交的过程总共生成了三个对像： 一个内容对象 ==> 存储了文件内容 一个树对像 ==> 存储了文件名及内容对像的 key 一个提交对像 ==> 存储了树对像的 key 及提交评论。 演示文件提交过程3.4GIT引用 当我们执行 git branch {branchName} 时创建了一个分支，其本质就是在 git 基于指定提交创建了一个引用文件，保存在 .git\\refs\\heads\\ 下。 演示分支的创建 git branch dev cat.git\\refs\\heads\\dev git 总共 有三种类型的引用： 分支引用 远程分支引用 标签引用 查询比较两个版本 git log master..experiment 版本提交历史网络 git log --pretty=format:'%h %s' --graph 查看分支树 git cat-file -p master^{tree} 4.基于 gogs 快速搭建企业私有 GIT 服务 概要： gogs 介绍与安装 gogs 基础配置 gogs 定时备份与恢复 gitlab ==> 功能多一些 4.1gogs 介绍安装 Gogs 是一款开源的轻量级 Git web 服务，其特点是简单易用完档齐全、国际化做的相当不错。其主要功能如下: 提供 Http 与 ssh 两种协议访问源码服务 提供可 WEB 界面可查看修改源码代码 提供较完善的权限管理功能、其中包括组织、团队、个人等仓库权限 提供简单的项目 viki 功能 提供工单管理与里程碑管理。 下载安装 官网：https://gogs.io 下载：https://gogs.io/docs/installation选择 linx amd64 下载安装 文档：https://gogs.io/docs/installation/install_from_binary 安装： 解压之后目录： 运行： 前台运行 ./gogs web 后台运行 $nohup ./gogs web & 默认端口：3000 初次访问 http://:3000 会进到初始化页,进行引导配置。 可选择 mysql 或 sqlite 等数据。这里选的是 sqllite 注：mysql 索引长度的问题没有安装成功,需要用 mysql5.7 以上版本 4.2gogs 基础配置 邮件配置说明： 邮件配置是用于注册时邮件确认，和找回密码时候的验证邮件发送。其配置分为两步： 第一：创建一个开通了 smtp 服务的邮箱帐号，一般用公司管理员邮箱。我这里用的是 QQ 邮箱。 第二：在{gogs_home/custom/conf/app.ini 文件中配置。 QQ 邮箱开通 smtp 服务 1、点击设置 2、开启 smtp 邮件设置 设置文件：{gogs_home/custom/conf/app.ini ENABLED = true HOST=smtp.qq.com:465 FROM=tuling2877438881@qq.com USER= PASSWD= ENABLED=true 表示启用邮件服务 host为 smtp 服务器地址，（需要对应邮箱开通 smtp 服务 且必须为 ssl 的形式访问） from发送人名称地址 user发送帐号 passwd开通 smtp 帐户时会有对应的授权码 重启后可直接测试 管理员登录==》控制面版==》应用配置管理==》邮件配置==》发送测试邮件 4.3gogs 定时备份与恢复 备份与恢复： 查看备份相关参数 ./gogs backup -h 默认备份,备份在当前目录 ./gogs backup 参数化备份 --target 输出目录 --database-only 只备份 db ./gogs backup --target=./backupes --database-only --exclude-repos 恢复。执行该命令前要先删除 custom.bak ./gogs restore --from=gogs-backup-20180411062712.zip 自动备份脚本 !/bin/sh -e gogs_home=\"/home/apps/svr/gogs/\" backup_dir=\"$gogs_home/backups\" cd dirname $0 执行备份命令 ./gogs backup --target=$backup_dir echo 'backup sucess' day=7 查找并删除 7 天前的备份 find $backup_dir -name '*.zip' -mtime +7 -type f |xargs rm -f; echo 'delete expire back data!' 添加定时任务 每天 4：00 执行备份 打开任务编辑器 crontab -e 输入如下命令 00 04 * 每天凌晨 4 点执行 do-backup.sh 并输出日志至 #backup.log 00 04 * /home/apps/svr/gogs/do-backup.sh >> /home/apps/svr/gogs/backup.log 2>&1 4、客户端公钥配置与添加 Git 配置 Git 安装完之后，需做最后一步配置。打开 git bash，分别执行以下两句命令 git config --global user.name “用户名” git config --global user.email “邮箱” git 自动记住用户和密码操作 git config --global credential.helper store SSH 公钥创建 1、打开 git bash 2、执行生成公钥和私钥的命令：ssh-keygen -t rsa 并按回车 3 下 3、执行查看公钥的命令：cat ~/.ssh/id_rsa.pub 4、拷贝 id_rsa.pub 内容至至服务~~/.ssh/authorized_keys 中 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:51:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"automation/maven/":{"url":"automation/maven/","title":"Maven依赖管理","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"automation/maven/maven-base-use.html":{"url":"automation/maven/maven-base-use.html","title":"1.Maven基本概念与核心配置 ","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.maven 安装与核心概念 1.1安装： 1.2maven 编译 1.3Maven打包 1.4maven 单元测试演示 创建测试目录 编写 测试类 测试类代码------------------------ 执行测试 1.5maven 依赖管理 2.maven核心配置 项目依懒 **2.1依赖传播特性: 2.2依赖优先原则 2.3可选依赖 2.4排除依赖 2.5依赖范围 手动加入本地仓库 项目聚合与继承 1、聚合 2、继承 3、依赖管理 项目构建配置 3.maven 生命周期 知识点概要： 3.1生命周期的概念与意义 执行清理 phase 执行 compile phase 也可以同时执行 清理加编译 3.2maven 三大生命周期与其对应的 phase(阶段) 执行编译 执行打包就包含了编译指令的执行 3.3生命周期与插件的关系 3.4生命周期与插件的默认绑定 mvn compile 直接执行 compile 插件目标 4.maven 自定义插件开发 知识点： 4.1maven 插件相关概念 将插件依赖拷贝到指定目录 4.2常用插件的使用 展示 pom 的依赖关系树 也可以直接简化版的命令，但前提必须是 maven 官方插件 查看 pom 文件的最终配置 原型项目生成 快速创建一个 WEB 程序 快速创建一个 java 项目 4.3开发一个自定义插件 5.nexus 私服搭建与核心功能 知识点概要: 5.1私服使用场景 5.2nexus 下载安装 解压 在环境变量当中设置启动用户 添加 profile 文件。安全起见不建议使用 root 用户，如果使用其它用户需要加相应权限 端口号 启动 停止 5.3nexus 仓库介绍 5.4本地远程仓库配置 5.5发布项目至 nexus 远程仓库 概要： maven 基本概念 maven 核心配置 maven 生命周期 Maven 自定义插件开发 基于 nexus 构建企业私服1.maven 安装与核心概念 概要： maven 安装 maven 编译(compile) 执行测试用例(test) maven 打包 maven 依懒管理 1.1安装： 官网下载 Maven （http://maven.apache.org/download.cgi） 解压指定目录 配置环境变量 检查安装是否成功 （mvn -version） maven 是什么？它的基本功能是什么？编译、打包、测试、依赖管理直观感受一下 maven 编译打包的过程。 1.2maven 编译 maven 编译过程演示 创建 maven 项目。 创建 src 文件 编写 pom 文件 执行编译命令 编写 pom 文件基础配置 4.0.0 org.codehaus.mojo my-project 1.0.SNAPSHOT mvn 编译命令 mvn compile [INFO] No sources to compile [INFO] --------------------------------------------------------------- [INFO] BUILD SUCCESS [INFO] --------------------------------------------------------------- [INFO] Total time: 0.473 s [INFO] Finished at: 2018-08-05T15:55:44+08:00 [INFO] Final Memory: 6M/153M [INFO] --------------------------------------------------------------- 请注意，在上述配置和命令当中，我们并没有指定源码文件在哪里？最后编译到哪里去？在这里 maven 采用了约定的方式从指项目结构中获取源码与资源文件进行编译打包。 1. 主源码文件：${project}/src/main/java 2. 主资源文件：${project}/src/main/resources 3. 测试源码文件：${project}/src/test/java 4. 测试资源文件：${project}/src/test/resources 将 java 文件移至 src/main/java 目录，重新执行编译. mv src/hello.java /src/main/java/hello.java mvn compile; 1.3Maven打包 maven 打包演示 mvn 打包命令 mvn package 1.4maven 单元测试演示 编写测试类 执行测试命令 编译测试类 创建测试目录 mkdir -p /src/test/java 编写 测试类 vim TestHello.java 测试类代码------------------------ package com.test.tuling; public class TestHello{ public void sayHelloTest(){ System.out.println(\"run test .....\"); } } 执行测试指令: 执行测试 mvn test 执行完指令发现没有执行我们的测试方法，这是为何？原因在于 maven 当中的测试类又做了约定，约定必须是 Test 开头的类名与 test 开头的方法才会执行。 重新修改方法名后 在执行 mvn test 即可正常执行。 package com.test.tuling; public class TestHello{ public void testsayHelloTest(){ System.out.println(\"run test .....\"); } } 通常测试我们是通过 junit 来编译测试用例，这时就就需添加 junit 的依赖。 1.5maven 依赖管理 在 pom 文件中添加 junit 依赖 修改测试类，加入 junit 代码 执行测试命令 加入依懒配置 junit junit 4.0 test 修改测试类引入 junit 类. //引入 junit 类 import org.junit.Assert; import org.junit.Test; Assert.assertEquals(\"\",\"hi\"); 注意：当我们在 classPath 当中加入 junit，原来以 test 开头的方法不会被执行，必须加入 @Test 注解才能被执行。 提问： 在刚才的演示过程当中 ，junit jar 包在哪里？是怎么加入到 classPath 当中去的？maven 是在执行 test 命令的时间 动态从本地仓库中去引入 junit jar 包，如果找不到就会去远程仓库下载，然后在引入。 默认远程仓库： 默认远程仓库 maven central 其配置在 maven-model-builder-3.2.1.jar\\org\\apache\\maven\\model\\pom-4.0.0.xml 位置 本地仓库位置： 本地仓库位置默认在 ~/.m2/respository 下 要修改${M2_HOME}/conf/settings.xml 来指定仓库目录 G:\\.m2\\repository maven 核心功能总结： maven 核心作用是编译、测试、打包。 根目录下的 pom.xml 文件设置分组 ID 与 artifactId。 maven 基于约定的方式从项目中获取源码与资源文件进行编译打包。 对于项目所依懒的组件与会本地仓库引用，如果本地仓库不存在则会从中央仓库下载。2.maven核心配置 概要： 项目依懒(内部、外部) 项目聚合与继承 项目构建配置项目依懒 项目依赖是指 maven 通过依赖传播、依赖优先原则、可选依赖、排除依赖、依赖范围等特性来管理项目ClassPath。 **2.1依赖传播特性: 我们的项目通常需要依赖第三方组件，而第三方组件又会依赖其它组件遇到这种情况 Maven 会将依赖网络中的所有节点都会加入 ClassPath 当中，这就是 Maven 的依赖传播特性。 * 举例演示 Spring MVC 的依赖网络 org.springframework spring-webmvc 4.0.4.RELEASE 在刚刚的演示当中，项目直接依赖了 spring-webmvc 叫直接依赖，而对 commons-logging 依赖是通过 webmvc 传递的所以叫间接依赖。 2.2依赖优先原则 基于依赖传播特性，导致整个依赖网络会很复杂，难免会出现相同组件不同版本的情况。Maven 此时会基于依赖优先原则选择其中一个版本。 第一原则：最短路径优先。 第二原则：相同路径下配置在前的优先。 * 第一原则演示 commons-logging commons-logging 1.2 上述例子中 commons-logging 通过 spring-webmvc 依赖了 1.1.3，而项目中直接依赖了 1.2，基于最短路径原则项目最终引入的是 1.2 版本。 * 第二原则演示： 步骤： 添加一个新工程 Project B 配置 Project B 依赖 spring-web.3.2.9.RELEASE 当前工程直接依赖 Project B 配置完之后，当前工程 project A 有两条路径可以依赖 spring-web,选择哪一条 就取决于 对 webmvc 和 Project B 的配置先后顺序。 Project A==> spring-webmvc.4.0.0.RELEASE ==>spring-web.4.0.0.RELEASE Project A==> Project B 1.0.SNAPSHOT ==>spring-web.3.2.9.RELEASE 注意：在同一 pom 文件，第二原则不在适应。如下配置，最终引用的是 1.2 版本，而不是配置在前面的 1.1.1 版本. commons-logging commons-logging 1.1.1 commons-logging commons-logging 1.2 2.3可选依赖 可选依赖表示这个依赖不是必须的。通过在 添 true 表示，默认是不可选的。可选依赖不会被传递。 演示可选依赖的效果。2.4排除依赖 即排除指定的间接依赖。通过配置 配置排除指定组件。 org.springframework spring-web 演示排除依赖2.5依赖范围 像 junit 这个组件 我们只有在运行测试用例的时候去要用到，这就没有必要在打包的时候把 junit.jar 包过构建进去，可以通过 Mave 的依赖范围配置来达到这种目的。maven 总共支持以下四种依赖范围： compile(默认): 编译范围，编译和打包都会依赖。 provided：提供范围，编译时依赖，但不会打包进去。如：servlet-api.jar runtime：运行时范围，打包时依赖，编译不会。如：mysql-connector-java.jar test：测试范围，编译运行测试用例依赖，不会打包进去。如：junit.jar system：表示由系统中 CLASSPATH 指定。编译时依赖，不会打包进去。配合 一起使用。示例：java.home 下的 tool.jar system 除了可以用于引入系统 classpath 中包，也可以用于引入系统非 maven 收录的第三方 Jar，做法是将第三方 Jar 放置在 项目的 lib 目录下，然后配置 相对路径，但因 system 不会打包进去所以需要配合 maven-dependency-plugin 插件配合使用。当然推荐大家还是通过 将第三方 Jar 手动 install 到仓库。 com.sun tools ${java.version} system true ${java.home}/../lib/tools.jar jsr jsr 3.5 system true ${basedir}/lib/jsr305.jar org.apache.maven.plugins maven-dependency-plugin 2.10 copy-dependencies compile copy-dependencies ${project.build.directory}/${project.build.finalName}/WEB-INF/lib system com.sun 手动加入本地仓库 mvn install:install-file -Dfile=abc_client_v1.20.jar -DgroupId=tuling -DartifactId=tuling-client -Dversion=1.20 -Dpackaging=jar 项目聚合与继承 1、聚合 是指将多个模块整合在一起，统一构建，避免一个一个的构建。聚合需要个父工程，然后使用 进行配置其中对应的是子工程的相对路径 tuling-client tuling-server * 演示聚合的配置 2、继承 继承是指子工程直接继承父工程 当中的属性、依赖、插件等配置，避免重复配置。 属性继承： 依赖继承： 插件继承： 上面的三个配置子工程都可以进行重写，重写之后以子工程的为准。 3、依赖管理 通过继承的特性，子工程是可以间接依赖父工程的依赖，但多个子工程依赖有时并不一至，这时就可以在父工程中加入 声明该功程需要的 JAR 包，然后在子工程中引入。 junit junit 4.12 junit junit 4、项目属性： 通过 配置 属性参数，可以简化配置。 ddd ${proName} maven 默认的属性 ${basedir} 项目根目录 ${version}表示项目版本; ${project.basedir}同${basedir}; ${project.version}表示项目版本,与${version}相同; ${project.build.directory} 构建目录，缺省为 target ${project.build.sourceEncoding}表示主源码的编码格式; ${project.build.sourceDirectory}表示主源码路径; ${project.build.finalName}表示输出文件名称; ${project.build.outputDirectory} 构建过程输出目录，缺省为 target/classes 项目构建配置 构建资源配置 编译插件 profile 指定编译环境 构建资源配置 基本配置示例： package ${basedir}/target2 ${artifactId}-${version} 说明： defaultGoal，执行构建时默认的 goal 或 phase，如 jar:jar 或者 package 等 directory，构建的结果所在的路径，默认为${basedir}/target 目录 finalName，构建的最终结果的名字，该名字可能在其他 plugin 中被改变 配置示例 src/main/java **/*.MF **/*.XML true src/main/resources **/* * true 说明： resources，build 过程中涉及的资源文件 targetPath，资源文件的目标路径 directory，资源文件的路径，默认位于${basedir}/src/main/resources/目录下 includes，一组文件名的匹配模式，被匹配的资源文件将被构建过程处理 excludes，一组文件名的匹配模式，被匹配的资源文件将被构建过程忽略。同时被 includes 和 excludes 匹配的资源文件，将被忽略。 filtering： 默认 false，true 表示 通过参数 对 资源文件中 的${key} 在编译时进行动态变更。替换源可 紧 -Dkey 和 pom 中的 值 或 中指定的 properties 文件。3.maven 生命周期 知识点概要： 生命周期的概念与意义 maven 三大生命周期与其对应的 phase(阶段) 生命周期与插件的关系 生命周期与默认插件的绑定3.1生命周期的概念与意义 在项目构建时通常会包含清理、编译、测试、打包、验证、部署，文档生成等步骤，maven 统一对其进行了整理抽像成三个生命周期 (lifecycle)及各自对应的多个阶段(phase)。这么做的意义是： 每个阶段都成为了一个扩展点，可以采用不同的方式来实现，提高了扩展性与灵活性。 规范统一了 maven 的执行路径。 在执行项目构建阶段时可以采用 jar 方式构建也可以采用 war 包方式构建提高了灵活性。我们可以通过命令 mvn ${phase name}直接触发指定阶段的执行如： 演示 phase 的执行 执行清理 phase mvn clean 执行 compile phase mvn compile 也可以同时执行 清理加编译 mvn clean comile 3.2maven 三大生命周期与其对应的 phase(阶段) maven 总共包含三大生生命周期 clean Lifecycle：清理生命周期，用于于清理项目 default Lifecycle：默认生命周期，用于编译、打包、测试、部署等 site Lifecycle站点文档生成，用于构建站点文档 |生命周期(lifecycle)|阶段(phase)|描述(describe)| |:----|:----|:----|:----|:----|:----| |clean Lifecycle|pre-clean|预清理| | |clean|清理| | |post-clean|清理之后| |default Lifecycle|validate|验证| | |initialize|初始化| | |generate-sources| | | |process-sources| | | |generate-resources| | | |process-resources| | | |compile|编译| | |process-classes| | | |generate-test-sources| | | |process-test-sources| | | |generate-test-resources| | | |process-test-resources| | | |test-compile|编译测试类| | |process-test-classes| | | |test|执行测试| | |prepare-package|构建前准备| | |package|打包构建| | |pre-integration-test| | | |integration-test| | | |post-integration-test| | | |verify|验证| | |install|上传到本地仓库| | |deploy|上传到远程仓库| |site Lifecycle|pre-site|准备构建站点| | |site|构建站点| | |post-site|构建站点之后| | |site-deploy|站点部署| 三大生命周期其相互独立执行，也可以合在一起执行。但 lifecycle 中的 phase 是有严格执行的顺序的，比如必须是先执行完 compile 才能执行 pakcage 动作，此外 phase 还有包含逻辑存在，即当你执行一个 phase 时 其前面的 phase 会自动执行。 演示 phase 执行 执行编译 mvn compile 执行打包就包含了编译指令的执行 mvn package 3.3生命周期与插件的关系 生命周期的 phase 组成了项目过建的完整过程，但这些过程具体由谁来实现呢？这就是插件，maven 的核心部分代码量其实很少，其大部分实现都是由插件来完成的。比如：test 阶段就是由maven-surefire-plugin 实现。在 pom.xml 中我们可以设置指定插件目标(gogal)与 phase 绑定，当项目构建到达指定 phase 时就会触发些插件 gogal 的执行。 一个插件有时会实现多个 phas 比如：maven-compiler-plugin插件分别实现了 compile 和 testCompile。 总结： 生命周期的 阶段 可以绑定具体的插件及目标 不同配置下同一个阶段可以对应多个插件和目标 phase==>plugin==>goal(功能) 3.4生命周期与插件的默认绑定 在我们的项目当中并没有配置 maven-compiler-plugin 插件,但当我们执行 compile 阶段时一样能够执行编译操作，原因是 maven 默认为指定阶段绑定了插件实现。列如下以下两个操作在一定程度上是等价的。 演示 # mvn compile 直接执行 compile 插件目标 mvn org.apache.maven.plugins:maven-compiler-plugin:3.1:compile lifecycle phase 的默认绑定见下表：。 clean Lifecycle 默认绑定 pre-clean clean post-clean org.apache.maven.plugins:maven-clean-plugin:2.5:clean site Lifecycle 默认绑定 pre-site site post-site site-deploy org.apache.maven.plugins:maven-site-plugin:3.3:site org.apache.maven.plugins:maven-site-plugin:3.3:deploy Default Lifecycle JAR 默认绑定 注：不同的项目类型 其默认绑定是不同的，这里只指列举了 packaging 为 jar 的默认绑定，全部的默认绑定参见：https://maven.apache.org/ref/3.5.4/maven-core/default-bindings.html#。 org.apache.maven.plugins:maven-resources-plugin:2.6:resources org.apache.maven.plugins:maven-compiler-plugin:3.1:compile org.apache.maven.plugins:maven-resources-plugin:2.6:testResources org.apache.maven.plugins:maven-compiler-plugin:3.1:testCompile org.apache.maven.plugins:maven-surefire-plugin:2.12.4:test org.apache.maven.plugins:maven-jar-plugin:2.4:jar org.apache.maven.plugins:maven-install-plugin:2.4:install org.apache.maven.plugins:maven-deploy-plugin:2.7:deploy 4.maven 自定义插件开发 知识点： 插件的相关概念 常用插件的使用 开发一个自定义插件4.1maven 插件相关概念 插件坐标定位： 插件与普通 jar 包一样包含 一组件坐标定位属性即： groupId、artifactId、version，当使用该插件时会从本地仓库中搜索，如果没有即从远程仓库下载 org.apache.maven.plugins maven-dependency-plugin 2.10 插件执行 execution： execution 配置包含一组指示插件如何执行的属性： id： 执行器命名 phase：在什么阶段执行？ goals：执行一组什么目标或功能？ configuration：执行目标所需的配置文件？ 演示一个插件的配置与使用 将插件依赖拷贝到指定目录 org.apache.maven.plugins maven-dependency-plugin 3.1.1 copy-dependencies package copy-dependencies ${project.build.directory}/alternateLocation false true true 4.2常用插件的使用 除了通过配置的方式使用插件以外，Maven 也提供了通过命令直接调用插件目标其命令格式如下： mvn groupId:artifactId:version:goal -D{参数名} 演示通过命令执行插件 展示 pom 的依赖关系树 mvn org.apache.maven.plugins:maven-dependency-plugin:2.10:tree 也可以直接简化版的命令，但前提必须是 maven 官方插件 mvn dependency:tree 其它常用插件： 查看 pom 文件的最终配置 mvn help:effective-pom 原型项目生成 archetype:generate 快速创建一个 WEB 程序 mvn archetype:generate -DgroupId=tuling -DartifactId=simple-webbapp -DarchetypeArtifactId=maven-archetype-webapp -DinteractiveMode=false 快速创建一个 java 项目 mvn archetype:generate -DgroupId=tuling -DartifactId=simple-java -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false 4.3开发一个自定义插件 实现步骤： * 创建 maven 插件项目 * 设定 packaging 为 maven-plugin * 添加插件依赖 * 编写插件实现逻辑 * 打包构建插件 插件 pom 配置 4.0.0 tuling 1.0.SNAPSHOT tuling-maven-plugin maven-plugin org.apache.maven maven-plugin-api 3.0 org.apache.maven.plugin-tools maven-plugin-annotations 3.4 插件实现类： package com.tuling.maven; import javafx.beans.DefaultProperty; import org.apache.maven.plugin.AbstractMojo; import org.apache.maven.plugin.MojoExecutionException; import org.apache.maven.plugin.MojoFailureException; import org.apache.maven.plugins.annotations.LifecyclePhase; import org.apache.maven.plugins.annotations.Mojo; import org.apache.maven.plugins.annotations.Parameter; /** @author Tommy Created by Tommy on 2018/8/8 **/ @Mojo(name = \"luban\") public class LubanPlugin extends AbstractMojo { @Parameter String sex; @Parameter String describe; public void execute() throws MojoExecutionException, MojoFailureException { getLog().info(String.format(\"luban sex=%s describe=%s\",sex,describe)); } } 5.nexus 私服搭建与核心功能 知识点概要: 私服的使用场景 nexus 下载安装 nexus 仓库介绍 本地远程仓库配置 发布项目至 nexus 远程仓库 关于 SNAPSHOT(快照)与 RELEASE(释放) 版本说明5.1私服使用场景 私服使用场景如下： 1、公司不能连接公网，可以用一个私服务来统一连接 2、公司内部 jar 组件的共享 5.2nexus 下载安装 nexus 下载地址： https://sonatype-download.global.ssl.fastly.net/nexus/oss/nexus-2.14.5-02-bundle.tar.gz 解压并设置环境变量 解压 shell>tar -zxvf nexus-2.14.5-02-bundle.tar.gz 在环境变量当中设置启动用户 shell> vim /etc/profile 添加 profile 文件。安全起见不建议使用 root 用户，如果使用其它用户需要加相应权限 export RUN_AS_USER=root 配置启动参数： shell> vi ${nexusBase}/conf/nexus.properties 端口号 application-port=9999 启动与停止 nexus 启动 shell> ${nexusBase}/bin/nexus start 停止 shell> ${nexusBase}/bin/nexus stop 登录 nexus 界面 地址：http://{ip}:9999/nexus/ 用户名:admin 密码：admin123 5.3nexus 仓库介绍 3rd party：第三方仓库 Apache Snapshots：apache 快照仓库 Central: maven 中央仓库 Releases：私有发布版本仓库 Snapshots：私有 快照版本仓库 5.4本地远程仓库配置 在 pom 中配置远程仓库 nexus-public my nexus repository http://192.168.0.147:9999/nexus/content/groups/public/ 或者在 settings.xml 文件中配置远程仓库镜像 效果一样，但作用范围广了 nexus-aliyun * Nexus aliyun http://192.168.0.147:9999/nexus/content/groups/public/ 5.5发布项目至 nexus 远程仓库 配置仓库地址 nexus-release nexus release http://192.168.0.147:9999/nexus/content/repositories/releases/ nexus-snapshot nexus snapshot http://192.168.0.147:9999/nexus/content/repositories/snapshots/ 设置 setting.xml 中设置 server nexus-snapshot deployment deployment123 nexus-release deployment deployment123 执行 deploy 命令 mvn deploy Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:47:10 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"automation/jenkins/":{"url":"automation/jenkins/","title":"Jenkins自动化","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"automation/k8s/":{"url":"automation/k8s/","title":"K8s服务编排","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"automation/k8s/kubeadm-install-one.html":{"url":"automation/k8s/kubeadm-install-one.html","title":"1.快速部署一个K8s集群","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1. 安装要求 2. 准备环境 3. 所有节点安装 Docker/kubeadm/kubelet 3.1 安装 Docker 3.2 添加阿里云 YUM 软件源 3.3 安装 kubeadm，kubelet 和 kubectl 4. 部署 Kubernetes Master 5. 加入 Kubernetes Node 6. 部署 CNI 网络插件 7. 测试 kubernetes 集群 kubeadm 是官方社区推出的一个用于快速部署 kubernetes 集群的工具。 这个工具能通过两条指令完成一个 kubernetes 集群的部署： # 创建一个 Master 节点 $ kubeadm init # 将一个 Node 节点加入到当前集群中 $ kubeadm join 1. 安装要求 在开始之前，部署 Kubernetes 集群机器需要满足以下几个条件： 一台或多台机器，操作系统 CentOS7.x-86_x64 硬件配置：2GB 或更多 RAM，2 个 CPU 或更多 CPU，硬盘 30GB 或更多 可以访问外网，需要拉取镜像，如果服务器不能上网，需要提前下载镜像并导入节点 禁止 swap 分区2. 准备环境 角色 IP master 192.168.62.132 node1 192.168.62.133 node2 192.168.62.134 # 关闭防火墙 systemctl stop firewalld systemctl disable firewalld # 关闭selinux sed -i 's/enforcing/disabled/' /etc/selinux/config # 永久 setenforce 0 # 临时 # 关闭swap swapoff -a # 临时 sed -ri 's/.*swap.*/#&/' /etc/fstab # 永久 # 根据规划设置主机名 hostnamectl set-hostname # 在master添加hosts cat >> /etc/hosts /etc/sysctl.d/k8s.conf 3. 所有节点安装 Docker/kubeadm/kubelet Kubernetes 默认 CRI（容器运行时）为 Docker，因此先安装 Docker。 3.1 安装 Docker $ wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo $ yum -y install docker-ce-18.06.1.ce-3.el7 $ systemctl enable docker && systemctl start docker $ docker --version Docker version 18.06.1-ce, build e68fc7a $ cat > /etc/docker/daemon.json 3.2 添加阿里云 YUM 软件源 $ cat > /etc/yum.repos.d/kubernetes.repo 3.3 安装 kubeadm，kubelet 和 kubectl 由于版本更新频繁，这里指定版本号部署： $ yum install -y kubelet-1.18.0 kubeadm-1.18.0 kubectl-1.18.0 $ systemctl enable kubelet 4. 部署 Kubernetes Master 在 192.168.62.132（Master）执行。 $ kubeadm init \\ --apiserver-advertise-address=192.168.62.132 \\ --image-repository registry.aliyuncs.com/google_containers \\ --kubernetes-version v1.18.0 \\ --service-cidr=10.96.0.0/12 \\ --pod-network-cidr=10.244.0.0/16 由于默认拉取镜像地址 k8s.gcr.io 国内无法访问，这里指定阿里云镜像仓库地址。 使用 kubectl 工具： mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config kubectl get nodes 5. 加入 Kubernetes Node 在 192.168.62.133/134（Node）执行。 向集群添加新节点，执行在 kubeadm init 输出的 kubeadm join 命令： $ kubeadm join 192.168.62.132:6443 --token dcxghk.5zgiiw6yk7qf5wol \\ --discovery-token-ca-cert-hash sha256:aad826e486e6728e176b14e803199a42805572ed8b266269d7581f1e244df33c 默认 token 有效期为 24 小时，当过期之后，该 token 就不可用了。这时就需要重新创建 token，操作如下： kubeadm token create --print-join-command 6. 部署 CNI 网络插件 wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 默认镜像地址无法访问，sed 命令修改为 docker hub 镜像仓库。 kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 或者用啊里的源 kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel-aliyun.yml kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE kube-flannel-ds-amd64-2pc95 1/1 Running 0 72s 7. 测试 kubernetes 集群 在 Kubernetes 集群中创建一个 pod，验证是否正常运行： $ kubectl create deployment nginx --image=nginx $ kubectl expose deployment nginx --port=80 --type=NodePort $ kubectl get pod,svc 访问地址：http://NodeIP:Port Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:40:07 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"automation/k8s/kubeadm-install-all.html":{"url":"automation/k8s/kubeadm-install-all.html","title":"2搭建高可用的K8s集群","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1. 安装要求 2. 准备环境 3. 所有 master 节点部署 keepalived 3.1 安装相关包和 keepalived 3.2 配置 master 节点 3.3 启动和检查 4. 部署 haproxy 4.1 安装 4.2 配置 4.3 启动和检查 5. 所有节点安装 Docker/kubeadm/kubelet 5.1 安装 Docker 5.2 添加阿里云 YUM 软件源 5.3 安装 kubeadm，kubelet 和 kubectl 6. 部署 Kubernetes Master 6.1 创建 kubeadm 配置文件 6.2 在 master1 节点执行 7.安装集群网络 8、master2 节点加入集群 8.1 复制密钥及相关文件 8.2 master2 加入集群 5. 加入 Kubernetes Node 7. 测试 kubernetes 集群 kubeadm 是官方社区推出的一个用于快速部署 kubernetes 集群的工具。 这个工具能通过两条指令完成一个 kubernetes 集群的部署： # 创建一个 Master 节点 $ kubeadm init # 将一个 Node 节点加入到当前集群中 $ kubeadm join 1. 安装要求 在开始之前，部署 Kubernetes 集群机器需要满足以下几个条件： 一台或多台机器，操作系统 CentOS7.x-86_x64 硬件配置：2GB 或更多 RAM，2 个 CPU 或更多 CPU，硬盘 30GB 或更多 可以访问外网，需要拉取镜像，如果服务器不能上网，需要提前下载镜像并导入节点 禁止 swap 分区2. 准备环境 角色 IP master1 192.168.44.155 master2 192.168.44.156 node1 192.168.44.157 VIP（虚拟 ip） 192.168.44.158 # 关闭防火墙 systemctl stop firewalld systemctl disable firewalld # 关闭 selinux sed -i 's/enforcing/disabled/' /etc/selinux/config # 永久 setenforce 0 # 临时 # 关闭 swap swapoff -a # 临时 sed -ri 's/.*swap.*/#&/' /etc/fstab # 永久 # 根据规划设置主机名 hostnamectl set-hostname # 在 master 添加 hosts cat >> /etc/hosts /etc/sysctl.d/k8s.conf 3. 所有 master 节点部署 keepalived 3.1 安装相关包和 keepalived yum install -y conntrack-tools libseccomp libtool-ltdl yum install -y keepalived 3.2 配置 master 节点 master1 节点配置 cat > /etc/keepalived/keepalived.conf master2 节点配置 cat > /etc/keepalived/keepalived.conf 3.3 启动和检查 在两台 master 节点都执行 # 启动 keepalived $ systemctl start keepalived.service 设置开机启动 $ systemctl enable keepalived.service # 查看启动状态 $ systemctl status keepalived.service 启动后查看 master1 的网卡信息 ip a s ens33 4. 部署 haproxy 4.1 安装 yum install -y haproxy 4.2 配置 两台 master 节点的配置均相同，配置中声明了后端代理的两个 master 节点服务器，指定了 haproxy 运行的端口为 16443 等，因此 16443 端口为集群的入口 cat > /etc/haproxy/haproxy.cfg 4.3 启动和检查 两台 master 都启动 # 设置开机启动 $ systemctl enable haproxy # 开启 haproxy $ systemctl start haproxy # 查看启动状态 $ systemctl status haproxy 检查端口 netstat -lntup|grep haproxy 5. 所有节点安装 Docker/kubeadm/kubelet Kubernetes 默认 CRI（容器运行时）为 Docker，因此先安装 Docker。 5.1 安装 Docker $ wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo $ yum -y install docker-ce-18.06.1.ce-3.el7 $ systemctl enable docker && systemctl start docker $ docker --version Docker version 18.06.1-ce, build e68fc7a $ cat > /etc/docker/daemon.json 5.2 添加阿里云 YUM 软件源 $ cat > /etc/yum.repos.d/kubernetes.repo 5.3 安装 kubeadm，kubelet 和 kubectl 由于版本更新频繁，这里指定版本号部署： $ yum install -y kubelet-1.16.3 kubeadm-1.16.3 kubectl-1.16.3 $ systemctl enable kubelet 6. 部署 Kubernetes Master 6.1 创建 kubeadm 配置文件 在具有 vip 的 master 上操作，这里为 master1 $ mkdir /usr/local/kubernetes/manifests -p $ cd /usr/local/kubernetes/manifests/ $ vi kubeadm-config.yaml apiServer: certSANs: - master1 - master2 - master.k8s.io - 192.168.44.158 - 192.168.44.155 - 192.168.44.156 - 127.0.0.1 extraArgs: authorization-mode: Node,RBAC timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta1 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controlPlaneEndpoint: \"master.k8s.io:16443\" controllerManager: {} dns: type: CoreDNS etcd: local: dataDir: /var/lib/etcd imageRepository: registry.aliyuncs.com/google_containers kind: ClusterConfiguration kubernetesVersion: v1.16.3 networking: dnsDomain: cluster.local podSubnet: 10.244.0.0/16 serviceSubnet: 10.1.0.0/16 scheduler: {} 6.2 在 master1 节点执行 $ kubeadm init --config kubeadm-config.yaml 按照提示配置环境变量，使用 kubectl 工具： mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config $ kubectl get nodes $ kubectl get pods -n kube-system 按照提示保存以下内容，一会要使用： kubeadm join master.k8s.io:16443 --token jv5z7n.3y1zi95p952y9p65 \\ --discovery-token-ca-cert-hash sha256:403bca185c2f3a4791685013499e7ce58f9848e2213e27194b75a2e3293d8812 \\ --control-plane 查看集群状态 kubectl get cs kubectl get pods -n kube-system 7.安装集群网络 从官方地址获取到 flannel 的 yaml，在 master1 上执行 mkdir flannel cd flannel wget -c https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 安装 flannel 网络 kubectl apply -f kube-flannel.yml 检查 kubectl get pods -n kube-system 8、master2 节点加入集群 8.1 复制密钥及相关文件 从 master1 复制密钥及相关文件到 master2 # ssh root@192.168.44.156 mkdir -p /etc/kubernetes/pki/etcd # scp /etc/kubernetes/admin.conf root@192.168.44.156:/etc/kubernetes # scp /etc/kubernetes/pki/{ca.*,sa.*,front-proxy-ca.*} root@192.168.44.156:/etc/kubernetes/pki # scp /etc/kubernetes/pki/etcd/ca.* root@192.168.44.156:/etc/kubernetes/pki/etcd 8.2 master2 加入集群 执行在 master1 上 init 后输出的 join 命令,需要带上参数--control-plane表示把 master 控制节点加入集群 kubeadm join master.k8s.io:16443 --token ckf7bs.30576l0okocepg8b --discovery-token-ca-cert-hash sha256:19afac8b11182f61073e254fb57b9f19ab4d798b70501036fc69ebef46094aba --control-plane 检查状态 kubectl get node kubectl get pods --all-namespaces 5. 加入 Kubernetes Node 在 node1 上执行 向集群添加新节点，执行在 kubeadm init 输出的 kubeadm join 命令： kubeadm join master.k8s.io:16443 --token ckf7bs.30576l0okocepg8b --discovery-token-ca-cert-hash sha256:19afac8b11182f61073e254fb57b9f19ab4d798b70501036fc69ebef46094aba 集群网络重新安装，因为添加了新的 node 节点 检查状态 kubectl get node kubectl get pods --all-namespaces 7. 测试 kubernetes 集群 在 Kubernetes 集群中创建一个 pod，验证是否正常运行： $ kubectl create deployment nginx --image=nginx $ kubectl expose deployment nginx --port=80 --type=NodePort $ kubectl get pod,svc 访问地址：http://NodeIP:Port Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:39:43 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"source/":{"url":"source/","title":"二、源码框架专题","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"source/mybatis/":{"url":"source/mybatis/","title":"mybatis","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"source/mybatis/base-use.html":{"url":"source/mybatis/base-use.html","title":"1.基本使用","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 预编译，防止sql注入(推荐) 三节课： 熟悉mybatis 源码分析 带徒手mybatis 传统JDBC的弊端： 总结： 1、jdbc底层没有用连接池、操作数据库需要频繁的创建和关联链接。消耗很大的资源 2、写原生的jdbc代码在java中，一旦我们要修改sql的话，java需要整体编译，不利于系统维护 3、使用PreparedStatement预编译的话对变量进行设置123数字，这样的序号不利于维护 4、返回result结果集也需要硬编码。 mybatis介绍： Mybatyis:Object relation mapping对象关系映射 快速开始mybatis（xml方式）： 1、maven org.mybatis mybatis x.x.x 2、mybatis-config.xml 3、Mapper.xml Mybatis**全局配置详解：** Mybatis之annotation： public interfaceUserMapper { @Select(\"select * from user where id=#{id}\") publicUser selectUser(Integer id); } Mybatis之注解和xml优缺点: Xml：增加xml文件、麻烦、条件不确定、容易出错，特殊字符转义 注释：不适合复杂sql，收集sql不方便，重新编译 Mybatis之#与**$区别： 参数标记符号 预编译，防止sql注入(推荐) $可以sql注入，代替作用 Mybatis之parameterType与parameterMap区别： 通过parameterType指定输入参数的类型，类型可以是简单类型、hashmap、pojo的包装类型 Mybatis之resultType与resultMap区别： 使用resultType进行输出映射，只有查询出来的列名和pojo中的属性名一致，该列才可以映射成功。 mybatis中使用resultMap完成高级输出结果映射。 Mybatis之plugin： com.jiagouedu.mybatis.plugin.SqlPrintInterceptor 自定义**reusltMap**（逆向工程中讲）： Mybatis**逆向工程：** 什么是逆向工程**:** MyBatis的一个主要的特点就是需要程序员自己编写sql，那么如果表太多的话，难免会很麻烦，所以mybatis官方提供了一个逆向工程，可以针对单表自动生成mybatis执行所需要的代码（包括mapper.xml、mapper.java、po..）。一般在开发中，常用的逆向工程方式是通过数据库的表生成代码 1、引入jar plugin> groupId>org.mybatis.generatorgroupId> artifactId>mybatis-generator-maven-pluginartifactId> version>1.3.7version> dependencies> dependency> groupId>mysqlgroupId> artifactId>mysql-connector-javaartifactId> version>${mysql-connector-java.version}version> dependency> dependencies> plugin> 2、配置mybatis-genrtator.xml 3、mybatis-generator:generate XMLMAPPER|ANNOTATEDMAPPER 去掉注释： 生成注解方式**:** http://www.mybatis.org/generator/configreference/javaClientGenerator.html Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:38:28 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"source/mybatis/analysis.html":{"url":"source/mybatis/analysis.html","title":"2源码分析","keywords":"","body":"mybatis**核心概念** Configuration**、SqlSessionFactory、Session、Executor、MappedStatement、StatementHandler、**ResultSetHandler 整体认识**mybatis**源码包 Debug**一行行看代码** 宏观 微观 画图 Mybatis**之**Configuration org.apache.ibatis.builder.xml.XMLConfigBuilder#parseConfiguration Properties**文件解析：** org.apache.ibatis.builder.xml.XMLConfigBuilder#propertiesElement Setting 文件解析： org.apache.ibatis.builder.xml.XMLConfigBuilder#settingsElement environments 文件解析： org.apache.ibatis.builder.xml.XMLConfigBuilder#environmentsElement Mybatis**之**Session Mybatis**之**Mapper :Type interface com.jiagouedu.UserMapper is not known to the MapperRegistry. Mybatis**之**Sql txt.txt文件 Mybatis**之**Executor 其实是不干事情的 org.apache.ibatis.executor.statement.StatementHandler org.apache.ibatis.executor.statement.PreparedStatementHandler org.apache.ibatis.executor.resultset.ResultSetHandler org.apache.ibatis.executor.resultset.DefaultResultSetHandler Mybatis**之cache：** 每当我们使用MyBatis开启一次和数据库的会话，MyBatis会创建出一个SqlSession对象表示一次数据库会话。 在对数据库的一次会话中，我们有可能会反复地执行完全相同的查询语句，如果不采取一些措施的话，每一次查询都会查询一次数据库,而我们在极短的时间内做了完全相同的查询，那么它们的结果极有可能完全相同，由于查询一次数据库的代价很大，这有可能造成很大的资源浪费。 为了解决这一问题，减少资源的浪费，MyBatis会在表示会话的SqlSession对象中建立一个简单的缓存，将每次查询到的结果结果缓存起来，当下次查询的时候，如果判断先前有个完全一样的查询，会直接从缓存中直接将结果取出，返回给用户，不需要再进行一次数据库查询了。 cache key: id +sql+limit+offsetxxx 作用域：一级缓存session 全局：二级缓存 今天源码分析涉及到的模式是（学员整理）： 1.sqlSessionFactory工厂 2.build建造者 getInstance ，Cache 单例 委派 （单词忘了）装饰 5.InterceptorChain责任链 6Proxy代理 7.ExecuteCommand命令 8.doQuery模板 Mybatis**作业** annotations中的@select源码加载执行 提交地址： http://git.jiagouedu.com/java-vip/tuling-mybatis/issues/new 要求：流程图+找出代码调用流程 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:59:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"source/mybatis/realization.html":{"url":"source/mybatis/realization.html","title":"3.代码实现","keywords":"","body":"mybatis**核心概念** Configuration**、SqlSessionFactory、Session、Executor、MappedStatement、StatementHandler、**ResultSetHandler 整体认识**mybatis**源码包 Mybatis**集成**Spring MyBatis-Spring会帮助你将MyBatis代码无缝地整合到Spring中。 使用这个类库中的类, Spring将会加载必要的MyBatis工厂类和session类。 这个类库也提供一个简单的方式来注入MyBatis数据映射器和SqlSession到业务层的bean中。 而且它也会处理事务,翻译MyBatis的异常到Spring的DataAccessException异常(数据访问异常,译者注)中。最终,它并 不会依赖于MyBatis,Spring或MyBatis-Spring来构建应用程序代码。 配置 dependency> groupId>org.mybatisgroupId> artifactId>mybatis-springartifactId> version>1.3.0version> dependency> beanid**=\"sqlSessionFactory\"** class**=\"org.mybatis.spring.SqlSessionFactoryBean\">****property**![图片](https://uploader.shimo.im/f/pSPfc8T1af0mddbt.png!thumbnail?fileGuid=FuyY885vp30f4yOb)**name****=\"dataSource\"**![图片](https://uploader.shimo.im/f/m2fhbQQDwTzsScM7.png!thumbnail?fileGuid=FuyY885vp30f4yOb)**ref****=\"dataSource\"**![图片](https://uploader.shimo.im/f/jT1upyO3MtgrjwYf.png!thumbnail?fileGuid=FuyY885vp30f4yOb)/ value=\"classpath:mybatis/UserMapper.xml\" />-->*bean> **bean**![图片](https://uploader.shimo.im/f/eRqgEnFaJFJPYx1s.png!thumbnail?fileGuid=FuyY885vp30f4yOb)**class****=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"****propertyname**=\"basePackage\"value**=\"com.jiagouedu.mapper\"**/> bean> org.mybatis.spring.SqlSessionTemplate等同于SqlSession 通用**mapper&mybatis-plus** Mybatis增强 反射+泛型技术 通用CRUD 徒手实现**mybatis** 不健全，方便我们去了解mybatis 也就是以后你的简历上可以写你熟悉mybatis源码 不用必做的作业、mybatis的1：N N:N 熟悉mybatis、mybatis源码分析、徒手实现mybatis Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:59:34 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"source/spring/":{"url":"source/spring/","title":"spring","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"source/spring/ioc.html":{"url":"source/spring/ioc.html","title":"1.IOC容器设计理念与源码解读","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 知识点： 1、Ioc 理论概要 2、实体 Bean 的构建 3、bean 的基本特性 4、依赖注入 二、IOC 设计原理与实现 1、源码学习目标： 2、Bean 的构建过程 3、BeanFactory 与 ApplicationContext 区别 课程概要： IOC 核心知识点回顾 IOC 设计原理 一、IOC 核心理论回顾 知识点： Ioc 理念概要 实体 Bean 的创建 Bean 的基本特性 依赖注入 set 方法注入 构造方法注入 自动注入(byName、byType） 依赖检测1、Ioc 理论概要 在 JAVA 的世界中，一个对象 A 怎么才能调用对象 B？通常有以下几种方法。 类别 描述 时间点 外部传入 构造方法传入 属性设置传入 设置对象状态时 运行时做为参数传入 调用时 内部创建 属性中直接创建 创建引用对象时 初始化方法创建 创建引用对象时 运行时动态创建 调用时 上表可以看到， 引用一个对象可以在不同地点（其它引用者）、不同时间由不同的方法完成。如果 B 只是一个非常简单的对象 如直接 new B()，怎样都不会觉得复杂，比如你从来不会觉得创建一个 String 是一个件复杂的事情。但如果 B 是一个有着复杂依赖的 Service 对象，这时在不同时机引用 B 将会变得很复杂。 无时无刻都要维护 B 的复杂依赖关系，试想 B 对象如果项目中有上百过，系统复杂度将会成陪数增加。 IOC 容器 的出现正是为解决这一问题，其可以将对象的构建方式统一，并且自动维护对象的依赖关系，从而降低系统的实现成本。前提是需要提前对目标对象基于 XML 进行声明。 2、实体 Bean 的构建 基于 Class 构建 构造方法构建 静态工厂方法创建 FactoryBean 创建 1、基于 ClassName 构建 这是最常规的方法，其原理是在 spring 底层会基于 class 属性 通过反射进行构建。 2、构造方法构建 如果需要基于参数进行构建，就采用构造方法构建，其对应属性如下： name:构造方法参数变量名称 type:参数类型 index:参数索引，从 0 开始 value:参数值，spring 会自动转换成参数实际类型值 ref:引用容串的其它对象 3、静态工厂方法创建 如果你正在对一个对象进行 A/B 测试 ，就可以采用静态工厂方法的方式创建，其于策略创建不同的对像或填充不同的属性。 该模式下必须创建一个静态工厂方法，并且方法返回该实例，spring 会调用该静态方法创建对象。 public static HelloSpring build(String type) { if (type.equals(\"A\")) { return new HelloSpring(\"luban\", \"man\"); } else if (type.equals(\"B\")) { return new HelloSpring(\"diaocan\", \"woman\"); } else { throw new IllegalArgumentException(\"type must A or B\"); } } 4、FactoryBean 创建 指定一个 Bean 工厂来创建对象，对象构建初始化 完全交给该工厂来实现。配置 Bean 时指定该工厂类的类名。 public class LubanFactoryBean implements FactoryBean { @Override public Object getObject() throws Exception { return new HelloSpring(); } @Override public Class getObjectType() { return HelloSpring.class; } @Override public boolean isSingleton() { return false; } } 3、bean 的基本特性 作用范围 生命周期 装载机制 a、作用范围 很多时候 Bean 对象是无状态的 ，而有些又是有状态的 无状态的对象我们采用单例即可，而有状态则必须是多例的模式，通过 scope 即可创建 scope=“prototype” scope=“singleton” scope=“prototype 如果一个 Bean 设置成 prototype 我们可以 通过 BeanFactoryAware 获取 BeanFactory 对象即可每次获取的都是新对像。 b、生命周期 Bean 对象的创建、初始化、销毁即是 Bean 的生命周期。通过 init-method、destroy-method 属性可以分别指定期构建方法与初始方法。 如果觉得麻烦，可以让 Bean 去实现 InitializingBean.afterPropertiesSet()、DisposableBean.destroy()方法。分别对应 初始和销毁方法 c、加载机制 指示 Bean 在何时进行加载。设置 lazy-init 即可，其值如下： true: 懒加载，即延迟加载 false:非懒加载，容器启动时即创建对象 default:默认，采用 default-lazy-init 中指定值，如果 default-lazy-init 没指定就是 false 什么时候使用懒加载？ 懒加载会容器启动的更快，而非懒加载可以容器启动时更快的发现程序当中的错误 ，选择哪一个就看追求的是启动速度，还是希望更早的发现错误，一般我们会选 择后者。 4、依赖注入 试想 IOC 中如果没有依赖注入，那这个框架就只能帮助我们构建一些简单的 Bean，而之前所说的复杂 Bean 的构建问题将无法解决，spring 这个框架不可能会像现在这样成功。spring 中 ioc 如何依赖注入呢。有以下几种方式： set 方法注入 构造方法注入 自动注入(byName、byType） 方法注入(lookup-method) 2、set 方法注入 3、构造方法注入 4、自动注入（byName\\byType\\constructor) byName：基于变量名与 bean 名称相同作为依据插入 byType：基于变量类别与 bean 名称作 constructor：基于 IOC 中 bean 与构造方法进行匹配（语义模糊，不推荐） 5、依赖方法注入(lookup-method) 当一个单例的 Bean，依赖于一个多例的 Bean，用常规方法只会被注入一次，如果每次都想要获取一个全新实例就可以采用 lookup-method 方法来实现。 #编写一个抽像类 public abstract class MethodInject { public void handlerRequest() { // 通过对该抽像方法的调用获取最新实例 getFine(); } # 编写一个抽像方法 public abstract FineSpring getFine(); } // 设定抽像方法实现 该操作的原理是基于动态代理技术，重新生成一个继承至目标类，然后重写抽像方法到达注入目的。 前面说所单例 Bean 依赖多例 Bean 这种情况也可以通过实现 ApplicationContextAware、BeanFactoryAware 接口来获取 BeanFactory 实例，从而可以直接调用 getBean 方法获取新实例，推荐使用该方法，相比 lookup-method 语义逻辑更清楚一些。 二、IOC 设计原理与实现 1、源码学习的目标 2、Bean 的构建过程 3、BeanFactory 与 ApplicationContext 区别 1、源码学习目标： 不要为了读书而读书，同样不要为了阅读源码而读源码。没有目的一头扎进源码的黑森林当中很快就迷路了。到时就不是我们读源码了，而是源码‘毒’我们。毕竟一个框架是由专业团队，历经 N 次版本迭代的产物，我们不能指望像读一本书的方式去阅读它。 所以必须在读源码之前找到目标。是什么呢？ 大家会想，读源码的目标不就是为了学习吗？这种目标太过抽像，目标无法验证。通常我们会设定两类型目标：一种是对源码进行改造，比如添加修改某些功能，在实现这种目标的过程当中自然就会慢慢熟悉了解该项目。但然这个难度较大，耗费的成本也大。另一个做法是 自己提出一些问题，阅读源码就是为这些问题寻找答案。以下就是我们要一起在源码中寻找答案的问题： Bean 工厂是如何生产 Bean 的？ Bean 的依赖关系是由谁解来决的？ Bean 工厂和应用上文的区别？2、Bean 的构建过程 spring.xml 文件中保存了我们对Bean 的描述配置，BeanFactory 会读取这些配置然后生成对应的 Bean。这是我们对 ioc 原理的一般理解。但在深入一些我们会有更多的问题？ 配置信息最后是谁 JAVA 中哪个对象承载的？ 这些承载对象是谁业读取 XML 文件并装载的？ 这些承载对象又是保存在哪里？ BeanDefinition （Bean 定义） ioc 实现中 我们在 xml 中描述的 Bean 信息最后 都将保存至 BeanDefinition （定义）对象中，其中 xml bean 与 BeanDefinition 程一对一的关系。 由此可见，xml bean 中设置的属性最后都会体现在BeanDefinition中。如: XML-bean BeanDefinition class beanClassName scope scope lazy-init lazyInit constructor-arg ConstructorArgument property MutablePropertyValues factory-method factoryMethodName destroy-method AbstractBeanDefinition.destroyMethodName init-method AbstractBeanDefinition.initMethodName autowire AbstractBeanDefinition.autowireMode id name [ ] 演示查看 BeanDefinition 属性结构 BeanDefinitionRegistry（Bean 注册器） 在上表中我们并没有看到 xml bean 中的 id 和 name 属性没有体现在定义中，原因是 ID 其作为当前 Bean 的存储 key 注册到了 BeanDefinitionRegistry 注册器中。name 作为别名 key 注册到了 AliasRegistry 注册中心。其最后都是指向其对应的 BeanDefinition。 [ ] 演示查看 BeanDefinitionRegistry 属性结构 BeanDefinitionReader（Bean 定义读取） 至此我们学习了 BeanDefinition 中存储了 Xml Bean 信息，而 BeanDefinitionRegister 基于 ID 和 name 保存了 Bean 的定义。接下要学习的是从 xml Bean 到 BeanDefinition 然后在注册至 BeanDefinitionRegister 整个过程。 上图中可以看出 Bean 的定义是由 BeanDefinitionReader 从 xml 中读取配置并构建出 BeanDefinitionReader,然后在基于别名注册到 BeanDefinitionRegister 中。 [ ] 查看 BeanDefinitionReader 结构 方法说明： loadBeanDefinitions(Resource resource) 基于资源装载 Bean 定义并注册至注册器 int loadBeanDefinitions(String location) 基于资源路径装载 Bean 定义并注册至注册器 BeanDefinitionRegistry getRegistry() 获取注册器 ResourceLoader getResourceLoader() 获取资源装载器 [ ] 基于示例演示 BeanDefinitionReader 装载过程//创建一个简单注册器 BeanDefinitionRegistry register = new SimpleBeanDefinitionRegistry(); //创建 bean 定义读取器 BeanDefinitionReader reader = new XmlBeanDefinitionReader(register); // 创建资源读取器 DefaultResourceLoader resourceLoader = new DefaultResourceLoader(); // 获取资源 Resource xmlResource = resourceLoader.getResource(\"spring.xml\"); // 装载 Bean 的定义 reader.loadBeanDefinitions(xmlResource); // 打印构建的 Bean 名称 System.out.println(Arrays.toString(register.getBeanDefinitionNames()); Beanfactory(bean 工厂) 有了 Bean 的定义就相当于有了产品的配方，接下来就是要把这个配方送到工厂进行生产了。在 ioc 当中 Bean 的构建是由 BeanFactory 负责的。其结构如下： 方法说明： getBean(String) 基于 ID 或 name 获取一个 Bean T getBean(Class requiredType) 基于 Bean 的类别获取一个 Bean（如果出现多个该类的实例，将会报错。但可以指定 primary=“true” 调整优先级来解决该错误 ） Object getBean(String name, Object... args) 基于名称获取一个 Bean，并覆盖默认的构造参数 boolean isTypeMatch(String name, Class typeToMatch) 指定 Bean 与指定 Class 是否匹配 以上方法中重点要关注 getBean，当用户调用 getBean 的时候就会触发 Bean 的创建动作，其是如何创建的呢？ [ ] 演示基本 BeanFactory 获取一个 Bean#创建 Bean 堆栈 // 其反射实例化 Bean java.lang.reflect.Constructor.newInstance(Unknown Source:-1) BeanUtils.instantiateClass() //基于实例化策略 实例化 Bean SimpleInstantiationStrategy.instantiate() AbstractAutowireCapableBeanFactory.instantiateBean() // 执行 Bean 的实例化方法 AbstractAutowireCapableBeanFactory.createBeanInstance() AbstractAutowireCapableBeanFactory.doCreateBean() // 执行 Bean 的创建 AbstractAutowireCapableBeanFactory.createBean() // 缓存中没有，调用指定 Bean 工厂创建 Bean AbstractBeanFactory$1.getObject() // 从单例注册中心获取 Bean 缓存 DefaultSingletonBeanRegistry.getSingleton() AbstractBeanFactory.doGetBean() // 获取 Bean AbstractBeanFactory.getBean() // 调用的客户类 com.tuling.spring.BeanFactoryExample.main() Bean 创建时序图： 从调用过程可以总结出以下几点： 调用 BeanFactory.getBean() 会触发 Bean 的实例化。 DefaultSingletonBeanRegistry 中缓存了单例 Bean Bean 的创建与初始化是由AbstractAutowireCapableBeanFactory完成的。3、BeanFactory 与 ApplicationContext 区别 BeanFactory 看下去可以去做 IOC 当中的大部分事情，为什么还要去定义一个 ApplicationContext 呢？ ApplicationContext 结构图 从图中可以看到 ApplicationContext 它由 BeanFactory 接口派生而来，因而提供了 BeanFactory 所有的功能。除此之外 context 包还提供了以下的功能： MessageSource, 提供国际化的消息访问 资源访问，如 URL 和文件 事件传播，实现了 ApplicationListener 接口的 bean 载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的 web 层 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:13:00 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"source/spring/aop.html":{"url":"source/spring/aop.html","title":"2.AOP事物底层原理分析","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、数据库的事物的基本特性 查看mysql 的默认隔离级别 二、Spring 对事物的支持与使用 1、spring 事物相关API说明 2、声明示事物 3、事物传播机制 三、aop 事物底层实现原理 概要： 数据库的事物的基本特性 Sring 对事物的支持与使用 aop 事物底层实现原理一、数据库的事物的基本特性 事物是区分文件存储系统与Nosql数据库重要特性之一，其存在的意义是为了保证即使在并发情况下也能正确的执行crud操作。怎样才算是正确的呢？这时提出了事物需要保证的四个特性即ACID： A: 原子性(atomicity) 事物中各项操作，要么全做要么全不做，任何一项操作的失败都会导致整个事物的失败； C: 一致性(consistency) 事物结束后系统状态是一致的； I: 隔离性(isolation) 并发执行的事物彼此无法看到对方的中间状态； D: 持久性(durability) 事物完成后所做的改动都会被持久化，即使发生灾难性的失败。 在高并发的情况下，要完全保证其ACID特性是非常困难的，除非把所有的事物串行化执行，但带来的负面的影响将是性能大打折扣。很多时候我们有些业务对事物的要求是不一样的，所以数据库中设计了四种隔离级别，供用户基于业务进行选择。 隔离级别 脏读（Dirty Read） 不可重复读（NonRepeatable Read） 幻读（Phantom Read） 未提交读（Read uncommitted） 可能 可能 可能 已提交读（Read committed） 不可能 可能 可能 可重复读（Repeatable read） 不可能 不可能 可能 可串行化（SERIALIZABLE） 不可能 不可能 不可能 脏读 : 一个事物读取到另一事物未提交的更新数据 不可重复读 : 在同一事物中,多次读取同一数据返回的结果有所不同, 换句话说, 后续读取可以读到另一事物已提交的更新数据. 相反, “可重复读”在同一事物中多次读取数据时, 能够保证所读数据一样, 也就是后续读取不能读到另一事物已提交的更新数据。 幻读 : 查询表中一条数据如果不存在就插入一条，并发的时候却发现，里面居然有两条相同的数据。这就幻读的问题。 代码演示脏读、不可重复读、幻读的情况。 演示源码：http://git.jiagouedu.com/java-vip/tuling-spring/src/master/tuling-spring-transaction 数据库默认隔离级别： Oracle中默认级别是 Read committed mysql 中默认级别 Repeatable read。另外要注意的是mysql 执行一条查询语句默认是一个独立的事物，所以看上去效果跟Read committed一样。 查看mysql 的默认隔离级别 SELECT @@tx_isolation 二、Spring 对事物的支持与使用 要点： spring 事物相关API说明 声明式事物的使用 事物传播机制1、spring 事物相关API说明 spring 事物是在数据库事物的基础上进行封装扩展 其主要特性如下： 1. 支持原有的数据事物的隔离级别 2. 加入了事物传播的概念 提供多个事物的和并或隔离的功能 3. 提供声明式事物，让业务代码与事物分离，事物变得更易用。 怎么样去使用Spring事物呢？spring 提供了三个接口供使用事物。分别是： TransactionDefinition 事物定义 PlatformTransactionManager 事物管理 TransactionStatus 事物运行时状态 接口结构图： API说明： 基于API实现事物 public class SpringTransactionExample { private static String url = \"jdbc:mysql://192.168.0.147:3306/luban2\"; private static String user = \"root\"; private static String password = \"123456\"; public static Connection openConnection() throws ClassNotFoundException, SQLException { Class.forName(\"com.mysql.jdbc.Driver\"); Connection conn = DriverManager.getConnection(\"jdbc:mysql://192.168.0.147:3306/luban2\", \"root\", \"123456\"); return conn; } public static void main(String[] args) { final DataSource ds = new DriverManagerDataSource(url, user, password); final TransactionTemplate template = new TransactionTemplate(); template.setTransactionManager(new DataSourceTransactionManager(ds)); template.execute(new TransactionCallback() { @Override public Object doInTransaction(TransactionStatus status) { Connection conn = DataSourceUtils.getConnection(ds); Object savePoint = null; try { { // 插入 PreparedStatement prepare = conn. prepareStatement(\"insert INTO account (accountName,user,money) VALUES (?,?,?)\"); prepare.setString(1, \"111\"); prepare.setString(2, \"aaaa\"); prepare.setInt(3, 10000); prepare.executeUpdate(); } // 设置保存点 savePoint = status.createSavepoint(); { // 插入 PreparedStatement prepare = conn. prepareStatement(\"insert INTO account (accountName,user,money) VALUES (?,?,?)\"); prepare.setString(1, \"222\"); prepare.setString(2, \"bbb\"); prepare.setInt(3, 10000); prepare.executeUpdate(); } { // 更新 PreparedStatement prepare = conn. prepareStatement(\"UPDATE account SET money= money+1 where user=?\"); prepare.setString(1, \"asdflkjaf\"); Assert.isTrue(prepare.executeUpdate() > 0, \"\"); } } catch (SQLException e) { e.printStackTrace(); } catch (Exception e) { System.out.println(\"更新失败\"); if (savePoint != null) { status.rollbackToSavepoint(savePoint); } else { status.setRollbackOnly(); } } return null; } }); } } 2、声明示事物 我们前面是通过调用API来实现对事物的控制，这非常的繁琐，与直接操作JDBC事物并没有太多的改善，所以Spring提出了声明示事物，使我们对事物的操作变得非常简单，甚至不需要关心它。 演示声明示事物使用 spring-tx.xml 配置spring.xml 编写服务类 @Transactional public void addAccount(String name, int initMenoy) { String accountid = new SimpleDateFormat(\"yyyyMMddhhmmss\").format(new Date()); jdbcTemplate.update(\"insert INTO account (accountName,user,money) VALUES (?,?,?)\", accountid, name, initMenoy); // 人为报错 int i = 1 / 0; } 演示添加 @Transactional 注解和不添加注解的情况。3、事物传播机制 类别 事物传播类型 说明 支持当前事物 PROPAGATION_REQUIRED（必须的） 如果当前没有事物，就新建一个事物，如果已经存在一个事物中，加入到这个事物中。这是最常见的选择。 PROPAGATION_SUPPORTS（支持） 支持当前事物，如果当前没有事物，就以非事物方式执行。 PROPAGATION_MANDATORY（强制） 使用当前的事物，如果当前没有事物，就抛出异常。 不支持当前事物 PROPAGATION_REQUIRES_NEW(隔离) 新建事物，如果当前存在事物，把当前事物挂起。 PROPAGATION_NOT_SUPPORTED(不支持) 以非事物方式执行操作，如果当前存在事物，就把当前事物挂起。 PROPAGATION_NEVER(强制非事物) 以非事物方式执行，如果当前存在事物，则抛出异常。 套事物 PROPAGATION_NESTED（嵌套事物） 如果当前存在事物，则在嵌套事物内执行。如果当前没有事物，则执行与PROPAGATION_REQUIRED类似的操作。 常用事物传播机制： PROPAGATION_REQUIRED， 这个也是默认的传播机制； PROPAGATION_NOT_SUPPORTED 可以用于发送提示消息，站内信、短信、邮件提示等。不属于并且不应当影响主体业务逻辑，即使发送失败也不应该对主体业务逻辑回滚。 PROPAGATION_REQUIRES_NEW 总是新启一个事物，这个传播机制适用于不受父方法事物影响的操作，比如某些业务场景下需要记录业务日志，用于异步反查，那么不管主体业务逻辑是否完成，日志都需要记录下来，不能因为主体业务逻辑报错而丢失日志； 演示常用事物的传播机制 用例1: 创建用户时初始化一个帐户，表结构和服务类如下。 表结构 服务类 功能描述 user UserSerivce 创建用户，并添加帐户 account AccountService 添加帐户 UserSerivce.createUser(name) 实现代码 @Transactional public void createUser(String name) { // 新增用户基本信息 jdbcTemplate.update(\"INSERT INTO `user` (name) VALUES(?)\", name); //调用accountService添加帐户 accountService.addAccount(name, 10000); ｝ AccountService.addAccount(name,initMoney) 实现代码（方法的最后有一个异常） @Transactional(propagation = Propagation.REQUIRED) public void addAccount(String name, int initMoney) { String accountid = new SimpleDateFormat(\"yyyyMMddhhmmss\").format(new Date()); jdbcTemplate.update(\"insert INTO account (accountName,user,money) VALUES (?,?,?)\", accountid, name, initMenoy); // 出现分母为零的异常 int i = 1 / 0; } 实验预测一： createUser addAccount(异常) 预测结果 场景一 无事物 required user （成功） Account（不成功）正确 场景二 required 无事物 user （不成功） Account（不成功）正确 场景三 required not_supported user （不成功） Account（成功）正确 场景四 required required_new user （不成功） Account（不成功）正确 场景五 required(异常移至createUser方法未尾) required_new user （不成功） Account（成功）正确 场景六 required(异常移至createUser方法未尾)（addAccount 方法称至当前类） required_new user （不成功） Account（不成功） 三、aop 事物底层实现原理 讲事物原理之前我们先来做一个实验，当场景五的环境改变，把addAccount 方法移至UserService 类下，其它配置和代码不变： @Override @Transactional public void createUser(String name) { jdbcTemplate.update(\"INSERT INTO `user` (name) VALUES(?)\", name); addAccount(name, 10000); // 人为报错 int i = 1 / 0; } @Transactional(propagation = Propagation.REQUIRES_NEW) public void addAccount(String name, int initMoney) { String accountid = new SimpleDateFormat(\"yyyyMMddhhmmss\").format(new Date()); jdbcTemplate.update(\"insert INTO account (accountName,user,money) VALUES (?,?,?)\", accountid, name, initMoney); } 演示新场景 经过演示我们发现得出的结果与场景五并不 一至，required_new 没有起到其对应的作用。原因在于spring 声明示事物使用动态代理实现，而当调用同一个类的方法时，是会不会走代理逻辑的，自然事物的配置也会失效。 通过一个动态代理的实现来模拟这种场景 UserSerivce proxyUserSerivce = (UserSerivce) Proxy.newProxyInstance(LubanTransaction.class.getClassLoader(), new Class[]{UserSerivce.class}, new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { try { System.out.println(\"开启事物:\"+method.getName()); return method.invoke(userSerivce, args); } finally { System.out.println(\"关闭事物:\"+method.getName()); } } }); proxyUserSerivce.createUser(\"luban\"); 当我们调用createUser 方法时 仅打印了 createUser 的事物开启、关闭，并没有打印addAccount 方法的事物开启、关闭，由此可见addAccount 的事物配置是失效的。 如果业务当中上真有这种场景该如何实现呢？在spring xml中配置 暴露proxy 对象，然后在代码中用AopContext.currentProxy() 就可以获当前代理对象 // 基于代理对象调用创建帐户，事物的配置又生效了 ((UserSerivce) AopContext.currentProxy()).addAccount(name, 10000); Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:14:27 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"source/spring/mvc.html":{"url":"source/spring/mvc.html","title":"3.Spring mvc原理深度解析","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、spring mvc 设计思想与体系结构组成 1、回顾servlet 与jsp 执行过程 2、spring mvc 执行流程： 3、spring mvc 体系结构 二、mvc 执行流程解析 要点： 2、HandlerMapping 详解 3、HandlerAdapter详解 4、ViewResolver 与View 详解 5、HandlerExceptionResolver详解 6、HandlerInterceptor 详解 三、注解配置 课程概要 spring mvc 设计思想与体系结构组成 mvc 执行流程解析 注解配置 一、spring mvc 设计思想与体系结构组成 jsp 执行过程回顾 spring mvc执行流程解析 mvc 体系结构1、回顾servlet 与jsp 执行过程 流程说明： 请求Servlet 处理业务逻辑 设置业务Model forward jsp Servlet jsp Servlet 解析封装html 返回 提问：这个是一个MVC应用场景吗？ spring mvc本质上还是在使用Servlet处理，并在其基础上进行了封装简化了开发流程，提高易用性、并使用程序逻辑结构变得更清晰 基于注解的URL映谢 http表单参数转换 全局统一异常处理 拦截器的实现2、spring mvc 执行流程： 整个过程是如何实现的？ dispatchServlet 如何找到对应的Control？ 如何执行调用Control 当中的业务方法？ 回答这些问题之前我们先来认识一下spring mvc 体系结构 3、spring mvc 体系结构 HandlerMapping'hændlə 'mæpɪŋ url与控制器的映谢 HandlerAdapter'hændlə ə'dæptə 控制器执行适配器 ViewResolvervjuː riː'zɒlvə 视图仓库 view 具体解析视图 HandlerExceptionResolver'hændlə ɪk'sepʃ(ə)n riː'zɒlvə 异常捕捕捉器 HandlerInterceptor'hændlə ɪntə'septə 拦截器 配置一个spring mvc 示例演示 验证上述流程 - [ ] 创建一个Controller 类 - [ ] 配置DispatchServlet - [ ] 创建spring-mvc.xml 文件 - [ ] 配置SimpleUrlHandlerMapping - [ ] 配置InternalResourceViewResolver 体系结构UML 二、mvc 执行流程解析 要点： mvc 具体执行流程 HandlerMapping详解 HandlerAdapter 详解 ViewResolver与View详解 HandlerExceptionResolver详解 HandlerInterceptor 详解 mvc 各组件执行流程 2、HandlerMapping 详解 其为mvc 中url路径与Control对像的映射，DispatcherServlet 就是基于此组件来寻找对应的Control，如果找不到就会报Not Found mapping 的异常。 HandlerMapping 接口方法 HandlerMapping 接口结构 目前主流的三种mapping 如下： BeanNameUrlHandlerMapping: 基于ioc name 中已 \"/\" 开头的Bean时行 注册至映谢. SimpleUrlHandlerMapping：基于手动配置 url 与control 映谢 RequestMappingHandlerMapping：基于@RequestMapping注解配置对应映谢 [ ] 演示基于 BeanNameUrlHandlerMapping 配置映谢。 编写mvc 文件 // beanname control 控制器 public class BeanNameControl implements HttpRequestHandler { @Override public void handleRequest(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException { request.getRequestDispatcher(\"/WEB-INF/page/userView.jsp\").forward(request, response); } } 当IOC 中实例化这些类之后 DispatcherServlet 就会通过org.springframework.web.servlet.DispatcherServlet#getHandler() 方法基于request查找对应Handler。 但找到对应的Handler之后我们发现他是一个Object类型，并没有实现特定接口。如何调用Handler呢？ 3、HandlerAdapter详解 这里spring mvc 采用适配器模式来适配调用指定Handler，根据Handler的不同种类采用不同的Adapter,其Handler与 HandlerAdapter 对应关系如下: Handler类别 对应适配器 描述 Controller SimpleControllerHandlerAdapter 标准控制器，返回ModelAndView HttpRequestHandler HttpRequestHandlerAdapter 业务自行处理 请求，不需要通过modelAndView 转到视图 Servlet SimpleServletHandlerAdapter 基于标准的servlet 处理 HandlerMethod RequestMappingHandlerAdapter 基于@requestMapping对应方法处理 HandlerAdapter 接口方法 HandlerAdapter 接口结构图 [ ] 演示基于Servlet 处理 SimpleServletHandlerAdapter // 标准Servlet public class HelloServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { resp.getWriter().println(\"hello luban \"); } } 上述例子中当IOC 中实例化这些类之后 DispatcherServlet 就会通过 org.springframework.web.servlet.DispatcherServlet#getHandlerAdapter() 方法查找对应handler的适配器 ，如果找不到就会报 No adapter for handler 。 4、ViewResolver 与View 详解 找到应的Adapter 之后就会基于适配器调用业务处理，处理完之后业务方会返回一个ModelAndView ，在去查找对应的视图进行处理。其在org.springframework.web.servlet.DispatcherServlet#resolveViewName() 中遍历 viewResolvers 列表查找，如果找不到就会报一个 Could not resolve view with name 异常。 在下一步就是基于ViewResolver.resolveViewName() 获取对应View来解析生成Html并返回 。对应VIEW结构如下： 至此整个正向流程就已经走完了，如果此时程序处理异常 MVC 该如何处理呢？ 5、HandlerExceptionResolver详解 该组件用于指示 当出现异常时 mvc 该如何处理。 dispatcherServlet 会调用org.springframework.web.servlet.DispatcherServlet#processHandlerException() 方法，遍历 handlerExceptionResolvers 处理异常，处理完成之后返回errorView 跳转到异常视图。 - [ ] 演示自定义异常捕捉 public class SimpleExceptionHandle implements HandlerExceptionResolver { @Override public ModelAndView resolveException(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) { return new ModelAndView(\"error\"); } } HandlerExceptionResolver 结构 除了上述组件之外 spring 中还引入了 我Interceptor 拦截器 机制，类似于Filter。 6、HandlerInterceptor 详解 [ ] 演示HandlerInterceptorpublic class SimpleHandlerInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { System.out.println(\"preHandle\"); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { System.out.println(\"postHandle\"); } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { System.out.println(\"afterCompletion\"); } } 其实现机制是基于 HandlerExecutionChain 分别在 doDispatch 方法中执行以下方法： preHandle ：业务处理前执行 postHandle：业务处理后（异常则不执行） afterCompletion：视图处理后 具体逻辑源码参见：org.springframework.web.servlet.DispatcherServlet#doDispatch 方法。 三、注解配置 [ ] 演示基于注解配置mvc mapping // 注解方法 @RequestMapping(\"/hello.do\") public ModelAndView hello() { ModelAndView mv = new ModelAndView(\"userView\"); mv.addObject(\"name\", \"luban\"); return mv; } 提问 为什么基于 配置就能实现mvc 的整个配置了，之前所提到的 handlerMapping 、与handlerAdapter 组件都不适用了？ 只要查看以类的源就可以知晓其中原因： [ ] 认识 NamespaceHandler 接口 [ ] 查看 MvcNamespaceHandler [ ] 查看AnnotationDrivenBeanDefinitionParser 结论： 在 对应的解析器，自动向ioc 里面注册了两个BeanDefinition。分别是：RequestMappingHandlerMapping与BeanNameUrlHandlerMapping Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:15:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"concurrent/":{"url":"concurrent/","title":"三、并发编程专题","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"concurrent/executor.html":{"url":"concurrent/executor.html","title":"1.Executor线程池详解","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.什么是线程 2.线程实现的三种方式 3.线程的生命周期&状态 4.线程的执行顺序 5.线程与线程池对比 6.线程池体系介绍 7.线程池源码分析 1.什么是线程 线程是进程的一个实体，是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源 (如程序计数器，一组寄存器和栈 )，但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。 2.线程实现的三种方式 Runnable、 Thread、 Callable 总结 最后再来看看它们三个之间的总结。 实现 Runnable接口相比继承 Thread类有如下优势 1）可以避免由于 Java的单继承特性而带来的局限 2）增强程序的健壮性，代码能够被多个线程共享，代码与数据是独立的 3）线程池只能放入实现 Runable或 Callable类线程，不能直接放入继承 Thread的类 实现 Runnable接口和实现 Callable接口的区别 1）Runnable是自从 java1.1就有了，而 Callable是 1.5之后才加上去的 2）实现 Callable接口的任务线程能返回执行结果，而实现 Runnable接口的任务线程不能返回结果 3 Callable接口的 call()方法允许抛出异 常，而 Runnable接口的 run()方法的异常只能在内部消化，不能继 续上抛 4）加入线程池运行 Runnable使用 ExecutorService的 execute方法， Callable使用 submit方法 注： Callable接口支持返回执行结果，此时需要调用 FutureTask.get()方法实现，此方法会阻塞主线程直到获 取返回结果，当不调用此方法时，主线程不会阻塞 3.线程的生命周期&状态 4.线程的执行顺序 5.线程与线程池对比 6.线程池体系介绍 7.线程池源码分析 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:46:25 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"concurrent/JMM&Lock&Tools.html":{"url":"concurrent/JMM&Lock&Tools.html","title":"2.JMM&Lock&Tools详解","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.JMM 内存模型 2.Volatile 可见性 3.Synchronized 同步 4.Lock 锁 5.ReentrantLock 6.ReentrantReadWriteLock 7.AbstractQueuedSynchronizer 8.CountDownLatch Semaphore 要点： JMM Volatile Synchronized Lock ReentrantLock ReentrantReadWriteLock AbstractQueuedSynchronizer CountDownLatch Semaphore1.JMM 内存模型 2.Volatile 可见性 3.Synchronized 同步 4.Lock 锁 5.ReentrantLock 6.ReentrantReadWriteLock 7.AbstractQueuedSynchronizer 8.CountDownLatch Semaphore Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:46:37 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"concurrent/atomic&collections.html":{"url":"concurrent/atomic&collections.html","title":"3.atomic&collections详解","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.Atomic体系介绍 2.CAS源码分析 3.CAS的ABA问题 4.HashMap 5.HashTable 6.ConcurrenthHashMap 7.ArrayList 8.CopyOnWriteArrayList Copyright &copy ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 要点： Atomic体系介绍 CAS源码分析 CAS的ABA问题 HashMap HashTable ConcurrenthHashMap ArrayList CopyOnWriteArrayList1.Atomic体系介绍 2.CAS源码分析 3.CAS的ABA问题 4.HashMap 5.HashTable 6.ConcurrenthHashMap 7.ArrayList 8.CopyOnWriteArrayList Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:46:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"concurrent/Fork-join.html":{"url":"concurrent/Fork-join.html","title":"4.Fork-join框架原理解析","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.Fork-join编程介绍 2.Fork-join原理分析 3.Fork-join最佳实践 要点： Fork-join编程介绍 Fork-join原理分析 Fork-join最佳实践1.Fork-join编程介绍 2.Fork-join原理分析 3.Fork-join最佳实践 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:46:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"concurrent/BlockingQueue.html":{"url":"concurrent/BlockingQueue.html","title":"5.BlockingQueue框架原理解析","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.基本概念介绍/DIY 并发/阻塞队列 2.JDK 阻塞队列实战与原理分析 2.1ArrayBlockingQueue 2.2LinkedBlockingQueue 2.3LinkedTransferQueue 2.4LinkedBlockingDeque 2.5SynchronousQueue 2.6PriorityBlockingQueue 2.7DelayQueue 3.高性能并发队列讨论 要点： 基本概念介绍/DIY 并发/阻塞队列 JDK 阻塞队列实战与原理分析 高性能并发队列讨论1.基本概念介绍/DIY 并发/阻塞队列 2.JDK 阻塞队列实战与原理分析 2.1ArrayBlockingQueue 基于数组结构的有界阻塞队列（长度不可变） 2.2LinkedBlockingQueue 基于链表结构的有界阻塞队列（默认容量 Integer.MAX_VALUE） 2.3LinkedTransferQueue 基于链表结构的无界阻塞/传递队列 2.4LinkedBlockingDeque 基于链表结构的有界阻塞双端队列（默认容量 Integer.MAX_VALUE） 2.5SynchronousQueue 不存储元素的阻塞/传递队列 2.6PriorityBlockingQueue 支持优先级排序的无界阻塞队列 2.7DelayQueue 支持延时获取元素的无界阻塞队列 3.高性能并发队列讨论 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:47:08 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/":{"url":"performance/","title":"四、性能调优专题","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/jvm/":{"url":"performance/jvm/","title":"jvm","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/jvm/base.html":{"url":"performance/jvm/base.html","title":"1.JVM整体结构介绍","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.JVM整体架构 2.JVM类加载器 2.1类加载过程 2.2类加载器种类（4种） 2.3类加载机制 3.JVM内存结构 4.JVM执行引擎 1.JVM整体架构 JVM由三个主要的子系统构成 类加载器子系统 运行时数据区（内存结构） 执行引擎 2.JVM类加载器 2.1类加载过程 类加载：类加载器将class文件加载到虚拟机的内存 加载：在硬盘上查找并通过IO读入字节码文件 连接：执行校验、准备、解析（可选）步骤 校验：校验字节码文件的正确性 准备：给类的静态变量分配内存，并赋予默认值 解析：类装载器装入类所引用的其他所有类 初始化：对类的静态变量初始化为指定的值，执行静态代码块 2.2类加载器种类（4种） 启动类加载器：负责加载JRE的核心类库，如jre目标下的rt.jar,charsets.jar等 扩展类加载器：负责加载JRE扩展目录ext中JAR类包 系统类加载器：负责加载ClassPath路径下的类包 用户自定义加载器：负责加载用户自定义路径下的类包2.3类加载机制 全盘负责委托机制：当一个ClassLoader加载一个类时，除非显示的使用另一个ClassLoader，该类所依赖和引用的类也由这个ClassLoader载入 双亲委派机制：指先委托父类加载器寻找目标类，在找不到的情况下在自己的路径中查找并载入目标类 3.JVM内存结构 4.JVM执行引擎 执行引擎：读取运行时数据区的Java字节码并逐个执行 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:48:55 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/jvm/view.html":{"url":"performance/jvm/view.html","title":"2.JVM性能调优监控工具","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.Jinfo 2.Jstat 3.Jmap 4.Jstack 5.远程连接jvisualvm 6.jstack找出占用cpu最高的堆栈信息 1.**Jinfo** 查看正在运行的Java应用程序的扩展参数 查看jvm的参数 查看java系统参数 2.Jstat jstat命令可以查看堆内存各部分的使用量，以及加载类的数量。命令的格式如下： jstat [-命令选项] [vmid] [间隔时间/毫秒] [查询次数] 注意：使用的jdk版本是jdk8. 类加载统计： Loaded：加载class的数量 Bytes：所占用空间大小 Unloaded：未加载数量 Bytes:未加载占用空间 Time：时间 垃圾回收统计 S0C：第一个幸存区的大小 S1C：第二个幸存区的大小 S0U：第一个幸存区的使用大小 S1U：第二个幸存区的使用大小 EC：伊甸园区的大小 EU：伊甸园区的使用大小 OC：老年代大小 OU：老年代使用大小 MC：方法区大小(元空间) MU：方法区使用大小 CCSC:压缩类空间大小 CCSU:压缩类空间使用大小 YGC：年轻代垃圾回收次数 YGCT：年轻代垃圾回收消耗时间 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 堆内存统计 NGCMN：新生代最小容量 NGCMX：新生代最大容量 NGC：当前新生代容量 S0C：第一个幸存区大小 S1C：第二个幸存区的大小 EC：伊甸园区的大小 OGCMN：老年代最小容量 OGCMX：老年代最大容量 OGC：当前老年代大小 OC:当前老年代大小 MCMN:最小元数据容量 MCMX：最大元数据容量 MC：当前元数据空间大小 CCSMN：最小压缩类空间大小 CCSMX：最大压缩类空间大小 CCSC：当前压缩类空间大小 YGC：年轻代gc次数 FGC：老年代GC次数 新生代垃圾回收统计 S0C：第一个幸存区的大小 S1C：第二个幸存区的大小 S0U：第一个幸存区的使用大小 S1U：第二个幸存区的使用大小 TT:对象在新生代存活的次数 MTT:对象在新生代存活的最大次数 DSS:期望的幸存区大小 EC：伊甸园区的大小 EU：伊甸园区的使用大小 YGC：年轻代垃圾回收次数 YGCT：年轻代垃圾回收消耗时间 新生代内存统计 NGCMN：新生代最小容量 NGCMX：新生代最大容量 NGC：当前新生代容量 S0CMX：最大幸存1区大小 S0C：当前幸存1区大小 S1CMX：最大幸存2区大小 S1C：当前幸存2区大小 ECMX：最大伊甸园区大小 EC：当前伊甸园区大小 YGC：年轻代垃圾回收次数 FGC：老年代回收次数 老年代垃圾回收统计 MC：方法区大小 MU：方法区使用大小 CCSC:压缩类空间大小 CCSU:压缩类空间使用大小 OC：老年代大小 OU：老年代使用大小 YGC：年轻代垃圾回收次数 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 老年代内存统计 OGCMN：老年代最小容量 OGCMX：老年代最大容量 OGC：当前老年代大小 OC：老年代大小 YGC：年轻代垃圾回收次数 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 元数据空间统计 MCMN:最小元数据容量 MCMX：最大元数据容量 MC：当前元数据空间大小 CCSMN：最小压缩类空间大小 CCSMX：最大压缩类空间大小 CCSC：当前压缩类空间大小 YGC：年轻代垃圾回收次数 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 S0：幸存1区当前使用比例 S1：幸存2区当前使用比例 E：伊甸园区使用比例 O：老年代使用比例 M：元数据区使用比例 CCS：压缩使用比例 YGC：年轻代垃圾回收次数 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 3.**Jmap** 此命令可以用来查看内存信息。 实例个数以及占用内存大小 打开log.txt，文件内容如下： num：序号 instances：实例数量 bytes：占用空间大小 class name：类名称 堆信息 堆内存dump 也可以设置内存溢出自动导出dump文件(内存很大的时候，可能会导不出来) -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./ （路径） 可以用jvisualvm命令工具导入该dump文件分析 4.**Jstack** 用jstack查找死锁，见如下示例，也可以用jvisualvm查看死锁 ** 5.**远程连接jvisualvm** 启动普通的jar程序JMX端口配置： java -Dcom.sun.management.jmxremote.port=12345 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -jar foo.jar tomcat的JMX配置 JAVA_OPTS=-Dcom.sun.management.jmxremote.port=8999 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false jvisualvm远程连接服务需要在远程服务器上配置host(连接ip 主机名)，并且要关闭防火墙 6.**jstack找出占用cpu最高的堆栈信息** 1，使用命令top -p ，显示你的java进程的内存情况，pid是你的java进程号，比如4977 2，按H，获取每个线程的内存情况 3，找到内存和cpu占用最高的线程tid，比如4977 4，转为十六进制得到 0x1371 ,此为线程id的十六进制表示 5，执行 jstack 4977|grep -A 10 1371，得到线程堆栈信息中1371这个线程所在行的后面10行 6，查看对应的堆栈信息找出可能存在问题的代码 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:49:07 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/jvm/gc.html":{"url":"performance/jvm/gc.html","title":"3.JVM垃圾回收与调优","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.JVM内存分配与回收 1.1 对象优先在Eden区分配 1.2 大对象直接进入老年代 1.3 长期存活的对象将进入老年代 2.如何判断对象可以被回收 2.1 引用计数法 2.2 可达性分析算法 2.3 finalize()方法最终判定对象是否存活 2.4 如何判断一个常量是废弃常量 2.5 如何判断一个类是无用的类 3.垃圾收集算法 3.1 标记-清除算法 3.2 复制算法 3.3 标记-整理算法 3.4 分代收集算法 4.垃圾收集器 4.1 Serial收集器 4.2 ParNew收集器 4.3 Parallel Scavenge收集器 4.4.Serial Old收集器 4.5 Parallel Old收集器 4.6 CMS收集器(-XX:+UseConcMarkSweepGC(主要是old区使用)) 4.7 G1收集器(-XX:+UseG1GC) 5. 如何选择垃圾收集器 6. 实战调优 6.1JVM调优主要就是调整下面两个指标 6.2GC调优步骤 6.3G1调优相关 1.JVM内存分配与回收 1.1 对象优先在Eden区分配 大多数情况下，对象在新生代中 Eden 区分配。当 Eden 区没有足够空间进行分配时，虚拟机将发起一次Minor GC。我们来进行实际测试一下。 在测试之前我们先来看看Minor Gc和Full GC 有什么不同呢？ 新生代GC（Minor GC）:指发生新生代的的垃圾收集动作，Minor GC非常频繁，回收速度一般也比较快。 老年代GC（Major GC/Full GC）:指发生在老年代的GC，出现了Major GC经常会伴随至少一次的Minor GC（并非绝对），Major GC的速度一般会比Minor GC的慢10倍以上。 测试： 通过以下方式运行： 添加的参数：**-XX:+PrintGCDetails** 运行结果： 从上图我们可以看出eden区内存几乎已经被分配完全（即使程序什么也不做，新生代也会使用至少2000多k内存）。假如我们再为allocation2分配内存会出现什么情况呢？ 简单解释一下为什么会出现这种情况：因为给allocation2分配内存的时候eden区内存几乎已经被分配完了，我们刚刚讲了当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC.GC期间虚拟机又发现allocation1无法存入Survior空间，所以只好通过分配担保机制把新生代的对象提前转移到老年代中去，老年代上的空间足够存放allocation1，所以不会出现Full GC。执行Minor GC后，后面分配的对象如果能够存在eden区的话，还是会在eden区分配内存。可以执行如下代码验证： 1.2 大对象直接进入老年代 大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。 为什么要这样呢？ 为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率。 1.3 长期存活的对象将进入老年代 既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别那些对象应放在新生代，那些对象应放在老年代中。为了做到这一点，虚拟机给每个对象一个对象年龄（Age）计数器。 如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为1.对象在 Survivor 中每熬过一次 MinorGC,年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数-XX:MaxTenuringThreshold来设置。 2.如何判断对象可以被回收 堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断那些对象已经死亡（即不能再被任何途径使用的对象）。 2.1 引用计数法 给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加1；当引用失效，计数器就减1；任何时候计数器为0的对象就是不可能再被使用的。 这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。所谓对象之间的相互引用问题，如下面代码所示：除了对象objA 和 objB 相互引用着对方之外，这两个对象之间再无任何引用。但是他们因为互相引用对方，导致它们的引用计数器都不为0，于是引用计数算法无法通知 GC 回收器回收他们。 2.2 可达性分析算法 这个算法的基本思想就是通过一系列的称为“GC Roots”的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。 GC Roots根节点：类加载器、Thread、虚拟机栈的本地变量表、static成员、常量引用、本地方法栈的变量等等 2.3 finalize()方法最终判定对象是否存活 即使在可达性分析算法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历再次标记过程。 标记的前提是对象在进行可达性分析后发现没有与GC Roots相连接的引用链。 1. 第一次标记并进行一次筛选。 筛选的条件是此对象是否有必要执行finalize()方法。 当对象没有覆盖finalize方法，或者finzlize方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”，对象被回收。 2. 第二次标记 如果这个对象被判定为有必要执行finalize（）方法，那么这个对象将会被放置在一个名为：F-Queue的队列之中，并在稍后由一条虚拟机自动建立的、低优先级的Finalizer线程去执行。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束。这样做的原因是，如果一个对象finalize（）方法中执行缓慢，或者发生死循环（更极端的情况），将很可能会导致F-Queue队列中的其他对象永久处于等待状态，甚至导致整个内存回收系统崩溃。 finalize（）方法是对象脱逃死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模标记，如果对象要在finalize（）中成功拯救自己----只要重新与引用链上的任何的一个对象建立关联即可，譬如把自己赋值给某个类变量或对象的成员变量，那在第二次标记时它将移除出“即将回收”的集合。如果对象这时候还没逃脱，那基本上它就真的被回收了。 见示例程序： 2.4 如何判断一个常量是废弃常量 运行时常量池主要回收的是废弃的常量。那么，我们如何判断一个常量是废弃常量呢？ 假如在常量池中存在字符串 \"abc\"，如果当前没有任何String对象引用该字符串常量的话，就说明常量 \"abc\" 就是废弃常量，如果这时发生内存回收的话而且有必要的话，\"abc\" 就会被系统清理出常量池。 2.5 如何判断一个类是无用的类 方法区主要回收的是无用的类，那么如何判断一个类是无用的类的呢？ 判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面3个条件才能算是“无用的类”： 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述3个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。 3.垃圾收集算法 3.1 标记-清除算法 算法分为“标记”和“清除”阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。它是最基础的收集算法，效率也很高，但是会带来两个明显的问题： 效率问题 空间问题（标记清除后会产生大量不连续的碎片） 3.2 复制算法 为了解决效率问题，“复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。 3.3 标记-整理算法 根据老年代的特点特出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一段移动，然后直接清理掉端边界以外的内存。 3.4 分代收集算法 当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将java堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。 比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。 4.垃圾收集器 如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。 虽然我们对各个收集器进行比较，但并非为了挑选出一个最好的收集器。因为直到现在为止还没有最好的垃圾收集器出现，更加没有万能的垃圾收集器，我们能做的就是根据具体应用场景选择适合自己的垃圾收集器。试想一下：如果有一种四海之内、任何场景下都适用的完美收集器存在，那么我们的HotSpot虚拟机就不会实现那么多不同的垃圾收集器了。 4.1 Serial收集器 Serial（串行）收集器收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的“单线程”的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（\"Stop The World\"），直到它收集结束。 新生代采用复制算法，老年代采用标记-整理算法。 虚拟机的设计者们当然知道Stop The World带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续）。 但是Serial收集器有没有优于其他垃圾收集器的地方呢？当然有，它简单而高效（与其他收集器的单线程相比）。Serial收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。 4.2 ParNew收集器 ParNew收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和Serial收集器完全一样。 新生代采用复制算法，老年代采用标记-整理算法。 它是许多运行在Server模式下的虚拟机的首要选择，除了Serial收集器外，只有它能与CMS收集器（真正意义上的并发收集器，后面会介绍到）配合工作。 并行和并发概念补充： 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。适合科学计算、后台处理等弱交互场景。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个CPU上。适合Web应用。4.3 Parallel Scavenge收集器 Parallel Scavenge 收集器类似于ParNew 收集器，是Server 模式（内存大于2G，2个cpu）下的默认收集器，那么它有什么特别之处呢？ Parallel Scavenge收集器关注点是吞吐量（高效率的利用CPU）。CMS等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是CPU中用于运行用户代码的时间与CPU总消耗时间的比值。Parallel Scavenge收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解的话，可以选择把内存管理优化交给虚拟机去完成也是一个不错的选择。 新生代采用复制算法，老年代采用标记-整理算法。 4.4.Serial Old收集器 Serial收集器的老年代版本，它同样是一个单线程收集器。它主要有两大用途：一种用途是在JDK1.5以及以前的版本中与Parallel Scavenge收集器搭配使用，另一种用途是作为CMS收集器的后备方案。 4.5 Parallel Old收集器 Parallel Scavenge收集器的老年代版本。使用多线程和“标记-整理”算法。在注重吞吐量以及CPU资源的场合，都可以优先考虑 Parallel Scavenge收集器和Parallel Old收集器。 4.6 CMS收集器(-XX:+UseConcMarkSweepGC(**主要是old区使用**)) CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它而非常符合在注重用户体验的应用上使用，它是HotSpot虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。 从名字中的Mark Sweep这两个词可以看出，CMS收集器是一种“标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤： 初始标记：暂停所有的其他线程(STW)，并记录下直接与root相连的对象，速度很快 ； 并发标记：同时开启GC和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以GC线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。 重新标记：重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短 并发清除：开启用户线程，同时GC线程开始对未标记的区域做清扫。 从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：并发收集、低停顿。但是它有下面三个明显的缺点： 对CPU资源敏感（会和服务抢资源）； 无法处理浮动垃圾(在java业务程序线程与垃圾收集线程并发执行过程中又产生的垃圾，这种浮动垃圾只能等到下一次gc再清理了)； 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。 CMS的相关参数 -XX:+UseConcMarkSweepGC 启用cms -XX:ConcGCThreads:并发的GC线程数（并非STW时间，而是和服务一起执行的线程数） -XX:+UseCMSCompactAtFullCollection:FullGC之后做压缩（减少碎片） -XX:CMSFullGCsBeforeCompaction:多少次FullGC之后压缩一次（因压缩非常的消耗时间，所以不能每次FullGC都做） -XX:CMSInitiatingOccupancyFraction:触发FulGC条件（默认是92） -XX:+UseCMSInitiatingOccupancyOnly:是否动态调节 -XX:+CMSScavengeBeforeRemark:FullGC之前先做YGC（一般这个参数是打开的） -XX:+CMSClassUnloadingEnabled:启用回收Perm区（jdk1.7及以前）4.7 G1收集器(-XX:+UseG1GC) G1 (Garbage-First)是一款面向服务器的垃圾收集器,**主要针对配备多颗处理器及大容量内存的机器**. 以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征. G1将Java堆划分为多个大小相等的独立区域（Region），虽保留新生代和老年代的概念，但不再是物理隔阂了，它们都是（可以不连续）Region的集合。 分配大对象（直接进Humongous区，专门存放短期巨型对象，不用直接进老年代，避免Full GC的大量开销）不会因为无法找到连续空间而提前触发下一次GC。 被视为JDK1.7中HotSpot虚拟机的一个重要进化特征。它具备以下特点： 并行与并发：G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿时间。部分其他收集器原本需要停顿Java线程来执行GC动作，G1收集器仍然可以通过并发的方式让java程序继续执行。 分代收集：虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但是还是保留了分代的概念。 空间整合：与CMS的“标记--清理”算法不同，G1从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。 可预测的停顿：这是G1相对于CMS的另一个大优势，降低停顿时间是G1 和 CMS 共同的关注点，但G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内完成垃圾收集。 G1收集器的运作大致分为以下几个步骤： 初始标记（initial mark，STW）：在此阶段，G1 GC 对根进行标记。该阶段与常规的 (STW) 年轻代垃圾回收密切相关。 并发标记（Concurrent Marking）：G1 GC 在整个堆中查找可访问的（存活的）对象。 最终标记（Remark，STW）：该阶段是 STW 回收，帮助完成标记周期。 筛选回收（Cleanup，STW）：筛选回收阶段首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。 G1收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的Region(这也就是它的名字Garbage-First的由来)。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了GF收集器在有限时间内可以尽可能高的收集效率。 G1垃圾收集分类 YoungGC 新对象进入Eden区 存活对象拷贝到Survivor区 存活时间达到年龄阈值时，对象晋升到Old区 MixedGC 不是FullGC，回收所有的Young和部分Old(根据期望的GC停顿时间确定old区垃圾收集的优先顺序) global concurrent marking （全局并发标记） Initial marking phase:标记GC Root，STW Root region scanning phase：标记存活Region Concurrent marking phase：标记存活的对象 Remark phase :重新标记,STW Cleanup phase:部分STW 相关参数 G1MixedGCLiveThresholdPercent Old区的region被回收的时候的存活对象占比 G1MixedGCCountTarget：一次global concurrent marking之后，最多执行Mixed GC的次数 G1OldCSetRegionThresholdPercent 一次Mixed GC中能被选入CSet的最多old区的region数量 触发的时机 InitiatingHeapOccupancyPercent:堆占有率达到这个值则触发global concurrent marking，默认45% G1HeapWastePercent:在global concurrent marking结束之后，可以知道区有多少空间要被回收，在每次YGC之后和再次发生Mixed GC之前，会检查垃圾占比是否达到了此参数，只有达到了，下次才会发生Mixed GC5. 如何选择垃圾收集器 优先调整堆的大小让服务器自己来选择 如果内存小于100M，使用串行收集器 如果是单核，并且没有停顿时间的要求，串行或JVM自己选择 如果允许停顿时间超过1秒，选择并行或者JVM自己选 如果响应时间最重要，并且不能超过1秒，使用并发收集器 下图有连线的可以搭配使用，官方推荐使用G1，因为性能高 6. 实战调优 6.1**JVM调优主要就是调整下面两个指标** 停顿时间**: 垃圾收集器做垃圾回收中断应用执行的时间。-XX:MaxGCPauseMillis** 吞吐量**：花在垃圾收集的时间和花在应用时间的占比 -XX:GCTimeRatio=,垃圾收集时间占比：1/(1+n)** 6.2**GC调优步骤** 打印GC日志 -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -Xloggc:./gc.log 分析日志得到关键性指标 分析GC原因，调优JVM参数 1、Parallel Scavenge收集器(默认) 分析parallel-gc.log 第一次调优，设置Metaspace大小：增大元空间大小-XX:MetaspaceSize=64M -XX:MaxMetaspaceSize=64M 第二次调优，添加吞吐量和停顿时间参数：-XX:MaxGCPauseMillis=100 -XX:GCTimeRatio=99 第三次调优，修改动态扩容增量：-XX:YoungGenerationSizeIncrement=30 2、配置CMS收集器 -XX:+UseConcMarkSweepGC 分析cms-gc.log 3、配置G1收集器 -XX:+UseG1GC 分析g1-gc.log 查看发生MixedGC的阈值：jinfo -flag InitiatingHeapOccupancyPercent 进程id 分析工具：gceasy，GCViewer 6.3**G1调优相关** 常用参数 -XX:+UseG1GC 开启G1 -XX:G1HeapRegionSize=n,region的大小，1-32M，2048个 -XX:MaxGCPauseMillis=200 最大停顿时间 -XX:G1NewSizePercent -XX:G1MaxNewSizePercent -XX:G1ReservePercent=10 保留防止to space溢出（） -XX:ParallelGCThreads=n SWT线程数（停止应用程序） -XX:ConcGCThreads=n 并发线程数=1/4*并行 最佳实践 年轻代大小：避免使用-Xmn、-XX:NewRatio等显示设置Young区大小，会覆盖暂停时间目标（常用参数3） 暂停时间目标：暂停时间不要太严苛，其吞吐量目标是90%的应用程序时间和10%的垃圾回收时间，太严苛会直接影响到吞吐量 是否需要切换到G1 50%以上的堆被存活对象占用 对象分配和晋升的速度变化非常大 垃圾回收时间特别长，超过1秒 G1调优目标 6GB以上内存 停顿时间是500ms以内 吞吐量是90%以上 GC常用参数 堆栈设置 -Xss:每个线程的栈大小 -Xms:初始堆大小，默认物理内存的1/64 -Xmx:最大堆大小，默认物理内存的1/4 -Xmn:新生代大小 -XX:NewSize:设置新生代初始大小 -XX:NewRatio:默认2表示新生代占年老代的1/2，占整个堆内存的1/3。 -XX:SurvivorRatio:默认8表示一个survivor区占用1/8的Eden内存，即1/10的新生代内存。 -XX:MetaspaceSize:设置元空间大小 -XX:MaxMetaspaceSize:设置元空间最大允许大小，默认不受限制，JVM Metaspace会进行动态扩展。 垃圾回收统计信息 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:filename 收集器设置 -XX:+UseSerialGC:设置串行收集器 -XX:+UseParallelGC:设置并行收集器 -XX:+UseParallelOldGC:老年代使用并行回收收集器 -XX:+UseParNewGC:在新生代使用并行收集器 -XX:+UseParalledlOldGC:设置并行老年代收集器 -XX:+UseConcMarkSweepGC:设置CMS并发收集器 -XX:+UseG1GC:设置G1收集器 -XX:ParallelGCThreads:设置用于垃圾回收的线程数 并行收集器设置 -XX:ParallelGCThreads:设置并行收集器收集时使用的CPU数。并行收集线程数。 -XX:MaxGCPauseMillis:设置并行收集最大暂停时间 -XX:GCTimeRatio:设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n) CMS收集器设置 -XX:+UseConcMarkSweepGC:设置CMS并发收集器 -XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况。 -XX:ParallelGCThreads:设置并发收集器新生代收集方式为并行收集时，使用的CPU数。并行收集线程数。 -XX:CMSFullGCsBeforeCompaction:设定进行多少次CMS垃圾回收后，进行一次内存压缩 -XX:+CMSClassUnloadingEnabled:允许对类元数据进行回收 -XX:UseCMSInitiatingOccupancyOnly:表示只在到达阀值的时候，才进行CMS回收 -XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况 -XX:ParallelCMSThreads:设定CMS的线程数量 -XX:CMSInitiatingOccupancyFraction:设置CMS收集器在老年代空间被使用多少后触发 -XX:+UseCMSCompactAtFullCollection:设置CMS收集器在完成垃圾收集后是否要进行一次内存碎片的整理 G1收集器设置 -XX:+UseG1GC:使用G1收集器 -XX:ParallelGCThreads:指定GC工作的线程数量 -XX:G1HeapRegionSize:指定分区大小(1MB~32MB，且必须是2的幂)，默认将整堆划分为2048个分区 -XX:GCTimeRatio:吞吐量大小，0-100的整数(默认9)，值为n则系统将花费不超过1/(1+n)的时间用于垃圾收集 -XX:MaxGCPauseMillis:目标暂停时间(默认200ms) -XX:G1NewSizePercent:新生代内存初始空间(默认整堆5%) -XX:G1MaxNewSizePercent:新生代内存最大空间 -XX:TargetSurvivorRatio:Survivor填充容量(默认50%) -XX:MaxTenuringThreshold:最大任期阈值(默认15) -XX:InitiatingHeapOccupancyPercen:老年代占用空间超过整堆比IHOP阈值(默认45%),超过则执行混合收集 -XX:G1HeapWastePercent:堆废物百分比(默认5%) -XX:G1MixedGCCountTarget:参数混合周期的最大总次数(默认8) Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/mysql/":{"url":"performance/mysql/","title":"mysql","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/mysql/use.html":{"url":"performance/mysql/use.html","title":"1.Mysql安装和使用","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 安装MySQL 1.安装包准备 2.安装MySQL服务器 3.安装MySQL客户端 4.MySQL中user表中主机配置 5.开启bin-log 安装MySQL 注意：一定要用root用户操作如下步骤；先卸载MySQL再安装 1.安装包准备 （1）查看MySQL是否安装 rpm -qa|grep mysql （2）如果安装了MySQL，就先卸载 rpm -e --nodeps mysql-libs-5.1.73-7.el6.x86_64 （3）上传mysql-libs.zip到hadoop102的/opt/software目录，并解压文件到当前目录 unzip mysql-libs.zip （4）进入到mysql-libs文件夹下 ll -rw-r--r--. 1 root root 18509960 3月 26 2015 MySQL-client-5.6.24-1.el6.x86_64.rpm -rw-r--r--. 1 root root 3575135 12月 1 2013 mysql-connector-java-5.1.27.tar.gz -rw-r--r--. 1 root root 55782196 3月 26 2015 MySQL-server-5.6.24-1.el6.x86_64.rpm 2.安装MySQL服务器 （1）安装MySQL服务端 rpm -ivh MySQL-server-5.6.24-1.el6.x86_64.rpm （2）查看产生的随机密码 cat /root/.mysql_secret OEXaQuS8IWkG19Xs （3）查看MySQL状态 service mysql status （4）启动MySQL service mysql start 3.安装MySQL客户端 （1）安装MySQL客户端 rpm -ivh MySQL-client-5.6.24-1.el6.x86_64.rpm （2）链接MySQL（密码替换成产生的随机密码） mysql -uroot -pOEXaQuS8IWkG19Xs （3）修改密码 mysql>SET PASSWORD=PASSWORD('000000'); （4）退出MySQL mysql>exit 4.MySQL中user表中主机配置 配置只要是root用户+密码，在任何主机上都能登录MySQL数据库。 （1）进入MySQL mysql -uroot -p000000 （2）显示数据库 mysql>show databases; （3）使用MySQL数据库 mysql>use mysql; （4）展示MySQL数据库中的所有表 mysql>show tables; （5）展示user表的结构 mysql>desc user; （6）查询user表 mysql>select User, Host, Password from user; （7）修改user表，把Host表内容修改为% mysql>update user set host='%' where host='localhost'; （8）删除root用户的其他host mysql> delete from user where Host='hadoop102'; delete from user where Host='127.0.0.1'; delete from user where Host='::1'; （9）刷新 mysql>flush privileges; （10）退出 mysql>quit; 5.开启bin-log 打开mysql 的配置文件my.ini(别说找不到哦) 在mysqld配置项下面加上log_bin=mysql_bin [mysqld] log_bin = mysql_bin 重启mysql 在次show variables like 'log_bin' Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:14:39 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/mysql/high-use.html":{"url":"performance/mysql/high-use.html","title":"2.Mysql性能优化","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.Mysql架构介绍 1.1Mysql存储引擎 1.2Mysql逻辑架构 1.3Mysql物理文件体系结构 （1）binlog二进制日志文件 （2）redo重做日志文件 （3）共享表空间和独立表空间 （4）undo log （5）临时表空间 （6）error log （7）slow.log 2.InnoDB存储引擎体系结构 2.1缓冲池 2.2change buffer 2.3自适应哈希索引 2.4redo log buffer 2.5double write 2.6InnoDB后台线程 2.6.1InnoDB后台主线程 2.6.2InnoDB后台I/O线程 2.6.3InnoDB脏页刷新线程 2.6.4InnoDB purge线程 2.7redo log 2.8undo log 2.9Query Cache 3.Mysql事务和锁 3.1事务隔离级别 3.2InoDB锁机制介绍 3.3锁等待和死锁 3.3.1锁等待 3.3.2死锁 3.5锁问题的监控 4.Mysql服务器全面优化 4.1Mysql 5.7 InnoDB存储引擎增强特性 4.2硬件层面优化 4.3Linux操作系统层面优化 4.4Mysql配置参数优化 4.5设计规范 1.Mysql架构介绍 1.1Mysql存储引擎 InnoDB 支持行锁,事务 MyISAM 支持表锁,不支持事务 Memory 默认使用hash索引,比b+tree效力高 可通过show engines;命令来查看 1.2Mysql逻辑架构 1.3Mysql物理文件体系结构 （1）binlog二进制日志文件 不管使用的是哪一种存储引擎，都会产生binlog。如果开启了binlog二进制日志，就会有若干个二进制日志文件，如mysql-bin.000001、mysql-bin.000002、mysql-bin.00003等。binlog记录了MySQL对数据库执行更改的所有操作。查看当前binlog文件列表，如图1-7所示。 show master logs ; 。从MySQL 5.1版本开始，MySQL引入了binlog_format参数。这个参数有可选值statement和row：statement就是之前的格式，基于SQL语句来记录；row记录的则是行的更改情况，可以避免之前提到的数据不一致的问题。做MySQL主从复制，statement格式的binlog可能会导致主备不一致，所以要使用row格式。我们还需要借助mysqlbinlog工具来解析和查看binlog中的内容。如果需要用binlog来恢复数据，标准做法是用mysqlbinlog工具把binlog中的内容解析出来，然后把解析结果整个发给MySQL执行。 （2）redo重做日志文件 ib_logfile0、ib_logfile1是InnoDB引擎特有的、用于记录InnoDB引擎下事务的日志，它记录每页更改的物理情况。首先要搞明白的是已经有binlog了为什么还需要redo log，因为两者分工不同。binlog主要用来做数据归档，但是并不具备崩溃恢复的能力，也就是说如果系统突然崩溃，重启后可能会有部分数据丢失。Innodb将所有对页面的修改操作写入一个专门的文件，并在数据库启动时从此文件进行恢复操作，这个文件就是redo log file。redo log的存在可以完美解决这个问题。默认情况下，每个InnoDB引擎至少有一个重做日志组，每组下至少有两个重做日志文件，例如前面提到的ib_logfile0和ib_logfile1。重做日志组中的每个日志文件大小一致且循环写入，也就是说先写iblogfile0，写满了之后写iblogfile1，一旦iblogfile1写满了，就继续写iblogfile0。 （3）共享表空间和独立表空间 在MySQL 5.6.6之前的版本中，InnoDB默认会将所有的数据库InnoDB引擎的表数据存储在一个共享表空间ibdata1中，这样管理起来很困难，增删数据库的时候，ibdata1文件不会自动收缩，单个数据库的备份也将成为问题。为了优化上述问题，在MySQL 5.6.6之后的版本中，独立表空间innodb_file_per_table参数默认开启，每个数据库的每个表都有自已独立的表空间，每个表的数据和索引都会存在自己的表空间中。即便是innnodb表指定为独立表空间，用户自定义数据库中的某些元数据信息、回滚（undo）信息、插入缓冲（change buffer）、二次写缓冲（double write buffer）等还是存放在共享表空间，所以又称为系统表空间。 show variables like 'innodb_data%'; （4）undo log undo log是回滚日志，如果事务回滚，则需要依赖undo日志进行回滚操作。MySQL在进行事务操作的同时，会记录事务性操作修改数据之前的信息，就是undo日志，确保可以回滚到事务发生之前的状态。innodb的undo log存放在ibdata1共享表空间中，当开启事务后，事务所使用的undo log会存放在ibdata1中，即使这个事务被关闭，undo log也会一直占用空间。 show variables like '%undo%'; （5）临时表空间 存储临时对象的空间，比如临时表对象等。如图1-10所示，参数innodb_temp_data_file_path可以看到临时表空间的信息，上限设置为5GB。 show variables like 'innodb_temp_data_file_path%'; （6）error log 错误日志记录了MySQL Server每次启动和关闭的详细信息，以及运行过程中所有较为严重的警告和错误信息。 show variables like 'log_error%'; （7）slow.log 如果配置了MySQL的慢查询日志，MySQL就会将运行过程中的慢查询日志记录到slow_log文件中。MySQL的慢查询日志是MySQL提供的一种日志记录，用来记录在MySQL中响应时间超过阀值的语句，具体指运行时间超过long_query_time值的SQL。 show variables like '%slow_query_log%'; 例如，mysqldumpslow -s r -t 20 /database/mysql/slow-log表示为得到返回记录集最多的20个查询；mysqldumpslow -s t -t 20 -g \"left join\" /database/mysql/slow-log表示得到按照时间排序的前20条里面含有左连接的查询语句。 2.InnoDB存储引擎体系结构 2.1缓冲池 InnoDB存储引擎是基于磁盘存储的。由于CPU速度和磁盘速度之间的鸿沟，InnoDB引擎使用缓冲池技术来提高数据库的整体性能。 show variables like 'innodb_buffer_pool_size%'; ，这个对InnoDB整体性能影响也最大，一般可以设置为50%到80%的内存大小。在专用数据库服务器上，可以将缓冲池大小设置得大些，多次访问相同的数据表数据所需要的磁盘I/O就更少 InnoDB存储引擎的缓存机制和MyISAM的最大区别就在于InnoDB缓冲池不仅仅缓存索引，还会缓存实际的数据。 InnoDB存储引擎的LRU列表中还加入了midpoint位置，即新读取的页并不是直接放到LRU列表首部，而是放到LRU列表的midpoint位置。这个算法在InnoDB存储引擎下称为midpoint insertion strategy，默认该位置在LRU列表长度的5/8处。midpoint的位置可由参数innodb_old_blocks_pct控制 show variables like 'innodb_old_blocks_pct%'; 在图中，innodb_old_blocks_pct默认值为37，表示新读取的页插入到LRU列表尾端37%的位置 MySQL 5.6之后的版本提供了一个新特性来快速预热buffer_pool缓冲池，如图2-4所示。参数innodb_buffer_pool_dump_at_shutdown=ON表示在关闭MySQL时会把内存中的热数据保存在磁盘里ib_buffer_pool文件中，其保存比率由参数innodb_buffer_pool_dump_pct控制，默认为25%。 2.2change buffer change buffer的主要目的是将对二级索引的数据操作缓存下来，以减少二级索引的随机I/O，并达到操作合并的效果。 2.3自适应哈希索引 InnoDB存储引擎会监控对表上二级索引的查找。如果发现某二级索引被频繁访问，二级索引就成为热数据；如果观察到建立哈希索引可以带来速度的提升，则建立哈希索引，所以称之为自适应（adaptive）的，即自适应哈希索引（Adaptive Hash Index，AHI）。 2.4redo log buffer redo log buffer是一块内存区域，存放将要写入redo log文件的数据 2.5double write double write（两次写）技术的引入是为了提高数据写入的可靠性 2.6InnoDB后台线程 2.6.1InnoDB后台主线程 master thread是InnoD存储引擎非常核心的一个在后台运行的主线程，相当重要。它做的主要工作包括但不限于：将缓冲池中的数据异步刷新到磁盘，保证数据的一致性，包括脏页的刷新、合并插入缓冲等。 2.6.2InnoDB后台I/O线程 在InnoDB存储引擎中大量使用了AIO（Async I/O）来处理写I/O请求，这样可以极大地提高数据库的性能。I/O线程的工作主要是负责这些I/O请求的回调（call back）处理。InnoDB 1.0版本之前共有4个I/O线程，分别是write、read、insert buffer和log I/O thread。在Linux平台下，I/O线程的数量不能进行调整，但是在Windows平台下可以通过参数innodb_file_io_threads来增大I/O线程。从InnoDB 1.0.x版本开始，read thread和write thread分别增大到了4个，并且不再使用innodb_file_io_threads参数，而是分别使用innodb_read_io_threads和innodb_write_io_threads参数进行设置，如此调整后，在Linux平台上就可以根据CPU核数来更改相应的参数值了。 2.6.3InnoDB脏页刷新线程 MySQL 5.6版本以前，脏页的清理工作交由master线程处理。page cleaner thread是5.6.2版本引入的一个新线程，实现从master线程中卸下缓冲池刷脏页的工作。为了进一步提升扩展性和刷脏效率，在5.7.4版本里引入了多个page cleaner线程，从而达到并行刷脏的效果。 2.6.4InnoDB purge线程 purge thread负责回收已经使用并分配的undo页 2.7redo log 明确一下InnoDB修改数据的基本流程。当我们想要修改DB上某一行数据的时候，InnoDB是把数据从磁盘读取到内存的缓冲池上进行修改。这个时候数据在内存中被修改，与磁盘中相比就存在了差异，我们称这种有差异的数据为脏页。InnoDB对脏页的处理不是每次生成脏页就将脏页刷新回磁盘，因为这样会产生海量的I/O操作，严重影响InnoDB的处理性能。既然脏页与磁盘中的数据存在差异，那么如果在此期间DB出现故障就会造成数据丢失。为了解决这个问题，redo log就应运而生了。 2.8undo log undo log是InnoDB MVCC事务特性的重要组成部分。当我们对记录做了变更操作时就会产生undo记录，undo记录默认被记录到系统表空间（ibdata）中，但从MySQL 5.6开始，也可以使用独立的undo表空间。 2.9Query Cache 3.Mysql事务和锁 3.1事务隔离级别 数据库提供了4种隔离级别，由低到高依次为read uncommitted（读未提交）、read committed（读已提交）、repeatable read（可重复读取）、serializable（序列化）。 3.2InoDB锁机制介绍 锁机制是事务型数据库中为了保证数据的一致性手段 InnoDB主要使用两种级别的锁机制： 行级锁和表级锁。 InnoDB的行级锁类型主要有共享（S）锁（又称读锁）、排他（X）锁（又称写锁）。共享（S）锁允许持有该锁的事务读取行；排他（X）锁允许持有该锁的事务更新或删除行。 3.3锁等待和死锁 3.3.1锁等待 锁等待是指一个事务过程中产生的锁，其他事务需要等待上一个事务释放它的锁才能占用该资源。如果该事务一直不释放，就需要持续等待下去，直到超过了锁等待时间，会报一个等待超时的错误。在MySQL中通过innodb_lock_wait_timeout参数来控制锁等待时间，单位是秒。如图3-9所示，可以通过语句show variables like '%innodb_lock_wait%'来查看锁等待超时时间 当MySQL发生锁等待情况时，可以通过语句select * from sys.innodb_lock_waits来在线查看， 3.3.2死锁 在MySQL中，两个或两个以上的事务相互持有和请求锁，并形成一个循环的依赖关系，就会产生死锁，也就是锁资源请求产生了死循环现象。InnoDB会自动检测事务死锁，立即回滚其中某个事务，并且返回一个错误。它根据某种机制来选择那个最简单（代价最小）的事务来进行回滚。常见的死锁会报错“ERROR 1213 (40001):deadlock found when trying to get lock; try restarting transaction.”。偶然发生的死锁不必担心，InnoDB存储引擎有一个后台的锁监控线程，该线程负责查看可能的死锁问题，并自动告知用户。 3.5锁问题的监控 我们通过show full processlist是为了查看当前MySQL是否有压力、都在跑什么语句、当前语句耗时多久了，从中可以看到总共有多少链接数、哪些线程有问题，然后把有问题的线程kill掉，临时解决一些突发性的问题。 通过执行show engine innodb status命令来查看是否存在锁表情况，如 MySQL将事务和锁信息记录在了information_schema数据库中，我们只需要查询即可。涉及的表主要有3个，即innodb_trx、innodb_locks、innodb_lock_waits， select * from information_schema.INNODB_TRX; select * from information_schema.INNODB_LOCKS; select * from information_schema.INNODB_LOCK_WAITS; 4.Mysql服务器全面优化 4.1Mysql 5.7 InnoDB存储引擎增强特性 Online Alter Table以及索引 innodb_buffer_pool online change innodb_buffer_pool_dump和load的增强 InnoDB临时表优化 page clean的效率提升 undo log自动清除4.2硬件层面优化 （1）使用SSD或者PCIe SSD设备，至少获得数百倍甚至万倍的IOPS提升。 4.3Linux操作系统层面优化 文件系统选择推荐使用xfs 4.4Mysql配置参数优化 4.5设计规范 库表的设计规范 索引设计规范 sql语句的规范 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:20:32 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/mysql/mysql-index.html":{"url":"performance/mysql/mysql-index.html","title":"3.索引底层数据结构","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.索引到底是什么 2.索引底层数据结构与算法 2.1B-Tree 2.2B+Tree(B-Tree变种) 3.索引最左前缀原理 1.索引到底是什么 索引是帮助MySQL高效获取数据的排好序的数据结构 数据结构教学网站：https://www.cs.usfca.edu/~galles/visualization/Algorithms.html 2.索引底层数据结构与算法 二叉树 红黑树 HASH BTREE 2.1B-Tree 度(Degree)-节点的数据存储个数 叶节点具有相同的深度 叶节点的指针为空 节点中的数据key从左到右递增排列 2.2B+Tree(B-Tree变种) 非叶子节点不存储data，只存储key，可以增大度 叶子节点不存储指针 顺序访问指针，提高区间访问的性能 3.索引最左前缀原理 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:01:37 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/mysql/Explain.html":{"url":"performance/mysql/Explain.html","title":"1.Explain详解","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.explain 中的列 1. id列 1）简单子查询 2）from子句中的子查询 3）union查询 2. select_type列 1）simple：简单查询。查询不包含子查询和union 2）primary：复杂查询中最外层的 select 3）subquery：包含在 select 中的子查询（不在 from 子句中） 4）derived：包含在 from 子句中的子查询。MySQL会将结果存放在一个临时表中，也称为派生表（derived的英文含义） 5）union：在 union 中的第二个和随后的 select 6）union result：从 union 临时表检索结果的 select 3. table列 4. type列 5. possible_keys列 6. key列 7. key_len列 8. ref列 9. rows列 10. Extra列 2.索引最佳实践 1. 全值匹配 2.最佳左前缀法则 3.不在索引列上做任何操作（计算、函数、（自动or手动）类型转换），会导致索引失效而转向全表扫描 4.存储引擎不能使用索引中范围条件右边的列 5.尽量使用覆盖索引（只访问索引的查询（索引列包含查询列）），减少select *语句 6.mysql在使用不等于（！=或者<>）的时候无法使用索引会导致全表扫描 7.is null,is not null 也无法使用索引 8.like以通配符开头（'$abc...'）mysql索引失效会变成全表扫描操作 9.字符串不加单引号索引失效 10.少用or,用它连接时很多情况下索引会失效 使用EXPLAIN关键字可以模拟优化器执行SQL语句，从而知道MySQL是 如何处理你的SQL语句的。分析你的查询语句或是结构的性能瓶颈 下面是使用 explain 的例子： 在 select 语句之前增加 explain 关键字，MySQL 会在查询上设置一个标记，执行查询时，会返回执行计划的信息，而不是执行这条SQL（如果 from 中包含子查询，仍会执行该子查询，将结果放入临时表中） 使用的表 DROP TABLE IF EXISTS `actor`; CREATE TABLE `actor` ( `id` int(11) NOT NULL, `name` varchar(45) DEFAULT NULL, `update_time` datetime DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; INSERT INTO `actor` (`id`, `name`, `update_time`) VALUES (1,'a','2017-12-22 15:27:18'), (2,'b','2017-12-22 15:27:18'), (3,'c','2017-12-22 15:27:18'); DROP TABLE IF EXISTS `film`; CREATE TABLE `film` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(10) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_name` (`name`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; INSERT INTO `film` (`id`, `name`) VALUES (3,'film0'),(1,'film1'),(2,'film2'); DROP TABLE IF EXISTS `film_actor`; CREATE TABLE `film_actor` ( `id` int(11) NOT NULL, `film_id` int(11) NOT NULL, `actor_id` int(11) NOT NULL, `remark` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_film_actor_id` (`film_id`,`actor_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; INSERT INTO `film_actor` (`id`, `film_id`, `actor_id`) VALUES (1,1,1),(2,1,2),(3,2,1); mysql> explain select * from actor; 在查询中的每个表会输出一行，如果有两个表通过 join 连接查询，那么会输出两行。表的意义相当广泛：可以是子查询、一个 union 结果等。 explain 有两个变种： 1）explain extended：会在 explain 的基础上额外提供一些查询优化的信息。紧随其后通过 show warnings 命令可以 得到优化后的查询语句，从而看出优化器优化了什么。额外还有 filtered 列，是一个半分比的值，rows * filtered/100 可以估算出将要和 explain 中前一个表进行连接的行数（前一个表指 explain 中的id值比当前表id值小的表）。 mysql> explain extended select * from film where id = 1; mysql> show warnings; 2）explain partitions：相比 explain 多了个 partitions 字段，如果查询是基于分区表的话，会显示查询将访问的分区。 1.explain 中的列 接下来我们将展示 explain 中每个列的信息。 1. id列 id列的编号是 select 的序列号，有几个 select 就有几个id，并且id的顺序是按 select 出现的顺序增长的。MySQL将 select 查询分为简单查询(SIMPLE)和复杂查询(PRIMARY)。 复杂查询分为三类：简单子查询、派生表（from语句中的子查询）、union 查询。 id列越大执行优先级越高，id相同则从上往下执行，id为NULL最后执行 1）简单子查询 mysql> explain select (select 1 from actor limit 1) from film; 2）from子句中的子查询 mysql> explain select id from (select id from film) as der; 这个查询执行时有个临时表别名为der，外部 select 查询引用了这个临时表 3）union查询 mysql> explain select 1 union all select 1; union结果总是放在一个匿名临时表中，临时表不在SQL中出现，因此它的id是NULL。 2. select_type列 select_type 表示对应行是简单还是复杂的查询，如果是复杂的查询，又是上述三种复杂查询中的哪一种。 1）simple：简单查询。查询不包含子查询和union mysql> explain select * from film where id = 2; 2）primary：复杂查询中最外层的 select 3）subquery：包含在 select 中的子查询（不在 from 子句中） 4）derived：包含在 from 子句中的子查询。MySQL会将结果存放在一个临时表中，也称为派生表（derived的英文含义） 用这个例子来了解 primary、subquery 和 derived 类型 mysql> explain select (select 1 from actor where id = 1) from (select * from film where id = 1) der; 5）union：在 union 中的第二个和随后的 select 6）union result：从 union 临时表检索结果的 select 用这个例子来了解 union 和 union result 类型： mysql> explain select 1 union all select 1; 3. table列 这一列表示 explain 的一行正在访问哪个表。 当 from 子句中有子查询时，table列是 格式，表示当前查询依赖 id=N 的查询，于是先执行 id=N 的查询。 当有 union 时，UNION RESULT 的 table 列的值为，1和2表示参与 union 的 select 行id。 4. type列 这一列表示关联类型或访问类型，即MySQL决定如何查找表中的行，查找数据行记录的大概范围。 依次从最优到最差分别为：system > const > eq_ref > ref > range > index > ALL 一般来说，得保证查询达到range级别，最好达到ref NULL：mysql能够在优化阶段分解查询语句，在执行阶段用不着再访问表或索引。例如：在索引列中选取最小值，可以单独查找索引来完成，不需要在执行时访问表 mysql> explain select min(id) from film; const, system：mysql能对查询的某部分进行优化并将其转化成一个常量（可以看show warnings 的结果）。用于 primary key 或 unique key 的所有列与常数比较时，所以表最多有一个匹配行，读取1次，速度比较快。system是const的特例，表里只有一条元组匹配时为system mysql> explain extended select from (select from film where id = 1) tmp; mysql> show warnings; eq_ref：primary key 或 unique key 索引的所有部分被连接使用 ，最多只会返回一条符合条件的记录。这可能是在 const 之外最好的联接类型了，简单的 select 查询不会出现这种 type。 mysql> explain select * from film_actor left join film on film_actor.film_id = film.id; ref：相比 eq_ref，不使用唯一索引，而是使用普通索引或者唯一性索引的部分前缀，索引要和某个值相比较，可能会找到多个符合条件的行。 简单 select 查询，name是普通索引（非唯一索引） mysql> explain select * from film where name = \"film1\"; 2.关联表查询，idx_film_actor_id是film_id和actor_id的联合索引，这里使用到了film_actor的左边前缀film_id部分。 mysql> explain select film_id from film left join film_actor on film.id = film_actor.film_id; range：范围扫描通常出现在 in(), between ,> ,= 等操作中。使用一个索引来检索给定范围的行。 mysql> explain select * from actor where id > 1; index：扫描全表索引，这通常比ALL快一些。（index是从索引中读取的，而all是从硬盘中读取） mysql> explain select * from film; ALL：即全表扫描，意味着mysql需要从头到尾去查找所需要的行。通常情况下这需要增加索引来进行优化了 mysql> explain select * from actor; 5. possible_keys列 这一列显示查询可能使用哪些索引来查找。 explain 时可能出现 possible_keys 有列，而 key 显示 NULL 的情况，这种情况是因为表中数据不多，mysql认为索引对此查询帮助不大，选择了全表查询。 如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查 where 子句看是否可以创造一个适当的索引来提高查询性能，然后用 explain 查看效果。 6. key列 这一列显示mysql实际采用哪个索引来优化对该表的访问。 如果没有使用索引，则该列是 NULL。如果想强制mysql使用或忽视possible_keys列中的索引，在查询中使用 force index、ignore index。 7. key_len列 这一列显示了mysql在索引里使用的字节数，通过这个值可以算出具体使用了索引中的哪些列。 举例来说，film_actor的联合索引 idx_film_actor_id 由 film_id 和 actor_id 两个int列组成，并且每个int是4字节。通过结果中的key_len=4可推断出查询使用了第一个列：film_id列来执行索引查找。 mysql> explain select * from film_actor where film_id = 2; key_len计算规则如下： 字符串 char(n)：n字节长度 varchar(n)：2字节存储字符串长度，如果是utf-8，则长度 3n + 2 数值类型 tinyint：1字节 smallint：2字节 int：4字节 bigint：8字节 时间类型 date：3字节 timestamp：4字节 datetime：8字节 如果字段允许为 NULL，需要1字节记录是否为 NULL 索引最大长度是768字节，当字符串过长时，mysql会做一个类似左前缀索引的处理，将前半部分的字符提取出来做索引。 8. ref列 这一列显示了在key列记录的索引中，表查找值所用到的列或常量，常见的有：const（常量），字段名（例：film.id） 9. rows列 这一列是mysql估计要读取并检测的行数，注意这个不是结果集里的行数。 10. Extra列 这一列展示的是额外信息。常见的重要值如下： Using index：查询的列被索引覆盖，并且where筛选条件是索引的前导列，是性能高的表现。一般是使用了覆盖索引(索引包含了所有查询的字段)。对于innodb来说，如果是辅助索引性能会有不少提高 mysql> explain select film_id from film_actor where film_id = 1; Using where：查询的列未被索引覆盖，where筛选条件非索引的前导列 mysql> explain select * from actor where name = 'a'; Using where Using index：查询的列被索引覆盖，并且where筛选条件是索引列之一但是不是索引的前导列，意味着无法直接通过索引查找来查询到符合条件的数据 mysql> explain select film_id from film_actor where actor_id = 1; NULL：查询的列未被索引覆盖，并且where筛选条件是索引的前导列，意味着用到了索引，但是部分字段未被索引覆盖，必须通过“回表”来实现，不是纯粹地用到了索引，也不是完全没用到索引 mysql>explain select * from film_actor where film_id = 1; Using index condition：与Using where类似，查询的列不完全被索引覆盖，where条件中是一个前导列的范围； mysql> explain select * from film_actor where film_id > 1; Using temporary：mysql需要创建一张临时表来处理查询。出现这种情况一般是要进行优化的，首先是想到用索引来优化。 actor.name没有索引，此时创建了张临时表来distinct mysql> explain select distinct name from actor; film.name建立了idx_name索引，此时查询时extra是using index,没有用临时表 mysql> explain select distinct name from film; Using filesort：mysql 会对结果使用一个外部索引排序，而不是按索引次序从表里读取行。此时mysql会根据联接类型浏览所有符合条件的记录，并保存排序关键字和行指针，然后排序关键字并按顺序检索行信息。这种情况下一般也是要考虑使用索引来优化的。 actor.name未创建索引，会浏览actor整个表，保存排序关键字name和对应的id，然后排序name并检索行记录 mysql> explain select * from actor order by name; film.name建立了idx_name索引,此时查询时extra是using indexmysql> explain select * from film order by name; 2.索引最佳实践 使用的表 CREATE TABLE `employees` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(24) NOT NULL DEFAULT '' COMMENT '姓名', `age` int(11) NOT NULL DEFAULT '0' COMMENT '年龄', `position` varchar(20) NOT NULL DEFAULT '' COMMENT '职位', `hire_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '入职时间', PRIMARY KEY (`id`), KEY `idx_name_age_position` (`name`,`age`,`position`) USING BTREE ) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8 COMMENT='员工记录表'; INSERT INTO employees(name,age,position,hire_time) VALUES('LiLei',22,'manager',NOW()); INSERT INTO employees(name,age,position,hire_time) VALUES('HanMeimei', 23,'dev',NOW()); INSERT INTO employees(name,age,position,hire_time) VALUES('Lucy',23,'dev',NOW()); 最佳实践 1. 全值匹配 EXPLAIN SELECT * FROM employees WHERE name= 'LiLei'; EXPLAIN SELECT * FROM employees WHERE name= 'LiLei' AND age = 22; EXPLAIN SELECT * FROM employees WHERE name= 'LiLei' AND age = 22 AND position ='manager'; 2.最佳左前缀法则 如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始并且不跳过索引中的列。 EXPLAIN SELECT * FROM employees WHERE age = 22 AND position ='manager'; EXPLAIN SELECT * FROM employees WHERE position = 'manager'; EXPLAIN SELECT * FROM employees WHERE name = 'LiLei'; 3.不在索引列上做任何操作（计算、函数、（自动or手动）类型转换），会导致索引失效而转向全表扫描 EXPLAIN SELECT * FROM employees WHERE name = 'LiLei'; EXPLAIN SELECT * FROM employees WHERE left(name,3) = 'LiLei'; 4.存储引擎不能使用索引中范围条件右边的列 EXPLAIN SELECT * FROM employees WHERE name= 'LiLei' AND age = 22 AND position ='manager'; EXPLAIN SELECT * FROM employees WHERE name= 'LiLei' AND age > 22 AND position ='manager'; 5.尽量使用覆盖索引（只访问索引的查询（索引列包含查询列）），减少select *语句 EXPLAIN SELECT name,age FROM employees WHERE name= 'LiLei' AND age = 23 AND position ='manager'; EXPLAIN SELECT * FROM employees WHERE name= 'LiLei' AND age = 23 AND position ='manager'; 6.mysql在使用不等于（！=或者<>）的时候无法使用索引会导致全表扫描 EXPLAIN SELECT * FROM employees WHERE name != 'LiLei' 7.is null,is not null 也无法使用索引 EXPLAIN SELECT * FROM employees WHERE name is null 8.like以通配符开头（'$abc...'）mysql索引失效会变成全表扫描操作 EXPLAIN SELECT * FROM employees WHERE name like '%Lei' EXPLAIN SELECT * FROM employees WHERE name like 'Lei%' 问题：解决like'%字符串%'索引不被使用的方法？ a）使用覆盖索引，查询字段必须是建立覆盖索引字段 EXPLAIN SELECT name,age,position FROM employees WHERE name like '%Lei%'; b）当覆盖索引指向的字段是varchar(380)及380以上的字段时，覆盖索引会失效！ 9.字符串不加单引号索引失效 EXPLAIN SELECT * FROM employees WHERE name = '1000'; EXPLAIN SELECT * FROM employees WHERE name = 1000; 10.少用or,用它连接时很多情况下索引会失效 EXPLAIN SELECT * FROM employees WHERE name = 'LiLei' or name = 'HanMeimei'; 总结： like KK%相当于=常量，%KK和%KK% 相当于范围 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:01:48 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/mysql/high-index.html":{"url":"performance/mysql/high-index.html","title":"2.索引优化深入","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.创建test表（测试表） 2.创建索引 3.分析以下Case索引使用情况 3.1Case 1： 3.2Case 2： 3.2.1Case 2.1： 3.2.1Case 2.2： 3.3Case 3： 3.3.1Case 3.1： 3.3.2Case 3.2： 3.4Case 4： 3.4.1Case 4.1： 3.4.2Case 4.2： 3.4.3Case 4.3： 3.5Case 5： 3.5.1Case 5.1： 3.6Case 6： 3.7Case 7： 3.8Case 8： 4.总结： 1.order by语句使用索引最左前列。 2.使用where子句与order by子句条件列组合满足索引最左前列。 等价于： 等价于 A表与B表的ID字段应建立索引 1.创建test表（测试表） drop table if exists test; create table test( id int primary key auto_increment, c1 varchar(10), c2 varchar(10), c3 varchar(10), c4 varchar(10), c5 varchar(10) ) ENGINE=INNODB default CHARSET=utf8; insert into test(c1,c2,c3,c4,c5) values('a1','a2','a3','a4','a5'); insert into test(c1,c2,c3,c4,c5) values('b1','b2','b3','b4','b5'); insert into test(c1,c2,c3,c4,c5) values('c1','c2','c3','c4','c5'); insert into test(c1,c2,c3,c4,c5) values('d1','d2','d3','d4','d5'); insert into test(c1,c2,c3,c4,c5) values('e1','e2','e3','e4','e5'); 2.创建索引 3.分析以下Case索引使用情况 3.1Case 1： 分析： ①创建复合索引的顺序为c1,c2,c3,c4。 ②上述四组explain执行的结果都一样：type=ref，key_len=132，ref=const,const,const,const。 结论：在执行常量等值查询时，改变索引列的顺序并不会更改explain的执行结果，因为mysql底层优化器会进行优化，但是推荐按照索引顺序列编写sql语句。 3.2Case 2： 分析： 当出现范围的时候，type=range，key_len=99，比不用范围key_len=66增加了，说明使用上了索引，但对比Case1中执行结果，说明c4上索引失效。 结论：范围右边索引列失效，但是范围当前位置（c3）的索引是有效的，从key_len=99可证明。 3.2.1Case 2.1： 分析： 与上面explain执行结果对比，key_len=132说明索引用到了4个，因为对此sql语句mysql底层优化器会进行优化：范围右边索引列失效（c4右边已经没有索引列了），注意索引的顺序（c1,c2,c3,c4），所以c4右边不会出现失效的索引列，因此4个索引全部用上。 结论：范围右边索引列失效，是有顺序的：c1,c2,c3,c4，如果c3有范围，则c4失效；如果c4有范围，则没有失效的索引列，从而会使用全部索引。 3.2.1Case 2.2： 分析： 如果在c1处使用范围，则type=ALL，key=Null，索引失效，全表扫描，这里违背了最佳左前缀法则，带头大哥已死，因为c1主要用于范围，而不是查询。 解决方式使用覆盖索引。 结论：在最佳左前缀法则中，如果最左前列（带头大哥）的索引失效，则后面的索引都失效。 3.3Case 3： 分析： 利用最佳左前缀法则：中间兄弟不能断，因此用到了c1和c2索引（查找），从key_len=66，ref=const,const，c3索引列用在排序过程中。 3.3.1Case 3.1： 分析： 从explain的执行结果来看：key_len=66，ref=const,const，从而查找只用到c1和c2索引，c3索引用于排序。 3.3.2Case 3.2： 分析： 从explain的执行结果来看：key_len=66，ref=const,const，查询使用了c1和c2索引，由于用了c4进行排序，跳过了c3，出现了Using filesort。 3.4Case 4： 分析： 查找只用到索引c1，c2和c3用于排序，无Using filesort。 3.4.1Case 4.1： 分析： 和Case 4中explain的执行结果一样，但是出现了Using filesort，因为索引的创建顺序为c1,c2,c3,c4，但是排序的时候c2和c3颠倒位置了。 3.4.2Case 4.2： 分析： 在查询时增加了c5，但是explain的执行结果一样，因为c5并未创建索引。 3.4.3Case 4.3： 分析： 与Case 4.1对比，在Extra中并未出现Using filesort，因为c2为常量，在排序中被优化，所以索引未颠倒，不会出现Using filesort。 3.5Case 5： 分析： 只用到c1上的索引，因为c4中间间断了，根据最佳左前缀法则，所以key_len=33，ref=const，表示只用到一个索引。 3.5.1Case 5.1： 分析： 对比Case 5，在group by时交换了c2和c3的位置，结果出现Using temporary和Using filesort，极度恶劣。原因：c3和c2与索引创建顺序相反。 3.6Case 6： 分析： ①在c1,c2,c3,c4上创建了索引，直接在c1上使用范围，导致了索引失效，全表扫描：type=ALL，ref=Null。因为此时c1主要用于排序，并不是查询。 ②使用c1进行排序，出现了Using filesort。 ③解决方法：使用覆盖索引。 3.7Case 7： 分析： 虽然排序的字段列与索引顺序一样，且order by默认升序，这里c2 desc变成了降序，导致与索引的排序方式不同，从而产生Using filesort。 3.8Case 8： EXPLAIN extended select c1 from test where c1 in ('a1','b1') ORDER BY c2,c3; 分析： 对于排序来说，多个相等条件也是范围查询 4.总结： ①MySQL支持两种方式的排序filesort和index，Using index是指MySQL扫描索引本身完成排序。index效率高，filesort效率低。 ②order by满足两种情况会使用Using index。 1.order by语句使用索引最左前列。 2.使用where子句与order by子句条件列组合满足索引最左前列。 ③尽量在索引列上完成排序，遵循索引建立（索引创建的顺序）时的最佳左前缀法则。 ④如果order by的条件不在索引列上，就会产生Using filesort。 ⑤group by与order by很类似，其实质是先排序后分组，遵照索引创建顺序的最佳左前缀法则。注意where高于having，能写在where中的限定条件就不要去having限定了。 通俗理解口诀： 全值匹配我最爱，最左前缀要遵守； 带头大哥不能死，中间兄弟不能断； 索引列上少计算，范围之后全失效； LIKE百分写最右，覆盖索引不写星； 不等空值还有or，索引失效要少用。 补充：in和exsits优化 原则：小表驱动大表，即小的数据集驱动大的数据集 in：当B表的数据集必须小于A表的数据集时，in优于exists select * from A where id in (select id from B) 等价于： for select id from B for select * from A where A.id = B.id exists：当A表的数据集小于B表的数据集时，exists优于in 将主查询A的数据，放到子查询B中做条件验证，根据验证结果（true或false）来决定主查询的数据是否保留 select * from A where exists (select 1 from B where B.id = A.id) 等价于 for select * from A for select * from B where B.id = A.id A表与B表的ID字段应建立索引 1、EXISTS (subquery)只返回TRUE或FALSE,因此子查询中的SELECT * 也可以是SELECT 1或select X,官方说法是实际执行时会忽略SELECT清单,因此没有区别 2、EXISTS子查询的实际执行过程可能经过了优化而不是我们理解上的逐条对比 3、EXISTS子查询往往也可以用JOIN来代替，何种最优需要具体问题具体分析 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:02:03 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/mysql/acid.html":{"url":"performance/mysql/acid.html","title":"3.Mysql锁与事务隔离级别","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 １. 概述 1.1 定义 1.2 锁的分类 2. 锁 2.1 表锁（偏读） 2.1.1 基本操作 2.1.2 案例分析(加读锁） 2.1.3 案例分析(加写锁） 2.1.4 案例结论 2.2 行锁（偏写） 2.2.1 行锁支持事务 2.2.2 行锁案例分析 2.2.3******隔离级别案例分析** 2.2.4 案例结论 2.2.5 行锁分析 2.2.6 死锁 2.2.7 优化建议 １. 概述 1.1 定义 锁是计算机协调多个进程或线程并发访问某一资源的机制。 在数据库中，除了传统的计算资源（如CPU、RAM、I/O等）的争用以外，数据也是一种供需要用户共享的资源。如何保证数据并发访问的一致性、有效性是所有数据库必须解决的一个问题，锁冲突也是影响数据库并发访问性能的一个重要因素。从这个角度来说，锁对数据库而言显得尤其重要，也更加复杂。 1.2 锁的分类 从性能上分为乐观锁(用版本对比来实现)和悲观锁 从对数据库操作的类型分，分为读锁和写锁(都属于悲观锁) 读锁（共享锁）：针对同一份数据，多个读操作可以同时进行而不会互相影响 写锁（排它锁）：当前写操作没有完成前，它会阻断其他写锁和读锁 从对数据操作的粒度分，分为表锁和行锁2. 锁 2.1 表锁（**偏读**） 表锁偏向MyISAM存储引擎，开销小，加锁快，无思索，锁定粒度大，发生锁冲突的概率最高，并发度最低。 2.1.1 基本操作 建表SQL CREATE TABLE `mylock` ( `id` INT (11) NOT NULL AUTO_INCREMENT, `NAME` VARCHAR (20) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE = MyISAM DEFAULT CHARSET = utf8; 插入数据 INSERT INTO`test`.`mylock`(`id`,`NAME`)VALUES('1','a'); INSERT INTO`test`.`mylock`(`id`,`NAME`)VALUES('2','b'); INSERT INTO`test`.`mylock`(`id`,`NAME`)VALUES('3','c'); INSERT INTO`test`.`mylock`(`id`,`NAME`)VALUES('4','d'); 手动增加表锁 lock table表名称read(write),表名称2read(write); 查看表上加过的锁 show opentables; 删除表锁 unlock tables; 2.1.2 案例分析(加读锁） 当前session和其他session都可以读该表 当前session中插入或者更新锁定的表都会报错，其他session插入或更新则会等待 2.1.3 案例分析(加写锁） 当前session对该表的增删改查都没有问题，其他session对该表的所有操作被阻塞 2.1.4 案例结论 MyISAM在执行查询语句(SELECT)前,会自动给涉及的所有表加读锁,在执行增删改操作前,会自动给涉及的表加写锁。 1、对MyISAM表的读操作(加读锁) ,不会阻寒其他进程对同一表的读请求,但会阻赛对同一表的写请求。只有当读锁释放后,才会执行其它进程的写操作。 2、对MylSAM表的写操作(加写锁) ,会阻塞其他进程对同一表的读和写操作,只有当写锁释放后,才会执行其它进程的读写操作 总结： 简而言之，就是读锁会阻塞写，但是不会阻塞读。而写锁则会把读和写都阻塞。 2.2 行锁（**偏写**） 行锁偏向InnoDB存储引擎，开销大，加锁慢，会出现死锁，锁定粒度最小，发生锁冲突的概率最低，并发度也最高。InnoDB与MYISAM的最大不同有两点：一是支持事务（TRANSACTION）；二是采用了行级锁。 2.2.1 行锁支持事务 事务（Transaction）及其ACID属性 事务是由一组SQL语句组成的逻辑处理单元,事务具有以下4个属性,通常简称为事务的ACID属性。 原子性(Atomicity)：事务是一个原子操作单元,其对数据的修改,要么全都执行,要么全都不执行。 一致性(Consistent)：在事务开始和完成时,数据都必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改,以保持数据的完整性;事务结束时,所有的内部数据结构(如B树索引或双向链表)也都必须是正确的。 隔离性(Isolation)：数据库系统提供一定的隔离机制,保证事务在不受外部并发操作影响的“独立”环境执行。这意味着事务处理过程中的中间状态对外部是不可见的,反之亦然。 持久性(Durable)：事务完成之后,它对于数据的修改是永久性的,即使出现系统故障也能够保持。 并发事务处理带来的问题 更新丢失（Lost Update） 当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题–最后的更新覆盖了由其他事务所做的更新。 脏读（Dirty Reads） 一个事务正在对一条记录做修改，在这个事务完成并提交前，这条记录的数据就处于不一致的状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”数据，并据此作进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象的叫做“脏读”。 一句话：事务A读取到了事务B已经修改但尚未提交的数据，还在这个数据基础上做了操作。此时，如果B事务回滚，A读取的数据无效，不符合一致性要求。 不可重读（Non-Repeatable Reads） 一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了！这种现象就叫做“不可重复读”。 一句话：事务A读取到了事务B已经提交的修改数据，不符合隔离性 幻读（Phantom Reads） 一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。 一句话：事务A读取到了事务B提交的新增数据，不符合隔离性 脏读是事务B里面修改了数据 幻读是事务B里面新增了数据 事务隔离级别 脏读”、“不可重复读”和“幻读”,其实都是数据库读一致性问题,必须由数据库提供一定的事务隔离机制来解决。 数据库的事务隔离越严格,并发副作用越小,但付出的代价也就越大,因为事务隔离实质上就是使事务在一定程度上“串行化”进行,这显然与“并发”是矛盾的。 同时,不同的应用对读一致性和事务隔离程度的要求也是不同的,比如许多应用对“不可重复读\"和“幻读”并不敏感,可能更关心数据并发访问的能力。 常看当前数据库的事务隔离级别: show variables like 'tx_isolation'; 设置事务隔离级别：**set tx_isolation='REPEATABLE-READ';** 2.2.2 行锁案例分析 用下面的表演示，需要开启事务，Session_1更新某一行，Session_2更新同一行被阻塞，但是更新其他行正常2.2.3**隔离级别案例分析** CREATE TABLE `account` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) DEFAULT NULL, `balance` int(11) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; INSERT INTO `test`.`account` (`name`, `balance`) VALUES ('lilei', '450'); INSERT INTO `test`.`account` (`name`, `balance`) VALUES ('hanmei', '16000'); INSERT INTO `test`.`account` (`name`, `balance`) VALUES ('lucy', '2400'); 1、读未提交： （1）打开一个客户端A，并设置当前事务模式为read uncommitted（未提交读），查询表account的初始值： set tx_isolation='read-uncommitted'; （2）在客户端A的事务提交之前，打开另一个客户端B，更新表account： （3）这时，虽然客户端B的事务还没提交，但是客户端A就可以查询到B已经更新的数据： （4）一旦客户端B的事务因为某种原因回滚，所有的操作都将会被撤销，那客户端A查询到的数据其实就是脏数据： （5）在客户端A执行更新语句update account set balance = balance - 50 where id =1，lilei的balance没有变成350，居然是400，是不是很奇怪，数据不一致啊，如果你这么想就太天真 了，在应用程序中，我们会用400-50=350，并不知道其他会话回滚了，要想解决这个问题可以采用读已提交的隔离级别 2、读已提交 （1）打开一个客户端A，并设置当前事务模式为read committed（未提交读），查询表account的所有记录： set tx_isolation='read-committed'; （2）在客户端A的事务提交之前，打开另一个客户端B，更新表account： （3）这时，客户端B的事务还没提交，客户端A不能查询到B已经更新的数据，解决了脏读问题： （4）客户端B的事务提交 （5）客户端A执行与上一步相同的查询，结果 与上一步不一致，即产生了不可重复读的问题 3、可重复读 （1）打开一个客户端A，并设置当前事务模式为repeatable read，查询表account的所有记录 set tx_isolation='repeatable-read'; （2）在客户端A的事务提交之前，打开另一个客户端B，更新表account并提交 （3）在客户端A查询表account的所有记录，与步骤（1）查询结果一致，没有出现不可重复读的问题 （4）在客户端A，接着执行update balance = balance - 50 where id = 1，balance没有变成400-50=350，lilei的balance值用的是步骤（2）中的350来算的，所以是300，数据的一致性倒是没有被破坏。可重复读的隔离级别下使用了MVCC机制，select操作不会更新版本号，是快照读（历史版本）；insert、update和delete会更新版本号，是当前读（当前版本）。 （5）重新打开客户端B，插入一条新数据后提交 （6）在客户端A查询表account的所有记录，没有 查出 新增数据，所以没有出现幻读 (7)验证幻读 在客户端A执行update account set balance=888 where id = 4;能更新成功，再次查询能查到客户端B新增的数据 4.串行化 （1）打开一个客户端A，并设置当前事务模式为serializable，查询表account的初始值： set tx_isolation='serializable'; mysql>setsessiontransactionisolationlevelserializable; Query OK,0rows affected (0.00sec) mysql>starttransaction; Query OK,0rows affected (0.00sec) mysql>selectfromaccount;+------+--------+---------+|id|name|balance|+------+--------+---------+|1|lilei|10000||2|hanmei|10000||3|lucy|10000||4|lily|10000|+------+--------+---------+4rowsinset(*0.00sec) （2）打开一个客户端B，并设置当前事务模式为serializable，插入一条记录报错，表被锁了插入失败，mysql中事务隔离级别为serializable时会锁表，因此不会出现幻读的情况，这种隔离级别并发性极低，开发中很少会用到。 mysql>setsessiontransactionisolationlevelserializable; Query OK,0rows affected (0.00sec) mysql>starttransaction; Query OK,0rows affected (0.00sec) mysql>insertintoaccountvalues(5,'tom',0); ERROR1205(HY000): Lock wait timeout exceeded; try restartingtransaction Mysql默认级别是repeatable-read，有办法解决幻读问题吗？ 间隙锁在某些情况下可以解决幻读问题 要避免幻读可以用间隙锁在Session_1下面执行update account set name = 'zhuge' where id > 10 and id 2.2.4 案例结论 Innodb存储引擎由于实现了行级锁定，虽然在锁定机制的实现方面所带来的性能损耗可能比表级锁定会要更高一下，但是在整体并发处理能力方面要远远优于MYISAM的表级锁定的。当系统并发量高的时候，Innodb的整体性能和MYISAM相比就会有比较明显的优势了。 但是，Innodb的行级锁定同样也有其脆弱的一面，当我们使用不当的时候，可能会让Innodb的整体性能表现不仅不能比MYISAM高，甚至可能会更差。 2.2.5 行锁分析 通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况 showstatuslike'innodb_row_lock%'; 对各个状态量的说明如下： Innodb_row_lock_current_waits: 当前正在等待锁定的数量 Innodb_row_lock_time: 从系统启动到现在锁定总时间长度 Innodb_row_lock_time_avg: 每次等待所花平均时间 Innodb_row_lock_time_max：从系统启动到现在等待最长的一次所花时间 Innodb_row_lock_waits:系统启动后到现在总共等待的次数 对于这5个状态变量，比较重要的主要是： Innodb_row_lock_time_avg （等待平均时长） Innodb_row_lock_waits （等待总次数） Innodb_row_lock_time（等待总时长） 尤其是当等待次数很高，而且每次等待时长也不小的时候，我们就需要分析系统中为什么会有如此多的等待，然后根据分析结果着手制定优化计划。 2.2.6 死锁 set tx_isolation='repeatable-read'; Session_1执行：select * from account where id=1 for update; Session_2执行：select * from account where id=2 for update; Session_1执行：select * from account where id=2 for update; Session_2执行：select * from account where id=1 for update; 查看近期死锁日志信息：show engine innodb status\\G; 大多数情况mysql可以自动检测死锁并回滚产生死锁的那个事务，但是有些情况mysql没法自动检测死锁 2.2.7 优化建议 尽可能让所有数据检索都通过索引来完成，避免无索引行锁升级为表锁 合理设计索引，尽量缩小锁的范围 尽可能减少检索条件，避免间隙锁 尽量控制事务大小，减少锁定资源量和时间长度 尽可能低级别事务隔离 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:18:12 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/nginx/":{"url":"performance/nginx/","title":"nginx","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/nginx/Nginx-config.html":{"url":"performance/nginx/Nginx-config.html","title":"1.Nginx核心模块与配置实践","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、Nginx 简介与安装 知识点： 1、Nginx简介： 2、编译与安装 二、Nginx 架构说明 三、Nginx 配置与使用 知识点 1、配置文件的语法格式： 2、配置第一个静态WEB服务 3、日志配置： 主讲：鲁班 时间：2018/10/12 概要： Nginx 简介 Nginx 架构说明 Nginx 基础配置与使用一、Nginx 简介与安装 知识点： Nginx 简介 Nginx 编译与安装1、Nginx简介： Nginx是一个高性能WEB服务器，除它之外Apache、Tomcat、Jetty、IIS，它们都是Web服务器，或者叫做WWW（World Wide Web）服务器，相应地也都具备Web服务器的基本功能。Nginx 相对基它WEB服务有什么优势呢？ Tomcat、Jetty 面向java语言，先天就是重量级的WEB服务器，其性能与Nginx没有可比性。 IIS只能在Windows操作系统上运行。Windows作为服务器在稳定性与其他一些性能上都不如类UNIX操作系统，因此，在需要高性能Web服务器的场合下IIS并不占优。 Apache的发展时期很长，而且是目前毫无争议的世界第一大Web服务器，其有许多优点，如稳定、开源、跨平台等，但它出现的时间太长了，在它兴起的年代，互联网的产业规模远远比不上今天，所以它被设计成了一个重量级的、不支持高并发的Web服务器。在Apache服务器上，如果有数以万计的并发HTTP请求同时访问，就会导致服务器上消耗大量内存，操作系统内核对成百上千的Apache进程做进程间切换也会消耗大量CPU资源，并导致HTTP请求的平均响应速度降低，这些都决定了Apache不可能成为高性能Web服务器，这也促使了Lighttpd和Nginx的出现。 下图可以看出07年到17 年强劲增长势头。 2、编译与安装 安装环境准备： （1）linux 内核2.6及以上版本: 只有2.6之后才支持epool ，在此之前使用select或pool多路复用的IO模型，无法解决高并发压力的问题。通过命令uname -a 即可查看。 #查看 linux 内核 uname -a （2）GCC编译器 GCC（GNU Compiler Collection）可用来编译C语言程序。Nginx不会直接提供二进制可执行程序,只能下载源码进行编译。 （3）PCRE库 PCRE（Perl Compatible Regular Expressions，Perl兼容正则表达式）是由Philip Hazel开发的函数库，目前为很多软件所使用，该库支持正则表达式。 （4）zlib库 zlib库用于对HTTP包的内容做gzip格式的压缩，如果我们在nginx.conf里配置了gzip on，并指定对于某些类型（content-type）的HTTP响应使用gzip来进行压缩以减少网络传输量。 （5）OpenSSL开发库 如果我们的服务器不只是要支持HTTP，还需要在更安全的SSL协议上传输HTTP，那么就需要拥有OpenSSL了。另外，如果我们想使用MD5、SHA1等散列函数，那么也需要安装它。 上面几个库都是Nginx 基础功能所必需的，为简单起见我们可以通过yum 命令统一安装。 #yum 安装nginx 环境 yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel pcre pcre-devel 源码获取： nginx 下载页：http://nginx.org/en/download.html 。 # 下载nginx 最新稳定版本 wget http://nginx.org/download/nginx-1.14.0.tar.gz #解压 tar -zxvf nginx-1.14.0.tar.gz 最简单的安装： # 全部采用默认安装 ./configure make && make install 执行完成之后 nginx 运行文件 就会被安装在 /usr/local/nginx 下。 基于参数构建 ./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module --with-debug 控制命令： #默认方式启动： ./sbin/nginx #指定配置文件启动 ./sbing/nginx -c /tmp/nginx.conf #指定nginx程序目录启动 ./sbin/nginx -p /usr/local/nginx/ #快速停止 ./sbin/nginx -s stop #优雅停止 ./sbin/nginx -s quit # 热装载配置文件 ./sbin/nginx -s reload # 重新打开日志文件 ./sbin/nginx -s reopen 模块更新： 二、Nginx 架构说明 Nginx 架构图: 架构说明： 1）nginx启动时，会生成两种类型的进程，一个是主进程（Master），一个（windows版本的目前只有一个）和多个工作进程（Worker）。主进程并不处理网络请求，主要负责调度工作进程，也就是图示的三项：加载配置、启动工作进程及非停升级。所以，nginx启动以后，查看操作系统的进程列表，我们就能看到至少有两个nginx进程。 2）服务器实际处理网络请求及响应的是工作进程（worker），在类unix系统上，nginx可以配置多个worker，而每个worker进程都可以同时处理数以千计的网络请求。 3）模块化设计。nginx的worker，包括核心和功能性模块，核心模块负责维持一个运行循环（run-loop），执行网络请求处理的不同阶段的模块功能，如网络读写、存储读写、内容传输、外出过滤，以及将请求发往上游服务器等。而其代码的模块化设计，也使得我们可以根据需要对功能模块进行适当的选择和修改，编译成具有特定功能的服务器。 4）事件驱动、异步及非阻塞，可以说是nginx得以获得高并发、高性能的关键因素，同时也得益于对Linux、Solaris及类BSD等操作系统内核中事件通知及I/O性能增强功能的采用，如kqueue、epoll及event ports。 Nginx 核心模块： 三、Nginx 配置与使用 知识点 配置文件语法格式 配置第一个静态WEB服务 配置案例 动静分离实现 防盗链 多域名站点 下载限速 IP 黑名单 基于user-agent分流 日志配置1、配置文件的语法格式： 先来看一个简单的nginx 配置worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 80; server_name localhost; location / { root html; index index.html index.htm; } location /nginx_status { stub_status on; access_log off; } } } 上述配置中的events、http、server、location、upstream等属于配置项块。而worker_processes 、worker_connections、include、listen 属于配置项块中的属性。 /nginx_status 属于配置块的特定参数参数。其中server块嵌套于http块，其可以直接继承访问Http块当中的参数。 | 配置块 | 名称开头用大口号包裹其对应属性 | |:----|:----| | 属性 | 基于空格切分属性名与属性值，属性值可能有多个项 都以空格进行切分 如： access_log logs/host.access.log main | | 参数 | 其配置在 块名称与大括号间，其值如果有多个也是通过空格进行拆 | 注意 如果配置项值中包括语法符号，比如空格符，那么需要使用单引号或双引号括住配置项值，否则Nginx会报语法错误。例如： log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; 2、配置第一个静态WEB服务 基础站点演示： [ ] 创建站点目录 mkdir -p /usr/www/luban [ ] 编写静态文件 [ ] 配置 nginx.conf [ ] 配置server [ ] 配置location 基本配置介绍说明： （1）监听端口 语法：listen address： 默认：listen 80; 配置块：server （2）主机名称 语法：server_name name[……]; 默认：server_name \"\"; 配置块：server server_name后可以跟多个主机名称，如server_name www.testweb.com、download.testweb.com;。 支持通配符与正则 （3）location 语法：location[=|～|～*|^～|@]/uri/{……} 配置块：server / 基于uri目录匹配 =表示把URI作为字符串，以便与参数中的uri做完全匹配。 ～表示正则匹配URI时是字母大小写敏感的。 ～*表示正则匹配URI时忽略字母大小写问题。 ^～表示正则匹配URI时只需要其前半部分与uri参数匹配即可。 动静分离演示： [ ] 创建静态站点 [ ] 配置 location /static [ ] 配置 ~* .(gif|png|css|js)$ 基于目录动静分离 server { listen 80; server_name *.luban.com; root /usr/www/luban; location / { index luban.html; } location /static { alias /usr/www/static; } } 基于正则动静分离 location ~* \\.(gif|jpg|png|css|js)$ { root /usr/www/static; } 防盗链配置演示： # 加入至指定location 即可实现 valid_referers none blocked *.luban.com; if ($invalid_referer) { return 403; } 下载限速： location /download { limit_rate 1m; limit_rate_after 30m; } 创建IP黑名单 # 创建黑名单文件 echo 'deny 192.168.0.132;' >> balck.ip #http 配置块中引入 黑名单文件 include black.ip; 3、日志配置： 日志格式： log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log logs/access.log main; #基于域名打印日志 access_log logs/$host.access.log main; error日志的设置 语法：error_log /path/file level; 默认：error_log logs/error.log error; level是日志的输出级别，取值范围是debug、info、notice、warn、error、crit、alert、emerg， 针对指定的客户端输出debug级别的日志 语法：debug_connection[IP|CIDR] events { debug_connection 192.168.0.147; debug_connection 10.224.57.0/200; } nginx.conf Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/nginx/Nginx-In-actual-combat.html":{"url":"performance/nginx/Nginx-In-actual-combat.html","title":"2.Nginx 性能优化实践","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、Nginx 反向代理实现 知识点： 2.负载均衡配置与参数解析 3.upstream 负载均衡算法介绍 二、Nginx 高速缓存 知识点： 1、案例分析： 2.Nginx 静态缓存基本配置 3.缓存的清除： 三、Nginx 性能参数调优 主讲：鲁班 时间：2018/10/14 概要： Nginx 反向代理与负载均衡 Nginx 实现高速缓存 Nginx 性能参数调优 一、Nginx 反向代理实现 知识点： 反向代理基本配置 负载均衡配置与参数解析 负载均衡算法详解 反向代理基本配置 提问：什么是反向代理其与正向代理有什么区别？ 正向代理的概念： 正向代理是指客户端与目标服务器之间增加一个代理服务器，客户端直接访问代理服务器，在由代理服务器访问目标服务器并返回客户端并返回 。这个过程当中客户端需要知道代理服务器地址，并配置连接。 反向代理的概念： 反向代理是指 客户端访问目标服务器，在目标服务内部有一个统一接入网关将请求转发至后端真正处理的服务器并返回结果。这个过程当中客户端不需要知道代理服务器地址，代理对客户端而言是透明的。 反向代理与正向代理的区别 | | 正向代理 | 反向代理 | |:----|:----|:----| | 代理服务器位置 | 客户端与服务都能连接的们位置 | 目标服务器内部 | | 主要作用 | 屏蔽客户端IP、集中式缓存、解决客户端不能直连服务端的问题。 | 屏蔽服务端内部实现、负载均衡、缓存。 | | 应用场景 | 爬虫、翻墙、maven 的nexus 服务 | Nginx 、Apache负载均衡应用 | Nginx代理基本配置 Nginx 代理只需要配置 location 中配置proxy_pass 属性即可。其指向代理的服务器地址。 # 正向代理到baidu 服务 location = /baidu.html { proxy_pass http://www.baidu.com; } # 反向代理至 本机的8010服务 location /luban/ { proxy_pass http://127.0.0.1:8010; } 代理相关参数： proxy_pass # 代理服务 proxy_redirect off; # 是否允许重定向 proxy_set_header Host $host; # 传 header 参数至后端服务 proxy_set_header X-Forwarded-For $remote_addr; # 设置request header 即客户端IP 地址 proxy_connect_timeout 90; # 连接代理服务超时时间 proxy_send_timeout 90; # 请求发送最大时间 proxy_read_timeout 90; # 读取最大时间 proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; 2.负载均衡配置与参数解析 通过proxy_pass 可以把请求代理至后端服务，但是为了实现更高的负载及性能， 我们的后端服务通常是多个， 这个是时候可以通过upstream 模块实现负载均衡。 演示upstream 的实现。 upstream backend { server 127.0.0.1:8010 weight=1; server 127.0.0.1:8080 weight=2; } location / { proxy_pass http://backend; } upstream 相关参数: service 反向服务地址 加端口 weight 权重 max_fails 失败多少次 认为主机已挂掉则，踢出 fail_timeout 踢出后重新探测时间 backup 备用服务 max_conns 允许最大连接数 slow_start 当节点恢复，不立即加入,而是等待 slow_start 后加入服务对列。3.upstream 负载均衡算法介绍 ll+weight： 轮询加权重 (默认) ip_hash : 基于Hash 计算 ,用于保持session 一至性 url_hash: 静态资源缓存,节约存储，加快速度（第三方） least_conn ：最少链接（第三方） least_time ：最小的响应时间,计算节点平均响应时间，然后取响应最快的那个，分配更高权重（第三方）二、Nginx 高速缓存 知识点： 缓存案例分析 Nginx 静态缓存基本配置 缓存更新 1、案例分析： 某电商平台商品详情页需要实现 700+ QPS，如何着手去做？ 首先为分析一下一个商品详情页有哪些信息 从中得出 商品详情页依懒了 对于商品详情页涉及了如下主要服务： 商品详情页HTML页面渲染 价格服务 促销服务 库存状态/配送至服务 广告词服务 预售/秒杀服务 评价服务 试用服务 推荐服务 商品介绍服务 各品类相关的一些特殊服务 解决方案： 采用Ajax 动态加载 价格、广告、库存等服务 采用key value 缓存详情页主体html。 方案架构： 问题： 当达到500QPS 的时候很难继续压测上去。 分析原因：一个详情页html 主体达平均150 kb 那么在500QPS 已接近千M局域网宽带极限。必须减少内网通信。 基于Nginx 静态缓存的解决方案： 2.Nginx 静态缓存基本配置 一、在http元素下添加缓存区声明。 #proxy_cache_path 缓存路径 #levels 缓存层级及目录位数 #keys_zone 缓存区内存大小 #inactive 有效期 #max_size 硬盘大小 proxy_cache_path /data/nginx/cache_luban levels=1:2 keys_zone=cache_luban:500m inactive=20d max_size=1g; 二、为指定location 设定缓存策略。 # 指定缓存区 proxy_cache cache_luban; #以全路径md5值做做为Key proxy_cache_key $host$uri$is_args$args; #对不同的HTTP状态码设置不同的缓存时间 proxy_cache_valid 200 304 12h; 演示缓存生效过程 [ ] 配置声明缓存路径 [ ] 为location 配置缓存策略 [ ] 重启nginx（修改了） [ ] 查看缓存目录生成 缓存参数详细说明| 父元素 | 名称 | 描述 | |:----|:----|:----| | http | proxy_cache_path | 指定缓存区的根路径 | | | levels | 缓存目录层级最高三层，每层1~2个字符表示。如1:1:2 表示三层。 | | | keys_zone | 缓存块名称 及内存块大小。如 cache_item:500m 。表示声明一个名为cache_item 大小为500m。超出大小后最早的数据将会被清除。 | | | inactive | 最长闲置时间 如:10d 如果一个数据被闲置10天将会被清除 | | | max_size | 缓存区硬盘最大值。超出闲置数据将会被清除 | | location | proxy_cache | 指定缓存区，对应keys_zone 中设置的值 | | | proxy_cache_key | 通过参数拼装缓存key 如：$host$uri$is_args$args 则会以全路径md5值做做为Key | | | proxy_cache_valid | 为不同的状态码设置缓存有效期 | 3.缓存的清除： 该功能可以采用第三方模块 ngx_cache_purge 实现。 为nginx 添加 ngx_cache_purge 模块 #下载ngx_cache_purge 模块包 ,这里nginx 版本为1.6.2 purge 对应2.0版 wget http://labs.frickle.com/files/ngx_cache_purge-2.3.tar.gz #查看已安装模块 ./sbin/nginx -V #进入nginx安装包目录 重新安装 --add-module为模块解压的全路径 ./configure --prefix=/root/svr/nginx --with-http_stub_status_module --with-http_ssl_module --add-module=/root/svr/nginx/models/ngx_cache_purge-2.0 #重新编译 make #拷贝 安装目录/objs/nginx 文件用于替换原nginx 文件 #检测查看安装是否成功 nginx -t 清除配置： location ~ /clear(/.*) { #允许访问的IP allow 127.0.0.1; allow 192.168.0.193; #禁止访问的IP deny all; #配置清除指定缓存区和路径(与proxy_cache_key一至) proxy_cache_purge cache_item $host$1$is_args$args; } 配置好以后 直接访问 ： # 访问生成缓存文件 http://www.luban.com/?a=1 # 清除生成的缓存,如果指定缓存不存在 则会报404 错误。 http://www.luban.com/clear/?a=1 三、Nginx 性能参数调优 worker_processes number; 每个worker进程都是单线程的进程，它们会调用各个模块以实现多种多样的功能。如果这些模块确认不会出现阻塞式的调用，那么，有多少CPU内核就应该配置多少个进程；反之，如果有可能出现阻塞式调用，那么需要配置稍多一些的worker进程。例如，如果业务方面会致使用户请求大量读取本地磁盘上的静态资源文件，而且服务器上的内存较小，以至于大部分的请求访问静态资源文件时都必须读取磁盘（磁头的寻址是缓慢的），而不是内存中的磁盘缓存，那么磁盘I/O调用可能会阻塞住worker进程少量时间，进而导致服务整体性能下降。 每个worker 进程的最大连接数 语法：worker_connections number; 默认：worker_connections 1024 worker_cpu_affinity cpumask[cpumask……] 绑定Nginx worker进程到指定的CPU内核 为什么要绑定worker进程到指定的CPU内核呢？假定每一个worker进程都是非常繁忙的，如果多个worker进程都在抢同一个CPU，那么这就会出现同步问题。反之，如果每一个worker进程都独享一个CPU，就在内核的调度策略上实现了完全的并发。 例如，如果有4颗CPU内核，就可以进行如下配置： worker_processes 4; worker_cpu_affinity 1000 0100 0010 0001; 注意 worker_cpu_affinity配置仅对Linux操作系统有效。 Nginx worker 进程优先级设置 语法：worker_priority nice; 默认：worker_priority 0; 优先级由静态优先级和内核根据进程执行情况所做的动态调整（目前只有±5的调整）共同决定。nice值是进程的静态优先级，它的取值范围是–20～+19，–20是最高优先级，+19是最低优先级。因此，如果用户希望Nginx占有更多的系统资源，那么可以把nice值配置得更小一些，但不建议比内核进程的nice值（通常为–5）还要小 Nginx worker进程可以打开的最大句柄描述符个数 语法： worker_rlimit_nofile limit; 默认：空 更改worker进程的最大打开文件数限制。如果没设置的话，这个值为操作系统的限制。设置后你的操作系统和Nginx可以处理比“ulimit -a”更多的文件，所以把这个值设高，这样nginx就不会有“too many open files”问题了。 是否打开accept锁 语法：accept_mutex[on|off] 默认：accept_mutext on; accept_mutex是Nginx的负载均衡锁，当某一个worker进程建立的连接数量达到worker_connections配置的最大连接数的7/8时，会大大地减小该worker进程试图建立新TCP连接的机会，accept锁默认是打开的，如果关闭它，那么建立TCP连接的耗时会更短，但worker进程之间的负载会非常不均衡，因此不建议关闭它。 使用accept锁后到真正建立连接之间的延迟时间 语法：accept_mutex_delay Nms; 默认：accept_mutex_delay 500ms; 在使用accept锁后，同一时间只有一个worker进程能够取到accept锁。这个accept锁不是堵塞锁，如果取不到会立刻返回。如果只有一个worker进程试图取锁而没有取到，他至少要等待accept_mutex_delay定义的时间才能再次试图取锁。 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/tomcat/":{"url":"performance/tomcat/","title":"tomcat","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/tomcat/Tomcat-pro-use.html":{"url":"performance/tomcat/Tomcat-pro-use.html","title":"1.Tomcat生产环境应用","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、Tomcat各组件认知 2.Tomcat 各组件及关系 3.Tomcat启动参数说明 二、Tomcat server.xml 配置详解 三、Tomcat IO模型介绍 1、Tomcat支持的IO模型说明 2、BIO 与NIO有什么区别 概要： Tomcat各核心组件认知 Tomcat server.xml 配置详解 Tomcat IO模型介绍 一、Tomcat各组件认知 知识点： Tomcat架构说明 Tomcat组件及关系详情介绍 Tomcat启动参数说明 Tomcat架构说明 Tomcat是一个基于JAVA的WEB容器，其实现了JAVA EE中的 Servlet 与 jsp 规范，与Nginx apache 服务器不同在于一般用于动态请求处理。在架构设计上采用面向组件的方式设计。即整体功能是通过组件的方式拼装完成。另外每个组件都可以被替换以保证灵活性。 那么是哪些组件组成了Tomcat呢？ 2.Tomcat 各组件及关系 Server 和 Service Connector 连接器 HTTP 1.1 SSL https AJP（ Apache JServ Protocol） apache 私有协议，用于apache 反向代理Tomcat Container Engine 引擎 catalina Host 虚拟机 基于域名 分发请求 Context 隔离各个WEB应用 每个Context的 ClassLoader都是独立 Component Manager （管理器） logger （日志管理） loader （载入器） pipeline (管道) valve （管道中的阀） 3.Tomcat启动参数说明 我们平时启动Tomcat过程是怎么样的？ 复制WAR包至Tomcat webapp 目录。 执行starut.bat 脚本启动。 启动过程中war 包会被自动解压装载。 但是我们在Eclipse 或idea 中启动WEB项目的时候 也是把War包复杂至webapps 目录解压吗？显然不是，其真正做法是在Tomcat程序文件之外创建了一个部署目录，在一般生产环境中也是这么做的 即：Tomcat 程序目录和部署目录分开 。 我们只需要在启动时指定CATALINA_HOME 与 CATALINA_BASE 参数即可实现。 启动参数 描述说明 JAVA_OPTS jvm 启动参数 , 设置内存 编码等 -Xms100m -Xmx200m -Dfile.encoding=UTF-8 JAVA_HOME 指定jdk 目录，如果未设置从java 环境变量当中去找。 CATALINA_HOME Tomcat 程序根目录 CATALINA_BASE 应用部署目录，默认为$CATALINA_HOME CATALINA_OUT 应用日志输出目录：默认$CATALINA_BASE/log CATALINA_TMPDIR 应用临时目录：默认：$CATALINA_BASE/temp 可以编写一个脚本 来实现自定义配置： 演示自定义启动Tomcat [ ] 下载并解压Tomcat [ ] 创建并拷贝应用目录 [ ] 创建Tomcat.sh [ ] 编写Tomcat.sh [ ] chmod +x tomcat.sh 添加执行权限 [ ] 拷贝conf 、webapps 、logs至应用目录。 [ ] 执行启动测试。 ```powershell!/bin/bash export JAVA_OPTS=\"-Xms100m -Xmx200m\" export JAVA_HOME=/root/svr/jdk/ export CATALINA_HOME=/usr/local/apache-tomcat-8.5.34 export CATALINA_BASE=\"pwd\" case $1 in start) $CATALINA_HOME/bin/catalina.sh start echo start success!! ;; stop) $CATALINA_HOME/bin/catalina.sh stop echo stop success!! ;; restart) $CATALINA_HOME/bin/catalina.sh stop echo stop success!! sleep 2 $CATALINA_HOME/bin/catalina.sh start echo start success!! ;; version) $CATALINA_HOME/bin/catalina.sh version ;; configtest) $CATALINA_HOME/bin/catalina.sh configtest ;; esac exit 0 ## 二、Tomcat server.xml 配置详解 --- Server 的基本基本配置： ```xml 元素说明： server root元素：server 的顶级配置 主要属性: port：执行关闭命令的端口号 shutdown：关闭命令 [ ] 演示shutdown的用法#基于telent 执行SHUTDOWN 命令即可关闭 telent 127.0.0.1 8005 SHUTDOWN service 服务：将多个connector 与一个Engine组合成一个服务，可以配置多个服务。 Connector 连接器：用于接收 指定协议下的连接 并指定给唯一的Engine 进行处理。 主要属性： protocol 监听的协议，默认是http/1.1 port 指定服务器端要创建的端口号 minThread 服务器启动时创建的处理请求的线程数 maxThread 最大可以创建的处理请求的线程数 enableLookups 如果为true，则可以通过调用request.getRemoteHost()进行DNS查询来得到远程客户端的实际主机名，若为false则不进行DNS查询，而是返回其ip地址 redirectPort 指定服务器正在处理http请求时收到了一个SSL传输请求后重定向的端口号 acceptCount 指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理 connectionTimeout 指定超时的时间数(以毫秒为单位) SSLEnabled 是否开启 sll 验证，在Https 访问时需要开启。 [ ] 演示配置多个Connector Engine 引擎：用于处理连接的执行器，默认的引擎是catalina。一个service 中只能配置一个Engine。 主要属性：name 引擎名称 defaultHost 默认host Host 虚拟机：基于域名匹配至指定虚拟机。类似于nginx 当中的server,默认的虚拟机是localhost. 主要属性： [ ] 演示配置多个Host Context 应用上下文：一个host 下可以配置多个Context ，每个Context 都有其独立的classPath。相互隔离，以免造成ClassPath 冲突。 主要属性： [ ] 演示配置多个Context Valve 阀门：可以理解成request 的过滤器，具体配置要基于具体的Valve 接口的子类。以下即为一个访问日志的Valve. 三、Tomcat IO模型介绍 知识点： Tomcat支持的IO模型说明 BIO 与NIO的区别 IO模型源码解读1、Tomcat支持的IO模型说明 | | 描述 | |:----|:----| | BIO | 阻塞式IO，即Tomcat使用传统的java.io进行操作。该模式下每个请求都会创建一个线程，对性能开销大，不适合高并发场景。优点是稳定，适合连接数目小且固定架构。 | | NIO | 非阻塞式IO，jdk1.4 之后实现的新IO。该模式基于多路复用选择器监测连接状态在通知线程处理，从而达到非阻塞的目的。比传统BIO能更好的支持并发性能。Tomcat 8.0之后默认采用该模式 | | APR | 全称是 Apache Portable Runtime/Apache可移植运行库)，是Apache HTTP服务器的支持库。可以简单地理解为，Tomcat将以JNI的形式调用Apache HTTP服务器的核心动态链接库来处理文件读取或网络传输操作。使用需要编译安装APR 库 | | AIO | 异步非阻塞式IO，jdk1.7后之支持 。与nio不同在于不需要多路复用选择器，而是请求处理线程执行完程进行回调调知，已继续执行后续操作。Tomcat 8之后支持。 | | | | 使用指定IO模型的配置方式: 配置 server.xml 文件当中的 修改即可。 默认配置 8.0 protocol=“HTTP/1.1” 8.0 之前是 BIO 8.0 之后是NIO BIO protocol=“org.apache.coyote.http11.Http11Protocol“ NIO protocol=”org.apache.coyote.http11.Http11NioProtocol“ AIO protocol=”org.apache.coyote.http11.Http11Nio2Protocol“ APR protocol=”org.apache.coyote.http11.Http11AprProtocol“ 2、BIO 与NIO有什么区别 分别演示在高并发场景下BIO与NIO的线程数的变化？ 演示数据： | | 每秒提交数 | BIO执行线程 | NIO执行线程 | | |:----|:----|:----|:----|:----| | 预测 | 200 | 200 | 50 | | | 实验环境 | 200 | 48 | 37 | | | 生产环境 | 200 | 419 | 23 | | 结论： BIO 线程模型讲解 NIO 线程模型讲解 BIO 源码解读 Http11Protocol Http BIO协议解析器 JIoEndpoint Acceptor implements Runnable SocketProcessor implements Runnable Http11NioProtocol Http Nio协议解析器 NioEndpoint Acceptor implements Runnable Poller implements Runnable SocketProcessor implements Runnable Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/":{"url":"distributed/","title":"五、分布式框架专题","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/zookeeper/":{"url":"distributed/zookeeper/","title":"zookeeper","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/zookeeper/zookeeper-base-use.html":{"url":"distributed/zookeeper/zookeeper-base-use.html","title":"1.特性与节点说明","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、zookeeper概要、背景及作用 zookeeper产生背景： zookeeper概要： znode 节点 二、部署与常规配置 版本说明： 常规配置文件说明： 客户端命令： 三、Zookeeper节点介绍 知识点： 节点类型 节点属性 节点的监听： acl权限设置 主题概要 zookeeper概要、背景及作用 部署与常规配置 节点类型 一、zookeeper概要、背景及作用 zookeeper产生背景： 项目从单体到分布式转变之后，将会产生多个节点之间协同的问题。如： 每天的定时任务由谁哪个节点来执行？ RPC调用时的服务发现? 如何保证并发请求的幂等 .... 这些问题可以统一归纳为多节点协调问题，如果靠节点自身进行协调这是非常不可靠的，性能上也不可取。必须由一个独立的服务做协调工作，它必须可靠，而且保证性能。 zookeeper概要： ZooKeeper是用于分布式应用程序的协调服务。它公开了一组简单的API，分布式应用程序可以基于这些API用于同步，节点状态、配置等信息、服务注册等信息。其由JAVA编写，支持JAVA 和C两种语言的客户端。 znode 节点 zookeeper 中数据基本单元叫节点，节点之下可包含子节点，最后以树级方式程现。每个节点拥有唯一的路径path。客户端基于PATH上传节点数据，zookeeper 收到后会实时通知对该路径进行监听的客户端。 二、部署与常规配置 zookeeper 基于JAVA开发，下载后只要有对应JVM环境即可运行。其默认的端口号是2181运行前得保证其不冲突。 版本说明： 2019年5月20日发行的3.5.5是3.5分支的第一个稳定版本。此版本被认为是3.4稳定分支的后续版本，可以用于生产。基于3.4它包含以下新功能 动态重新配置 本地会议 新节点类型：容器，TTL 原子广播协议的SSL支持 删除观察者的能力 多线程提交处理器 升级到Netty 4.1 Maven构建 另请注意：建议的最低JDK版本为1.8 文件说明： apache-zookeeper-xxx-tar.gz 代表源代码 apache-zookeeper-xxx-bin.tar.gz 运行版本 下载地址：https://zookeeper.apache.org/releases.html#download 具体部署流程： #下载 wget https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/current/apache-zookeeper-3.5.5-bin.tar.gz #解压 tar -zxvf apache-zookeeper-3.5.5-bin.tar.gz #拷贝默认配置 cd {zookeeper_home}/conf cp zoo_sample.cfg zoo.cfg #启动 {zookeeper_home}/bin/zkServer.sh 常规配置文件说明： # zookeeper时间配置中的基本单位 (毫秒) tickTime=2000 # 允许follower初始化连接到leader最大时长，它表示tickTime时间倍数 即:initLimit*tickTime initLimit=10 # 允许follower与leader数据同步最大时长,它表示tickTime时间倍数 syncLimit=5 #zookeper 数据存储目录 dataDir=/tmp/zookeeper #对客户端提供的端口号 clientPort=2181 #单个客户端与zookeeper最大并发连接数 maxClientCnxns=60 # 保存的数据快照数量，之外的将会被清除 autopurge.snapRetainCount=3 #自动触发清除任务时间间隔，小时为单位。默认为0，表示不自动清除。 autopurge.purgeInterval=1 客户端命令： 基本命令列表 close 关闭当前会话 connect host:port 重新连接指定Zookeeper服务 create [-s] [-e] [-c] [-t ttl] path [data] [acl] 创建节点 delete [-v version] path 删除节点，(不能存在子节点） deleteall path 删除路径及所有子节点 setquota -n|-b val path 设置节点限额 -n 子节点数 -b 字节数 listquota path 查看节点限额 delquota [-n|-b] path 删除节点限额 get [-s] [-w] path 查看节点数据 -s 包含节点状态 -w 添加监听 getAcl [-s] path ls [-s] [-w] [-R] path 列出子节点 -s状态 -R 递归查看所有子节点 -w 添加监听 printwatches on|off 是否打印监听事件 quit 退出客户端 history 查看执行的历史记录 redo cmdno 重复 执行命令，history 中命令编号确定 removewatches path [-c|-d|-a] [-l] 删除指定监听 set [-s] [-v version] path data 设置值 setAcl [-s] [-v version] [-R] path acl 为节点设置ACL权限 stat [-w] path 查看节点状态 -w 添加监听 sync path 强制同步节点 node数据的增删改查 # 列出子节点 ls / #创建节点 create /luban \"luban is good man\" # 查看节点 get /luban # 创建子节点 create /luban/sex \"man\" # 删除节点 delete /luban/sex # 删除所有节点 包括子节点 deleteall /luban 三、Zookeeper节点介绍 知识点： 节点类型 节点的监听(watch) 节点属性说明(stat) 权限设置(acl) zookeeper 中节点叫znode存储结构上跟文件系统类似，以树级结构进行存储。不同之外在于znode没有目录的概念，不能执行类似cd之类的命令。znode结构包含如下： path:唯一路径 childNode：子节点 stat:状态属性 type:节点类型 节点类型 | 类型 | 描述 | |:----|:----| | PERSISTENT | 持久节点 | | PERSISTENT_SEQUENTIAL | 持久序号节点 | | EPHEMERAL | 临时节点(不可在拥有子节点) | | EPHEMERAL_SEQUENTIAL | 临时序号节点(不可在拥有子节点) | PERSISTENT（持久节点） 持久化保存的节点，也是默认创建的 #默认创建的就是持久节点 create /test PERSISTENT_SEQUENTIAL(持久序号节点) 创建时zookeeper 会在路径上加上序号作为后缀，。非常适合用于分布式锁、分布式选举等场景。创建时添加 -s 参数即可。 #创建序号节点 create -s /test #返回创建的实际路径 Created /test0000000001 create -s /test #返回创建的实际路径2 Created /test0000000002 EPHEMERAL（临时节点） 临时节点会在客户端会话断开后自动删除。适用于心跳，服务发现等场景。创建时添加参数-e 即可。 #创建临时节点， 断开会话 在连接将会自动删除 create -e /temp EPHEMERAL_SEQUENTIAL（临时序号节点） 与持久序号节点类似，不同之处在于EPHEMERAL_SEQUENTIAL是临时的会在会话断开后删除。创建时添加 -e -s create -e -s /temp/seq 节点属性 # 查看节点属性 stat /luban 其属性说明如下表： #创建节点的事物ID cZxid = 0x385 #创建时间 ctime = Tue Sep 24 17:26:28 CST 2019 #修改节点的事物ID mZxid = 0x385 #最后修改时间 mtime = Tue Sep 24 17:26:28 CST 2019 # 子节点变更的事物ID pZxid = 0x385 #这表示对此znode的子节点进行的更改次数（不包括子节点） cversion = 0 # 数据版本，变更次数 dataVersion = 0 #权限版本，变更次数 aclVersion = 0 #临时节点所属会话ID ephemeralOwner = 0x0 #数据长度 dataLength = 17 #子节点数(不包括子子节点) numChildren = 0 节点的监听： 客户添加 -w 参数可实时监听节点与子节点的变化，并且实时收到通知。非常适用保障分布式情况下的数据一至性。其使用方式如下： | 命令 | 描述 | |:----|:----| | ls -w path | 监听子节点的变化（增，删） | | get -w path | 监听节点数据的变化 | | stat -w path | 监听节点属性的变化 | | printwatches on|off | 触发监听后，是否打印监听事件(默认on) | acl权限设置 ACL全称为Access Control List（访问控制列表），用于控制资源的访问权限。ZooKeeper使用ACL来控制对其znode的防问。基于scheme:id:permission的方式进行权限控制。scheme表示授权模式、id模式对应值、permission即具体的增删改权限位。 scheme:认证模型 | 方案 | 描述 | |:----|:----| | world | 开放模式，world表示全世界都可以访问（这是默认设置） | | ip | ip模式，限定客户端IP防问 | | auth | 用户密码认证模式，只有在会话中添加了认证才可以防问 | | digest | 与auth类似，区别在于auth用明文密码，而digest 用sha-1+base64加密后的密码。在实际使用中digest 更常见。 | permission权限位 | 权限位 | 权限 | 描述 | |:----|:----|:----| | c | CREATE | 可以创建子节点 | | d | DELETE | 可以删除子节点（仅下一级节点） | | r | READ | 可以读取节点数据及显示子节点列表 | | w | WRITE | 可以设置节点数据 | | a | ADMIN | 可以设置节点访问控制列表权限 | acl 相关命令： | 命令 | 使用方式 | 描述 | |:----|:----|:----| | getAcl | getAcl | 读取ACL权限 | | setAcl | setAcl | 设置ACL权限 | | addauth | addauth | 添加认证用户 | world权限**示例** 语法： setAcl world:anyone: 注：world模式中anyone是唯一的值,表示所有人 查看默认节点权限： #创建一个节点 create -e /testAcl #查看节点权限 getAcl /testAcl #返回的默认权限表示 ，所有人拥有所有权限。 'world,'anyone: cdrwa 修改默认权限为 读写 #设置为rw权限 setAcl /testAcl world:anyone:rw # 可以正常读 get /testAcl # 无法正常创建子节点 create -e /testAcl/t \"hi\" # 返回没有权限的异常 Authentication is not valid : /testAcl/t IP权限示例： 语法： setAcl ip:: auth模式示例: 语法： setAcl auth::: addauth digest : digest 权限示例： 语法： setAcl digest ::: addauth digest : 注1：密钥 通过sha1与base64组合加密码生成，可通过以下命令生成 echo -n : | openssl dgst -binary -sha1 | openssl base64 注2：为节点设置digest 权限后，访问前必须执行addauth，当前会话才可以防问。 设置digest 权限 #先 sha1 加密，然后base64加密 echo -n luban:123456 | openssl dgst -binary -sha1 | openssl base64 #返回密钥 2Rz3ZtRZEs5RILjmwuXW/wT13Tk= #设置digest权限 setAcl /luban digest:luban:2Rz3ZtRZEs5RILjmwuXW/wT13Tk=:cdrw 查看节点将显示没有权限 #查看节点 get /luban #显示没有权限访问 org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /luban 给当前会话添加认证后在次查看 #给当前会话添加权限帐户 addauth digest luban:123456 #在次查看 get /luban #获得返回结果 luban is good man ACL的特殊说明： 权限仅对当前节点有效，不会让子节点继承。如限制了IP防问A节点，但不妨碍该IP防问A的子节点 /A/B。 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/zookeeper/zookeeper-client-use.html":{"url":"distributed/zookeeper/zookeeper-client-use.html","title":"2.客户端使用与集群特性","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、客户端API常规应用 2.创建、查看节点 3.监听节点 4.设置节点ACL权限 5.第三方客户端ZkClient 二、Zookeeper集群 3.选举机制 5.四字运维命令 主要内容： 客户端 zookeeper客户端简介，C客户端 客户端连接参数说明 客户端CRUD 客户端监听 集群 集群架构说明 集群配置及参数说明 选举投票机制 主从复制机制一、客户端API常规应用 zookeeper 提供了java与C两种语言的客户端。我们要学习的就是java客户端。引入最新的maven依赖： org.apache.zookeeper zookeeper 3.5.5 知识点： 初始连接 创建、查看节点 监听节点 设置节点权限 第三方客户端ZkClient 初始连接： 常规的客户端类是 org.apache.zookeeper.ZooKeeper，实例化该类之后将会自动与集群建立连接。构造参数说明如下： | 参数名称 | 类型 | 说明 | |:----|:----|:----|:----:| | connectString | String | 连接串，包括ip+端口 ,集群模式下用逗号隔开 192.168.0.149:2181,192.168.0.150:2181 | | sessionTimeout | int | 会话超时时间，该值不能超过服务端所设置的 minSessionTimeout 和maxSessionTimeout | | watcher | Watcher | 会话监听器，服务端事件将会触该监听 | | sessionId | long | 自定义会话ID | | sessionPasswd | byte[] | 会话密码 | | canBeReadOnly | boolean | 该连接是否为只读的 | | hostProvider | HostProvider | 服务端地址提供者，指示客户端如何选择某个服务来调用，默认采用StaticHostProvider实现 | 2.创建、查看节点 创建节点 通过org.apache.zookeeper.ZooKeeper#create()即可创建节点，其参数说明如下： | 参数名称 | 类型 | 说明 | |:----|:----|:----| | path | String | | | data | byte[] | | | acl | List | | | createMode | CreateMode | | | cb | StringCallback | | | ctx | Object | | 查看节点： 通过org.apache.zookeeper.ZooKeeper#getData()即可创建节点，其参数说明如下： | 参数名称 | 类型 | 说明 | |:----|:----|:----| | path | String | | | watch | boolean | | | watcher | Watcher | | | cb | DataCallback | | | ctx | Object | | 查看子节点： 通过org.apache.zookeeper.ZooKeeper#getChildren()即可获取子节点，其参数说明如下： | 参数名称 | 类型 | 说明 | |:----:|:----:|:----| | path | String | | | watch | boolean | | | watcher | Watcher | | | cb | Children2Callback | | | ctx | Object | | 3.监听节点 在getData() 与getChildren()两个方法中可分别设置监听数据变化和子节点变化。通过设置watch为true，当前事件触发时会调用zookeeper()构建函数中Watcher.process()方法。也可以添加watcher参数来实现自定义监听。一般采用后者。 注：所有的监听都是一次性的，如果要持续监听需要触发后在添加一次监听。 4.设置节点ACL权限 ACL包括结构为scheme:id:permission（有关ACL的介绍参照第一节课关于ACL的讲解） 客户端中由org.apache.zookeeper.data.ACL 类表示，类结构如下： ACL Id scheme // 对应权限模式scheme id // 对应模式中的id值 perms // 对应权限位permission 关于权限位的表示方式： 每个权限位都是一个唯一数字，将其合时通过或运行生成一个全新的数字即可 @InterfaceAudience.Public public interface Perms { int READ = 1 5.第三方客户端ZkClient zkClient 是在zookeeper客户端基础之上封装的，使用上更加友好。主要变化如下： 可以设置持久监听，或删除某个监听 可以插入JAVA对象，自动进行序列化和反序列化 简化了基本的增删改查操作。 二、Zookeeper集群 知识点： 集群部署 集群角色说明 选举机制 数据提交机制 集群配置说明 zookeeper集群的目的是为了保证系统的性能承载更多的客户端连接设专门提供的机制。通过集群可以实现以下功能： 读写分离：提高承载，为更多的客户端提供连接，并保障性能。 主从自动切换：提高服务容错性，部分节点故障不会影响整个服务集群。 半数以上运行机制说明： 集群至少需要三台服务器，并且强烈建议使用奇数个服务器。因为zookeeper 通过判断大多数节点的存活来判断整个服务是否可用。比如3个节点，挂掉了2个表示整个集群挂掉，而用偶数4个，挂掉了2个也表示其并不是大部分存活，因此也会挂掉。 集群部署 配置语法： server.=:: 节点**ID**：服务id手动指定1至125之间的数字，并写到对应服务节点的 {dataDir}/myid 文件中。 IP地址：节点的远程IP地址，可以相同。但生产环境就不能这么做了，因为在同一台机器就无法达到容错的目的。所以这种称作为伪集群。 数据同步端口：主从同时数据复制端口，（做伪集群时端口号不能重复）。 远举端口：主从节点选举端口，（做伪集群时端口号不能重复）。 配置文件示例： tickTime=2000 dataDir=/var/lib/zookeeper/ clientPort=2181 initLimit=5 syncLimit=2 #以下为集群配置，必须配置在所有节点的zoo.cfg文件中 server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 集群配置流程： 分别创建3个data目录用于存储各节点数据mkdir data mkdir data/1 mkdir data/3 mkdir data/3 编写myid文件echo 1 > data/1/myid echo 3 > data/3/myid echo 2 > data/2/myid 3、编写配置文件 conf/zoo1.cfg tickTime=2000 initLimit=10 syncLimit=5 dataDir=data/1 clientPort=2181 #集群配置 server.1=127.0.0.1:2887:3887 server.2=127.0.0.1:2888:3888 server.3=127.0.0.1:2889:3889 conf/zoo2.cfg tickTime=2000 initLimit=10 syncLimit=5 dataDir=data/2 clientPort=2182 #集群配置 server.1=127.0.0.1:2887:3887 server.2=127.0.0.1:2888:3888 server.3=127.0.0.1:2889:3889 conf/zoo3.cfg tickTime=2000 initLimit=10 syncLimit=5 dataDir=data/3 clientPort=2183 #集群配置 server.1=127.0.0.1:2887:3887 server.2=127.0.0.1:2888:3888 server.3=127.0.0.1:2889:3889 4.分别启动 ./bin/zkServer.sh start conf/zoo1.cfg ./bin/zkServer.sh start conf/zoo2.cfg ./bin/zkServer.sh start conf/zoo3.cfg 5.分别查看状态 ./bin/zkServer.sh status conf/zoo1.cfg Mode: follower ./bin/zkServer.sh status conf/zoo2.cfg Mode: leader ./bin/zkServer.sh status conf/zoo3.cfg Mode: follower 检查集群复制情况： 1、分别连接指定节点 zkCli.sh 后加参数-server 表示连接指定IP与端口。 ./bin/zkCli.sh -server 127.0.0.1:2181 ./bin/zkCli.sh -server 127.0.0.1:2182 ./bin/zkCli.sh -server 127.0.0.1:2183 [ ] 任意节点中创建数据，查看其它节点已经同步成功。 注意： -server参数后同时连接多个服务节点，并用逗号隔开 127.0.0.1:2181,127.0.0.1:2182 集群角色说明 zookeeper 集群中总共有三种角色，分别是leader（主节点）follower(子节点) observer（次级子节点） | 角色 | 描述 | |:----|:----| | leader | 主节点，又名领导者。用于写入数据，通过选举产生，如果宕机将会选举新的主节点。 | | follower | 子节点，又名追随者。用于实现数据的读取。同时他也是主节点的备选节点，并用拥有投票权。 | | observer | 次级子节点，又名观察者。用于读取数据，与fllower区别在于没有投票权，不能选为主节点。并且在计算集群可用状态时不会将observer计算入内。 | observer配置： 只要在集群配置中加上observer后缀即可，示例如下： server.3=127.0.0.1:2889:3889:observer 3.选举机制 通过 ./bin/zkServer.sh status 命令可以查看到节点状态 ./bin/zkServer.sh status conf/zoo1.cfg Mode: follower ./bin/zkServer.sh status conf/zoo2.cfg Mode: leader ./bin/zkServer.sh status conf/zoo3.cfg Mode: follower 可以发现中间的2182 是leader状态.其选举机制如下图： 投票机制说明： 第一轮投票全部投给自己 第二轮投票给myid比自己大的相邻节点 如果得票超过半数，选举结束。 选举触发： 当集群中的服务器出现已下两种情况时会进行Leader的选举 服务节点初始化启动 半数以上的节点无法和Leader建立连接 当节点初始起动时会在集群中寻找Leader节点，如果找到则与Leader建立连接，其自身状态变化follower或observer。如果没有找到Leader，当前节点状态将变化LOOKING，进入选举流程。 在集群运行其间如果有follower或observer节点宕机只要不超过半数并不会影响整个集群服务的正常运行。但如果leader宕机，将暂停对外服务，所有follower将进入LOOKING 状态，进入选举流程。 数据同步机制 zookeeper 的数据同步是为了保证各节点中数据的一至性，同步时涉及两个流程，一个是正常的客户端数据提交，另一个是集群某个节点宕机在恢复后的数据同步。 客户端写入请求： 写入请求的大至流程是，收leader接收客户端写请求，并同步给各个子节点。如下图： 但实际情况要复杂的多，比如client 它并不知道哪个节点是leader 有可能写的请求会发给follower ，由follower在转发给leader进行同步处理 客户端写入流程说明： client向zk中的server发送写请求，如果该server不是leader，则会将该写请求转发给leader server，leader将请求事务以proposal形式分发给follower； 当follower收到收到leader的proposal时，根据接收的先后顺序处理proposal； 当Leader收到follower针对某个proposal过半的ack后，则发起事务提交，重新发起一个commit的proposal Follower收到commit的proposal后，记录事务提交，并把数据更新到内存数据库； 当写成功后，反馈给client。 服务节点初始化同步： 在集群运行过程当中如果有一个follower节点宕机，由于宕机节点没过半，集群仍然能正常服务。当leader 收到新的客户端请求，此时无法同步给宕机的节点。造成数据不一至。为了解决这个问题，当节点启动时，第一件事情就是找当前的Leader，比对数据是否一至。不一至则开始同步,同步完成之后在进行对外提供服务。 如何比对Leader的数据版本呢，这里通过ZXID事物ID来确认。比Leader就需要同步。 ZXID说明： ZXID是一个长度64位的数字，其中低32位是按照数字递增，任何数据的变更都会导致,低32位的数字简单加1。高32位是leader周期编号，每当选举出一个新的leader时，新的leader就从本地事物日志中取出ZXID,然后解析出高32位的周期编号，进行加1，再将低32位的全部设置为0。这样就保证了每次新选举的leader后，保证了ZXID的唯一性而且是保证递增的。 思考题： 如果leader 节点宕机，在恢复后它还能被选为leader吗？ 5.四字运维命令 ZooKeeper响应少量命令。每个命令由四个字母组成。可通过telnet或nc向ZooKeeper发出命令。 这些命令默认是关闭的，需要配置4lw.commands.whitelist来打开，可打开部分或全部示例如下： #打开指定命令 4lw.commands.whitelist=stat, ruok, conf, isro #打开全部 4lw.commands.whitelist=* 安装Netcat工具，已使用nc命令 #安装Netcat 工具 yum install -y nc #查看服务器及客户端连接状态 echo stat | nc localhost 2181 命令列表 conf：3.3.0中的新增功能：打印有关服务配置的详细信息。 缺点：3.3.0中的新增功能：列出了连接到该服务器的所有客户端的完整连接/会话详细信息。包括有关已接收/已发送的数据包数量，会话ID，操作等待时间，最后执行的操作等信息。 crst：3.3.0中的新增功能：重置所有连接的连接/会话统计信息。 dump：列出未完成的会话和临时节点。这仅适用于领导者。 envi：打印有关服务环境的详细信息 ruok：测试服务器是否以非错误状态运行。如果服务器正在运行，它将以imok响应。否则，它将完全不响应。响应“ imok”不一定表示服务器已加入仲裁，只是服务器进程处于活动状态并绑定到指定的客户端端口。使用“ stat”获取有关状态仲裁和客户端连接信息的详细信息。 srst：重置服务器统计信息。 srvr：3.3.0中的新功能：列出服务器的完整详细信息。 stat：列出服务器和连接的客户端的简要详细信息。 wchs：3.3.0中的新增功能：列出有关服务器监视的简要信息。 wchc：3.3.0中的新增功能：按会话列出有关服务器监视的详细信息。这将输出具有相关监视（路径）的会话（连接）列表。请注意，根据手表的数量，此操作可能会很昂贵（即影响服务器性能），请小心使用。 dirs：3.5.1中的新增功能：以字节为单位显示快照和日志文件的总大小 wchp：3.3.0中的新增功能：按路径列出有关服务器监视的详细信息。这将输出具有关联会话的路径（znode）列表。请注意，根据手表的数量，此操作可能会很昂贵（即影响服务器性能），请小心使用。 mntr：3.4.0中的新增功能：输出可用于监视集群运行状况的变量列表。 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/zookeeper/zookeeper-sence-use.html":{"url":"distributed/zookeeper/zookeeper-sence-use.html","title":"3.典型使用场景实践","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、 分布式集群管理 分布式集群管理的需求： 架构设计： 功能实现： 二 、分布式注册中心 Dubbo 对zookeeper的使用 Dubbo Zookeeper注册中心存储结构： 示例演示： 三、分布式JOB 分布式JOB需求： 架构设计： 四、分布式锁 锁的的基本概念： 锁的获取： 关于羊群效应： 示例演示： 课程概要： 分布式集群管理 分布式注册中心 分布式JOB 分布式锁 一、 分布式集群管理 分布式集群管理的需求： 主动查看线上服务节点 查看服务节点资源使用情况 服务离线通知 服务资源（CPU、内存、硬盘）超出阀值通知架构设计： 节点结构： tuling-manger // 根节点 server00001 : //服务节点 1 server00002 ://服务节点 2 server........n ://服务节点 n 服务状态信息: ip cpu memory disk功能实现： 数据生成与上报： 创建临时节点： 定时变更节点状态信息： 主动查询： 1、实时查询 zookeeper 获取集群节点的状态信息。 被动通知： 监听根节点下子节点的变化情况,如果CPU 等硬件资源低于警告位则发出警报。 关键示例代码： package com.tuling; import com.fasterxml.jackson.core.JsonProcessingException; import com.fasterxml.jackson.databind.ObjectMapper; import com.tuling.os.CPUMonitorCalc; import com.tuling.os.OsBean; import org.I0Itec.zkclient.IZkChildListener; import org.I0Itec.zkclient.ZkClient; import java.io.IOException; import java.lang.instrument.Instrumentation; import java.lang.management.ManagementFactory; import java.lang.management.MemoryUsage; import java.net.InetAddress; import java.net.UnknownHostException; import java.util.ArrayList; import java.util.List; import java.util.stream.Collectors; /** * @author Tommy * Created by Tommy on 2019/9/22 **/ public class Agent { private String server = \"192.168.0.149:2181\"; ZkClient zkClient; private static Agent instance; private static final String rootPath = \"/tuling-manger\"; private static final String servicePath = rootPath + \"/service\"; private String nodePath; private Thread stateThread; List list = new ArrayList<>(); public static void premain(String args, Instrumentation instrumentation) { instance = new Agent(); if (args != null) { instance.server = args; } instance.init(); } // 初始化连接 public void init() { zkClient = new ZkClient(server, 5000, 10000); System.out.println(\"zk连接成功\" + server); buildRoot(); createServerNode(); stateThread = new Thread(() -> { while (true) { updateServerNode(); try { Thread.sleep(5000); } catch (InterruptedException e) { e.printStackTrace(); } } }, \"zk_stateThread\"); stateThread.setDaemon(true); stateThread.start(); } // 构建根节点 public void buildRoot() { if (!zkClient.exists(rootPath)) { zkClient.createPersistent(rootPath); } } // 生成服务节点 public void createServerNode() { nodePath = zkClient.createEphemeralSequential(servicePath, getOsInfo()); System.out.println(\"创建节点:\" + nodePath); } // 监听服务节点状态改变 public void updateServerNode() { zkClient.writeData(nodePath, getOsInfo()); } // 更新服务节点状态 public String getOsInfo() { OsBean bean = new OsBean(); bean.lastUpdateTime = System.currentTimeMillis(); bean.ip = getLocalIp(); bean.cpu = CPUMonitorCalc.getInstance().getProcessCpu(); MemoryUsage memoryUsag = ManagementFactory.getMemoryMXBean().getHeapMemoryUsage(); bean.usableMemorySize = memoryUsag.getUsed() / 1024 / 1024; bean.usableMemorySize = memoryUsag.getMax() / 1024 / 1024; ObjectMapper mapper = new ObjectMapper(); try { return mapper.writeValueAsString(bean); } catch (JsonProcessingException e) { throw new RuntimeException(e); } } public void updateNode(String path, Object data) { if (zkClient.exists(path)) { zkClient.writeData(path, data); } else { zkClient.createEphemeral(path, data); } } public static String getLocalIp() { InetAddress addr = null; try { addr = InetAddress.getLocalHost(); } catch (UnknownHostException e) { throw new RuntimeException(e); } return addr.getHostAddress(); } } 实现效果图： 二 、分布式注册中心 在单体式服务中，通常是由多个客户端去调用一个服务，只要在客户端中配置唯一服务节点地址即可，当升级到分布式后，服务节点变多，像阿里一线大厂服务节点更是上万之多，这么多节点不可能手动配置在客户端，这里就需要一个中间服务，专门用于帮助客户端发现服务节点，即许多技术书籍经常提到的服务发现。 一个完整的注册中心涵盖以下功能特性： 服务注册：提供者上线时将自提供的服务提交给注册中心。 服务注销：通知注册心提供者下线。 服务订阅：动态实时接收服务变更消息。 可靠：注册服务本身是集群的，数据冗余存储。避免单点故障，及数据丢失。 容错：当服务提供者出现宕机，断电等极情况时，注册中心能够动态感知并通知客户端服务提供者的状态。Dubbo 对zookeeper的使用 阿里著名的开源项目Dubbo 是一个基于JAVA的RCP框架，其中必不可少的注册中心可基于多种第三方组件实现，但其官方推荐的还是Zookeeper做为注册中心服务。 Dubbo Zookeeper注册中心存储结构： 节点说明： | 类别 | 属性 | 说明 | |:----|:----|:----| | Root | 持久节点 | 根节点名称，默认是 \"dubbo\" | | Service | 持久节点 | 服务名称，完整的服务类名 | | type | 持久节点 | 可选值：providers(提供者)、consumers（消费者）、configurators(动态配置)、routers | | URL | 临时节点 | url名称 包含服务提供者的 IP 端口 及配置等信息。 | 流程说明： 服务提供者启动时: 向 /dubbo/com.foo.BarService/providers 目录下写入自己的 URL 地址 服务消费者启动时: 订阅 /dubbo/com.foo.BarService/providers 目录下的提供者 URL 地址。并向 /dubbo/com.foo.BarService/consumers 目录下写入自己的 URL 地址 监控中心启动时: 订阅 /dubbo/com.foo.BarService 目录下的所有提供者和消费者 URL 地址。示例演示： 服务端代码： package com.tuling.zk.dubbo; import com.alibaba.dubbo.config.ApplicationConfig; import com.alibaba.dubbo.config.ProtocolConfig; import com.alibaba.dubbo.config.RegistryConfig; import com.alibaba.dubbo.config.ServiceConfig; import java.io.IOException; /** * @author Tommy * Created by Tommy on 2019/10/8 **/ public class Server { public void openServer(int port) { // 构建应用 ApplicationConfig config = new ApplicationConfig(); config.setName(\"simple-app\"); // 通信协议 ProtocolConfig protocolConfig = new ProtocolConfig(\"dubbo\", port); protocolConfig.setThreads(200); ServiceConfig serviceConfig = new ServiceConfig(); serviceConfig.setApplication(config); serviceConfig.setProtocol(protocolConfig); serviceConfig.setRegistry(new RegistryConfig(\"zookeeper://192.168.0.149:2181\")); serviceConfig.setInterface(UserService.class); UserServiceImpl ref = new UserServiceImpl(); serviceConfig.setRef(ref); //开始提供服务 开张做生意 serviceConfig.export(); System.out.println(\"服务已开启!端口:\"+serviceConfig.getExportedUrls().get(0).getPort()); ref.setPort(serviceConfig.getExportedUrls().get(0).getPort()); } public static void main(String[] args) throws IOException { new Server().openServer(-1); System.in.read(); } } 客户端代码： package com.tuling.zk.dubbo; import com.alibaba.dubbo.config.ApplicationConfig; import com.alibaba.dubbo.config.ReferenceConfig; import com.alibaba.dubbo.config.RegistryConfig; import java.io.IOException; /** * @author Tommy * Created by Tommy on 2018/11/20 **/ public class Client { UserService service; // URL 远程服务的调用地址 public UserService buildService(String url) { ApplicationConfig config = new ApplicationConfig(\"young-app\"); // 构建一个引用对象 ReferenceConfig referenceConfig = new ReferenceConfig<>(); referenceConfig.setApplication(config); referenceConfig.setInterface(UserService.class); // referenceConfig.setUrl(url); referenceConfig.setRegistry(new RegistryConfig(\"zookeeper://192.168.0.149:2181\")); referenceConfig.setTimeout(5000); // 透明化 this.service = referenceConfig.get(); return service; } static int i = 0; public static void main(String[] args) throws IOException { Client client1 = new Client(); client1.buildService(\"\"); String cmd; while (!(cmd = read()).equals(\"exit\")) { UserVo u = client1.service.getUser(Integer.parseInt(cmd)); System.out.println(u); } } private static String read() throws IOException { byte[] b = new byte[1024]; int size = System.in.read(b); return new String(b, 0, size).trim(); } } 查询zk 实际存储内容： /dubbo /dubbo/com.tuling.zk.dubbo.UserService /dubbo/com.tuling.zk.dubbo.UserService/configurators /dubbo/com.tuling.zk.dubbo.UserService/routers /dubbo/com.tuling.zk.dubbo.UserService/providers /dubbo/com.tuling.zk.dubbo.UserService/providers/dubbo://192.168.0.132:20880/com.tuling.zk.dubbo.UserService?anyhost=true&application=simple-app&dubbo=2.6.2&generic=false&interface=com.tuling.zk.dubbo.UserService&methods=getUser&pid=11128&side=provider&threads=200&timestamp=1570518302772 /dubbo/com.tuling.zk.dubbo.UserService/providers/dubbo://192.168.0.132:20881/com.tuling.zk.dubbo.UserService?anyhost=true&application=simple-app&dubbo=2.6.2&generic=false&interface=com.tuling.zk.dubbo.UserService&methods=getUser&pid=12956&side=provider&threads=200&timestamp=1570518532382 /dubbo/com.tuling.zk.dubbo.UserService/providers/dubbo://192.168.0.132:20882/com.tuling.zk.dubbo.UserService?anyhost=true&application=simple-app&dubbo=2.6.2&generic=false&interface=com.tuling.zk.dubbo.UserService&methods=getUser&pid=2116&side=provider&threads=200&timestamp=1570518537021 /dubbo/com.tuling.zk.dubbo.UserService/consumers /dubbo/com.tuling.zk.dubbo.UserService/consumers/consumer://192.168.0.132/com.tuling.zk.dubbo.UserService?application=young-app&category=consumers&check=false&dubbo=2.6.2&interface=com.tuling.zk.dubbo.UserService&methods=getUser&pid=9200&side=consumer&timeout=5000&timestamp=1570518819628 三、分布式JOB 分布式JOB需求： 多个服务节点只允许其中一个主节点运行JOB任务。 当主节点挂掉后能自动切换主节点，继续执行JOB任务。架构设计： node结构： tuling-master server0001:master server0002:slave server000n:slave 选举流程： 服务启动： 在tuling-maste下创建server子节点，值为slave 获取所有tuling-master 下所有子节点 判断是否存在master 节点 如果没有设置自己为master节点 子节点删除事件触发： 获取所有tuling-master 下所有子节点 判断是否存在master 节点 如果没有设置最小值序号为master 节点四、分布式锁 锁的的基本概念： 开发中锁的概念并不陌生，通过锁可以实现在多个线程或多个进程间在争抢资源时，能够合理的分配置资源的所有权。在单体应用中我们可以通过 synchronized 或ReentrantLock 来实现锁。但在分布式系统中，仅仅是加synchronized 是不够的，需要借助第三组件来实现。比如一些简单的做法是使用 关系型数据行级锁来实现不同进程之间的互斥，但大型分布式系统的性能瓶颈往往集中在数据库操作上。为了提高性能得采用如Redis、Zookeeper之内的组件实现分布式锁。 共享锁：也称作只读锁，当一方获得共享锁之后，其它方也可以获得共享锁。但其只允许读取。在共享锁全部释放之前，其它方不能获得写锁。 排它锁：也称作读写锁，获得排它锁后，可以进行数据的读写。在其释放之前，其它方不能获得任何锁。 锁的获取： 某银行帐户，可以同时进行帐户信息的读取，但读取其间不能修改帐户数据。其帐户ID为:888 获得读锁流程： 1、基于资源ID创建临时序号读锁节点 /lock/888.R0000000002 Read 2、获取 /lock 下所有子节点，判断其最小的节点是否为读锁，如果是则获锁成功 3、最小节点不是读锁，则阻塞等待。添加lock/ 子节点变更监听。 4、当节点变更监听触发，执行第2步 数据结构： 获得写锁： 1、基于资源ID创建临时序号写锁节点 /lock/888.R0000000002 Write 2、获取 /lock 下所有子节点，判断其最小的节点是否为自己，如果是则获锁成功 3、最小节点不是自己，则阻塞等待。添加lock/ 子节点变更监听。 4、当节点变更监听触发，执行第2步 释放锁： 读取完毕后，手动删除临时节点，如果获锁期间宕机，则会在会话失效后自动删除。 关于羊群效应： 在等待锁获得期间，所有等待节点都在监听 Lock节点，一但lock 节点变更所有等待节点都会被触发，然后在同时反查Lock 子节点。如果等待对例过大会使用Zookeeper承受非常大的流量压力。 为了改善这种情况，可以采用监听链表的方式，每个等待对列只监听前一个节点，如果前一个节点释放锁的时候，才会被触发通知。这样就形成了一个监听链表。 示例演示： package com.tuling.zookeeper.lock; import org.I0Itec.zkclient.IZkDataListener; import org.I0Itec.zkclient.ZkClient; import java.util.List; import java.util.stream.Collectors; /** * @author Tommy * Created by Tommy on 2019/9/23 **/ public class ZookeeperLock { private String server = \"192.168.0.149:2181\"; private ZkClient zkClient; private static final String rootPath = \"/tuling-lock\"; public ZookeeperLock() { zkClient = new ZkClient(server, 5000, 20000); buildRoot(); } // 构建根节点 public void buildRoot() { if (!zkClient.exists(rootPath)) { zkClient.createPersistent(rootPath); } } public Lock lock(String lockId, long timeout) { Lock lockNode = createLockNode(lockId); lockNode = tryActiveLock(lockNode);// 尝试激活锁 if (!lockNode.isActive()) { try { synchronized (lockNode) { lockNode.wait(timeout); } } catch (InterruptedException e) { throw new RuntimeException(e); } } if (!lockNode.isActive()) { throw new RuntimeException(\" lock timeout\"); } return lockNode; } public void unlock(Lock lock) { if (lock.isActive()) { zkClient.delete(lock.getPath()); } } // 尝试激活锁 private Lock tryActiveLock(Lock lockNode) { // 判断当前是否为最小节点 List list = zkClient.getChildren(rootPath) .stream() .sorted() .map(p -> rootPath + \"/\" + p) .collect(Collectors.toList()); String firstNodePath = list.get(0); if (firstNodePath.equals(lockNode.getPath())) { lockNode.setActive(true); } else { String upNodePath = list.get(list.indexOf(lockNode.getPath()) - 1); zkClient.subscribeDataChanges(upNodePath, new IZkDataListener() { @Override public void handleDataChange(String dataPath, Object data) throws Exception { } @Override public void handleDataDeleted(String dataPath) throws Exception { // 事件处理 与心跳 在同一个线程，如果Debug时占用太多时间，将导致本节点被删除，从而影响锁逻辑。 System.out.println(\"节点删除:\" + dataPath); Lock lock = tryActiveLock(lockNode); synchronized (lockNode) { if (lock.isActive()) { lockNode.notify(); } } zkClient.unsubscribeDataChanges(upNodePath, this); } }); } return lockNode; } public Lock createLockNode(String lockId) { String nodePath = zkClient.createEphemeralSequential(rootPath + \"/\" + lockId, \"lock\"); return new Lock(lockId, nodePath); } } Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/zookeeper/zookeeper-zab.html":{"url":"distributed/zookeeper/zookeeper-zab.html","title":"4.ZAB协议实现源码分析","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、启动流程 1.工程结构介绍 2.启动宏观流程图： 3.集群启动详细流程 4.netty 服务启动流程： 二、快照与事务日志存储结构 概要: 存储结构: 快照相关配置： 快照装载流程： 课程概要： 启动流程源码分析 快照与事物日志的存储结构一、启动流程 知识点： 工程结构介绍 启动流程宏观图 集群启动详细流程 netty 服务工作机制1.工程结构介绍 项目地址:https://github.com/apache/zookeeper.git 分支tag ：3.5.5 zookeeper-recipes: 示例源码 zookeeper-client: C语言客户端 zookeeper-server：主体源码 2.启动宏观流程图： [ ] 启动示例演示： 服务端：ZooKeeperServerMain 客户端：ZooKeeperMain 3.集群启动详细流程 装载配置： # zookeeper 启动流程堆栈 >QuorumPeerMain#initializeAndRun //启动工程 >QuorumPeerConfig#parse // 加载config 配置 >QuorumPeerConfig#parseProperties// 解析config配置 >new DatadirCleanupManager // 构造一个数据清器 >DatadirCleanupManager#start // 启动定时任务 清除过期的快照 代码堆栈 ： >QuorumPeerMain#main //启动main方法 >QuorumPeerConfig#parse // 加载zoo.cfg 文件 >QuorumPeerConfig#parseProperties // 解析配置 >DatadirCleanupManager#start // 启动定时任务清除日志 >QuorumPeerConfig#isDistributed // 判断是否为集群模式 >ServerCnxnFactory#createFactory() // 创建服务默认为NIO，推荐netty //***创建 初始化集群管理器**/ >QuorumPeerMain#getQuorumPeer >QuorumPeer#setTxnFactory >new FileTxnSnapLog // 数据文件管理器，用于检测快照与日志文件 /** 初始化数据库*/ >new ZKDatabase >ZKDatabase#createDataTree //创建数据树，所有的节点都会存储在这 // 启动集群：同时启动线程 > QuorumPeer#start // > QuorumPeer#loadDataBase // 从快照文件以及日志文件 加载节点并填充到dataTree中去 > QuorumPeer#startServerCnxnFactory // 启动netty 或java nio 服务，对外开放2181 端口 > AdminServer#start// 启动管理服务，netty http服务，默认端口是8080 > QuorumPeer#startLeaderElection // 开始执行选举流程 > quorumPeer.join() // 防止主进程退出 流程说明: main方法启动 加载zoo.cfg 配置文件 解析配置 创建服务工厂 创建集群管理线程 设置数据库文件管理器 设置数据库 ....设置设置 start启动集群管理线程 加载数据节点至内存 启动netty 服务，对客户端开放端口 启动管理员Http服务，默认8080端口 启动选举流程 join 管理线程，防止main 进程退出 4.netty 服务启动流程： 服务UML类图 设置netty启动参数 -Dzookeeper.serverCnxnFactory=org.apache.zookeeper.server.NettyServerCnxnFactory 初始化： 关键代码： #初始化管道流 #channelHandler 是一个内部类是具体的消息处理器。 protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); if (secure) { initSSL(pipeline); } pipeline.addLast(\"servercnxnfactory\", channelHandler); } channelHandler 类结构 执行堆栈： NettyServerCnxnFactory#NettyServerCnxnFactory // 初始化netty服务工厂 > NettyUtils.newNioOrEpollEventLoopGroup // 创建IO线程组 > NettyUtils#newNioOrEpollEventLoopGroup() // 创建工作线程组 >ServerBootstrap#childHandler(io.netty.channel.ChannelHandler) // 添加管道流 >NettyServerCnxnFactory#start // 绑定端口，并启动netty服务 创建连接： 每当有客户端新连接进来，就会进入该方法 创建 NettyServerCnxn对象。并添加至cnxns对例 执行堆栈 CnxnChannelHandler#channelActive >new NettyServerCnxn // 构建连接器 >NettyServerCnxnFactory#addCnxn // 添加至连接器，并根据客户端IP进行分组 >ipMap.get(addr) // 基于IP进行分组 读取消息： 执行堆栈 CnxnChannelHandler#channelRead >NettyServerCnxn#processMessage // 处理消息 >NettyServerCnxn#receiveMessage // 接收消息 >ZooKeeperServer#processPacket //处理消息包 >org.apache.zookeeper.server.Request // 封装request 对象 >org.apache.zookeeper.server.ZooKeeperServer#submitRequest // 提交request >org.apache.zookeeper.server.RequestProcessor#processRequest // 处理请求 二、快照与事务日志存储结构 概要: ZK中所有的数据都是存储在内存中，即zkDataBase中。但同时所有对ZK数据的变更都会记录到事物日志中，并且当写入到一定的次数就会进行一次快照的生成。已保证数据的备份。其后缀就是ZXID（唯一事物ID）。 事物日志：每次增删改，的记录日志都会保存在文件当中 快照日志：存储了在指定时间节点下的所有的数据存储结构: zkDdataBase 是zk数据库基类，所有节点都会保存在该类当中，而对Zk进行任何的数据变更都会基于该类进行。zk数据的存储是通过DataTree 对象进行，其用了一个map 来进行存储。 UML 类图： 读取快照日志： org.apache.zookeeper.server.SnapshotFormatter 读取事物日志： org.apache.zookeeper.server.LogFormatter 快照相关配置： dataLogDir 事物日志目录 zookeeper.preAllocSize 预先开辟磁盘空间，用于后续写入事务日志，默认64M zookeeper.snapCount 每进行snapCount次事务日志输出后，触发一次快照，默认是100,000 autopurge.snapRetainCount 自动清除时 保留的快照数 autopurge.purgeInterval 清除时间间隔，小时为单位 -1 表示不自动清除。 快照装载流程： >ZooKeeperServer#loadData // 加载数据 >FileTxnSnapLog#restore // 恢复数据 >FileSnap#deserialize() // 反序列化数据 >FileSnap#findNValidSnapshots // 查找有效的快照 >Util#sortDataDir // 基于后缀排序文件 >persistence.Util#isValidSnapshot // 验证是否有效快照文件 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/netty/":{"url":"distributed/netty/","title":"netty","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/netty/shell.html":{"url":"distributed/netty/shell.html","title":"1.启停脚本","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 ! /bin/bash #! /bin/bash case $1 in \"start\"){ for i in hadoop101 hadoop102 hadoop103 do echo \" --------启动 $i Kafka-------\" # 用于KafkaManager监控 ssh $i \"export JMX_PORT=9988 && /usr/local/software/kafka_2.12-2.6.0/bin/kafka-server-start.sh -daemon /usr/local/software/kafka_2.12-2.6.0/config/server.properties \" done };; \"stop\"){ for i in hadoop101 hadoop102 hadoop103 do echo \" --------停止 $i Kafka-------\" ssh $i \"/usr/local/software/kafka_2.12-2.6.0/bin/kafka-server-stop.sh stop\" done };; esac Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:36:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/netty/netty.html":{"url":"distributed/netty/netty.html","title":"2.分布式之netty","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.Java IO 与 NIO 1.1Linux I/O 模型介绍 1.1.1Linux I/O 流程 1.1.2 将 I/O 模型划分为以下五种类型： 1.1.3 各种 I/O 模型的比较 1.2Java I/O 1.3Java NIO 1.3.1java io 和 java nio 对比 1.3.2Java NIO 主要由3 部分核心组件组成 1.3.3NIO 带来了什么 2.Netty 编程实践 2.1Netty 介绍 2.1.1特性 2.2Netty 主要组件介绍 2.2.1Bootstrap 和 ServerBootstrap 2.2.2Transport Channel 2.2.3EventLoop和EventLoopGroup 2.2.4ChannelHandler和ChannelPipeline 2.2.5ByteBuf 2.3Netty 编程示例 3.Netty 线程模型解析 3.1Reactor 模式及其与 Netty 的对应关系 3.1.1单线程Reactor 3.1.2多线程Reactor 3.1.3Multiple Reactor 3.1.4主从Reactor 3.2Netty EventLoop 源码解析 3.2.1NioEventLoopGroup整体结构 3.2.2NioEventLoop创建分析 3.2.3NioEventLoop启动流程分析 3.2.4NioEventLoop执行流程分析 4.Netty 编解码编程实战 4.1 半包粘包问题示例与分析 4.2Netty 半包粘包问题解决 4.2.1LineBasedFrameDecoder（\\n, \\r\\n) 4.2.2DelimiterBasedFrameDecoder 4.2.3FixedLengthFrameDecoder 4.2.4LengthFieldBasedFrameDecoder 4.3Netty 编解码器分析 5.基于 Netty 实现高性能弹幕系统 5.1 弹幕系统概要设计 5.1.1弹幕系统特点 5.1.2弹幕系统架构设计 5.2Netty 对 Http 协议解析实现 5.2.1http报文解析方案： 5.2.2netty关于http 的解决方案： 5.2.3Netty Http的请求处理流程 5.3WebScoket 协议解析实现 5.3.1webSocket 协议简介： 5.3.2webSocket特点如下： 5.3.3WebSocket 协议报文格式： 6.基于 Netty 实现 RPC 框架 6.1RPC构建需要考虑的主要因素 6..1.2RPC框架 1.Java IO 与 NIO 1.1Linux I/O 模型介绍 1.1.1Linux I/O 流程 1.1.2 将 I/O 模型划分为以下五种类型： 阻塞式 I/O 模型 非阻塞式 I/O 模型 I/O 复用 信号驱动式 I/O 异步 I/O 1.1.3 各种 I/O 模型的比较 1.2Java I/O 1.3Java NIO 1.3.1java io 和 java nio 对比 1.3.2Java NIO 主要由3 部分核心组件组成 a. Buffer 一个 Buffer 本质上是内存中的一块， 可以将数据写入这块内存， 从这块内存获取数据 java.nio 定义了以下几个 Buffer 的实现 Java NIO Buffer 三大核心概念：position、limit、capacity 最好理解的当然是 capacity，它代表这个缓冲区的容量，一旦设定就不可以更改。比如 capacity 为 1024 的 IntBuffer，代表其一次可以存放 1024 个 int 类型的值。 一旦 Buffer 的容量达到 capacity，需要清空 Buffer，才能重新写入值。 b. Channel 所有的 NIO 操作始于通道，通道是数据来源或数据写入的目的地，主要地，java.nio 包中主要实现的以下几个 Channel： c. Selector Selector 是 Java NIO 中的一个组件，用于检查一个或多个 NIO Channel 的状态是否处于可读、可写 如此可以实现单线程管理多个 channels,也就是可以管理多个网络链接 1.3.3NIO 带来了什么 事件驱动模型 避免多线程 单线程处理多任务 非阻塞 IO,IO 读写不再阻塞,而是返回 0 基于 block 的传输,通常比基于流的传输更高效 更高级的 IO 函数,zero-copy IO 多路复用大大提高了 java 网络应用的可伸缩性和实用性 注意 使用NIO = 高性能 NIO不一定更快的场景 客户端应用 连接数 并发程度不高 局域网环境下 NIO完全屏蔽了平台差异(Linux poll/select/epoll, FreeBSD Kqueue) NIO仍然是基于各个OS平台的IO系统实现的,差异仍然存在 使用NIO做网络编程很容易 离散的事件驱动模型，编程困难2.Netty 编程实践 2.1Netty 介绍 2.1.1特性 设计 统一的API,适用于不同的协议(阻塞和非阻塞) 基于灵活、可扩展的事件驱动模型（SEDA） 高度可定制的线程模型 可靠的无连接数据Socket支持(UDP) 性能 更好的吞吐量,低延迟 更省资源 尽量减少不必要的内存拷贝 安全 完整的SSL/ TLS和STARTTLS的支持 易用 完善的Java doc,用户指南和样例 仅依赖于JDK1.6（netty 4.x)2.2Netty 主要组件介绍 2.2.1Bootstrap 和 ServerBootstrap Netty Server启动主要流程： 设置服务端ServerBootStrap启动参数 group(parentGroup, childGroup): channel(NioServerSocketChannel): 设置通道类型 handler()：设置NioServerSocketChannel的ChannelHandlerPipeline childHandler(): 设置NioSocketChannel的ChannelHandlerPipeline 通过ServerBootStrap的bind方法启动服务端，bind方法会在parentGroup中注册NioServerScoketChannel，监听客户端的连接请求 会创建一个NioServerSocketChannel实例，并将其在parentGroup中进行注册 Netty Server执行主要流程： Client发起连接CONNECT请求，parentGroup中的NioEventLoop不断轮循是否有新的客户端请求，如果有，ACCEPT事件触发 ACCEPT事件触发后，parentGroup中NioEventLoop会通过NioServerSocketChannel获取到对应的代表客户端的NioSocketChannel，并将其注册到childGroup中 childGroup中的NioEventLoop不断检测自己管理的NioSocketChannel是否有读写事件准备好 2.2.2Transport Channel 提供了统一的API，支持不同类型的传输层： OIO -阻塞IO NIO - Java NIO Epoll - Linux Epoll(JNI) Local Transport - IntraVM调用 Embedded Transport - 供测试使用的嵌入传输 UDS - Unix套接字的本地传输 2.2.3EventLoop和EventLoopGroup EventLoopGroup 包括多个EventLoop 多个EventLoop之间不交互 EventLoop： 每个EventLoop对应一个线程 所有连接(channel)都将注册到一个EventLoop，并且只注册到一个，整个生命周期中都不会变化 每个EventLoop管理着多个连接(channel) EventLoop来处理连接(Channel)上的读写事件 ServerBootstrap包括2个不同类型的EventLoopGroup: Parent EventLoop:负责处理Accept事件，接收请求 Child EventLoop：负责处理读写事件 ByteBuf通过两个索引（reader index、writer index）划分为三个区域： reader index前面的数据是已经读过的数据，这些数据可以丢弃 从reader index开始，到writer index之前的数据是可读数据 从writer index开始，为可写区域2.2.4ChannelHandler和ChannelPipeline ChannelHandler - 业务处理核心逻辑，用户自定义 Netty 提供2个重要的 ChannelHandler 子接口： ChannelInboundHandler - 处理进站数据和所有状态更改事件 ChannelOutboundHandler - 处理出站数据，允许拦截各种操作 ChannelPipeline 是ChannelHandler容器 包括一系列的ChannelHandler 实例,用于拦截流经一个 Channel 的入站和出站事件 每个Channel都有一个其ChannelPipeline 可以修改 ChannelPipeline 通过动态添加和删除 ChannelHandler 定义了丰富的API调用来回应入站和出站事件 ChannelHandlerContext表示 ChannelHandler 和ChannelPipeline 之间的关联 在 ChannelHandler 添加到 ChannelPipeline 时创建 ChannelHandlerContext表示 ChannelHandler 和ChannelPipeline 之间的关联 2.2.5ByteBuf 相比JDK ByteBuffer， 更加易于使用： 为读/写分别维护单独的指针，不需要通过flip()进行读/写模式切换 容量自动伸缩（类似于 ArrayList，StringBuilder） Fluent API (链式调用） 更好的性能： 通过内置的CompositeBuffer来减少数据拷贝（Zero copy） 支持内存池，减少GC压力2.3Netty 编程示例 3.Netty 线程模型解析 3.1Reactor 模式及其与 Netty 的对应关系 3.1.1单线程Reactor 3.1.2多线程Reactor 3.1.3Multiple Reactor 3.1.4主从Reactor 3.2Netty EventLoop 源码解析 3.2.1NioEventLoopGroup整体结构 3.2.2NioEventLoop创建分析 3.2.3NioEventLoop启动流程分析 3.2.4NioEventLoop执行流程分析 4.Netty 编解码编程实战 4.1 半包粘包问题示例与分析 4.2Netty 半包粘包问题解决 4.2.1LineBasedFrameDecoder（\\n, \\r\\n) 回车换行解码器 配合StringDecoder 4.2.2DelimiterBasedFrameDecoder 分隔符解码器 4.2.3FixedLengthFrameDecoder 固定长度解码器 4.2.4LengthFieldBasedFrameDecoder 基于'长度'解码器(私有协议最常用) 4.3Netty 编解码器分析 5.基于 Netty 实现高性能弹幕系统 5.1 弹幕系统概要设计 5.1.1弹幕系统特点 1.实时性高：你发我收， 毫秒之差 2.并发量大：一人吐槽，万人观看 5.1.2弹幕系统架构设计 业务架构 实现方案一 实现方案二 5.2Netty 对 Http 协议解析实现 request 报文 response 报文 5.2.1http报文解析方案： 1：请求行的边界是CRLF(回车)，如果读取到CRLF(回车)，则意味着请求行的信息已经读取完成。 2：Header的边界是CRLF，如果连续读取两个CRLF，则意味着header的信息读取完成。 3：body的长度是有Content-Length 来进行确定。 5.2.2netty关于http 的解决方案： // 解析请求 很多http server的实现都是基于servlet标准，但是netty对http实现并没有基于servlet。所以在使用上比Servlet复杂很多。比如在servlet 中直接可以通过 HttpServletRequest 获取 请求方法、请求头、请求参数。而netty 确需要通过如下对象自行解析获取。 HttpMethod：主要是对method的封装，包含method序列化的操作 HttpVersion: 对version的封装，netty包含1.0和1.1的版本 QueryStringDecoder: 主要是对urI进行解析，解析path和url上面的参数。 HttpPostRequestDecoder：对post 中body 内容进行解析获取 form 参数。 HttpHeaders：包含对header的内容进行封装及操作 HttpContent：是对body进行封装，本质上就是一个ByteBuf。如果ByteBuf的长度是固定的，则请求的body过大，可能包含多个HttpContent，其中最后一个为LastHttpContent(空的HttpContent),用来说明body的结束。 HttpRequest：主要包含对Request Line和Header的组合 FullHttpRequest： 主要包含对HttpRequest和httpContent的组合 5.2.3Netty Http的请求处理流程 从图中可以看出做为服务端的Netty 就是在做 编码和解码操作。其分别通过以下两个ChannelHandler对象实现： HttpRequestDecoder :用于从byteBuf 获取数据并解析封装成HttpRequest 对象 HttpResponseEncoder：用于将业务返回数据编码成 Response报文并发送到ByteBuf。 将以上两个对象添加进 Netty 的 pipeline 即可实现最简单的http 服务。 Decoder 流程 encode 流程 5.3WebScoket 协议解析实现 5.3.1webSocket 协议简介： webSocket 是html5 开始提供的一种浏览器与服务器间进行全双工二进制通信协议，其基于TCP双向全双工作进行消息传递，同一时刻即可以发又可以接收消息，相比Http的半双工协议性能有很大的提升， 5.3.2webSocket特点如下： 1.单一TCP长连接，采用全双工通信模式 2.对代理、防火墙透明 3.无头部信息、消息更精简 4.通过ping/pong 来保活 5.服务器可以主动推送消息给客户端，不在需要客户轮询 5.3.3WebSocket 协议报文格式： 我们知道，任何应用协议都有其特有的报文格式，比如Http协议通过 空格 换行组成其报文。如http 协议不同在于WebSocket属于二进制协议，通过规范进二进位来组成其报文。具体组成如下图： 通过javaScript 中的API可以直接操作WebSocket 对象，其示例如下： var ws = new WebSocket(“ws://localhost:8080”); ws.onopen = function()// 建立成功之后触发的事件 { console.log(“打开连接”); ws.send(\"ddd\"); // 发送消息 }; ws.onmessage = function(evt) { // 接收服务器消息 console.log(evt.data); }; ws.onclose = function(evt) { console.log(“WebSocketClosed!”); // 关闭连接 }; ws.onerror = function(evt) { console.log(“WebSocketError!”); // 连接异常 }; 6.基于 Netty 实现 RPC 框架 6.1RPC构建需要考虑的主要因素 通信协议 文本协议或二进制协议（RESTful with JSON or RPC with Binary Encoding） 支持的调用方式：单向、双向、Streaming API容错、可伸缩性6..1.2RPC框架 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:27:02 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/dubbo/":{"url":"distributed/dubbo/","title":"dubbo","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/dubbo/dubbo-introduce.html":{"url":"distributed/dubbo/dubbo-introduce.html","title":"1.从0到1整体认知分布式系统","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、分布式架构的发展历史与背景 架构的发展历史： 分布式架构所带来的成本与风险: 二、如何选型分布式架构 基于反向代理的集中式分布式架构 嵌入应用内部的去中心化架构 基于独立代理进程的架构(Service Mesh) 三种架构的比较 **三、Dubbo 架构与设计说明 ** dubbo架构简要讲解 Dubbo 整体设计 Dubbo 中的SPI机制 概要： 分布式架构的发展历史与背景 如何着手架构一套分布示式系统 Dubbo 架构与设计说明 一、分布式架构的发展历史与背景 场景一： 一家做政务OA系统的公司老板发现跟竞争对手比发现自己的系统的架构不是分布示的，找到技术负责人问，把系统架构升级成分布示架构要多长时间？技术负责人网上查了查 dubbo官网看了看 Demo 这不很简单吗，拍着胸脯一个月能升级好。 现在我的问题是：这位技术理在改造过程中可能会遇到什么风险和问题？ 新功能和旧BUG的问题 业务完整性的问题 团队协作方式转变 开发人员技能提升 系统交付方式转变 这些问题解决涉及业务部门及整个技术部门（开发、测试、运维）协商与工作标准的制定。业务相关问题暂不做讨论,技术架构上应该要清楚自己的职责是，如何通过技术手段把业务波动降至最低、开发成本最低、实施风险最低？ 架构的发展历史： 单体式架构： 垂直架构: 分布示架构： 分布式架构所带来的成本与风险: 分布式事物： 分布式事物是指一个操作，分成几个小操作在多个服务器上执行，要么多成功，要么多失败这些分布事物要做的 不允许服务有状态（**stateless service**） 无状态服务是指对单次请求的处理，不依赖其他请求，也就是说，处理一次请求所需的全部信息，要么都包含在这个请求里，要么可以从外部获取到（比如说数据库），服务器本身不存储任何信息。 服务依懒关系复杂 服务 A --> B--> C 那和服务C 的修改 就可能会影响 B 和C，事实上当服务越来 越多的时候，C的变动将会越来越困难。 部署运维成本增加 不用说了，相比之前几个节点，运维成本的增加必须的。 源码管理成本增加： 原本一套或几套源码现在拆分成几十个源码库，其中分支、tag都要进行相应管理。 如何保证系统的伸缩性： 伸缩性是指,当前服务器硬件升级后或新增服务器处理能力就能相对应的提升。 分布式会话： 此仅针对应用层服务，不能将Session 存储在一个服务器上。 分布式JOB 通常定时任务只需要在一台机器上触发执行，分布式的情况下在哪台执行呢？ 最后通过一张图直观感受一下 单体到分布式的区别： 二、如何选型分布式架构 提问：实现一个分布示框架最核心功能是什么? RPC远程调用技术： 大家知道的 有哪些远程调用的 方式？拿几个大家比较熟悉的来举例：RMI 、Web Service、Http | 协议 | 描述 | 优点 | 缺点 | |:----|:----|:----|:----| | RMI | JAVA 远程方法调用、使用原生二进制方式进行序列化 | 简单易用、SDK支持，提高开发效率 | 不支持跨语言 | | Web Service | 比较早系统调用解决方案 ，跨语言, 其基于WSDL 生成 SOAP 进行消息的传递。 | SDK支持、跨语言 | 实现较重，发布繁琐 | | Http | 采用htpp +json 实现 | 简单、轻量、跨语言 | 不支持SDK | 基于比较上述比较，大家会选择哪个方案，综合考虑 RMI是比较合适的方案，基本没有学习成本。而跨语言问题基本可以勿略。 如果服务端不是单个的话，这个方案差点我就用了。实际上服务端是多个的 ，好了新的问题又来了。 负载均衡：这么多个机器调用哪一台? 服务发现：样发现新的服务地址呢？ 健康检测：服务关宕机或恢复后怎么办？ 容错：如果调用其中一台调用出错了怎么办？ 这些功能怎么解决呢？一个一个的去编码实现么？。有没有现成的方案可以直接借鉴呢？ 分布式架构的三种解决方案： 基于反向代理的中心化架构 嵌入应用内部的去中心化架构 基于独立代理进程的Service Mesh架构基于反向代理的集中式分布式架构 这是最简单和传统做法，在服务消费者和生产者之间，代理作为独立一层集中部署，由独立团队(一般是运维或框架)负责治理和运维。常用的集中式代理有硬件负载均衡器(如F5)，或者软件负载均衡器(如Nginx)，这种软硬结合两层代理也是业内常见做法，兼顾配置的灵活性(Nginx比F5易于配置)。 Http+Nginx 方案总结： 优点：简单快速、几乎没有学习成本 适用场景：轻量级分布式系统、局部分布式架构。 瓶颈：Nginx中心负载、Http传输、JSON序列化、开发效率、运维效率。 嵌入应用内部的去中心化架构 这是很多互联网公司比较流行的一种做法，代理(包括服务发现和负载均衡逻辑)以客户库的形式嵌入在应用程序中。这种模式一般需要独立的服务注册中心组件配合，服务启动时自动注册到注册中心并定期报心跳，客户端代理则发现服务并做负载均衡。我们所熟悉的 duboo 和spring cloud Eureka +Ribbon/'rɪbən/ 都是这种方式实现。 相比第一代架构它有以下特点几点： 去中心化，客户端直连服务端 动态注册和发现服务 高效稳定的网络传输 高效可容错的序列化基于独立代理进程的架构(Service Mesh) 这种做法是上面两种模式的一个折中，代理既不是独立集中部署，也不嵌入在客户应用程序中，而是作为独立进程部署在每一个主机上，一个主机上的多个消费者应用可以共用这个代理，实现服务发现和负载均衡，如下图所示。这个模式一般也需要独立的服务注册中心组件配合，作用同第二代架构。 三种架构的比较 模式 优点 缺点 适应场景 案例 集中式负载架构 简单 集中式治理 与语言无关 配置维护成本高 多了一层IO 单点问题 大部分公司都适用，对运维有要求 亿贝、携程、早期互联网公司 客户端嵌入式架构 无单点 性能更好 客户端复杂 语言栈要求 中大规模公司、语言栈统一 Dubbo 、 Twitter finagle、 Spring Cloud Ribbon 独立进程代理架构 无单点 性能更好 与语言无关 运维部署复杂 开发联调复杂 中大规模公司 对运维有要求 Smart Stack Service Mesh 三、Dubbo 架构与设计说明 dubbo架构简要讲解 架构图 流程说明： Provider(提供者)绑定指定端口并启动服务 指供者连接注册中心，并发本机IP、端口、应用信息和提供服务信息发送至注册中心存储 Consumer(消费者），连接注册中心 ，并发送应用信息、所求服务信息至注册中心 注册中心根据 消费 者所求服务信息匹配对应的提供者列表发送至Consumer 应用缓存。 Consumer 在发起远程调用时基于缓存的消费者列表择其一发起调用。 Provider 状态变更会实时通知注册中心、在由注册中心实时推送至Consumer 这么设计的意义： Consumer 与Provider 解偶，双方都可以横向增减节点数。 注册中心对本身可做对等集群，可动态增减节点，并且任意一台宕掉后，将自动切换到另一台 去中心化，双方不直接依懒注册中心，即使注册中心全部宕机短时间内也不会影响服务的调用 服务提供者无状态，任意一台宕掉后，不影响使用 Dubbo 整体设计 config 配置层：对外配置接口，以 ServiceConfig, ReferenceConfig 为中心，可以直接初始化配置类，也可以通过 spring 解析配置生成配置类 proxy 服务代理层：服务接口透明代理，生成动态代理 扩展接口为 ProxyFactory registry 注册中心层：封装服务地址的注册与发现，以服务 URL 为中心，扩展接口为 RegistryFactory, Registry, RegistryService cluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster, Directory, Router, LoadBalance monitor 监控层：RPC 调用次数和调用时间监控，以 Statistics 为中心，扩展接口为 MonitorFactory, Monitor, MonitorService protocol 远程调用层：封装 RPC 调用，以 Invocation, Result 为中心，扩展接口为 Protocol, Invoker, Exporter exchange 信息交换层：封装请求响应模式，同步转异步，以 Request, Response 为中心，扩展接口为 Exchanger, ExchangeChannel, ExchangeClient, ExchangeServer transport 网络传输层：抽象 mina 和 netty 为统一接口，以 Message 为中心，扩展接口为 Channel, Transporter, Client, Server, Codec serialize 数据序列化层：可复用的一些工具，扩展接口为 Serialization, ObjectInput, ObjectOutput, ThreadPool 其协作流程如下： Dubbo 中的SPI机制 在了解Dubbo的spi之前 先来了解一下 JAVA自带的SPI java spi的具体约定为:当服务的提供者，提供了服务接口的一种实现之后，在jar包的META-INF/services/目录里同时创建一个以服务接口命名的文件。该文件里就是实现该服务接口的具体实现类。而当外部程序装配这个模块的时候，就能通过该jar包META-INF/services/里的配置文件找到具体的实现类名，并装载实例化，完成模块的注入。 基于这样一个约定就能很好的找到服务接口的实现类，而不需要再代码里制定。jdk提供服务实现查找的一个工具类java.util.ServiceLoader 演示JAVA SPI机制 [ ] 编写接口 [ ] 编写实现类 [ ] 编辑META-INF/services/xxx 文件 [ ] 演示spi 实现 spi 目录文件： META-INF/services/tuling.dubbo.server.UserService 中的值： tuling.dubbo.server.impl.UserServiceImpl2 装载获取SPI实现类： public static void main(String[] args) { Iterator services = ServiceLoader.load(UserService.class).iterator(); UserService service = null; while (services.hasNext()) { service = services.next(); } System.out.println(service.getUser(111)); } Dubbo的SPI机制： dubbo spi 在JAVA自带的SPI基础上加入了扩展点的功能，即每个实现类都会对应至一个扩展点名称，其目的是 应用可基于此名称进行相应的装配。 演示Dubbo SPI机制： [ ] 编写Filter 过滤器 [ ] 编写 dubbo spi 配置文件 [ ] 装配自定义Filter dubbo spi 目录文件 dubbo spi 文件内容： luban=tuling.dubbo.server.LubanFilter 装配自定义Filter Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/dubbo/dubbo-base-use.html":{"url":"distributed/dubbo/dubbo-base-use.html","title":"2.快速掌握Dubbo常规应用","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、Dubbo 快速入门 Dubbo核心功能解释 快速演示Dubbo的远程调用 基于Dubbo实现服务集群： 二、Dubbo常规配置说明 Dubbo配置的整体说明： dubbo 配置的一些套路: 一般建议配置示例： Copyright &copy ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 概要： Dubbo 快速入门 Dubbo 常规配置说明一、Dubbo 快速入门 Dubbo核心功能解释 dubbo 阿里开源的一个SOA服务治理框架，从目前来看把它称作是一个RPC远程调用框架更为贴切。单从RPC框架来说，功能较完善，支持多种传输和序列化方案。所以想必大家已经知道他的核心功能了：就是远程调用。 快速演示Dubbo的远程调用 实现步骤 [ ] 创建服务端项目 [ ] 引入dubbo 依赖 [ ] 编写服务端代码 [ ] 创建客户端项目 [ ] 引入dubbo 依赖 [ ] 编写客户端调用代码 dubbo 引入： com.alibaba dubbo 2.6.2 dubbo 默认依懒： 客户端代码： static String remoteUrl = \"dubbo://127.0.0.1:12345/tuling.dubbo.server.UserService\"; // 构建远程服务对象 public UserService buildRemoteService(String remoteUrl) { ApplicationConfig application = new ApplicationConfig(); application.setName(\"young-app\"); ReferenceConfig referenceConfig = new ReferenceConfig<>(); referenceConfig.setApplication(application); referenceConfig.setInterface(UserService.class); referenceConfig.setUrl(remoteUrl); UserService userService = referenceConfig.get(); return userService; } 服务端代码： public void openServer(int port) { ApplicationConfig config = new ApplicationConfig(); config.setName(\"simple-app\"); ProtocolConfig protocolConfig=new ProtocolConfig(); protocolConfig.setName(\"dubbo\"); protocolConfig.setPort(port); protocolConfig.setThreads(20); ServiceConfig serviceConfig=new ServiceConfig(); serviceConfig.setApplication(config); serviceConfig.setProtocol(protocolConfig); serviceConfig.setRegistry(new RegistryConfig(RegistryConfig.NO_AVAILABLE)); serviceConfig.setInterface(UserService.class); serviceConfig.setRef(new UserServiceImpl()); serviceConfig.export(); } 基于Dubbo实现服务集群： 在上一个例子中如多个服务的集群？即当有多个服务同时提供的时候，客户端该调用哪个？以什么方式进行调用以实现负载均衡？ 一个简单的办法是将多个服务的URL同时设置到客户端并初始化对应的服务实例，然后以轮询的方式进行调用。 但如果访问增大，需要扩容服务器数量，那么就必须增加配置重启客户端实例。显然这不是我们愿意看到的。Dubbo引入了服务注册中的概念，可以解决动态扩容的问题。 演示基于注册中心实现服集群： [ ] 修改服务端代码，添加multicast 注册中心。 [ ] 修改客户端代码，添加multicast 注册中心。 [ ] 观察 多个服务时，客户端如何调用。 [ ] 观察 动态增减服务，客户端的调用。 # 服务端连接注册中心 serviceConfig.setRegistry(new RegistryConfig(\"multicast://224.1.1.1:2222\")); # 客户端连接注册中心 referenceConfig.setRegistry(new RegistryConfig(\"multicast://224.1.1.1:2222\")); #查看 基于UDP 占用的2222 端口 netstat -ano|findstr 2222 基于spring IOC维护Dubbo 实例 在前面两个例子中 出现了,ApplicationConfig、ReferenceConfig、RegistryConfig、com.alibaba.dubbo.config.ServiceConfig等实例 ，很显然不需要每次调用的时候都去创建该实例那就需要一个IOC 容器去管理这些实例，spring 是一个很好的选择。 提供者配置---------------------------------- 提供者服务暴露代码： ApplicationContext context = new ClassPathXmlApplicationContext(\"/spring-provide.xml\"); ((ClassPathXmlApplicationContext) context).start(); System.in.read(); 消费者配置--------------------------------------- 消费者调用代码： ApplicationContext context = new ClassPathXmlApplicationContext(\"/spring-consumer.xml\"); UserService userService = context.getBean(UserService.class); UserVo u = userService.getUser(1111); System.out.println(u); 二、Dubbo常规配置说明 Dubbo配置的整体说明： 标签 用途 解释 公共 用于配置当前应用信息，不管该应用是提供者还是消费者 公共 用于配置连接注册中心相关信息 服务 用于配置提供服务的协议信息，协议由提供方指定，消费方被动接受 服务 用于暴露一个服务，定义服务的元信息，一个服务可以用多个协议暴露，一个服务也可以注册到多个注册中心 服务 当 ProtocolConfig 和 ServiceConfig 某属性没有配置时，采用此缺省值，可选 引用 当 ReferenceConfig 某属性没有配置时，采用此缺省值，可选 引用 用于创建一个远程服务代理，一个引用可以指向多个注册中心 公共 用于 ServiceConfig 和 ReferenceConfig 指定方法级的配置信息 公共 用于指定方法参数配置 配置关系图： 配置分类 所有配置项分为三大类。 服务发现：表示该配置项用于服务的注册与发现，目的是让消费方找到提供方。 服务治理：表示该配置项用于治理服务间的关系，或为开发测试提供便利条件。 性能调优：表示该配置项用于调优性能，不同的选项对性能会产生影响。dubbo 配置的一些套路: 先来看一个简单配置 通过字面了解 timeout即服务的执行超时时间。但当服务执行真正超时的时候 报的错跟timeout并没有半毛钱的关系，其异常堆栈如下： 可以看到错误表达的意思是 因为Channel 关闭导致 无法返回 Response 消息。 出现这情况的原因在于 虽然timeout 配置在服务端去是用在客户端，其表示的是客户端调用超时间，而非服务端方法的执行超时。当我们去看客户端的日志时候就能看到timeout异常了 类似这种配在服务端用在客户端的配置还有很多，如retries/riː'traɪ/(重试次数)、async/əˈsɪŋk/（是否异步）、loadbalance(负载均衡)。。。等。 套路一：*服务端配置客户端来使用*。 注：其参数传递机制是 服务端所有配置都会封装到URL参数，在通过注册中心传递到客户端 如果需要暴露多个服务的时候，每个服务都要设置其超时时间，貌似有点繁琐。Dubbo中可以通过 来实现服务端缺省配置。它可以同时为 和 两个标签提供缺省配置。如： #相当于每个服务提供者设置了超时时间 和重试次数 同样客户端也有缺省配置标签：，这些缺省设置可以配置多个 通过 ,如果没指定就用第一个。 、 套路二：与 ，与傻傻分不清楚 在服务端配置timeout 之后 所有客户端都会采用该方超时时间，其客户端可以自定义超时时间吗？通过 可以设定或者在 也可以设定 甚至可以设定到方法级别 。加上服务端的配置，超时总共有6处可以配置。如果6处都配置了不同的值，最后肯定只会有一个超时值生效，其优先级如下： 小提示：通过DefaultFuture的get 方法就可观测到实际的超时设置。 com.alibaba.dubbo.remoting.exchange.support.DefaultFuture 套路三：同一属性到处配置，优先级要小心。 一般建议配置示例： 提供端：--------------------------- 消费端示例：-------------------- Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/dubbo/dubbo-high-use.html":{"url":"distributed/dubbo/dubbo-high-use.html","title":"3.Dubbo企业级应用进阶","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、分布式项目开发与联调 接口暴露与引用 自动化构建与协作 接口平滑升级： 开发联调： 二、Dubbo控制管理后台使用 Dubbo 控制后台版本说明： Dubbo 控制后台的安装： 三、Dubbo注册中心详解 注册中心的作用 Dubbo所支持的注册中心 Redis 注册中心 Zookeeper 注册中心 课程概要： 分布式项目开发与联调 控制管理后台使用 Dubbo注册中心详解 一、分布式项目开发与联调 接口暴露与引用 在一个RPC场景中 ，调用方是通过接口来调用服务端，传入参数并获得返回结果。这样服务端的接口和模型必须暴露给调用方项目。服务端如何暴露呢？客户端如何引用呢？ 接口信息 、模型信息 、异常 暴露接口的通常做法是 接口与实现分离，服务端将 接口、模型、异常 等统一放置于一个模块，实现置于另一个模块。调用方通过Maven进行引用。 自动化构建与协作 当项目越来越多，服务依懒关系越发复杂的时候，为了提高协作效率，必须采用自动化工具 完成 接口从编写到构建成JAR包，最后到引用的整个过程。 流程描述： 服务提供者项目发人员编写Client 接口 push 至远程仓库 jenkins 构建指定版本 jenkins Deploye 至私服仓库 nexus 服务消费者项目开发人员基于maven 从私服务仓库下载接口平滑升级： 在项目迭代过程当中， 经常会有多个项目依懒同一个接口，如下图 项目B、C都依懒了项目A当中的接口1，此时项目B业务需要，需要接口1多增加一个参数，升级完成后。项目B能正确构建上线，项目C却不行。 解决办法与原则： 接口要做到向下兼容：接口参数尽量以对象形式进行封装。Model属性只增不删，如果需要作废，可以添加@Deprecated 标识。 如果出现了不可兼容的变更，则必须通知调用方整改，并制定上线计划。 开发联调： 在项目开发过程当中，一个开发或测试环境的注册中心很有可能会同时承载着多个服务，如果两组服务正在联调，如何保证调用的是目标服务呢？ 1、基于临时分组联调 group 分组 在reference 和server 当中采用相同的临时组 ,通过group 进行设置 2、直连提供者： 在reference 中指定提供者的url即可做到直连 3、只注册： 一个项目有可能同是为即是服务提供者又消费者，在测试时需要调用某一服务同时又不希望正在开发的服务影响到其它订阅者如何实现？ 通过修改 register=false 即可实现 二、Dubbo控制管理后台使用 Dubbo 控制后台版本说明： dubbo 在2.6.0 以前 使用dubbo-admin 作为管理后台，2.6 以后已经去掉dubbo-admin 并采用 incubator-dubbo-ops 作为新的管理后台，目前该后台还在开发中还没有发布正式的版本 ，所以本节课还是采用的旧版的dubbo-admin 来演示。 Dubbo 控制后台的安装： #从github 中下载dubbo 项目 git clone https://github.com/apache/incubator-dubbo.git #更新项目 git fetch #临时切换至 dubbo-2.5.8 版本 git checkout dubbo-2.5.8 #进入 dubbo-admin 目录 cd dubbo-admin #mvn 构建admin war 包 mvn clean pakcage -DskipTests #得到 dubbo-admin-2.5.8.war 即可直接部署至Tomcat #修改 dubbo.properties 配置文件 dubbo.registry.address=zookeeper://127.0.0.1:2181 注：如果实在懒的构建 可直接下载已构建好的： 链接：https://pan.baidu.com/s/1zJFNPgwNVgZZ-xobAfi5eQ 提取码：gjtv 控制后台基本功能介绍 ： 服务查找： 服务关系查看: 服务权重调配： 服务路由： 服务禁用 三、Dubbo注册中心详解 注册中心的作用 为了到达服务集群动态扩容的目的，注册中心存储了服务的地址信息与可用状态信息，并实时推送给订阅了相关服务的客户端。 一个完整的注册中心需要实现以下功能： 接收服务端的注册与客户端的引用，即将引用与消费建立关联，并支持多对多。 当服务非正常关闭时能即时清除其状态 当注册中心重启时，能自动恢复注册数据，以及订阅请求 注册中心本身的集群 Dubbo所支持的注册中心 Multicast 注册中心 基于组网广播技术，只能用在局域网内，一般用于简单的测试服务 Zookeeper 注册中心(**推荐**) Zookeeper 是 Apacahe Hadoop 的子项目，是一个树型的目录服务，支持变更推送，适合作为 Dubbo 服务的注册中心，工业强度较高，可用于生产环境，并推荐使用 Redis 注册中心 基于Redis的注册中心 Simple 注册中心 基于本身的Dubbo服务实现（SimpleRegistryService），不支持集群可作为自定义注册中心的参考，但不适合直接用于生产环境。 Redis 注册中心 关于Redis注册中心我们需要了解两点， 如何存储服务的注册与订阅关系 是当服务状态改变时如何即时更新 演示使用Redis 做为注册中心的使用。 [ ] 启动Redis服务 [ ] 服务端配置注册中心 [ ] 启动两个服务端 [ ] 通过RedisClient 客户端观察Redis中的数据 redis 注册中心配置： 当我们启动两个服务端后发现，Reids中增加了一个Hash 类型的记录，其key为/dubbo/tuling.dubbo.server.UserService/providers。Value中分别存储了两个服务提供者的URL和有效期。 同样消费者也是类似其整体结构如下： //服务提供者注册信息 /dubbbo/com.tuling.teach.service.DemoService/providers dubbo://192.168.246.1:20880/XXX.DemoService=1542619052964 dubbo://192.168.246.2:20880/XXX.DemoService=1542619052964 //服务消费订阅信息 /dubbbo/com.tuling.teach.service.DemoService/consumers dubbo://192.168.246.1:20880/XXX.DemoService=1542619788641 主 Key 为服务名和类型 Map 中的 Key 为 URL 地址 Map 中的 Value 为过期时间，用于判断脏数据，脏数据由监控中心删除 接下来回答第二个问题 当提供者突然 宕机状态能即里变更吗？ 这里Dubbo采用的是定时心跳的机制 来维护服务URL的有效期，默认每30秒更新一次有效期。即URL对应的毫秒值。具体代码参见：com.alibaba.dubbo.registry.redis.RedisRegistry#expireExecutor com.alibaba.dubbo.registry.redis.RedisRegistry#deferExpired com.alibaba.dubbo.registry.integration.RegistryDirectory com.alibaba.dubbo.registry.support.ProviderConsumerRegTable Zookeeper 注册中心 关于Zookeeper 注册中心同样需要了解其存储结构和更新机制。 Zookeper是一个树型的目录服务，本身支持变更推送相比redis的实现Publish/Subscribe功能更稳定。 结构： 失败重连 com.alibaba.dubbo.registry.support.FailbackRegistry 提供者突然断开： 基于Zookeeper 临时节点机制实现，在客户端会话超时后 Zookeeper会自动删除所有临时节点，默认为40秒。 // 创建临时节点 com.alibaba.dubbo.remoting.zookeeper.curator.CuratorZookeeperClient#createEphemeral 提问： 在zookeeper 断开的40秒内 如果 有客户端加入 会调用 已失效的提供者连接吗？ 答：不会，提供者宕机后 ，其与客户端的链接也随即断开，客户端在调用前会检测长连接状态。 // 检测连接是否有效 com.alibaba.dubbo.rpc.protocol.dubbo.DubboInvoker#isAvailable 创建 configurators与routers 会创建持久节点 // 创建持久节点 com.alibaba.dubbo.remoting.zookeeper.curator.CuratorZookeeperClient#createPersistent 服务订阅机制实现： // 注册目录 com.alibaba.dubbo.registry.integration.RegistryDirectory 源码解析： com.alibaba.dubbo.registry.integration.RegistryDirectory Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/dubbo/dubbo-module-detail.html":{"url":"distributed/dubbo/dubbo-module-detail.html","title":"2.Dubb调用模块详解","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、Dubbo 调用模块基本组成 Dubbo调用模块概述： 透明代理： 负载均衡 TODO 一至性hash 演示 容错 异步调用 过滤器 TODO 演示添加日志访问过滤: 二 、Dubbo 调用非典型使用场景 泛化提供&引用 TODO 示例演示 隐示传参 令牌验证 三、调用通信内部实现源码分析 网络传输的实现组成 Dubbo 长连接实现与配置 dubbo传输uml类图: Dubbo 传输协作线程 概要： 一、Dubbo 调用模块基本组成 二 、Dubbo 调用非典型使用场景 三、调用通信内部实现源码分析 一、Dubbo 调用模块基本组成 Dubbo调用模块概述： dubbo调用模块核心功能是发起一个远程方法的调用并顺利拿到返回结果，其体系组成如下： 透明代理：通过动态代理技术，屏蔽远程调用细节以提高编程友好性。 负载均衡：当有多个提供者是，如何选择哪个进行调用的负载算法。 容错机制：当服务调用失败时采取的策略 调用方式：支持同步调用、异步调用 透明代理： 参见源码： com.alibaba.dubbo.config.ReferenceConfig#createProxy com.alibaba.dubbo.common.bytecode.ClassGenerator com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory 负载均衡 Dubbo 目前官方支持以下负载均衡策略： 随机(random)：按权重设置随机概率。此为默认算法. 轮循 (roundrobin):按公约后的权重设置轮循比率。 最少活跃调用数(leastactive):相同活跃数的随机，活跃数指调用前后计数差。 一致性Hash(consistenthash ):相同的参数总是发到同一台机器 设置方式支持如下四种方式设置，优先级由低至高 TODO 一至性hash 演示 [ ] 配置loadbalance [ ] 配置需要hash 的参数与虚拟节点数 [ ] 发起远程调用 一至性hash 算法详解： 容错 Dubbo 官方目前支持以下容错策略： 失败自动切换：调用失败后基于retries=“2” 属性重试其它服务器 快速失败：快速失败，只发起一次调用，失败立即报错。 勿略失败：失败后勿略，不抛出异常给客户端。 失败重试：失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作 并行调用: 只要一个成功即返回，并行调用指定数量机器，可通过 forks=\"2\" 来设置最大并行数。 广播调用：广播调用所有提供者，逐个调用，任意一台报错则报错 设置方式支持如下两种方式设置，优先级由低至高 注：容错机制 在基于 API设置时无效 如 referenceConfig.setCluster(\"failback\"); 经测试不启作用 异步调用 异步调用是指发起远程调用之后获取结果的方式。 同步等待结果返回（默认） 异步等待结果返回 不需要返回结果 Dubbo 中关于异步等待结果返回的实现流程如下图： 异步调用配置: 注：在进行异步调用时 容错机制不能为 cluster=\"forking\" 或 cluster=\"broadcast\" 异步获取结果演示： [ ] 编写异步调用代码 [ ] 编写同步调用代码 [ ] 分别演示同步调用与异步调用耗时 异步调用结果获取Demo demoService.sayHello1(\"han\"); Future future1 = RpcContext.getContext().getFuture(); demoService.sayHello2(\"han2\"); Future future2 = RpcContext.getContext().getFuture(); Object r1 = null, r2 = null; // wait 直到拿到结果 获超时 r1 = future1.get(); // wait 直到拿到结果 获超时 r2 = future2.get(); 过滤器 类似于 WEB 中的Filter ，Dubbo本身提供了Filter 功能用于拦截远程方法的调用。其支持自定义过滤器与官方的过滤器使用： TODO 演示添加日志访问过滤: 以上配置 就是 为 服务提供者 添加 日志记录过滤器， 所有访问日志将会集中打印至 accesslog 当中 二 、Dubbo 调用非典型使用场景 泛化提供&引用 泛化提供 是指不通过接口的方式直接将服务暴露出去。通常用于Mock框架或服务降级框架实现。 TODO 示例演示 public static void doExportGenericService() { ApplicationConfig applicationConfig = new ApplicationConfig(); applicationConfig.setName(\"demo-provider\"); // 注册中心 RegistryConfig registryConfig = new RegistryConfig(); registryConfig.setProtocol(\"zookeeper\"); registryConfig.setAddress(\"192.168.0.147:2181\"); ProtocolConfig protocol=new ProtocolConfig(); protocol.setPort(-1); protocol.setName(\"dubbo\"); GenericService demoService = new MyGenericService(); ServiceConfig service = new ServiceConfig(); // 弱类型接口名 service.setInterface(\"com.tuling.teach.service.DemoService\"); // 指向一个通用服务实现 service.setRef(demoService); service.setApplication(applicationConfig); service.setRegistry(registryConfig); service.setProtocol(protocol); // 暴露及注册服务 service.export(); } 泛化引用 是指不通过常规接口的方式去引用服务，通常用于测试框架。 ApplicationConfig applicationConfig = new ApplicationConfig(); applicationConfig.setName(\"demo-provider\"); // 注册中心 RegistryConfig registryConfig = new RegistryConfig(); registryConfig.setProtocol(\"zookeeper\"); registryConfig.setAddress(\"192.168.0.147:2181\"); // 引用远程服务 ReferenceConfig reference = new ReferenceConfig(); // 弱类型接口名 reference.setInterface(\"com.tuling.teach.service.DemoService\"); // 声明为泛化接口 reference.setGeneric(true); reference.setApplication(applicationConfig); reference.setRegistry(registryConfig); // 用com.alibaba.dubbo.rpc.service.GenericService可以替代所有接口引用 GenericService genericService = reference.get(); Object result = genericService.$invoke(\"sayHello\", new String[]{\"java.lang.String\"}, new Object[]{\"world\"}); 隐示传参 是指通过非常方法参数传递参数，类似于http 调用当中添加cookie值。通常用于分布式追踪框架的实现。使用方式如下 ： //客户端隐示设置值 RpcContext.getContext().setAttachment(\"index\", \"1\"); // 隐式传参，后面的远程调用都会隐 //服务端隐示获取值 String index = RpcContext.getContext().getAttachment(\"index\"); 令牌验证 通过令牌验证在注册中心控制权限，以决定要不要下发令牌给消费者，可以防止消费者绕过注册中心访问提供者，另外通过注册中心可灵活改变授权方式，而不需修改或升级提供者 使用： 三、调用通信内部实现源码分析 网络传输的实现组成 IO模型： BIO 同步阻塞 NIO 同步非阻塞 AIO 异步非阻塞 连接模型： 长连接 短连接 线程分类： IO线程 服务端业务线程 客户端调度线程 客户端结果exchange线程。 保活心跳线程 重连线程 线程池模型： 固定数量线程池 缓存线程池 有限线程池Dubbo 长连接实现与配置 初始连接： 引用服务增加提供者==>获取连接===》是否获取共享连接==>创建连接客户端==》开启心跳检测状态检查定时任务===》开启连接状态检测 源码见：com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol#getClients 心跳发送： 在创建一个连接客户端同时也会创建一个心跳客户端，客户端默认基于60秒发送一次心跳来保持连接的存活，可通过 heartbeat 设置。 源码见：com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeClient#startHeatbeatTimer 断线重连： 每创建一个客户端连接都会启动一个定时任务每两秒中检测一次当前连接状态，如果断线则自动重连。 源码见：com.alibaba.dubbo.remoting.transport.AbstractClient#initConnectStatusCheckCommand 连接销毁: 基于注册中心通知，服务端断开后销毁 源码见：com.alibaba.dubbo.remoting.transport.AbstractClient#close() dubbo传输uml类图: Dubbo 传输协作线程 客户端调度线程：用于发起远程方法调用的线程。 客户端结果**Exchange**线程：当远程方法返回response后由该线程填充至指定ResponseFuture，并叫醒等待的调度线程。 客户端IO线程：由传输框架实现，用于request 消息流发送、response 消息流读取与解码等操作。 服务端IO线程：由传输框架实现，用于request消息流读取与解码 与Response发送。 业务执行线程：服务端具体执行业务方法的线程 客户端线程协作流程： 调度线程 调用远程方法 对request 进行协议编码 发送request 消息至IO线程 等待结果的获取 IO线程 读取response流 response 解码 提交Exchange 任务 Exchange线程 填写response值 至 ResponseFuture 唤醒调度线程，通知其获取结果 调用调试： 客户端的执行线程: 1、业务线程 1) DubboInvoker#doInvoke(隐示传公共参数、获取客户端、异步、单向、同步（等待返回结果）) 2)AbstractPeer#send// netty Client客户端发送消息 写入管道 3)DubboCodec#encodeRequestData // Request 协议编码 2、IO线程 DubboCodec#decodeBody //Response解码 AllChannelHandler#received //// 派发消息处理线程 3、调度线程 DefaultFuture#doReceived // 设置返回结果 服务端线程协作： IO线程： request 流读取 request 解码 提交业务处理任务 业务线程： 业务方法执行 response 编码 回写结果至channel 线程池 fixed：固定线程池,此线程池启动时即创建固定大小的线程数，不做任何伸缩， cached：缓存线程池,此线程池可伸缩，线程空闲一分钟后回收，新请求重新创建线程 Limited：有限线程池,此线程池一直增长，直到上限，增长后不收缩。 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/dubbo/dubbo-proto-detail.html":{"url":"distributed/dubbo/dubbo-proto-detail.html","title":"3.Dubbo协议模块源码剖析","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 RPC协议基本组成 RPC 协议名词解释 协议基本组成： Dubbo中所支持RPC协议使用 协议的使用与配置: TODO 演示采用其它协议来配置Dubbo Hessian 序列化： 三 、RPC协议报文编码与实现详解 RPC 传输实现： 拆包与粘包产生的原因： 拆包与粘包解决办法： Dubbo 协议报文编码： Dubbo协议的编解码过程： 主讲：鲁班 时间：2018/12/2 8:10 地址：腾讯课堂图灵学院 课程概要： RPC协议基本组成 RPC协议报文编码与实现详解 Dubbo中所支持RPC协议与使用 RPC协议基本组成 RPC 协议名词解释 在一个典型RPC的使用场景中，包含了服务发现、负载、容错、网络传输、序列化等组件，其中RPC协议就指明了程序如何进行网络传输和序列化 。也就是说一个RPC协议的实现就等于一个非透明的远程调用实现，如何做到的的呢？ 协议基本组成： 地址：服务提供者地址 端口：协议指定开放的端口 报文编码：协议报文编码 ，分为请求头和请求体两部分。 序列化方式：将请求体序列化成对象 Hessian2Serialization、 DubboSerialization、 JavaSerialization JsonSerialization 运行服务: 网络传输实现 netty mina RMI 服务 servlet 容器（jetty、Tomcat、Jboss） Dubbo中所支持RPC协议使用 dubbo 支持的RPC协议列表 | 名称 | 实现描述 | 连接描述 | 适用场景 | |:----|:----|:----|:----| | dubbo | 传输服务: mina, netty(默认), grizzy序列化: hessian2(默认), java, fastjson自定义报文 | 单个长连接NIO异步传输 | 1、常规RPC调用2、传输数据量小3、提供者少于消费者 | | rmi | 传输：java rmi 服务序列化：java原生二进制序列化 | 多个短连接BIO同步传输 | 1、常规RPC调用2、与原RMI客户端集成3、可传少量文件4、不支持防火墙穿透 | | hessian | 传输服务：servlet容器序列化：hessian二进制序列化 | 基于Http 协议传输，依懒servlet容器配置 | 1、提供者多于消费者2、可传大字段和文件3、跨语言调用 | | http | 传输服务：servlet容器序列化：java原生二进制序列化 | 依懒servlet容器配置 | 1、数据包大小混合 | | thrift | 与thrift RPC 实现集成，并在其基础上修改了报文头 | 长连接、NIO异步传输 | | 关于RMI不支持防火墙穿透的补充说明： 原因在于RMI 底层实现中会有两个端口，一个是固定的用于服务发现的注册端口，另外会生成一个随机端口用于网络传输。因为这个随机端口就不能在防火墙中提前设置开放开。所以存在防火墙穿透问题 协议的使用与配置: Dubbo框架配置协议非常方便，用户只需要在 provider 应用中 配置 元素即可。 TODO 演示采用其它协议来配置Dubbo [ ] dubbo 协议采用 json 进行序列化 (源码参见：com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol) [ ] 采用RMI协议 (源码参见：com.alibaba.dubbo.rpc.protocol.rmi.RmiProtocol) [ ] 采用Http协议 (源码参见：com.alibaba.dubbo.rpc.protocol.http.HttpProtocol.InternalHandler) [ ] 采用Heason协议 (源码参见:com.alibaba.dubbo.rpc.protocol.hessian.HessianProtocol.HessianHandler) netstat -aon|findstr \"17732\" 序列化： | | 特点 | |:----|:----| | fastjson | 文本型：体积较大，性能慢、跨语言、可读性高 | | fst | 二进制型：体积小、兼容 JDK 原生的序列化。要求 JDK 1.7 支持。 | | hessian2 | 二进制型：跨语言、容错性高、体积小 | | java | 二进制型：在JAVA原生的基础上 可以写入Null | | compactedjava | 二进制型：与java 类似，内容做了压缩 | | nativejava | 二进制型：原生的JAVA 序列化 | | kryo | 二进制型：体积比hessian2 还要小，但容错性 没有hessian2 好 | Hessian 序列化： 参数及返回值需实现 Serializable 接口 参数及返回值不能自定义实现 List, Map, Number, Date, Calendar 等接口，只能用 JDK 自带的实现，因为 hessian 会做特殊处理，自定义实现类中的属性值都会丢失。 Hessian 序列化，只传成员属性值和值的类型，不传方法或静态变量，兼容情况 [1][2]： | 数据通讯 | 情况 | 结果 | |:----|:----|:----| | A->B | 类A多一种 属性（或者说类B少一种 属性） | 不抛异常，A多的那 个属性的值，B没有， 其他正常 | | A->B | 枚举A多一种 枚举（或者说B少一种 枚举），A使用多 出来的枚举进行传输 | 抛异常 | | A->B | 枚举A多一种 枚举（或者说B少一种 枚举），A不使用 多出来的枚举进行传输 | 不抛异常，B正常接 收数据 | | A->B | A和B的属性 名相同，但类型不相同 | 抛异常 | | A->B | serialId 不相同 | 正常传输 | 接口增加方法，对客户端无影响，如果该方法不是客户端需要的，客户端不需要重新部署。输入参数和结果集中增加属性，对客户端无影响，如果客户端并不需要新属性，不用重新部署。 输入参数和结果集属性名变化，对客户端序列化无影响，但是如果客户端不重新部署，不管输入还是输出，属性名变化的属性值是获取不到的。 总结：服务器端和客户端对领域对象并不需要完全一致，而是按照最大匹配原则。 [ ] 演示Hession2 序列化的容错性 三 、RPC协议报文编码与实现详解 RPC 传输实现： RPC的协议的传输是基于 TCP/IP 做为基础使用Socket 或Netty、mina等网络编程组件实现。但有个问题是TCP是面向字节流的无边边界协议，其只管负责数据传输并不会区分每次请求所对应的消息，这样就会出现TCP协义传输当中的拆包与粘包问题 拆包与粘包产生的原因： 我们知道tcp是以流动的方式传输数据，传输的最小单位为一个报文段（segment）。tcp Header中有个Options标识位，常见的标识为mss(Maximum Segment Size)指的是，连接层每次传输的数据有个最大限制MTU(Maximum Transmission Unit)，一般是1500比特，超过这个量要分成多个报文段，mss则是这个最大限制减去TCP的header，光是要传输的数据的大小，一般为1460比特。换算成字节，也就是180多字节。 tcp为提高性能，发送端会将需要发送的数据发送到缓冲区，等待缓冲区满了之后，再将缓冲中的数据发送到接收方。同理，接收方也有缓冲区这样的机制，来接收数据。这时就会出现以下情况： 应用程序写入的数据大于MSS大小，这将会发生拆包。 应用程序写入数据小于MSS大小，这将会发生粘包。 接收方法不及时读取套接字缓冲区数据，这将发生粘包。拆包与粘包解决办法： 设置定长消息，服务端每次读取既定长度的内容作为一条完整消息。 {\"type\":\"message\",\"content\":\"hello\"}\\n 使用带消息头的协议、消息头存储消息开始标识及消息长度信息，服务端获取消息头的时候解析出消息长度，然后向后读取该长度的内容。 比如：Http协议 heade 中的 Content-Length 就表示消息体的大小。 (注①：http 报文编码) Dubbo 协议报文编码： 注②Dubbo 协议报文编码： | | 0-7 | 8-15 | 16-20 | 21 | 22 | 23 | 24-31 | | |:----|:----|:----|:----|:----|:----|:----|:----|:----| | | | 1 | 1 | | | | | | | 32-95 | | | | | | | | | | 96-127 | | | | | | | | | magic：类似java字节码文件里的魔数，用来判断是不是dubbo协议的数据包。魔数是常量0xdabb,用于判断报文的开始。 flag：标志位, 一共8个地址位。低四位用来表示消息体数据用的序列化工具的类型（默认hessian），高四位中，第一位为1表示是request请求，第二位为1表示双向传输（即有返回response），第三位为1表示是心跳ping事件。 status：状态位, 设置请求响应状态，dubbo定义了一些响应的类型。具体类型见 com.alibaba.dubbo.remoting.exchange.Response invoke id：消息id, long 类型。每一个请求的唯一识别id（由于采用异步通讯的方式，用来把请求request和返回的response对应上） body length：消息体 body 长度, int 类型，即记录Body Content有多少个字节。 （注：相关源码参见 com.alibaba.dubbo.rpc.protocol.dubbo.DubboCodec**） Dubbo协议的编解码过程： Dubbo 协议编解码实现过程 (源码来源于**dubbo2.5.8 ) 1、DubboCodec.encodeRequestData() 116L // 编码request 2、DecodeableRpcInvocation.decode() 89L // 解码request 3、DubboCodec.encodeResponseData() 184L // 编码response 4、DecodeableRpcResult.decode() 73L // 解码response Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/rocketmq/":{"url":"distributed/rocketmq/","title":"rocketmq","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/rocketmq/shell.html":{"url":"distributed/rocketmq/shell.html","title":"1.启停脚本","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 ! /bin/bash #! /bin/bash case $1 in \"start\"){ for i in hadoop101 hadoop102 hadoop103 do echo \" --------启动 $i Kafka-------\" # 用于KafkaManager监控 ssh $i \"export JMX_PORT=9988 && /usr/local/software/kafka_2.12-2.6.0/bin/kafka-server-start.sh -daemon /usr/local/software/kafka_2.12-2.6.0/config/server.properties \" done };; \"stop\"){ for i in hadoop101 hadoop102 hadoop103 do echo \" --------停止 $i Kafka-------\" ssh $i \"/usr/local/software/kafka_2.12-2.6.0/bin/kafka-server-stop.sh stop\" done };; esac Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:36:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/rocketmq/rocketmq.html":{"url":"distributed/rocketmq/rocketmq.html","title":"2.分布式之RockeqMq","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.概述 1.1 简介 1.2 特点 1.3 场景 1.4 架构 1.5 工作原理 2.环境搭建 2.1 版本 2.2 主机规划 2.3 下载 2.4 单机启动 2.4.1启动NameServer 2.4.2启动Broker 2.4.3测试RocketMQ 2.5集群部署 2.5.1服务器环境 2.5.2 Host添加信息 2.5.3 防火墙配置 2.5.4环境变量配置 2.5.5 创建消息存储路径 2.5.6broker配置文件 1）master1 2）slave2 3）master2 4）slave1 2.5.7 修改启动脚本文件 1）runbroker.sh 2）runserver.sh 2.5.8 服务启动 1）启动NameServe集群 2）启动Broker集群 2.5.9 查看进程状态 2.5.10 查看日志 3.快速入门 3.1 普通消息 3.2 定时消息 3.3 顺序消息 3.4 事务消息 4.深入了解 4.1Consumer端 4.1.1消费模型 4.1.2消费选择 4.1.3消息重复幂等： 4.1.4消息过滤： 4.2Namesrv端 4.3Broker端 5.优化 5.1 5.2 5.3 1.概述 1.1 简介 1.2 特点 1.3 场景 解耦 异步 肖锋1.4 架构 1.5 工作原理 2.环境搭建 2.1 版本 组件 版本 备注 centos 64 位 7.x 以上 jdk 1.8 rocketmq 4.x 2.2 主机规划 ip host 安装软件 192.168.62.130 hadoop102 rocketmq jdk 192.168.62.131 hadoop103 rocketmq jdk 2.3 下载 https://github.com/apache/rocketmq/ 2.4 单机启动 2.4.1启动NameServer # 1.启动NameServer nohup sh bin/mqnamesrv & # 2.查看启动日志 tail -f ~/logs/rocketmqlogs/namesrv.log 2.4.2启动Broker # 1.启动Broker nohup sh bin/mqbroker -n localhost:9876 & # 2.查看启动日志 tail -f ~/logs/rocketmqlogs/broker.log 问题描述： RocketMQ默认的虚拟机内存较大，启动Broker如果因为内存不足失败，需要编辑如下两个配置文件，修改JVM内存大小# 编辑runbroker.sh和runserver.sh修改默认JVM大小 vi runbroker.sh vi runserver.sh 参考设置： JAVA_OPT=\"${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m\" 2.4.3测试RocketMQ 发送消息 # 1.设置环境变量 export NAMESRV_ADDR=localhost:9876 # 2.使用安装包的Demo发送消息 sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer 接收消息 # 1.设置环境变量 export NAMESRV_ADDR=localhost:9876 # 2.接收消息 sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer 关闭RocketMQ # 1.关闭NameServer sh bin/mqshutdown namesrv # 2.关闭Broker sh bin/mqshutdown broker 2.5集群部署 2.5.1服务器环境 序号 IP 角色 架构模式 1 192.168.62.130 nameserver、brokerserver Master1、Slave2 2 192.168.62.131 nameserver、brokerserver Master2、Slave1 2.5.2 Host添加信息 vim /etc/hosts 配置如下: # nameserver 192.168.62.130 rocketmq-nameserver1 192.168.62.131 rocketmq-nameserver2 # broker 192.168.62.130 rocketmq-master1 192.168.62.130 rocketmq-slave2 192.168.62.131 rocketmq-master2 192.168.62.131 rocketmq-slave1 # nameserver sudo echo '192.168.62.130 rocketmq-nameserver1' >>/etc/hosts echo '192.168.62.131 rocketmq-nameserver2' >>/etc/hosts # broker echo '192.168.62.130 rocketmq-master1' >>/etc/hosts echo '192.168.62.130 rocketmq-slave2' >>/etc/hosts echo '192.168.62.131 rocketmq-master2' >>/etc/hosts echo '192.168.62.131 rocketmq-slave1' >>/etc/hosts 配置完成后, 重启网卡 systemctl restart network 2.5.3 防火墙配置 宿主机需要远程访问虚拟机的rocketmq服务和web服务，需要开放相关的端口号，简单粗暴的方式是直接关闭防火墙 # 关闭防火墙 systemctl stop firewalld.service # 查看防火墙的状态 firewall-cmd --state # 禁止firewall开机启动 systemctl disable firewalld.service 或者为了安全，只开放特定的端口号，RocketMQ默认使用3个端口：9876 、10911 、11011 。如果防火墙没有关闭的话，那么防火墙就必须开放这些端口： nameserver默认使用 9876 端口 master默认使用 10911 端口 slave默认使用11011 端口 执行以下命令： # 开放name server默认端口 firewall-cmd --remove-port=9876/tcp --permanent # 开放master默认端口 firewall-cmd --remove-port=10911/tcp --permanent # 开放slave默认端口 (当前集群模式可不开启) firewall-cmd --remove-port=11011/tcp --permanent # 重启防火墙 firewall-cmd --reload 2.5.4环境变量配置 vim /etc/profile 在profile文件的末尾加入如下命令 #set rocketmq ROCKETMQ_HOME=/usr/local/software/rocketmq PATH=$PATH:$ROCKETMQ_HOME/bin export ROCKETMQ_HOME PATH #set rocketmq echo 'ROCKETMQ_HOME=/usr/local/rocketmq/rocketmq-all-4.4.0-bin-release' >>/etc/profile echo 'PATH=$PATH:$ROCKETMQ_HOME/bin' >>/etc/profile echo 'export ROCKETMQ_HOME PATH' >>/etc/profile 输入:wq! 保存并退出， 并使得配置立刻生效： source /etc/profile 2.5.5 创建消息存储路径 sudo mkdir -p /usr/local/rocketmq/store sudo mkdir -p /usr/local/rocketmq/store/commitlog sudo mkdir -p /usr/local/rocketmq/store/consumequeue sudo mkdir -p /usr/local/rocketmq/store/index sudo mkdir -p /usr/local/rocketmqs/store sudo mkdir -p /usr/local/rocketmqs/store/commitlog sudo mkdir -p /usr/local/rocketmqs/store/consumequeue sudo mkdir -p /usr/local/rocketmqs/store/index 2.5.6broker配置文件 1）master1 服务器：192.168.62.130 vim /usr/local/software/rocketmq/conf/2m-2s-sync/broker-a.properties 修改配置如下： #所属集群名字 brokerClusterName=rocketmq-cluster #broker名字，注意此处不同的配置文件填写的不一样 brokerName=broker-a #0 表示 Master，>0 表示 Slave brokerId=0 #nameServer地址，分号分割 namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876 #在发送消息时，自动创建服务器不存在的topic，默认创建的队列数 defaultTopicQueueNums=4 #是否允许 Broker 自动创建Topic，建议线下开启，线上关闭 autoCreateTopicEnable=true #是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭 autoCreateSubscriptionGroup=true #Broker 对外服务的监听端口 listenPort=10911 #删除文件时间点，默认凌晨 4点 deleteWhen=04 #文件保留时间，默认 48 小时 fileReservedTime=120 #commitLog每个文件的大小默认1G mapedFileSizeCommitLog=1073741824 #ConsumeQueue每个文件默认存30W条，根据业务情况调整 mapedFileSizeConsumeQueue=300000 #destroyMapedFileIntervalForcibly=120000 #redeleteHangedFileInterval=120000 #检测物理文件磁盘空间 diskMaxUsedSpaceRatio=88 #存储路径 storePathRootDir=/usr/local/rocketmq/store #commitLog 存储路径 storePathCommitLog=/usr/local/rocketmq/store/commitlog #消费队列存储路径存储路径 storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue #消息索引存储路径 storePathIndex=/usr/local/rocketmq/store/index #checkpoint 文件存储路径 storeCheckpoint=/usr/local/rocketmq/store/checkpoint #abort 文件存储路径 abortFile=/usr/local/rocketmq/store/abort #限制的消息大小 maxMessageSize=65536 #flushCommitLogLeastPages=4 #flushConsumeQueueLeastPages=2 #flushCommitLogThoroughInterval=10000 #flushConsumeQueueThoroughInterval=60000 #Broker 的角色 #- ASYNC_MASTER 异步复制Master #- SYNC_MASTER 同步双写Master #- SLAVE brokerRole=SYNC_MASTER #刷盘方式 #- ASYNC_FLUSH 异步刷盘 #- SYNC_FLUSH 同步刷盘 flushDiskType=SYNC_FLUSH #checkTransactionMessageEnable=false #发消息线程池数量 #sendMessageThreadPoolNums=128 #拉消息线程池数量 #pullMessageThreadPoolNums=128 2）slave2 服务器：192.168.62.130 vim /usr/local/software/rocketmq/conf/2m-2s-sync/broker-b-s.properties 修改配置如下： #所属集群名字 brokerClusterName=rocketmq-cluster #broker名字，注意此处不同的配置文件填写的不一样 brokerName=broker-b #0 表示 Master，>0 表示 Slave brokerId=1 #nameServer地址，分号分割 namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876 #在发送消息时，自动创建服务器不存在的topic，默认创建的队列数 defaultTopicQueueNums=4 #是否允许 Broker 自动创建Topic，建议线下开启，线上关闭 autoCreateTopicEnable=true #是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭 autoCreateSubscriptionGroup=true #Broker 对外服务的监听端口 listenPort=11011 #删除文件时间点，默认凌晨 4点 deleteWhen=04 #文件保留时间，默认 48 小时 fileReservedTime=120 #commitLog每个文件的大小默认1G mapedFileSizeCommitLog=1073741824 #ConsumeQueue每个文件默认存30W条，根据业务情况调整 mapedFileSizeConsumeQueue=300000 #destroyMapedFileIntervalForcibly=120000 #redeleteHangedFileInterval=120000 #检测物理文件磁盘空间 diskMaxUsedSpaceRatio=88 #存储路径 storePathRootDir=/usr/local/rocketmqs/store #commitLog 存储路径 storePathCommitLog=/usr/local/rocketmqs/store/commitlog #消费队列存储路径存储路径 storePathConsumeQueue=/usr/local/rocketmqs/store/consumequeue #消息索引存储路径 storePathIndex=/usr/local/rocketmqs/store/index #checkpoint 文件存储路径 storeCheckpoint=/usr/local/rocketmqs/store/checkpoint #abort 文件存储路径 abortFile=/usr/local/rocketmqs/store/abort #限制的消息大小 maxMessageSize=65536 #flushCommitLogLeastPages=4 #flushConsumeQueueLeastPages=2 #flushCommitLogThoroughInterval=10000 #flushConsumeQueueThoroughInterval=60000 #Broker 的角色 #- ASYNC_MASTER 异步复制Master #- SYNC_MASTER 同步双写Master #- SLAVE brokerRole=SLAVE #刷盘方式 #- ASYNC_FLUSH 异步刷盘 #- SYNC_FLUSH 同步刷盘 flushDiskType=ASYNC_FLUSH #checkTransactionMessageEnable=false #发消息线程池数量 #sendMessageThreadPoolNums=128 #拉消息线程池数量 #pullMessageThreadPoolNums=128 3）master2 服务器：192.168.62.131 vim /usr/local/software/rocketmq/conf/2m-2s-sync/broker-b.properties 修改配置如下： #所属集群名字 brokerClusterName=rocketmq-cluster #broker名字，注意此处不同的配置文件填写的不一样 brokerName=broker-b #0 表示 Master，>0 表示 Slave brokerId=0 #nameServer地址，分号分割 namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876 #在发送消息时，自动创建服务器不存在的topic，默认创建的队列数 defaultTopicQueueNums=4 #是否允许 Broker 自动创建Topic，建议线下开启，线上关闭 autoCreateTopicEnable=true #是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭 autoCreateSubscriptionGroup=true #Broker 对外服务的监听端口 listenPort=10911 #删除文件时间点，默认凌晨 4点 deleteWhen=04 #文件保留时间，默认 48 小时 fileReservedTime=120 #commitLog每个文件的大小默认1G mapedFileSizeCommitLog=1073741824 #ConsumeQueue每个文件默认存30W条，根据业务情况调整 mapedFileSizeConsumeQueue=300000 #destroyMapedFileIntervalForcibly=120000 #redeleteHangedFileInterval=120000 #检测物理文件磁盘空间 diskMaxUsedSpaceRatio=88 #存储路径 storePathRootDir=/usr/local/rocketmq/store #commitLog 存储路径 storePathCommitLog=/usr/local/rocketmq/store/commitlog #消费队列存储路径存储路径 storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue #消息索引存储路径 storePathIndex=/usr/local/rocketmq/store/index #checkpoint 文件存储路径 storeCheckpoint=/usr/local/rocketmq/store/checkpoint #abort 文件存储路径 abortFile=/usr/local/rocketmq/store/abort #限制的消息大小 maxMessageSize=65536 #flushCommitLogLeastPages=4 #flushConsumeQueueLeastPages=2 #flushCommitLogThoroughInterval=10000 #flushConsumeQueueThoroughInterval=60000 #Broker 的角色 #- ASYNC_MASTER 异步复制Master #- SYNC_MASTER 同步双写Master #- SLAVE brokerRole=SYNC_MASTER #刷盘方式 #- ASYNC_FLUSH 异步刷盘 #- SYNC_FLUSH 同步刷盘 flushDiskType=SYNC_FLUSH #checkTransactionMessageEnable=false #发消息线程池数量 #sendMessageThreadPoolNums=128 #拉消息线程池数量 #pullMessageThreadPoolNums=128 4）slave1 服务器：192.168.62.131 vim /usr/local/software/rocketmq/conf/2m-2s-sync/broker-a-s.properties 修改配置如下： #所属集群名字 brokerClusterName=rocketmq-cluster #broker名字，注意此处不同的配置文件填写的不一样 brokerName=broker-a #0 表示 Master，>0 表示 Slave brokerId=1 #nameServer地址，分号分割 namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876 #在发送消息时，自动创建服务器不存在的topic，默认创建的队列数 defaultTopicQueueNums=4 #是否允许 Broker 自动创建Topic，建议线下开启，线上关闭 autoCreateTopicEnable=true #是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭 autoCreateSubscriptionGroup=true #Broker 对外服务的监听端口 listenPort=11011 #删除文件时间点，默认凌晨 4点 deleteWhen=04 #文件保留时间，默认 48 小时 fileReservedTime=120 #commitLog每个文件的大小默认1G mapedFileSizeCommitLog=1073741824 #ConsumeQueue每个文件默认存30W条，根据业务情况调整 mapedFileSizeConsumeQueue=300000 #destroyMapedFileIntervalForcibly=120000 #redeleteHangedFileInterval=120000 #检测物理文件磁盘空间 diskMaxUsedSpaceRatio=88 #存储路径 storePathRootDir=/usr/local/rocketmqs/store #commitLog 存储路径 storePathCommitLog=/usr/local/rocketmqs/store/commitlog #消费队列存储路径存储路径 storePathConsumeQueue=/usr/local/rocketmqs/store/consumequeue #消息索引存储路径 storePathIndex=/usr/local/rocketmqs/store/index #checkpoint 文件存储路径 storeCheckpoint=/usr/local/rocketmqs/store/checkpoint #abort 文件存储路径 abortFile=/usr/local/rocketmqs/store/abort #限制的消息大小 maxMessageSize=65536 #flushCommitLogLeastPages=4 #flushConsumeQueueLeastPages=2 #flushCommitLogThoroughInterval=10000 #flushConsumeQueueThoroughInterval=60000 #Broker 的角色 #- ASYNC_MASTER 异步复制Master #- SYNC_MASTER 同步双写Master #- SLAVE brokerRole=SLAVE #刷盘方式 #- ASYNC_FLUSH 异步刷盘 #- SYNC_FLUSH 同步刷盘 flushDiskType=ASYNC_FLUSH #checkTransactionMessageEnable=false #发消息线程池数量 #sendMessageThreadPoolNums=128 #拉消息线程池数量 #pullMessageThreadPoolNums=128 2.5.7 修改启动脚本文件 1）runbroker.sh vim /usr/local/software/rocketmq/bin/runbroker.sh 需要根据内存大小进行适当的对JVM参数进行调整： #=================================================== # 开发环境配置 JVM Configuration JAVA_OPT=\"${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m\" 2）runserver.sh vim /usr/local/software/rocketmq/bin/runserver.sh JAVA_OPT=\"${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m\" 2.5.8 服务启动 1）启动NameServe集群 分别在192.168.25.135和192.168.25.138启动NameServer cd /usr/local/software/rocketmq/bin nohup sh mqnamesrv & 2）启动Broker集群 在192.168.62.130上启动master1和slave2 master1： cd /usr/local/software/rocketmq/bin nohup sh mqbroker -c /usr/local/software/rocketmq/conf/2m-2s-sync/broker-a.properties & slave2： cd /usr/local/software/rocketmq/bin nohup sh mqbroker -c /usr/local/software/rocketmq/conf/2m-2s-sync/broker-b-s.properties & 在192.168.62.131上启动master2和slave2 master2 cd /usr/local/software/rocketmq/bin nohup sh mqbroker -c /usr/local/software/rocketmq/conf/2m-2s-sync/broker-b.properties & slave1 /usr/local/software/rocketmq/bin nohup sh mqbroker -c /usr/local/software/rocketmq/conf/2m-2s-sync/broker-a-s.properties & 2.5.9 查看进程状态 启动后通过JPS查看启动进程 2.5.10 查看日志 # 查看nameServer日志 tail -500f ~/logs/rocketmqlogs/namesrv.log # 查看broker日志 tail -500f ~/logs/rocketmqlogs/broker.log 3.快速入门 3.1 普通消息 3.2 定时消息 3.3 顺序消息 3.4 事务消息 4.深入了解 4.1Consumer端 RocketMQ提供了两种消费模式：PUSH（pull进行监听）和PULL（长轮训） Push 方式：rocketmq 已经提供了很全面的实现， consumer 通过长轮询拉取消息后回调 MessageListener 接口实现完成消费， 应用系统只要 MessageListener 完成业务逻辑即可 Pull 方式：完全由业务系统去控制，定时拉取消息，指定队列消费等等， 当然这里需要业务系统 根据自己的业务需求去实现。 这两种模式分别对应的是DefaultMQPushConsumer类和DefaultMQPullConsumer类 org.apache.rocketmq.client.impl.consumer.PullMessageService#run 4.1.1消费模型 org.apache.rocketmq.common.protocol.heartbeat.MessageModel#BROADCASTING org.apache.rocketmq.common.protocol.heartbeat.MessageModel#CLUSTERING 4.1.2消费选择 org.apache.rocketmq.common.consumer.ConsumeFromWhere#CONSUME_FROM_LAST_OFFSET 第一次启动从队列最后位置消费，后续再启动接着上次消费的进度开始消费 org.apache.rocketmq.common.consumer.ConsumeFromWhere#CONSUME_FROM_FIRST_OFFSET 第一次启动从队列初始位置消费，后续再启动接着上次消费的进度开始消费 org.apache.rocketmq.common.consumer.ConsumeFromWhere#CONSUME_FROM_TIMESTAMP 第一次启动从指定时间点位置消费，后续再启动接着上次消费的进度开始消费 以上所说的第一次启动是指从来没有消费过的消费者，如果该消费者消费过，那么会在broker端记录该消费者的消费位置，如果该消费者挂了再启动，那么自动从上次消费的进度开始 4.1.3消息重复幂等： RocketMQ无法避免消息重复，所以如果业务对消费重复非常敏感，务必要在业务层面去重 Ps：见开发文档 接口幂等性处理 redis incr 4.1.4消息过滤： enablePropertyFilter=true Status=1 消费 status=2不需要 4.2Namesrv端 Namesrv 名称服务，是没有状态可集群横向扩展。可以理解为一个注册中心, 整个Namesrv的代码非常简单，主要包含两块功能： 1、管理一些 KV 的配置 2、管理一些 Topic、Broker的注册信息 大致提供服务为： 每个 broker 启动的时候会向 namesrv 注册 Producer 发送消息的时候根据 topic 获取路由到 broker 的信息 Consumer 根据 topic 到 namesrv 获取 topic 的路由到 broker 的信息 4.3Broker端 5.优化 5.1 5.2 5.3 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:34:40 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/rabbitmq/":{"url":"distributed/rabbitmq/","title":"rabbitmq","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/kafka/":{"url":"distributed/kafka/","title":"kafka","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/kafka/shell.html":{"url":"distributed/kafka/shell.html","title":"1.集群启动停止脚本","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 ! /bin/bash #! /bin/bash case $1 in \"start\"){ for i in hadoop101 hadoop102 hadoop103 do echo \" --------启动 $i Kafka-------\" # 用于KafkaManager监控 ssh $i \"export JMX_PORT=9988 && /usr/local/software/kafka_2.12-2.6.0/bin/kafka-server-start.sh -daemon /usr/local/software/kafka_2.12-2.6.0/config/server.properties \" done };; \"stop\"){ for i in hadoop101 hadoop102 hadoop103 do echo \" --------停止 $i Kafka-------\" ssh $i \"/usr/local/software/kafka_2.12-2.6.0/bin/kafka-server-stop.sh stop\" done };; esac Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:36:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/kafka/kafka.html":{"url":"distributed/kafka/kafka.html","title":"2.大数据技术之Kafka","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.概述 1.1 简介 1.2 特点 1.3 场景 1.4 架构 2.kafka 环境搭建 1）解压安装包 2）在kafka_2.12-2.6.0 目录下创建 logs 文件夹 3）修改配置文件 4）分发安装包 5）分别在 hadoop102 和 hadoop103 上修改配置文件 config/server.properties 中的 broker.id=1、broker.id=2 8）启动集群 9）关闭集群 3.Kafka shell 使用 1）查看当前服务器中的所有 topic 2）创建 topic 3）删除 topic 4）发送消息 5）消费消息 6）查看某个 Topic 的详情 4. Kafka API 实战 4.1 环境准备 4.2 Kafka 生产者 Java API 4.2.1 创建生产者（过时的 API） 4.2.2 创建生产者（新 API） 4.2.3 创建生产者带回调函数（新 API） 4.2.4 自定义分区生产者 4.3 Kafka 消费者 Java API 4.3.1 高级 API 4.3.2 低级 API 5. Kafka producer 拦截器(interceptor) 5.1 拦截器原理 6. Kafka 工作流程分析 3.1 Kafka 生产过程分析 3.1.1 写入方式 3.1.2 分区（Partition） 3.1.3 副本（Replication） 3.1.4 写入流程 3.2 Broker 保存消息 3.2.1 存储方式 3.2.2 存储策略 3.2.3 Zookeeper 存储结构 3.3 Kafka 消费过程分析 3.3.1 高级 API 3.3.2 低级 API 3.3.3 消费者组 3.3.4 消费方式 3.3.5 消费者组案例 7. 扩展 7.1 Kafka 与 Flume 比较 7.2 Flume 与 kafka 集成 7.3 Kafka 配置信息 7.3.1 Broker 配置信息 7.3.2 Producer 配置信息 7.3.3 Consumer 配置信息 1.概述 1.1 简介 Apache Kafka 是一个分布式消息系统，由Scala写成。是由 Apache 软件基金会开发的一个开源消息系统项目 1.2 特点 高吞吐量：Kafka 每秒可以生产约 25 万消息（50 MB），每秒处理 55 万消息（110 MB） 持久化数据存储：可进行持久化操作。将消息持久化到磁盘，因此可用于批量消费，例如 ETL，以及实时应用程序。通过将数据持久化到硬盘以及 replication 防止数据丢失。 分布式系统易于扩展：所有的 producer、broker 和 consumer 都会有多个，均为分布式的。无需停机即可扩展机器。 客户端状态维护：消息被处理的状态是在 consumer 端维护，而不是由 server 端维护。当失败时能自动平衡。 1.3 场景 大数据日志收集缓存 1.4 架构 2.kafka 环境搭建 1）解压安装包 tar -zxvf kafka_2.12-2.6.0.tgz -C /usr/local/software 2）在kafka_2.12-2.6.0 目录下创建 logs 文件夹 cd kafka_2.12-2.6.0 && mkdir logs 3）修改配置文件 vim server.properties 输入以下内容： #broker 的全局唯一编号，不能重复 broker.id=0 #删除 topic 功能使能 delete.topic.enable=true #处理网络请求的线程数量 num.network.threads=3 #用来处理磁盘 IO 的现成数量 num.io.threads=8 #发送套接字的缓冲区大小 socket.send.buffer.bytes=102400 #接收套接字的缓冲区大小 socket.receive.buffer.bytes=102400 #请求套接字的缓冲区大小 socket.request.max.bytes=104857600 #kafka 运行日志存放的路径 log.dirs=/usr/local/software/kafka_2.12-2.6.0/logs #topic 在当前 broker 上的分区个数 num.partitions=1 #用来恢复和清理 data 下数据的线程数量 num.recovery.threads.per.data.dir=1 #segment 文件保留的最长时间，超时将被删除 log.retention.hours=168 #配置连接 Zookeeper 集群地址 zookeeper.connect=hadoop101:2181,hadoop102:2181,hadoop103:2181 broker.id=0 log.dirs=/usr/local/software/kafka_2.12-2.6.0/logs zookeeper.connect=hadoop101:2181,hadoop102:2181,hadoop103:2181 4）分发安装包 xsync kafka_2.12-2.6.0 注意：分发之后记得配置其他机器的环境变量 5）分别在 hadoop102 和 hadoop103 上修改配置文件 config/server.properties 中的 broker.id=1、broker.id=2 注：broker.id 不得重复 8）启动集群 依次在 hadoop101、hadoop102、hadoop103 节点上启动 kafka bin/kafka-server-start.sh config/server.properties & 9）关闭集群 依次在 hadoop101、hadoop102、hadoop103 节点上关闭 kafka bin/kafka-server-stop.sh stop 3.Kafka shell 使用 1）查看当前服务器中的所有 topic bin/kafka-topics.sh --zookeeper hadoop101:2181 --list 2）创建 topic bin/kafka-topics.sh --zookeeper hadoop101:2181 --create --replication-factor 1 --partitions 1 --topic first 选项说明： --topic 定义 topic 名 --replication-factor 定义副本数 --partitions 定义分区数 bin/kafka-topics.sh --create --topic quickstart-events --bootstrap-server hadoop101:9092 3）删除 topic bin/kafka-topics.sh --zookeeper hadoop101:2181 --delete --topic first 需要 server.properties 中设置 delete.topic.enable=true 否则只是标记删除或者直接重启。 4）发送消息 bin/kafka-console-producer.sh --broker-list hadoop101:9092 --topic first hello world bin/kafka-console-producer.sh --topic quickstart-events --bootstrap-server hadoop101:9092 5）消费消息 bin/kafka-console-consumer.sh --zookeeper hadoop101:2181 --from-beginning --topic first --from-beginning：会把 first 主题中以往所有的数据都读取出来。根据业务场景选择是否增加该配置。 bin/kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server hadoop101:9092 6）查看某个 Topic 的详情 bin/kafka-topics.sh --zookeeper hadoop101:2181 --describe --topic first bin/kafka-topics.sh --describe --topic quickstart-events --bootstrap-server hadoop101:9092 4. Kafka API 实战 4.1 环境准备 1）启动 zk 和 kafka 集群，在 kafka 集群中打开一个消费者 bin/kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server hadoop101:9092 2）导入 pom 依赖 org.apache.kafka kafka-clients 0.11.0.0 org.apache.kafka kafka_2.12 0.11.0.0 4.2 Kafka 生产者 Java API 4.2.1 创建生产者（过时的 API） import java.util.Properties; import kafka.javaapi.producer.Producer; import kafka.producer.KeyedMessage; import kafka.producer.ProducerConfig; public class OldProducer { public static void main(String[] args) { Properties properties = new Properties(); properties.put(\"metadata.broker.list\", \"hadoop102:9092\"); properties.put(\"request.required.acks\", \"1\"); properties.put(\"serializer.class\", \"kafka.serializer.StringEncoder\"); Producer producer = new Producer(new ProducerConfig(properties)); KeyedMessage message = new KeyedMessage(\"first\", \"hello world\"); producer.send(message ); } } 4.2.2 创建生产者（新 API） import java.util.Properties; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.Producer; import org.apache.kafka.clients.producer.ProducerRecord; public class NewProducer { public static void main(String[] args) { Properties props = new Properties(); // Kafka 服务端的主机名和端口号 props.put(\"bootstrap.servers\", \"hadoop103:9092\"); // 等待所有副本节点的应答 props.put(\"acks\", \"all\"); // 消息发送最大尝试次数 props.put(\"retries\", 0); // 一批消息处理大小 props.put(\"batch.size\", 16384); // 请求延时 props.put(\"linger.ms\", 1); // 发送缓存区内存大小 props.put(\"buffer.memory\", 33554432); // key 序列化 props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); // value 序列化 props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); Producer producer = new KafkaProducer<>(props); for (int i = 0; i (\"first\", Integer.toString(i), \"hello world-\" + i)); } producer.close(); } } 4.2.3 创建生产者带回调函数（新 API） import java.util.Properties; import org.apache.kafka.clients.producer.Callback; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.clients.producer.RecordMetadata; public class CallBackProducer { public static void main(String[] args) { Properties props = new Properties(); // Kafka 服务端的主机名和端口号 props.put(\"bootstrap.servers\", \"hadoop103:9092\"); // 等待所有副本节点的应答 props.put(\"acks\", \"all\"); // 消息发送最大尝试次数 props.put(\"retries\", 0); // 一批消息处理大小 props.put(\"batch.size\", 16384); // 增加服务端请求延时 props.put(\"linger.ms\", 1); // 发送缓存区内存大小 props.put(\"buffer.memory\", 33554432); // key 序列化 props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); // value 序列化 props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); KafkaProducer kafkaProducer = new KafkaProducer<>(props); for (int i = 0; i (\"first\", \"hello\" + i), new Callback() { @Override public void onCompletion(RecordMetadata metadata, Exception exception) { if (metadata != null) { System.err.println(metadata.partition() + \"---\" + metadata.offset()); } } }); } kafkaProducer.close(); } } 4.2.4 自定义分区生产者 0）需求：将所有数据存储到 topic 的第 0 号分区上 1）定义一个类实现 Partitioner 接口，重写里面的方法（过时 API） import java.util.Map; import kafka.producer.Partitioner; public class CustomPartitioner implements Partitioner { public CustomPartitioner() { super(); } @Override public int partition(Object key, int numPartitions) { // 控制分区 return 0; } } 2）自定义分区（新 API） import java.util.Map; import org.apache.kafka.clients.producer.Partitioner; import org.apache.kafka.common.Cluster; public class CustomPartitioner implements Partitioner { @Override public void configure(Map configs) { } @Override public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) { // 控制分区 return 0; } @Override public void close() { } } 3）在代码中调用 import java.util.Properties; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.Producer; import org.apache.kafka.clients.producer.ProducerRecord; public class PartitionerProducer { public static void main(String[] args) { Properties props = new Properties(); // Kafka 服务端的主机名和端口号 props.put(\"bootstrap.servers\", \"hadoop103:9092\"); // 等待所有副本节点的应答 props.put(\"acks\", \"all\"); // 消息发送最大尝试次数 props.put(\"retries\", 0); // 一批消息处理大小 props.put(\"batch.size\", 16384); // 增加服务端请求延时 props.put(\"linger.ms\", 1); // 发送缓存区内存大小 props.put(\"buffer.memory\", 33554432); // key 序列化 props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); // value 序列化 props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); // 自定义分区 props.put(\"partitioner.class\", \"com.haha.kafka.CustomPartitioner\"); Producer producer = new KafkaProducer<>(props); producer.send(new ProducerRecord(\"first\", \"1\", \"haha\")); producer.close(); } } 4）测试 （1）在 hadoop102 上监控/opt/module/kafka/logs/目录下 first 主题 3 个分区的 log 日志动态变化情况 tail -f 00000000000000000000.log （2）发现数据都存储到指定的分区了。 4.3 Kafka 消费者 Java API 4.3.1 高级 API 0）在控制台创建发送者 bin/kafka-console-producer.sh \\ --broker-list hadoop102:9092 --topic first >hello world 1）创建消费者（过时 API） import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Properties; import kafka.consumer.Consumer; import kafka.consumer.ConsumerConfig; import kafka.consumer.ConsumerIterator; import kafka.consumer.KafkaStream; import kafka.javaapi.consumer.ConsumerConnector; public class CustomConsumer { public static void main(String[] args) { Properties properties = new Properties(); properties.put(\"zookeeper.connect\", \"hadoop102:2181\"); properties.put(\"group.id\", \"g1\"); properties.put(\"zookeeper.session.timeout.ms\", \"500\"); properties.put(\"zookeeper.sync.time.ms\", \"250\"); properties.put(\"auto.commit.interval.ms\", \"1000\"); // 创建消费者连接器 ConsumerConnector consumer = Consumer.createJavaConsumerConnector(new ConsumerConfig(properties)); HashMap topicCount = new HashMap<>(); topicCount.put(\"first\", 1); Map>> consumerMap = consumer.createMessageStreams(topicCount); KafkaStream stream = consumerMap.get(\"first\").get(0); ConsumerIterator it = stream.iterator(); while (it.hasNext()) { System.out.println(new String(it.next().message())); } } } 2）官方提供案例（自动维护消费情况）（新 API） import java.util.Arrays; import java.util.Properties; import org.apache.kafka.clients.consumer.ConsumerRecord; import org.apache.kafka.clients.consumer.ConsumerRecords; import org.apache.kafka.clients.consumer.KafkaConsumer; public class CustomNewConsumer { public static void main(String[] args) { Properties props = new Properties(); // 定义 kakfa 服务的地址，不需要将所有 broker 指定上 props.put(\"bootstrap.servers\", \"hadoop102:9092\"); // 制定 consumer group props.put(\"group.id\", \"test\"); // 是否自动确认 offset props.put(\"enable.auto.commit\", \"true\"); // 自动确认 offset 的时间间隔 props.put(\"auto.commit.interval.ms\", \"1000\"); // key 的序列化类 props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); // value 的序列化类 props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); // 定义 consumer KafkaConsumer consumer = new KafkaConsumer<>(props); // 消费者订阅的 topic, 可同时订阅多个 consumer.subscribe(Arrays.asList(\"first\", \"second\",\"third\")); while (true) { // 读取数据，读取超时时间为 100ms ConsumerRecords records = consumer.poll(100); for (ConsumerRecord record : records) System.out.printf(\"offset = %d, key = %s, value = %s%n\", record.offset(), record.key(), record.value()); } } } 4.3.2 低级 API 实现使用低级 API 读取指定 topic，指定 partition,指定 offset 的数据。 1）消费者使用低级 API 的主要步骤： 步骤 主要工作 1 根据指定的分区从主题元数据中找到主副本 2 获取分区最新的消费进度 3 从主副本拉取分区的消息 4 识别主副本的变化，重试 2）方法描述： findLeader() 客户端向种子节点发送主题元数据，将副本集加入备用节点 getLastOffset() 消费者客户端发送偏移量请求，获取分区最近的偏移量 run() 消费者低级 AP I 拉取消息的主要方法 findNewLeader() 当分区的主副本节点发生故障，客户将要找出新的主副本 3）代码： import java.nio.ByteBuffer; import java.util.ArrayList; import java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; import kafka.api.FetchRequest; import kafka.api.FetchRequestBuilder; import kafka.api.PartitionOffsetRequestInfo; import kafka.cluster.BrokerEndPoint; import kafka.common.ErrorMapping; import kafka.common.TopicAndPartition; import kafka.javaapi.FetchResponse; import kafka.javaapi.OffsetResponse; import kafka.javaapi.PartitionMetadata; import kafka.javaapi.TopicMetadata; import kafka.javaapi.TopicMetadataRequest; import kafka.javaapi.consumer.SimpleConsumer; import kafka.message.MessageAndOffset; public class SimpleExample { private List m_replicaBrokers = new ArrayList<>(); public SimpleExample() { m_replicaBrokers = new ArrayList<>(); } public static void main(String args[]) { SimpleExample example = new SimpleExample(); // 最大读取消息数量 long maxReads = Long.parseLong(\"3\"); // 要订阅的 topic String topic = \"test1\"; // 要查找的分区 int partition = Integer.parseInt(\"0\"); // broker 节点的 ip List seeds = new ArrayList<>(); seeds.add(\"192.168.9.102\"); seeds.add(\"192.168.9.103\"); seeds.add(\"192.168.9.104\"); // 端口 int port = Integer.parseInt(\"9092\"); try { example.run(maxReads, topic, partition, seeds, port); } catch (Exception e) { System.out.println(\"Oops:\" + e); e.printStackTrace(); } } public void run(long a_maxReads, String a_topic, int a_partition, List a_seedBrokers, int a_port) throws Exception { // 获取指定 Topic partition 的元数据 PartitionMetadata metadata = findLeader(a_seedBrokers, a_port, a_topic, a_partition); if (metadata == null) { System.out.println(\"Can't find metadata for Topic and Partition. Exiting\"); return; } if (metadata.leader() == null) { System.out.println(\"Can't find Leader for Topic and Partition. Exiting\"); return; } String leadBroker = metadata.leader().host(); String clientName = \"Client\" + a_topic + \"\" + a_partition; SimpleConsumer consumer = new SimpleConsumer(leadBroker, a_port, 100000, 64 * 1024, clientName); long readOffset = getLastOffset(consumer, a_topic, a_partition, kafka.api.OffsetRequest.EarliestTime(), clientName); int numErrors = 0; while (a_maxReads > 0) { if (consumer == null) { consumer = new SimpleConsumer(leadBroker, a_port, 100000, 64 * 1024, clientName); } FetchRequest req = new FetchRequestBuilder().clientId(clientName).addFetch(a_topic, a_partition, readOffset, 100000).build(); FetchResponse fetchResponse = consumer.fetch(req); if (fetchResponse.hasError()) { numErrors++; // Something went wrong! short code = fetchResponse.errorCode(a_topic, a_partition); System.out.println(\"Error fetching data from the Broker:\" + leadBroker + \" Reason: \" + code); if (numErrors > 5) break; if (code == ErrorMapping.OffsetOutOfRangeCode()) { // We asked for an invalid offset. For simple case ask for // the last element to reset readOffset = getLastOffset(consumer, a_topic, a_partition, kafka.api.OffsetRequest.LatestTime(), clientName); continue; } consumer.close(); consumer = null; leadBroker = findNewLeader(leadBroker, a_topic, a_partition, a_port); continue; } numErrors = 0; long numRead = 0; for (MessageAndOffset messageAndOffset : fetchResponse.messageSet(a_topic, a_partition)) { long currentOffset = messageAndOffset.offset(); if (currentOffset System.out.println(\"Found an old offset: \" + currentOffset + \" Expecting: \" + readOffset); continue; } readOffset = messageAndOffset.nextOffset(); ByteBuffer payload = messageAndOffset.message().payload(); byte[] bytes = new byte[payload.limit()]; payload.get(bytes); System.out.println(String.valueOf(messageAndOffset.offset()) + \": \" + new String(bytes, \"UTF-8\")); numRead++; a_maxReads--; } if (numRead == 0) { try { Thread.sleep(1000); } catch (InterruptedException ie) { } } } if (consumer != null) consumer.close(); } public static long getLastOffset(SimpleConsumer consumer, String topic, int partition, long whichTime, String clientName) { TopicAndPartition topicAndPartition = new TopicAndPartition(topic, partition); Map requestInfo = new HashMap(); requestInfo.put(topicAndPartition, new PartitionOffsetRequestInfo(whichTime, 1)); kafka.javaapi.OffsetRequest request = new kafka.javaapi.OffsetRequest(requestInfo, kafka.api.OffsetRequest.CurrentVersion(), clientName); OffsetResponse response = consumer.getOffsetsBefore(request); if (response.hasError()) { System.out.println(\"Error fetching data Offset Data the Broker. Reason: \" + response.errorCode(topic, partition)); return 0; } long[] offsets = response.offsets(topic, partition); return offsets[0]; } private String findNewLeader(String a_oldLeader, String a_topic, int a_partition, int a_port) throws Exception { for (int i = 0; i boolean goToSleep = false; PartitionMetadata metadata = findLeader(m_replicaBrokers, a_port, a_topic, a_partition); if (metadata == null) { goToSleep = true; } else if (metadata.leader() == null) { goToSleep = true; } else if (a_oldLeader.equalsIgnoreCase(metadata.leader().host()) && i == 0) { // first time through if the leader hasn't changed give // ZooKeeper a second to recover // second time, assume the broker did recover before failover, // or it was a non-Broker issue // goToSleep = true; } else { return metadata.leader().host(); } if (goToSleep) { Thread.sleep(1000); } } System.out.println(\"Unable to find new leader after Broker failure. Exiting\"); throw new Exception(\"Unable to find new leader after Broker failure. Exiting\"); } private PartitionMetadata findLeader(List a_seedBrokers, int a_port, String a_topic, int a_partition) { PartitionMetadata returnMetaData = null; loop: for (String seed : a_seedBrokers) { SimpleConsumer consumer = null; try { consumer = new SimpleConsumer(seed, a_port, 100000, 64 * 1024, \"leaderLookup\"); List topics = Collections.singletonList(a_topic); TopicMetadataRequest req = new TopicMetadataRequest(topics); kafka.javaapi.TopicMetadataResponse resp = consumer.send(req); List metaData = resp.topicsMetadata(); for (TopicMetadata item : metaData) { for (PartitionMetadata part : item.partitionsMetadata()) { if (part.partitionId() == a_partition) { returnMetaData = part; break loop; } } } } catch (Exception e) { System.out.println(\"Error communicating with Broker [\" + seed + \"] to find Leader for [\" + a_topic + \", \" + a_partition + \"] Reason: \" + e); } finally { if (consumer != null) consumer.close(); } } if (returnMetaData != null) { m_replicaBrokers.clear(); for (BrokerEndPoint replica : returnMetaData.replicas()) { m_replicaBrokers.add(replica.host()); } } return returnMetaData; } } 5. Kafka producer 拦截器(interceptor) 5.1 拦截器原理 Producer 拦截器(interceptor)是在 Kafka 0.10 版本被引入的，主要用于实现 clients 端的定制化控制逻辑。 对于 producer 而言，interceptor 使得用户在消息发送前以及 producer 回调逻辑前有机会对消息做一些定制化需求，比如修改消息等。同时，producer 允许用户指定多个 interceptor 按序作用于同一条消息从而形成一个拦截链(interceptor chain)。Intercetpor 的实现接口是 org.apache.kafka.clients.producer.ProducerInterceptor，其定义的方法包括： （1）configure(configs) 获取配置信息和初始化数据时调用。 （2）onSend(ProducerRecord)： 该方法封装进 KafkaProducer.send 方法中，即它运行在用户主线程中。Producer 确保在消息被序列化以及计算分区前调用该方法。用户可以在该方法中对消息做任何操作，但最好保证不要修改消息所属的 topic 和分区，否则会影响目标分区的计算 （3）onAcknowledgement(RecordMetadata, Exception)： 该方法会在消息被应答或消息发送失败时调用，并且通常都是在 producer 回调逻辑触发之前。onAcknowledgement 运行在 producer 的 IO 线程中，因此不要在该方法中放入很重的逻辑，否则会拖慢 producer 的消息发送效率 （4）close： 关闭 interceptor，主要用于执行一些资源清理工作 如前所述，interceptor 可能被运行在多个线程中，因此在具体实现时用户需要自行确保线程安全。另外倘若指定了多个 interceptor，则 producer 将按照指定顺序调用它们，并仅仅是捕获每个 interceptor 可能抛出的异常记录到错误日志中而非在向上传递。这在使用过程中要特别留意。 5.2 拦截器案例 1）需求： 实现一个简单的双 interceptor 组成的拦截链。第一个 interceptor 会在消息发送前将时间戳信息加到消息 value 的最前部；第二个 interceptor 会在消息发送后更新成功发送消息数或失败发送消息数。 2）案例实操 （1）增加时间戳拦截器 import java.util.Map; import org.apache.kafka.clients.producer.ProducerInterceptor; import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.clients.producer.RecordMetadata; public class TimeInterceptor implements ProducerInterceptor { @Override public void configure(Map configs) { } @Override public ProducerRecord onSend(ProducerRecord record) { // 创建一个新的 record，把时间戳写入消息体的最前部 return new ProducerRecord(record.topic(), record.partition(), record.timestamp(), record.key(), System.currentTimeMillis() + \",\" + record.value().toString()); } @Override public void onAcknowledgement(RecordMetadata metadata, Exception exception) { } @Override public void close() { } } （2）统计发送消息成功和发送失败消息数，并在 producer 关闭时打印这两个计数器 import java.util.Map; import org.apache.kafka.clients.producer.ProducerInterceptor; import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.clients.producer.RecordMetadata; public class CounterInterceptor implements ProducerInterceptor{ private int errorCounter = 0; private int successCounter = 0; @Override public void configure(Map configs) { } @Override public ProducerRecord onSend(ProducerRecord record) { return record; } @Override public void onAcknowledgement(RecordMetadata metadata, Exception exception) { // 统计成功和失败的次数 if (exception == null) { successCounter++; } else { errorCounter++; } } @Override public void close() { // 保存结果 System.out.println(\"Successful sent: \" + successCounter); System.out.println(\"Failed sent: \" + errorCounter); } } （3）producer 主程序 import java.util.ArrayList; import java.util.List; import java.util.Properties; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.Producer; import org.apache.kafka.clients.producer.ProducerConfig; import org.apache.kafka.clients.producer.ProducerRecord; public class InterceptorProducer { public static void main(String[] args) throws Exception { // 1 设置配置信息 Properties props = new Properties(); props.put(\"bootstrap.servers\", \"hadoop102:9092\"); props.put(\"acks\", \"all\"); props.put(\"retries\", 0); props.put(\"batch.size\", 16384); props.put(\"linger.ms\", 1); props.put(\"buffer.memory\", 33554432); props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); // 2 构建拦截链 List interceptors = new ArrayList<>(); interceptors.add(\"com.atguigu.kafka.interceptor.TimeInterceptor\"); interceptors.add(\"com.atguigu.kafka.interceptor.CounterInterceptor\"); props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors); String topic = \"first\"; Producer producer = new KafkaProducer<>(props); // 3 发送消息 for (int i = 0; i record = new ProducerRecord<>(topic, \"message\" + i); producer.send(record); } // 4 一定要关闭 producer，这样才会调用 interceptor 的 close 方法 producer.close(); } } 3）测试 （1）在 kafka 上启动消费者，然后运行客户端 java 程序。 bin/kafka-console-consumer.sh \\ --zookeeper hadoop102:2181 --from-beginning --topic first 1501904047034,message0 1501904047225,message1 1501904047230,message2 1501904047234,message3 1501904047236,message4 1501904047240,message5 1501904047243,message6 1501904047246,message7 1501904047249,message8 1501904047252,message9 （2）观察 java 平台控制台输出数据如下： Successful sent: 10 Failed sent: 0 6. Kafka 工作流程分析 3.1 Kafka 生产过程分析 3.1.1 写入方式 producer 采用推（push）模式将消息发布到 broker，每条消息都被追加（append）到分区（patition）中，属于顺序写磁盘（顺序写磁盘效率比随机写内存要高，保障 kafka 吞吐率）。 3.1.2 分区（Partition） 消息发送时都被发送到一个 topic，其本质就是一个目录，而 topic 是由一些 Partition Logs(分区日志)组成，其组织结构如下图所示： 我们可以看到，每个 Partition 中的消息都是有序的，生产的消息被不断追加到 Partition log 上，其中的每一个消息都被赋予了一个唯一的 offset 值。 1）分区的原因 （1）方便在集群中扩展，每个 Partition 可以通过调整以适应它所在的机器，而一个 topic 又可以有多个 Partition 组成，因此整个集群就可以适应任意大小的数据了； （2）可以提高并发，因为可以以 Partition 为单位读写了。 2）分区的原则 （1）指定了 patition，则直接使用； （2）未指定 patition 但指定 key，通过对 key 的 value 进行 hash 出一个 patition； （3）patition 和 key 都未指定，使用轮询选出一个 patition。 DefaultPartitioner 类 public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) { List partitions = cluster.partitionsForTopic(topic); int numPartitions = partitions.size(); if (keyBytes == null) { int nextValue = nextValue(topic); List availablePartitions = cluster.availablePartitionsForTopic(topic); if (availablePartitions.size() > 0) { int part = Utils.toPositive(nextValue) % availablePartitions.size(); return availablePartitions.get(part).partition(); } else { // no partitions are available, give a non-available partition return Utils.toPositive(nextValue) % numPartitions; } } else { // hash the keyBytes to choose a partition return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions; } } 3.1.3 副本（Replication） 同一个 partition 可能会有多个 replication（对应 server.properties 配置中的 default.replication.factor=N）。没有 replication 的情况下，一旦 broker 宕机，其上所有 patition 的数据都不可被消费，同时 producer 也不能再将数据存于其上的 patition。引入 replication 之后，同一个 partition 可能会有多个 replication，而这时需要在这些 replication 之间选出一个 leader，producer 和 consumer 只与这个 leader 交互，其它 replication 作为 follower 从 leader 中复制数据。 3.1.4 写入流程 producer 写入消息流程如下： 1）producer 先从 zookeeper 的 \"/brokers/.../state\"节点找到该 partition 的 leader 2）producer 将消息发送给该 leader 3）leader 将消息写入本地 log 4）followers 从 leader pull 消息，写入本地 log 后向 leader 发送 ACK 5）leader 收到所有 ISR 中的 replication 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset）并向 producer 发送 ACK 3.2 Broker 保存消息 3.2.1 存储方式 物理上把 topic 分成一个或多个 patition（对应 server.properties 中的 num.partitions=3 配置），每个 patition 物理上对应一个文件夹（该文件夹存储该 patition 的所有消息和索引文件），如下： ll drwxrwxr-x. 2 atguigu atguigu 4096 8 月 6 14:37 first-0 drwxrwxr-x. 2 atguigu atguigu 4096 8 月 6 14:35 first-1 drwxrwxr-x. 2 atguigu atguigu 4096 8 月 6 14:37 first-2 cd first-0 ll -rw-rw-r--. 1 atguigu atguigu 10485760 8 月 6 14:33 00000000000000000000.index -rw-rw-r--. 1 atguigu atguigu 219 8 月 6 15:07 00000000000000000000.log -rw-rw-r--. 1 atguigu atguigu 10485756 8 月 6 14:33 00000000000000000000.timeindex -rw-rw-r--. 1 atguigu atguigu 8 8 月 6 14:37 leader-epoch-checkpoint 3.2.2 存储策略 无论消息是否被消费，kafka 都会保留所有消息。有两种策略可以删除旧数据： 1）基于时间：log.retention.hours=168 2）基于大小：log.retention.bytes=1073741824 需要注意的是，因为 Kafka 读取特定消息的时间复杂度为 O(1)，即与文件大小无关，所以这里删除过期文件与提高 Kafka 性能无关。 3.2.3 Zookeeper 存储结构 注意：producer 不在 zk 中注册，消费者在 zk 中注册。 3.3 Kafka 消费过程分析 kafka 提供了两套 consumer API：高级 Consumer API 和低级 Consumer API。 3.3.1 高级 API 1）高级 API 优点 高级 API 写起来简单 不需要自行去管理 offset，系统通过 zookeeper 自行管理。 不需要管理分区，副本等情况，.系统自动管理。 消费者断线会自动根据上一次记录在 zookeeper 中的 offset 去接着获取数据（默认设置 1 分钟更新一下 zookeeper 中存的 offset） 可以使用 group 来区分对同一个 topic 的不同程序访问分离开来（不同的 group 记录不同的 offset，这样不同程序读取同一个 topic 才不会因为 offset 互相影响） 2）高级 API 缺点 不能自行控制 offset（对于某些特殊需求来说） 不能细化控制如分区、副本、zk 等 3.3.2 低级 API 1）低级 API 优点 能够让开发者自己控制 offset，想从哪里读取就从哪里读取。 自行控制连接分区，对分区自定义进行负载均衡 对 zookeeper 的依赖性降低（如：offset 不一定非要靠 zk 存储，自行存储 offset 即可，比如存在文件或者内存中） 2）低级 API 缺点 太过复杂，需要自行控制 offset，连接哪个分区，找到分区 leader 等。 3.3.3 消费者组 消费者是以 consumer group 消费者组的方式工作，由一个或者多个消费者组成一个组，共同消费一个 topic。每个分区在同一时间只能由 group 中的一个消费者读取，但是多个 group 可以同时消费这个 partition。在图中，有一个由三个消费者组成的 group，有一个消费者读取主题中的两个分区，另外两个分别读取一个分区。某个消费者读取某个分区，也可以叫做某个消费者是某个分区的拥有者。 在这种情况下，消费者可以通过水平扩展的方式同时读取大量的消息。另外，如果一个消费者失败了，那么其他的 group 成员会自动负载均衡读取之前失败的消费者读取的分区。 3.3.4 消费方式 consumer 采用 pull（拉）模式从 broker 中读取数据。 push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成 consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而 pull 模式则可以根据 consumer 的消费能力以适当的速率消费消息。 对于 Kafka 而言，pull 模式更合适，它可简化 broker 的设计，consumer 可自主控制消费消息的速率，同时 consumer 可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。 pull 模式不足之处是，如果 kafka 没有数据，消费者可能会陷入循环中，一直等待数据到达。为了避免这种情况，我们在我们的拉请求中有参数，允许消费者请求在等待数据到达的“长轮询”中进行阻塞（并且可选地等待到给定的字节数，以确保大的传输大小）。 3.3.5 消费者组案例 1）需求：测试同一个消费者组中的消费者，同一时刻只能有一个消费者消费。 2）案例实操 （1）在 hadoop102、hadoop103 上修改/opt/module/kafka/config/consumer.properties 配置文件中的 group.id 属性为任意组名。 vi consumer.properties group.id=atguigu （2）在 hadoop102、hadoop103 上分别启动消费者 bin/kafka-console-consumer.sh \\ --zookeeper hadoop102:2181 --topic first --consumer.config config/consumer.properties bin/kafka-console-consumer.sh --zookeeper hadoop102:2181 --topic first --consumer.config config/consumer.properties （3）在 hadoop104 上启动生产者 bin/kafka-console-producer.sh \\ --broker-list hadoop102:9092 --topic first >hello world （4）查看 hadoop102 和 hadoop103 的接收者。 同一时刻只有一个消费者接收到消息。 7. 扩展 7.1 Kafka 与 Flume 比较 在企业中必须要清楚流式数据采集框架 flume 和 kafka 的定位是什么： flume：cloudera 公司研发: 适合多个生产者； 适合下游数据消费者不多的情况； 适合数据安全性要求不高的操作； 适合与 Hadoop 生态圈对接的操作。 kafka：linkedin 公司研发: 适合数据下游消费众多的情况； 适合数据安全性要求较高的操作，支持 replication。 因此我们常用的一种模型是： 线上数据 --> flume --> kafka --> flume(根据情景增删该流程) --> HDFS 7.2 Flume 与 kafka 集成 1）配置 flume(flume-kafka.conf) # define a1.sources = r1 a1.sinks = k1 a1.channels = c1 # source a1.sources.r1.type = exec a1.sources.r1.command = tail -F -c +0 /opt/module/datas/flume.log a1.sources.r1.shell = /bin/bash -c # sink a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink a1.sinks.k1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092 a1.sinks.k1.kafka.topic = first a1.sinks.k1.kafka.flumeBatchSize = 20 a1.sinks.k1.kafka.producer.acks = 1 a1.sinks.k1.kafka.producer.linger.ms = 1 # channel a1.channels.c1.type = memory a1.channels.c1.capacity = 1000 a1.channels.c1.transactionCapacity = 100 # bind a1.sources.r1.channels = c1 a1.sinks.k1.channel = c1 2） 启动 kafkaIDEA 消费者 3） 进入 flume 根目录下，启动 flume bin/flume-ng agent -c conf/ -n a1 -f jobs/flume-kafka.conf 4） 向 /opt/module/datas/flume.log 里追加数据，查看 kafka 消费者消费情况 $ echo hello > /opt/module/datas 7.3 Kafka 配置信息 7.3.1 Broker 配置信息 属性 默认值 描述 broker.id 必填参数，broker 的唯一标识 log.dirs /tmp/kafka-logs Kafka 数据存放的目录。可以指定多个目录，中间用逗号分隔，当新 partition 被创建的时会被存放到当前存放 partition 最少的目录。 port 9092 BrokerServer 接受客户端连接的端口号 zookeeper.connect null Zookeeper 的连接串，格式为：hostname1:port1,hostname2:port2,hostname3:port3。可以填一个或多个，为了提高可靠性，建议都填上。注意，此配置允许我们指定一个 zookeeper 路径来存放此 kafka 集群的所有数据，为了与其他应用集群区分开，建议在此配置中指定本集群存放目录，格式为：hostname1:port1,hostname2:port2,hostname3:port3/chroot/path。需要注意的是，消费者的参数要和此参数一致。 message.max.bytes 1000000 服务器可以接收到的最大的消息大小。注意此参数要和 consumer 的 maximum.message.size 大小一致，否则会因为生产者生产的消息太大导致消费者无法消费。 num.io.threads 8 服务器用来执行读写请求的 IO 线程数，此参数的数量至少要等于服务器上磁盘的数量。 queued.max.requests 500 I/O 线程可以处理请求的队列大小，若实际请求数超过此大小，网络线程将停止接收新的请求。 socket.send.buffer.bytes 100 * 1024 The SO_SNDBUFF buffer the server prefers for socket connections. socket.receive.buffer.bytes 100 * 1024 The SO_RCVBUFF buffer the server prefers for socket connections. socket.request.max.bytes 100 1024 1024 服务器允许请求的最大值， 用来防止内存溢出，其值应该小于 Java heap size. num.partitions 1 默认 partition 数量，如果 topic 在创建时没有指定 partition 数量，默认使用此值，建议改为 5 log.segment.bytes 1024 1024 1024 Segment 文件的大小，超过此值将会自动新建一个 segment，此值可以被 topic 级别的参数覆盖。 log.roll.{ms,hours} 24 * 7 hours 新建 segment 文件的时间，此值可以被 topic 级别的参数覆盖。 log.retention.{ms,minutes,hours} 7 days Kafka segment log 的保存周期，保存周期超过此时间日志就会被删除。此参数可以被 topic 级别参数覆盖。数据量大时，建议减小此值。 log.retention.bytes -1 每个 partition 的最大容量，若数据量超过此值，partition 数据将会被删除。注意这个参数控制的是每个 partition 而不是 topic。此参数可以被 log 级别参数覆盖。 log.retention.check.interval.ms 5 minutes 删除策略的检查周期 auto.create.topics.enable true 自动创建 topic 参数，建议此值设置为 false，严格控制 topic 管理，防止生产者错写 topic。 default.replication.factor 1 默认副本数量，建议改为 2。 replica.lag.time.max.ms 10000 在此窗口时间内没有收到 follower 的 fetch 请求，leader 会将其从 ISR(in-sync replicas)中移除。 replica.lag.max.messages 4000 如果 replica 节点落后 leader 节点此值大小的消息数量，leader 节点就会将其从 ISR 中移除。 replica.socket.timeout.ms 30 * 1000 replica 向 leader 发送请求的超时时间。 replica.socket.receive.buffer.bytes 64 * 1024 The socket receive buffer for network requests to the leader for replicating data. replica.fetch.max.bytes 1024 * 1024 The number of byes of messages to attempt to fetch for each partition in the fetch requests the replicas send to the leader. replica.fetch.wait.max.ms 500 The maximum amount of time to wait time for data to arrive on the leader in the fetch requests sent by the replicas to the leader. num.replica.fetchers 1 Number of threads used to replicate messages from leaders. Increasing this value can increase the degree of I/O parallelism in the follower broker. fetch.purgatory.purge.interval.requests 1000 The purge interval (in number of requests) of the fetch request purgatory. zookeeper.session.timeout.ms 6000 ZooKeeper session 超时时间。如果在此时间内 server 没有向 zookeeper 发送心跳，zookeeper 就会认为此节点已挂掉。 此值太低导致节点容易被标记死亡；若太高，.会导致太迟发现节点死亡。 zookeeper.connection.timeout.ms 6000 客户端连接 zookeeper 的超时时间。 zookeeper.sync.time.ms 2000 H ZK follower 落后 ZK leader 的时间。 controlled.shutdown.enable true 允许 broker shutdown。如果启用，broker 在关闭自己之前会把它上面的所有 leaders 转移到其它 brokers 上，建议启用，增加集群稳定性。 auto.leader.rebalance.enable true If this is enabled the controller will automatically try to balance leadership for partitions among the brokers by periodically returning leadership to the “preferred” replica for each partition if it is available. leader.imbalance.per.broker.percentage 10 The percentage of leader imbalance allowed per broker. The controller will rebalance leadership if this ratio goes above the configured value per broker. leader.imbalance.check.interval.seconds 300 The frequency with which to check for leader imbalance. offset.metadata.max.bytes 4096 The maximum amount of metadata to allow clients to save with their offsets. connections.max.idle.ms 600000 Idle connections timeout: the server socket processor threads close the connections that idle more than this. num.recovery.threads.per.data.dir 1 The number of threads per data directory to be used for log recovery at startup and flushing at shutdown. unclean.leader.election.enable true Indicates whether to enable replicas not in the ISR set to be elected as leader as a last resort, even though doing so may result in data loss. delete.topic.enable false 启用 deletetopic 参数，建议设置为 true。 offsets.topic.num.partitions 50 The number of partitions for the offset commit topic. Since changing this after deployment is currently unsupported, we recommend using a higher setting for production (e.g., 100-200). offsets.topic.retention.minutes 1440 Offsets that are older than this age will be marked for deletion. The actual purge will occur when the log cleaner compacts the offsets topic. offsets.retention.check.interval.ms 600000 The frequency at which the offset manager checks for stale offsets. offsets.topic.replication.factor 3 The replication factor for the offset commit topic. A higher setting (e.g., three or four) is recommended in order to ensure higher availability. If the offsets topic is created when fewer brokers than the replication factor then the offsets topic will be created with fewer replicas. offsets.topic.segment.bytes 104857600 Segment size for the offsets topic. Since it uses a compacted topic, this should be kept relatively low in order to facilitate faster log compaction and loads. offsets.load.buffer.size 5242880 An offset load occurs when a broker becomes the offset manager for a set of consumer groups (i.e., when it becomes a leader for an offsets topic partition). This setting corresponds to the batch size (in bytes) to use when reading from the offsets segments when loading offsets into the offset manager’s cache. offsets.commit.required.acks -1 The number of acknowledgements that are required before the offset commit can be accepted. This is similar to the producer’s acknowledgement setting. In general, the default should not be overridden. offsets.commit.timeout.ms 5000 The offset commit will be delayed until this timeout or the required number of replicas have received the offset commit. This is similar to the producer request timeout. 7.3.2 Producer 配置信息 属性 默认值 描述 metadata.broker.list 启动时 producer 查询 brokers 的列表，可以是集群中所有 brokers 的一个子集。注意，这个参数只是用来获取 topic 的元信息用，producer 会从元信息中挑选合适的 broker 并与之建立 socket 连接。格式是：host1:port1,host2:port2。 request.required.acks 0 参见 3.2 节介绍 request.timeout.ms 10000 Broker 等待 ack 的超时时间，若等待时间超过此值，会返回客户端错误信息。 producer.type sync 同步异步模式。async 表示异步，sync 表示同步。如果设置成异步模式，可以允许生产者以 batch 的形式 push 数据，这样会极大的提高 broker 性能，推荐设置为异步。 serializer.class kafka.serializer.DefaultEncoder 序列号类，.默认序列化成 byte[] 。 key.serializer.class Key 的序列化类，默认同上。 partitioner.class kafka.producer.DefaultPartitioner Partition 类，默认对 key 进行 hash。 compression.codec none 指定 producer 消息的压缩格式，可选参数为： “none”, “gzip” and “snappy”。关于压缩参见 4.1 节 compressed.topics null 启用压缩的 topic 名称。若上面参数选择了一个压缩格式，那么压缩仅对本参数指定的 topic 有效，若本参数为空，则对所有 topic 有效。 message.send.max.retries 3 Producer 发送失败时重试次数。若网络出现问题，可能会导致不断重试。 retry.backoff.ms 100 Before each retry, the producer refreshes the metadata of relevant topics to see if a new leader has been elected. Since leader election takes a bit of time, this property specifies the amount of time that the producer waits before refreshing the metadata. topic.metadata.refresh.interval.ms 600 * 1000 The producer generally refreshes the topic metadata from brokers when there is a failure (partition missing, leader not available…). It will also poll regularly (default: every 10min so 600000ms). If you set this to a negative value, metadata will only get refreshed on failure. If you set this to zero, the metadata will get refreshed after each message sent (not recommended). Important note: the refresh happen only AFTER the message is sent, so if the producer never sends a message the metadata is never refreshed queue.buffering.max.ms 5000 启用异步模式时，producer 缓存消息的时间。比如我们设置成 1000 时，它会缓存 1 秒的数据再一次发送出去，这样可以极大的增加 broker 吞吐量，但也会造成时效性的降低。 queue.buffering.max.messages 10000 采用异步模式时 producer buffer 队列里最大缓存的消息数量，如果超过这个数值，producer 就会阻塞或者丢掉消息。 queue.enqueue.timeout.ms -1 当达到上面参数值时 producer 阻塞等待的时间。如果值设置为 0，buffer 队列满时 producer 不会阻塞，消息直接被丢掉。若值设置为-1，producer 会被阻塞，不会丢消息。 batch.num.messages 200 采用异步模式时，一个 batch 缓存的消息数量。达到这个数量值时 producer 才会发送消息。 send.buffer.bytes 100 * 1024 Socket write buffer size client.id “” The client id is a user-specified string sent in each request to help trace calls. It should logically identify the application making the request. 7.3.3 Consumer 配置信息 属性 默认值 描述 group.id Consumer 的组 ID，相同 goup.id 的 consumer 属于同一个组。 zookeeper.connect Consumer 的 zookeeper 连接串，要和 broker 的配置一致。 consumer.id null 如果不设置会自动生成。 socket.timeout.ms 30 * 1000 网络请求的 socket 超时时间。实际超时时间由 max.fetch.wait + socket.timeout.ms 确定。 socket.receive.buffer.bytes 64 * 1024 The socket receive buffer for network requests. fetch.message.max.bytes 1024 * 1024 查询 topic-partition 时允许的最大消息大小。consumer 会为每个 partition 缓存此大小的消息到内存，因此，这个参数可以控制 consumer 的内存使用量。这个值应该至少比 server 允许的最大消息大小大，以免 producer 发送的消息大于 consumer 允许的消息。 num.consumer.fetchers 1 The number fetcher threads used to fetch data. auto.commit.enable true 如果此值设置为 true，consumer 会周期性的把当前消费的 offset 值保存到 zookeeper。当 consumer 失败重启之后将会使用此值作为新开始消费的值。 auto.commit.interval.ms 60 * 1000 Consumer 提交 offset 值到 zookeeper 的周期。 queued.max.message.chunks 2 用来被 consumer 消费的 message chunks 数量， 每个 chunk 可以缓存 fetch.message.max.bytes 大小的数据量。 auto.commit.interval.ms 60 * 1000 Consumer 提交 offset 值到 zookeeper 的周期。 queued.max.message.chunks 2 用来被 consumer 消费的 message chunks 数量， 每个 chunk 可以缓存 fetch.message.max.bytes 大小的数据量。 fetch.min.bytes 1 The minimum amount of data the server should return for a fetch request. If insufficient data is available the request will wait for that much data to accumulate before answering the request. fetch.wait.max.ms 100 The maximum amount of time the server will block before answering the fetch request if there isn’t sufficient data to immediately satisfy fetch.min.bytes. rebalance.backoff.ms 2000 Backoff time between retries during rebalance. refresh.leader.backoff.ms 200 Backoff time to wait before trying to determine the leader of a partition that has just lost its leader. auto.offset.reset largest What to do when there is no initial offset in ZooKeeper or if an offset is out of range ;smallest : automatically reset the offset to the smallest offset; largest : automatically reset the offset to the largest offset;anything else: throw exception to the consumer consumer.timeout.ms -1 若在指定时间内没有消息消费，consumer 将会抛出异常。 exclude.internal.topics true Whether messages from internal topics (such as offsets) should be exposed to the consumer. zookeeper.session.timeout.ms 6000 ZooKeeper session timeout. If the consumer fails to heartbeat to ZooKeeper for this period of time it is considered dead and a rebalance will occur. zookeeper.connection.timeout.ms 6000 The max time that the client waits while establishing a connection to zookeeper. zookeeper.sync.time.ms 2000 How far a ZK follower can be behind a ZK leader Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:36:39 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/mongo/":{"url":"distributed/mongo/","title":"mongo","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/mongo/mongoDb-data.html":{"url":"distributed/mongo/mongoDb-data.html","title":"1.准备数据","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.职工信息 2. 学生信息 3. 学生科目 4. 课程项目 1.职工信息 db.emp.insert([ {_id:1101,name:'鲁班' ,job:'讲师' ,dep:'讲师部',salary:10000}, {_id:1102,name:'悟空' ,job:'讲师' ,dep:'讲师部',salary:10000}, {_id:1103,name:'诸葛' ,job:'讲师' ,dep:'讲师部',salary:10000}, {_id:1105,name:'赵云' ,job:'讲师' ,dep:'讲师部',salary:8000}, {_id:1106,name:'韩信',job:'校长' ,dep:'校办',salary:20000}, {_id:1107,name:'貂蝉' ,job:'班主任' ,dep:'客服部',salary:8000}, {_id:1108,name:'安其' ,job:'班主任' ,dep:'客服部',salary:8000}, {_id:1109,name:'李白' ,job:'教务' ,dep:'教务处',salary:8000}, {_id:1110,name:'默子' ,job:'教务',dep:'教务处',salary:8000}, {_id:1111,name:'大乔',job:'助教' ,dep:'客服部',salary:5000}, {_id:1112,name:'小乔' ,job:'助教' ,dep:'客服部',salary:3000}, ]); 2. 学生信息 db.student.insertMany([ {_id:\"001\",name:\"陈霸天\",age:5,grade:{redis:87,zookeper:85,dubbo:90}}, {_id:\"002\",name:\"张明明\",age:3,grade:{redis:86,zookeper:82,dubbo:59}}, {_id:\"003\",name:\"肖炎炎\",age:2,grade:{redis:81,zookeper:94,dubbo:88}}, {_id:\"004\",name:\"李鬼才\",age:6,grade:{redis:48,zookeper:87,dubbo:48}} ]) 3. 学生科目 db.subject.insertMany([ {_id:\"001\",name:\"陈霸天\",subjects:[\"redis\",\"zookeper\",\"dubbo\"]}, {_id:\"002\",name:\"张明明\",subjects:[\"redis\",\"Java\",\"mySql\"]}, {_id:\"003\",name:\"肖炎炎\",subjects:[\"mySql\",\"zookeper\",\"bootstrap\"]}, {_id:\"004\",name:\"李鬼才\",subjects:[\"Java\",\"dubbo\",\"Java\"]}, ]) db.subject2.insertMany([ {_id:\"001\",name:\"陈霸天\",subjects:[{name:\"redis\",hour:12},{name:\"dubbo\",hour:120},{name:\"zookeper\",hour:56}]}, {_id:\"002\",name:\"张明明\",subjects:[{name:\"java\",hour:120},{name:\"mysql\",hour:10},{name:\"oracle\",hour:30}]}, {_id:\"003\",name:\"肖炎炎\",subjects:[{name:\"mysql\",hour:12},{name:\"html5\",hour:120},{name:\"netty\",hour:56}]}, {_id:\"004\",name:\"李鬼才\",subjects:[{name:\"redis\",hour:12},{name:\"dubbo\",hour:120},{name:\"netty\",hour:56}]} ]) 4. 课程项目 db.project.insert([ { _id: 1, name: \"Java Script\", description: \"name is js and jquery\" }, { _id: 2, name: \"Git\", description: \"Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency\" }, { _id: 3, name: \"Apache dubbo\", description: \"Apache Dubbo is a high-performance, java based open source RPC framework.阿里 开源 项目\" }, { _id: 4, name: \"Redis\", description: \"Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker. It supports data structures\" }, { _id: 5, name: \"Apache ZooKeeper\", description: \"Apache ZooKeeper is an effort to develop and maintain an open-source server which enables highly reliable distributed coordination\" } ]) Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/mongo/mongoDb-quick-start.html":{"url":"distributed/mongo/mongoDb-quick-start.html","title":"2.快速上手","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、MongoDb的体系结构 1、NoSql的概念 2、NoSql的应用场景 3、MongoDb的逻辑组成 二、MongoDb安装配置与基础命令 2.mongoDb启动参数说明 3.客户端Shell 的使用及参数说明 4.数据库与集合的基础操作 三、MongoDB CRUD与全文索引 2、数据的查询 排序与分页： 修改 3、数据的修改与删除 4、全文索引 大纲： 1、MongoDb的体系结构 2、MongoDb安装配置与基础命令 3、MongoDB CRUD与全文索引 数据脚本.txt 一、MongoDb的体系结构 概要： NoSql的概念 NoSql的应用场景 MongoDb的逻辑组成 1、NoSql的概念 NoSQL(NoSQL = Not Only SQL )，意即“不仅仅是 [SQL](https://baike.baidu.com/item/SQL) ”，互联网的早期我们的数据大多以关系型数据库来存储的。其特点是规范的数据结构（预定义模式）、强一至性、表与表之间通过外键进行关联，这些特征使我们对数据的管理更加清晰和严谨，但随着互联网的发展数据成爆炸式的增长我们对数据库需要更好的灵活性和更快的速度。这就是NoSql可以做到的。它不需要预先定义模式，没有主外键关联、支持分片、支持复本。 NoSql的分类： 键值(Key-Value)存储数据库 这一类数据库主要会使用到一个哈希表，这个表中有一个特定的键和一个指针指向特定的数据。Key/value模型对于IT系统来说的优势在于简单、易部署。但是如果DBA只对部分值进行查询或更新的时候，Key/value就显得效率低下了。举例如：Tokyo Cabinet/Tyrant, Redis, Voldemort, Oracle BDB. 列存储数据库。 这部分数据库通常是用来应对分布式存储的海量数据。键仍然存在，但是它们的特点是指向了多个列。这些列是由列家族来安排的。如：Cassandra, HBase, Riak. 文档型数据库 文档型数据库的灵感是来自于Lotus Notes办公软件的，而且它同第一种键值存储相类似。该类型的数据模型是版本化的文档，半结构化的文档以特定的格式存储，比如JSON。文档型数据库可 以看作是键值数据库的升级版，允许之间嵌套键值。而且文档型数据库比键值数据库的查询效率更高。如：CouchDB, MongoDb. 国内也有文档型数据库SequoiaDB，已经开源。 图形(Graph)数据库 图形结构的数据库同其他行列以及刚性结构的SQL数据库不同，它是使用灵活的图形模型，并且能够扩展到多个服务器上。NoSQL数据库没有标准的查询语言(SQL)，因此进行数据库查询需要制定数据模型。许多NoSQL数据库都有REST式的数据接口或者查询API。如：Neo4J, InfoGrid, Infinite Graph. 2、NoSql的应用场景 NoSQL数据库在以下的这几种情况下比较适用： 1、数据模型比较简单； 2、需要灵活性更强的IT系统； 3、对数据库性能要求较高； 4、不需要高度的数据一致性； [ ] 基于豆瓣电影举例说明NoSQL的应用场景 [ ] 电影基本信息分析 [ ] 电影与明星关系存储 3、MongoDb的逻辑组成 体系结构： 逻辑结构与关系数据库的对比： | 关系型数据库 | MongoDb | |:----|:----| | database(数据库) | database（数据库） | | table （表） | collection（ 集合） | | row（ 行） | document（ BSON 文档） | | column （列） | field （字段） | | index（唯一索引、主键索引） | index （全文索引） | | join （主外键关联） | embedded Document (嵌套文档) | | primary key(指定1至N个列做主键) | primary key (指定_id field做为主键) | | aggreation(groupy) | aggreation (pipeline mapReduce) | 二、MongoDb安装配置与基础命令 概要： mongoDb版本说明 mongoDb启动参数说明 客户端Shell 的使用及参数说明 数据库与集合的基础操作 mongoDb社区版说明 下载地址：https://www.mongodb.com/download-center/community #下载 wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.5.tgz # 解压 tar -zxvf mongodb-linux-x86_64-4.0.5.tgz 2.mongoDb启动参数说明 mongoDb 由C++编写，下载下来的包可以直接启动 #创建数据库目录 mkdir -p /data/mongo # 启动mongo ./bin/mongod --dbpath=/data/mongo/ 常规参数 | 参数 | 说明 | |:----|:----| | dbpath | 数据库目录，默认/data/db | | bind_ip | 监听IP地址，默认全部可以访问 | | port | 监听的端口，默认27017 | | logpath | 日志路径 | | logappend | 是否追加日志 | | auth | 是开启用户密码登陆 | | fork | 是否已后台启动的方式登陆 | | config | 指定配置文件 | 配置文件示例 vim mongo.conf 内容： dbpath=/data/mongo/ port=27017 bind_ip=0.0.0.0 fork=true logpath = /data/mongo/mongodb.log logappend = true auth=false 已配置文件方式启动 ./bin/mongod -f mongo.conf 3.客户端Shell 的使用及参数说明 #启动客户端 连接 本机的地的默认端口 ./bin/mongo # 指定IP和端口 ./bin/mongo --host=127.0.0.1 --port=27017 mongo shell 是一个js 控台，可以执行js 相关运算如: > 1+1 2 > var i=123; > print(i) 123 > 4.数据库与集合的基础操作 #查看数据库 show dbs; #切换数据库 use luban; #创建数据库与集合，在插入数据时会自动 创建数据库与集和 db.friend.insertOne({name:\"wukong\"，sex:\"man\"}); #查看集合 show tables; show collections; #删除集合 db.friend.drop(); #删除数据库 db.dropDatabase(); 三、MongoDB CRUD与全文索引 概要： 数据的新增的方式 数据的查询 数据的修改删除 全文索引查询 数据的新增的方式 关于Mongodb数据插入的说明 数据库的新增不需要序先设计模型结构，插入数据时会自动创建。 同一个集合中不同数据字段结构可以不一样 插入相关方法： //插入单条 db.friend.insertOne({name:\"wukong\"，sex:\"man\"}); // 插入多条 db.friend.insertMany([ {name:\"wukong\",sex:\"man\"},{name:\"diaocan\",sex:\"woman\",age:18,birthday:new Date(\"1995-11-02\")},{name:\"zixiao\",sex:\"woman\"} ]); // 指定ID db.friend.insert([ {_id:1,name:\"wokong\",sex:\"man\",age:1}, {_id:2,name:\"diaocan\",sex:\"women\",birthday:new Date(\"1988-11- 11\")} ]) 2、数据的查询 概要： 基于条件的基础查询 $and、$or、$in、$gt、$gte、$lt、$lte 运算符 基于 sort skip limit 方法实现排序与分页 嵌套查询 数组查询 数组嵌套查询 基础查询： #基于ID查找 db.emp.find({_id:1101}) #基于属性查找 db.emp.find({\"name\":\"鲁班\"}) # && 运算 与大于 运算 db.emp.find({\"job\":\"讲师\",\"salary\":{$gt:8000}}) # in 运算 db.emp.find({\"job\":{$in:[\"讲师\",\"客服部\"]}}) # or 运算 db.emp.find({$or:[{job:\"讲师\" },{job:\"客服部\"}] }) 排序与分页： // sort skip limit db.emp.find().sort({dep:1,salary:-1}).skip(5).limit(2) 嵌套查询： # 错误示例：无结果 db.student.find({grade:{redis:87,dubbo:90 }); #错误示例：无结果 db.student.find({grade:{redis:87,dubbo:90,zookeper:85} }) # 基于复合属性查找 时必须包含其所有的值 并且顺序一至 db.student.find({grade:{redis:87,zookeper:85,dubbo:90} }) #基于复合属性当中的指定值 查找。注：名称必须用双引号 db.student.find({\"grade.redis\":87}); db.student.find({\"grade.redis\":{\"$gt\":80}}); 数组查询： db.subject.insertMany([ {_id:\"001\",name:\"陈霸天\",subjects:[\"redis\",\"zookeper\",\"dubbo\"]}, {_id:\"002\",name:\"张明明\",subjects:[\"redis\",\"Java\",\"mySql\"]}, {_id:\"003\",name:\"肖炎炎\",subjects:[\"mySql\",\"zookeper\",\"bootstrap\"]}, {_id:\"004\",name:\"李鬼才\",subjects:[\"Java\",\"dubbo\",\"Java\"]}, ]) #无结果 db.subject.find({subjects:[\"redis\",\"zookeper\"]}) #无结果 db.subject.find({subjects:[\"zookeper\",\"redis\",\"dubbo\"]}) # 与嵌套查询一样，必须是所有的值 并且顺序一至 db.subject.find({subjects:[\"redis\",\"zookeper\",\"dubbo\"]}) # $all 匹配数组中包含该两项的值。注：顺序不作要求 db.subject.find({subjects:{\"$all\": [\"redis\",\"zookeper\"]}}) 注： # 简化数组查询 db.subject.find({subjects:\"redis\"}) # 简化数组查询 ，匹配数组中存在任意一值。与$all相对应 db.subject.find({subjects:{$in: [\"redis\",\"zookeper\"]}}) 数组嵌套查询： #基础查询 ，必须查询全部，且顺序一至 db.subject2.find({subjects:{name:\"redis\",hour:12} }) #指定查询第一个数组 课时大于12 db.subject2.find({\"subjects.0.hour\":{$gt:12}}) #查询任科目 课时大于12 db.subject2.find({\"subjects.hour\":{$gt:12}}) # $elemMatch 元素匹配，指定属性满足，且不要求顺序一至 db.subject2.find({subjects:{$elemMatch:{name:\"redis\",hour:12}}}) # 数组中任意元素匹配 不限定在同一个对象当中 db.subject2.find({\"subjects.name\":\"mysql\",\"subjects.hour\":120}) 修改 #设置值 db.emp.update({_id:1101} ,{ $set:{salary:10300} }) #自增 db.emp.update({_id:1101} ,{ $inc:{salary:200}}) #基于条件 更新多条数据 # 只会更新第一条 db.emp.update({\"dep\":\"客服部\"},{$inc:{salary:100}}) # 更新所有 匹配的条件 db.emp.updateMany({\"dep\":\"客服部\"},{$inc:{salary:100}}) 3、数据的修改与删除 修改 #设置值 db.emp.update({_id:1101} ,{ $set:{salary:10300} }) #自增 db.emp.update({_id:1101} ,{ $inc:{salary:200}}) #基于条件 更新多条数据 # 只会更新第一条 db.emp.update({\"dep\":\"客服部\"},{$inc:{salary:100}}) # 更新所有 匹配的条件 db.emp.updateMany({\"dep\":\"客服部\"},{$inc:{salary:100}}) 删除： // 基于查找删除 db.emp.deleteOne({_id:1101}) // 删除整个集合 db.project.drop() // 删除库 db.dropDatabase() 4、全文索引 索引的创建 db.project.createIndex({name:\"text\",description:\"text\"}) 基于索引分词进行查询 db.project.find({$text:{$search:\"java jquery\"}}) 基于索引 短语 db.project.find({$text:{$search:\"\\\"Apache ZooKeeper\\\"\"}}) 过滤指定单词 db.project.find({$text:{$search:\"java apache -阿里\"}}) 查看执行计划 db.project.find({$text:{$search:\"java -阿里\"}}).explain(\"executionStats\") Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/mongo/mongoDb-enterprise.html":{"url":"distributed/mongo/mongoDb-enterprise.html","title":"3.企业应用","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、 mongoDB的聚合操作 1.pipeline 聚合 2.mapRedurce 聚合 3.在聚合中使用索引 二、mongodb 的主从复制机制 1.复制集群的架构 2.复制集群搭建基础示例 子节点配置2 3.复制集群选举操作 三、mongodb 中的分片机制 1.为什么需要分片？ 1.mongodb 中的分片架构 2.分片示例流程： 节点1 config1-37017.conf 节点2 config2-37018.conf 配置 shard 节点集群============== 节点 route-27017.conf 四、用户管理与数据集验证 概要： mongoDB的聚合操作 mongodb 集群：复制 mongodb 集群：分片 一、 mongoDB的聚合操作 知识点： pipeline 聚合 mapRedurce 聚合 在聚合中使用索引 1.pipeline 聚合 pipeline相关运算符： $match ：匹配过滤聚合的数据 $project：返回需要聚合的字段 $group：统计聚合数据 示例： # $match 与 $project使用 db.emp.aggregate( {$match:{\"dep\":{$eq:\"客服部\"}}}, {$project:{name:1,dep:1,salary:1}} ); # $group 与 $sum 使用 db.emp.aggregate( {$project:{dep:1,salary:1}}, {$group:{\"_id\":\"$dep\",total:{$sum:\"$salary\"}}} ); # 低于4000 忽略 db.emp.aggregate( {$match:{salary:{$gt:4000}}}, {$project:{dep:1,salary:1}}, {$group:{\"_id\":\"$dep\",total:{$sum:\"$salary\"}}} ); # 基于多个字段 进行组合group 部门+职位进行统计 db.emp.aggregate( {$project:{dep:1,job:1,salary:1}}, {$group:{\"_id\":{\"dep\":\"$dep\",\"job\":\"$job\"},total:{$sum:\"$salary\"}}} ); 二次过滤 db.emp.aggregate( {$project:{dep:1,job:1,salary:1}}, {$group:{\"_id\":{\"dep\":\"$dep\",\"job\":\"$job\"},total:{$sum:\"$salary\"}}}， {$match:{\"$total\":{$gt:10000}}} ); 2.mapRedurce 聚合 mapRedurce 说明： 为什么需要 MapReduce？ (1) 海量数据在单机上处理因为硬件资源限制，无法胜任 (2) 而一旦将单机版程序扩展到集群来分布式运行，将极大增加程序的复杂度和开发难度 (3) 引入 MapReduce 框架后，开发人员可以将绝大部分工作集中在业务逻辑的开发上，而将 分布式计算中的复杂性交由框架来处理 mongodb中mapRedurce的使用流程 创建Map函数， 创建Redurce函数 将map、Redurce 函数添加至集合中，并返回新的结果集 查询新的结果集 示例操作 // 创建map 对象 var map1=function (){ emit(this.job,1); } // 创建reduce 对象 var reduce1=function(job,count){ return Array.sum(count); } // 执行mapReduce 任务 并将结果放到新的集合 result 当中 db.emp.mapReduce(map1,reduce1,{out:\"result\"}) // 查询新的集合 db.result.find() # 使用复合对象作为key var map2=function (){ emit({\"job\":this.job,\"dep\":this.dep},1); } var reduce2=function(key,values){ return values.length; } db.emp.mapReduce(map2,reduce2,{out:\"result2\"}).find() mapRedurce的原理 在map函数中使用emit函数添加指定的 key 与Value ，相同的key 将会发给Redurce进行聚合操作，所以Redurce函数中第二个参数 就是 所有集的数组。return 的显示就是聚合要显示的值。 3.在聚合中使用索引 通过$Math内 可以包合对$text 的运算 示例： db.project.aggregate( {$match:{$text:{$search:\"apache\"}}}, {$project:{\"name\":1,\"price\":1}}, {$group:{_id:\"$name\",price:{$sum:\"$price\"}}} ) 关于索引 除了全文索引之外，还有单键索引。即整个字段的值作为索引。单键索引用值1和-1表示，分别代表正序和降序索引。 示例： de 创建单键索引 db.emp.createIndex({\"dep\":1}) 查看基于索引的执行计划 db.emp.find({\"dep\":\"客服部\"}).explain() 除了单键索引外还可以创建联合索引如下： db.emp.createIndex({\"dep\":1,\"job\":-1}) 查看 复合索引的执行计划 db.emp.find({\"dep\":\"ddd\"}).explain() 查看索引在排序当中的使用 db.emp.find().sort({\"job\":-1,\"dep\":1}).explain() 二、mongodb 的主从复制机制 知识点： 复制集群的架构 复制集群搭建 复制集群的选举配置 1.复制集群的架构 2.复制集群搭建基础示例 主节点配置 dbpath=/data/mongo/master port=27017 fork=true logpath=master.log replSet=tulingCluster 从节点配置 dbpath=/data/mongo/slave port=27018 fork=true logpath=slave.log replSet=tulingCluster 子节点配置2 dbpath=/data/mongo/slave2 port=27019 fork=true logpath=slave2.log replSet=tulingCluster [ ] 分别启动三个节点 [ ] 进入其中一个节点 集群复制配置管理 #查看复制集群的帮助方法 rs.help() 添加配置 // 声明配置变量 var cfg ={\"_id\":\"tulingCluster\", \"members\":[ {\"_id\":0,\"host\":\"127.0.0.1:27017\"}, {\"_id\":1,\"host\":\"127.0.0.1:27018\"} ] } // 初始化配置 rs.initiate(cfg) // 查看集群状态 rs.status() 变更节点示例： // 插入新的复制节点 rs.add(\"127.0.0.1:27019\") // 删除slave 节点 rs.remove(\"127.0.0.1:27019\") [ ] 演示复制状态 [ ] 进入主节点客户端 [ ] 插入数据 [ ] 进入从节点查看数据 [ ] 尝试在从节点下插入数据 注：默认节点下从节点不能读取数据。调用 rs.slaveOk() 解决。 3.复制集群选举操作 为了保证高可用，在集群当中如果主节点挂掉后，会自动 在从节点中选举一个 重新做为主节点。 [ ] 演示节点的切换操作 [ ] kill 主节点 [ ] 进入从节点查看集群状态 。rs.status() 选举的原理： 在mongodb 中通过在 集群配置中的 rs.属性值大小来决定选举谁做为主节点，通时也可以设置arbiterOnly 为true 表示 做为裁判节点用于执行选举操作，该配置下的节点 永远不会被选举为主节点和从节点。 示例： 重新配置节点 var cfg ={\"_id\":\"tulingCluster\", \"protocolVersion\" : 1, \"members\":[ {\"_id\":0,\"host\":\"127.0.0.1:27017\",\"priority\":10}, {\"_id\":1,\"host\":\"127.0.0.1:27018\",\"priority\":2}, {\"_id\":2,\"host\":\"127.0.0.1:27019\",\"arbiterOnly\":true} ] } // 重新装载配置，并重新生成集群节点。 rs.reconfig(cfg) //重新查看集群状态 rs.status() 节点说明： PRIMARY 节点： 可以查询和新增数据 SECONDARY 节点：只能查询 不能新增 基于priority 权重可以被选为主节点 RBITER 节点： 不能查询数据 和新增数据 ，不能变成主节点 三、mongodb 中的分片机制 知识点： 分片的概念 mongodb 中的分片架构 分片示例 1.为什么需要分片？ 随着数据的增长，单机实例的瓶颈是很明显的。可以通过复制的机制应对压力，但mongodb中单个集群的 节点数量限制到了12个以内，所以需要通过分片进一步横向扩展。此外分片也可节约磁盘的存储。 1.mongodb 中的分片架构 分片中的节点说明： 路由节点(mongos)：用于分发用户的请求，起到反向代理的作用。 配置节点(config)：用于存储分片的元数据信息，路由节基于元数据信息 决定把请求发给哪个分片。（3.4版本之后，该节点，必须使用复制集。） 分片节点(shard):用于实际存储的节点，其每个数据块默认为64M，满了之后就会产生新的数据库。 2.分片示例流程： 配置 并启动config 节点集群 配置集群信息 配置并启动2个shard 节点 配置并启动路由节点 添加shard 节点 添加shard 数据库 添加shard 集合 插入测试数据 检查数据的分布 插入大批量数据查看shard 分布 设置shard 数据块为一M 插入10万条数据 配置 并启动config 节点集群 节点1 config1-37017.conf dbpath=/data/mongo/config1 port=37017 fork=true logpath=logs/config1.log replSet=configCluster configsvr=true 节点2 config2-37018.conf dbpath=/data/mongo/config2 port=37018 fork=true logpath=logs/config2.log replSet=configCluster configsvr=true 进入shell 并添加 config 集群配置： var cfg ={\"_id\":\"configCluster\", \"protocolVersion\" : 1, \"members\":[ {\"_id\":0,\"host\":\"127.0.0.1:37017\"}, {\"_id\":1,\"host\":\"127.0.0.1:37018\"} ] } // 重新装载配置，并重新生成集群。 rs.initiate(cfg) 配置 shard 节点集群============== # 节点1 shard1-47017.conf dbpath=/data/mongo/shard1 port=47017 fork=true logpath=logs/shard1.log shardsvr=true # 节点2 shard2-47018.conf dbpath=/data/mongo/shard2 port=47018 fork=true logpath=logs/shard2.log shardsvr=true 配置 路由节点 mongos ============== 节点 route-27017.conf port=27017 bind_ip=0.0.0.0 fork=true logpath=logs/route.log configdb=configCluster/127.0.0.1:37017,127.0.0.1:37018 // 添加分片节点 sh.status() sh.addShard(\"127.0.0.1:47017\"); sh.addShard(\"127.0.0.1:47018\"); 为数据库开启分片功能 sh.enableSharding(\"tuling\") 为指定集合开启分片功能 sh.shardCollection(\"tuling.emp\",{\"_id\":1}) 修改分片大小 use config db.settings.find() db.settings.save({_id:\"chunksize\",value:1}) 尝试插入1万条数据： for(var i=1;i 四、用户管理与数据集验证 // 创建管理员用户 use admin; db.createUser({\"user\":\"admin\",\"pwd\":\"123456\",\"roles\":[\"root\"]}) #验证用户信息 db.auth(\"admin\",\"123456\") #查看用户信息 db.getUsers() # 修改密码 db.changeUserPassword(\"admin\",\"123456\") 以auth 方式启动mongod，需要添加auth=true 参数 ，mongdb 的权限体系才会起作用： #以auth 方向启动mongod （也可以在mongo.conf 中添加auth=true 参数） ./bin/mongod -f conf/mongo.conf --auth # 验证用户 use admin; db.auth(\"admin\",\"123456\") 创建只读用户 db.createUser({\"user\":\"dev\",\"pwd\":\"123456\",\"roles\":[\"read\"]}) 重新登陆 验证用户权限 use luban ; db.auth(\"dev\",\"123456\") [ ] 演示查看数据 [ ] 演示插入数据 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/redis/":{"url":"distributed/redis/","title":"redis缓存","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/redis/redis.html":{"url":"distributed/redis/redis.html","title":"1.分布式之Redis","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.概述 1.1 简介 1.2 特点 1.3 场景 1.4 架构 1.5 工作原理 2.环境搭建 2.1redis 集群方案比较 2.1.1 哨兵模式 2.1.2 高可用集群模式 2.2 版本(高可用集群模式搭建) 2.2 主机规划 2.3 下载 2.4 配置环境 2.4.1redis 安装 2.4.2redis 集群搭建 3.快速入门 3.1Redis 基础数据结构 3.2Java 操作 redis 集群 3.3 4.深入了解 4.1Redis 的单线程和高性能 4.2 持久化 4.2.1RDB 快照（snapshot） save 60 1000 4.2.2AOF（append-only file） appendonly yes 4.2.3RDB 和 AOF，我应该用哪一个？ 4.2.4Redis 4.0 混合持久化 aof-use-rdb-preamble yes 4.3 六种缓存淘汰策略 4.4Redis 集群原理分析 4.4.1 槽位定位算法 4.4.2 跳转重定位 4.4.3 网络抖动 4.5Redis集群选举原理分析 5.优化 5.1 5.2 5.3 1.概述 1.1 简介 1.2 特点 1.3 场景 1.4 架构 1.5 工作原理 2.环境搭建 2.1redis 集群方案比较 2.1.1 哨兵模式 在 redis3.0 以前的版本要实现集群一般是借助哨兵 sentinel 工具来监控 master 节点的状态，如果 master 节点异常，则会做主从切换，将某一台 slave 作为 master，哨兵的配置略微复杂，并且性能和高可用性等各方面表现一般，特别是在主从切换的瞬间存在访问瞬断的情况，而且哨兵模式只有一个主节点对外提供服务，没法支持很高的并发，且单个主节点内存也不宜设置得过大，否则会导致持久化文件过大，影响数据恢复或主从同步的效率 2.1.2 高可用集群模式 redis 集群是一个由多个主从节点群组成的分布式服务器群，它具有复制、高可用和分片特性。Redis 集群不需要 sentinel 哨兵也能完成节点移除和故障转移的功能。需要将每个节点设置成集群模式，这种集群模式没有中心节点，可水平扩展，据官方文档称可以线性扩展到上万个节点(官方推荐不超过 1000 个节点)。redis 集群的性能和高可用性均优于之前版本的哨兵模式，且集群配置非常简单 2.2 版本(高可用集群模式搭建) 组件 版本 备注 centos 64 位 7.x 以上 redis 5.0 gcc xxx 2.2 主机规划 ip host 安装软件 127.0.0.1 hadoop101 redis gcc 2.3 下载 http://download.redis.io/releases/redis-5.0.2.tar.gz tar xzf redis-5.0.2.tar.gz 2.4 配置环境 2.4.1redis 安装 进入到解压好的 redis-5.0.2 目录下，进行编译与安装 make & make install 启动并指定配置文件 src/redis-server redis.conf（注意要使用后台启动，所以修改 redis.conf 里的daemonize 改为 yes) 验证启动是否成功 ps -ef | grep redis 进入 redis 客户端 /usr/local/redis/bin/redis-cli 退出客户端 quit 退出 redis 服务： （1）pkill redis-server （2）kill 进程号 （3）src/redis-cli shutdown 2.4.2redis 集群搭建 redis 集群需要至少要三个 master 节点，我们这里搭建三个 master 节点，并且给每个 master 再搭建一个 slave 节点，总共 6 个 redis 节点，这里用三台机器部署 6 个 redis 实例，每台机器一主一从，搭建集群的步骤如下： 第一步：在第一台机器的/usr/local 下创建文件夹 redis-cluster，然后在其下面分别创建 2 个文件夾如下: （1）mkdir -p /usr/local/redis-cluster （2）mkdir 8001、mkdir 8004 第二步：把之前的 redis.conf 配置文件 copy 到 8001 下，修改如下内容： （1）daemonize yes （2）port 8001（分别对每个机器的端口号进行设置） （3）dir /usr/local/redis-cluster/8001/（指定数据文件存放位置，必须要指定不同的目录位置，不然会丢失数据） （4）cluster-enabled yes（启动集群模式） （5）cluster-config-file nodes-8001.conf（集群节点信息文件，这里 800x 最好和 port 对应上） （6）cluster-node-timeout 5000 (7) # bind 127.0.0.1（去掉 bind 绑定访问 ip 信息） (8) protected-mode no （关闭保护模式） （9）appendonly yes 如果要设置密码需要增加如下配置： （10）requirepass zhuge (设置 redis 访问密码) （11）masterauth zhuge (设置集群节点间访问密码，跟上面一致) 第三步：把修改后的配置文件，copy 到 8002，修改第 2、3、5 项里的端口号，可以用批量替换： :%s/源字符串/目的字符串/g 第四步：另外两台机器也需要做上面几步操作，第二台机器用 8002 和 8005，第三台机器用 8003 和 8006 第五步：分别启动 6 个 redis 实例，然后检查是否启动成功 （1）/usr/local/redis-5.0.2/src/redis-server /usr/local/redis-cluster/800*/redis.conf （2）ps -ef | grep redis 查看是否启动成功 第六步：用 redis-cli 创建整个 redis 集群(redis5 以前的版本集群是依靠 ruby 脚本 redis-trib.rb 实现)（1）/usr/local/redis-5.0.2/src/redis-cli -a zhuge --cluster create --cluster-replicas 1 192.168.0.61:8001 192.168.0.62:8002 192.168.0.63:8003 192.168.0.61:8004 192.168.0.62:8005 192.168.0.63:8006 代表为每个创建的主服务器节点创建一个从服务器节点第七步：验证集群： （1）连接任意一个客户端即可：./redis-cli -c -h -p (-a 访问服务端密码，-c 表示集群模式，指定 ip 地址和端口号）如：/usr/local/redis-5.0.2/src/redis-cli -a zhuge -c -h 192.168.0.61 -p 800* （2）进行验证：cluster info（查看集群信息）、cluster nodes（查看节点列表） （3）进行数据操作验证 （4）关闭集群则需要逐个进行关闭，使用命令： /usr/local/redis/bin/redis-cli -a zhuge -c -h 192.168.0.60 -p 800* shutdown 3.快速入门 3.1Redis 基础数据结构 Redis 有 5 种基础数据结构，分别为：string (字符串)、list (列表)、set (集合)、hash (哈希) 和 zset (有序集合)。 3.2Java 操作 redis 集群 借助 redis 的 java 客户端 jedis 可以操作以上集群，引用 jedis 版本的 maven 坐标如下： redis.clients jedis 2.9.0 Java 编写访问 redis 集群的代码非常简单，如下所示： import java.io.IOException; import java.util.HashSet; import java.util.Set; import redis.clients.jedis.HostAndPort; import redis.clients.jedis.JedisCluster; import redis.clients.jedis.JedisPoolConfig; /** * 访问 redis 集群 */ public class RedisCluster { public static void main(String[] args) throws IOException{ Set jedisClusterNode = new HashSet(); jedisClusterNode.add(new HostAndPort(\"192.168.0.61\", 8001)); jedisClusterNode.add(new HostAndPort(\"192.168.0.62\", 8002)); jedisClusterNode.add(new HostAndPort(\"192.168.0.63\", 8003)); jedisClusterNode.add(new HostAndPort(\"192.168.0.61\", 8004)); jedisClusterNode.add(new HostAndPort(\"192.168.0.62\", 8005)); jedisClusterNode.add(new HostAndPort(\"192.168.0.63\", 8006)); JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(100); config.setMaxIdle(10); config.setTestOnBorrow(true); //connectionTimeout：指的是连接一个 url 的连接等待时间 //soTimeout：指的是连接上一个 url，获取 response 的返回等待时间 JedisCluster jedisCluster = new JedisCluster(jedisClusterNode, 6000, 5000, 10, \"zhuge\", config); System.out.println(jedisCluster.set(\"student\", \"zhuge\")); System.out.println(jedisCluster.set(\"age\", \"19\")); System.out.println(jedisCluster.get(\"student\")); System.out.println(jedisCluster.get(\"age\")); jedisCluster.close(); } } 3.3 4.深入了解 4.1Redis 的单线程和高性能 Redis 单线程为什么还能这么快？ 因为它所有的数据都在内存中，所有的运算都是内存级别的运算，而且单线程避免了多线程的切换性能损耗问题。正因为 Redis 是单线程，所以要小心使用 Redis 指令，对于那些耗时的指令(比如 keys)，一定要谨慎使用，一不小心就可能会导致 Redis 卡顿。 Redis 单线程如何处理那么多的并发客户端连接？ Redis 的 IO 多路复用：redis 利用 epoll 来实现 IO 多路复用，将连接信息和事件放到队列中，依次放到文件事件分派器，事件分派器将事件分发给事件处理器。 Nginx 也是采用 IO 多路复用原理解决 C10K 问题 4.2 持久化 4.2.1RDB 快照（snapshot） 在默认情况下，Redis 将内存数据库快照保存在名字为 dump.rdb 的二进制文件中。 你可以对 Redis 进行设置， 让它在“ N 秒内数据集至少有 M 个改动”这一条件被满足时， 自动保存一次数据集。 比如说，以下设置会让 Redis 在满足“ 60 秒内有至少有 1000 个键被改动”这一条件时， 自动保存一次数据集： save 60 1000 4.2.2AOF（append-only file） 快照功能并不是非常耐久（durable）：如果 Redis 因为某些原因而造成故障停机， 那么服务器将丢失最近写入、且仍未保存到快照中的那些数据。从 1.1 版本开始，Redis 增加了一种完全耐久的持久化方式：AOF 持久化，将修改的每一条指令记录进文件 你可以通过修改配置文件来打开 AOF 功能： appendonly yes 从现在开始， 每当 Redis 执行一个改变数据集的命令时（比如 SET）， 这个命令就会被追加到 AOF 文件的末尾。 这样的话， 当 Redis 重新启时， 程序就可以通过重新执行 AOF 文件中的命令来达到重建数据集的目的。 你可以配置 Redis 多久才将数据 fsync 到磁盘一次。 有三个选项：  每次有新命令追加到 AOF 文件时就执行一次 fsync ：非常慢，也非常安全。  每秒 fsync 一次：足够快（和使用 RDB 持久化差不多），并且在故障时只会丢失 1 秒钟的数据。  从不 fsync ：将数据交给操作系统来处理。更快，也更不安全的选择。 推荐（并且也是默认）的措施为每秒 fsync 一次， 这种 fsync 策略可以兼顾速度和安全性。 4.2.3RDB 和 AOF，我应该用哪一个？ 如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化。 有很多用户都只使用 AOF 持久化， 但我们并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快。 4.2.4Redis 4.0 混合持久化 重启 Redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。AOF在重写(aof文件里可能有太多没用指令，所以aof会定期根据内存的最新数据生成aof文件)时将重写这一刻之前的内存rdb快照文件的内容和增量的 AOF修改内存数据的命令日志文件存在一起，都写入新的aof文件，新的文件一开始不叫appendonly.aof，等到重写完新的AOF文件才会进行改名，原子的覆盖原有的AOF文件，完成新旧两个AOF文件的替换； AOF 根据配置规则在后台自动重写，也可以人为执行命令 bgrewriteaof 重写 AOF。 于是在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。 开启混合持久化： aof-use-rdb-preamble yes 混合持久化 aof 文件结构 4.3 六种缓存淘汰策略 当 Redis 内存超出物理内存限制时，内存的数据会开始和磁盘产生频繁的交换 (swap)。交换会让 Redis 的性能急剧下降，对于访问量比较频繁的 Redis 来说，这样龟速的存取效率基本上等于不可用。 在生产环境中我们是不允许 Redis 出现交换行为的，为了限制最大使用内存，Redis 提供了配置参数 maxmemory 来限制内存超出期望大小。 当实际内存超出 maxmemory 时，Redis 提供了几种可选策略 (maxmemory-policy) 来让用户自己决定该如何腾出新的空间以继续提供读写服务。 noeviction不会继续服务写请求 (DEL 请求可以继续服务)，读请求可以继续进行。这样可以保证不会丢失数据，但是会让线上的业务不能持续进行。这是默认的淘汰策略。 volatile-lru尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。没有设置过期时间的 key 不会被淘汰，这样可以保证需要持久化的数据不会突然丢失。 volatile-ttl跟上面一样，除了淘汰的策略不是 LRU，而是 key 的剩余寿命 ttl 的值，ttl 越小越优先被淘汰。 volatile-random跟上面一样，不过淘汰的 key 是过期 key 集合中随机的 key。 allkeys-lru区别于 volatile-lru，这个策略要淘汰的 key 对象是全体的 key 集合，而不只是过期的 key 集合。这意味着没有设置过期时间的 key 也会被淘汰。 allkeys-random跟上面一样，不过淘汰的策略是随机的 key。 volatile-xxx策略只会针对带过期时间的 key 进行淘汰，allkeys-xxx 策略会对所有的 key 进行淘汰。如果你只是拿 Redis 做缓存，那应该使用 allkeys-xxx，客户端写缓存时不必携带过期时间。如果你还想同时使用 Redis 的持久化功能，那就使用 volatile-xxx 策略，这样可以保留没有设置过期时间的 key，它们是永久的 key 不会被 LRU 算法淘汰。 4.4Redis 集群原理分析 Redis Cluster 将所有数据划分为16384 的 slots(槽位)，每个节点负责其中一部分槽位。槽位的信息存储于每个节点中，。 当 Redis Cluster 的客户端来连接集群时，它也会得到一份集群的槽位配置信息并将其缓存在客户端本地。这样当客户端要查找某个 key 时，可以直接定位到目标节点。同时因为槽位的信息可能会存在客户端与服务器不一致的情况，还需要纠正机制来实现槽位信息的校验调整。 4.4.1 槽位定位算法 Cluster 默认会对 key 值使用 crc16 算法进行 hash 得到一个整数值，然后用这个整数值对 16384 进行取模来得到具体槽位。 HASH_SLOT = CRC16(key) mod 16384 4.4.2 跳转重定位 当客户端向一个错误的节点发出了指令，该节点会发现指令的 key 所在的槽位并不归自己管理，这时它会向客户端发送一个特殊的跳转指令携带目标操作的节点地址，告诉客户端去连这个节点去获取数据。客户端收到指令后除了跳转到正确的节点上去操作，还会同步更新纠正本地的槽位映射表缓存，后续所有 key 将使用新的槽位映射表。 4.4.3 网络抖动 真实世界的机房网络往往并不是风平浪静的，它们经常会发生各种各样的小问题。比如网络抖动就是非常常见的一种现象，突然之间部分连接变得不可访问，然后很快又恢复正常。 为解决这种问题，Redis Cluster 提供了一种选项 cluster-node-timeout，表示当某个节点持续 timeout 的时间失联时，才可以认定该节点出现故障，需要进行主从切换。如果没有这个选项，网络抖动会导致主从频繁切换 (数据的重新复制)。 4.5Redis集群选举原理分析 当slave发现自己的master变为FAIL状态时，便尝试进行Failover，以期成为新的master。由于挂掉的master可能会有多个slave，从而存在多个slave竞争成为master节点的过程， 其过程如下： 1.slave发现自己的master变为FAIL 2.将自己记录的集群currentEpoch加1，并广播FAILOVER_AUTH_REQUEST 信息 3.其他节点收到该信息，只有master响应，判断请求者的合法性，并发送FAILOVER_AUTH_ACK，对每一个epoch只发送一次ack 4.尝试failover的slave收集FAILOVER_AUTH_ACK 5.超过半数后变成新Master 6.广播Pong通知其他集群节点。 从节点并不是在主节点一进入 FAIL 状态就马上尝试发起选举，而是有一定延迟，一定的延迟确保我们等待FAIL状态在集群中传播，slave如果立即尝试选举，其它masters或许尚未意识到FAIL状态，可能会拒绝投票 •延迟计算公式： DELAY = 500ms + random(0 ~ 500ms) + SLAVE_RANK * 1000ms •SLAVE_RANK表示此slave已经从master复制数据的总量的rank。Rank越小代表已复制的数据越新。这种方式下，持有最新数据的slave将会首先发起选举（理论上）。 5.优化 5.1 5.2 5.3 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:38:25 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/redis/redis6.html":{"url":"distributed/redis/redis6.html","title":"2.Redis6.0","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.NoSQL数据库简介 1.1技术发展 1.1.1Web1.0时代 1.1.2Web2.0时代 1.1.3解决CPU及内存压力 1.1.4解决IO压力 1.2NoSQL数据库 1.2.1NoSQL数据库概述 1.2.2NoSQL适用场景 1.2.3NoSQL不适用场景 1.2.4Memcache 1.2.5Redis 1.2.6MongoDB 1.3行式存储数据库（大数据时代） 1.3.1行式数据库 1.3.2列式数据库 1.4图关系型数据库 1.5DB-Engines 数据库排名 2.Redis概述安装 2.1应用场景 2.2Redis安装 2.2.1安装版本 2.2.2安装步骤 2.2.3安装目录：/usr/local/bin 2.2.4前台启动（不推荐） 2.2.5后台启动（推荐） 3.常用五大数据类型 3.1Redis键(key) 3.2Redis字符串(String) 3.3Redis列表(List) 3.4Redis集合(Set) 3.5Redis哈希(Hash) 3.6Redis有序集合Zset(sorted set) 4.Redis配置文件介绍 Units单位### INCLUDES包含### 网络相关配置 ### GENERAL通用### SECURITY安全### 5.Redis的发布和订阅 6.Redis新数据类型 7.Redis_Jedis_测试 8.Redis_Jedis_实例 9.Redis与Spring Boot整合 10.Redis_事务锁机制秒杀 11.Redis_事务_秒杀案例 12.Redis持久化之RDB SNAPSHOTTING快照### 13.Redis持久化之AOF 14.Redis_主从复制 15.Redis集群 16.Redis应用问题解决 16.1缓存穿透 17.2缓存击穿 17.3缓存雪崩 17.4分布式锁 17.Redis6.0新功能 17.1ACL 17.2IO多线程 框架高级课程系列之Redis6 尚硅谷JavaEE教研组 1.NoSQL数据库简介 1.1技术发展 技术的分类 1、解决功能性的问题：Java、Jsp、RDBMS、Tomcat、HTML、Linux、JDBC、SVN 2、解决扩展性的问题：Struts、Spring、SpringMVC、Hibernate、Mybatis 3、解决性能的问题：NoSQL、Java线程、Hadoop、Nginx、MQ、ElasticSearch 1.1.1Web1.0时代 Web1.0的时代，数据访问量很有限，用一夫当关的高性能的单点服务器可以解决大部分问题。 1.1.2Web2.0时代 随着Web2.0的时代的到来，用户访问量大幅度提升，同时产生了大量的用户数据。加上后来的智能移动设备的普及，所有的互联网平台都面临了巨大的性能挑战。 1.1.3解决CPU及内存压力 1.1.4解决IO压力 1.2NoSQL数据库 1.2.1NoSQL数据库概述 NoSQL(NoSQL = Not Only SQL )，意即“不仅仅是SQL”，泛指非关系型的数据库。 NoSQL 不依赖业务逻辑方式存储，而以简单的key-value模式存储。因此大大的增加了数据库的扩展能力。 不遵循SQL标准。 不支持ACID。 远超于SQL的性能。 1.2.2NoSQL适用场景 对数据高并发的读写 海量数据的读写 对数据高可扩展性的 1.2.3NoSQL不适用场景 需要事务支持 基于sql的结构化查询存储，处理复杂的关系,需要即席查询。 （用不着sql的和用了sql也不行的情况，请考虑用NoSql） 1.2.4Memcache 很早出现的NoSql数据库数据都在内存中，一般不持久化支持简单的key-value模式，支持类型单一一般是作为缓存数据库辅助持久化的数据库 1.2.5Redis 几乎覆盖了Memcached的绝大部分功能数据都在内存中，支持持久化，主要用作备份恢复除了支持简单的key-value模式，还支持多种数据结构的存储，比如list、set、hash、zset等。一般是作为缓存数据库辅助持久化的数据库 1.2.6MongoDB 高性能、开源、模式自由(schema free)的文档型数据库数据都在内存中，如果内存不足，把不常用的数据保存到硬盘虽然是key-value模式，但是对value（尤其是json）提供了丰富的查询功能支持二进制数据及大型对象可以根据数据的特点替代RDBMS，成为独立的数据库。或者配合RDBMS，存储特定的数据。 1.3行式存储数据库（大数据时代） 1.3.1行式数据库 1.3.2列式数据库 Hbase HBase是Hadoop项目中的数据库。它用于需要对大量的数据进行随机、实时的读写操作的场景中。 HBase的目标就是处理数据量非常庞大的表，可以用普通的计算机处理超过10亿行数据，还可处理有数百万列元素的数据表。 Cassandra[kəˈsændrə] Apache Cassandra是一款免费的开源NoSQL数据库，其设计目的在于管理由大量商用服务器构建起来的庞大集群上的海量数据集(数据量通常达到PB级别)。在众多显著特性当中，Cassandra最为卓越的长处是对写入及读取操作进行规模调整，而且其不强调主集群的设计思路能够以相对直观的方式简化各集群的创建与扩展流程。 计算机存储单位计算机存储单位一般用B，KB，MB，GB，TB，EB，ZB，YB，BB来表示，它们之间的关系是：位bit (比特)(Binary Digits)：存放一位二进制数，即0或1，最小的存储单位。字节byte：8个二进制位为一个字节(B)，最常用的单位。1KB (Kilobyte千字节)=1024B，1MB (Megabyte兆字节简称“兆”)=1024KB，1GB (Gigabyte吉字节又称“千兆”)=1024MB，1TB (Trillionbyte万亿字节太字节)=1024GB，其中1024=2^10 ( 2的10次方)，1PB（Petabyte千万亿字节拍字节）=1024TB，1EB（Exabyte百亿亿字节艾字节）=1024PB，1ZB (Zettabyte十万亿亿字节泽字节)= 1024 EB,1YB (Jottabyte一亿亿亿字节尧字节)= 1024 ZB,1BB (Brontobyte一千亿亿亿字节)= 1024 YB.注：“兆”为百万级数量单位。 1.4图关系型数据库 主要应用：社会关系，公共交通网络，地图及网络拓谱(n*(n-1)/2) 1.5DB-Engines 数据库排名 http://db-engines.com/en/ranking 2.Redis概述安装 Redis是一个开源的key-value存储系统。 和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set --有序集合)和hash（哈希类型）。 这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。 在此基础上，Redis支持各种不同方式的排序。 与memcached一样，为了保证效率，数据都是缓存在内存中。 区别的是Redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件。 并且在此基础上实现了master-slave(主从)同步。 2.1应用场景 配合关系型数据库做高速缓存 高频次，热门访问的数据，降低数据库IO 分布式架构，做session共享 多样的数据结构存储持久化数据 2.2Redis安装 Redis官方网站 Redis中文官方网站 http://redis.io http://redis.cn/ 2.2.1安装版本 6.2.1 for Linux（redis-6.2.1.tar.gz） 不用考虑在windows环境下对Redis的支持 2.2.2安装步骤 准备工作：下载安装最新版的gcc编译器 安装C 语言的编译环境 yum install centos-release-scl scl-utils-build yum install -y devtoolset-8-toolchain scl enable devtoolset-8 bash 测试 gcc版本 gcc --version 下载redis-6.2.1.tar.gz放/opt目录 解压命令：tar -zxvf redis-6.2.1.tar.gz 解压完成后进入目录：cd redis-6.2.1 在redis-6.2.1目录下再次执行make命令（只是编译好） 如果没有准备好C语言编译环境，make 会报错—Jemalloc/jemalloc.h：没有那个文件 解决方案：运行make distclean 在redis-6.2.1目录下再次执行make命令（只是编译好） 跳过make test 继续执行: make install 2.2.3安装目录：/usr/local/bin 查看默认安装目录： redis-benchmark:性能测试工具，可以在自己本子运行，看看自己本子性能如何 redis-check-aof：修复有问题的AOF文件，rdb和aof后面讲 redis-check-dump：修复有问题的dump.rdb文件 redis-sentinel：Redis集群使用 redis-server：Redis服务器启动命令 redis-cli：客户端，操作入口 2.2.4前台启动（不推荐） 前台启动，命令行窗口不能关闭，否则服务器停止 2.2.5后台启动（推荐） 备份redis.conf 拷贝一份redis.conf到其他目录 cp /opt/redis-3.2.5/redis.conf /myredis 后台启动设置daemonize no改成yes 修改redis.conf(128行)文件将里面的daemonize no 改成 yes，让服务在后台启动 Redis启动 redis-server/myredis/redis.conf 用客户端访问：redis-cli 多个端口可以：redis-cli -p6379 测试验证： ping Redis关闭 单实例关闭：redis-cli shutdown 也可以进入终端后再关闭 多实例关闭，指定端口关闭：redis-cli -p 6379 shutdown Redis介绍相关知识 端口6379从何而来Alessia Merz 默认16个数据库，类似数组下标从0开始，初始默认使用0号库使用命令select 来切换数据库。如: select 8统一密码管理，所有库同样密码。dbsize查看当前数据库的key的数量flushdb清空当前库flushall通杀全部库 Redis是单线程+多路IO复用技术 多路复用是指使用一个线程来检查多个文件描述符（Socket）的就绪状态，比如调用select和poll函数，传入多个文件描述符，如果有一个文件描述符就绪，则返回，否则阻塞直到超时。得到就绪状态后进行真正的操作可以在同一个线程里执行，也可以启动线程执行（比如使用线程池） 串行 vs 多线程+锁（memcached） vs 单线程+多路IO复用(Redis) （与Memcache三点不同: 支持多数据类型，支持持久化，单线程+多路IO复用） 3.常用五大数据类型 哪里去获得redis常见数据类型操作命令http://www.redis.cn/commands.html 3.1Redis键(key) keys 查看当前库所有key (匹配：keys 1) exists key判断某个key是否存在 type key 查看你的key是什么类型 del key 删除指定的key数据 unlink key 根据value选择非阻塞删除 仅将keys从keyspace元数据中删除，真正的删除会在后续异步操作。 expire key 10 10秒钟：为给定的key设置过期时间 ttl key 查看还有多少秒过期，-1表示永不过期，-2表示已过期 select命令切换数据库 dbsize查看当前数据库的key的数量 flushdb清空当前库 flushall通杀全部库 3.2Redis字符串(String) 简介 String是Redis最基本的类型，你可以理解成与Memcached一模一样的类型，一个key对应一个value。 String类型是二进制安全的。意味着Redis的string可以包含任何数据。比如jpg图片或者序列化的对象。 String类型是Redis最基本的数据类型，一个Redis中字符串value最多可以是512M 常用命令 set 添加键值对 *NX：当数据库中key不存在时，可以将key-value添加数据库 *XX：当数据库中key存在时，可以将key-value添加数据库，与NX参数互斥 *EX：key的超时秒数 *PX：key的超时毫秒数，与EX互斥 get 查询对应键值 append 将给定的 追加到原值的末尾 strlen 获得值的长度 setnx 只有在 key 不存在时 设置 key 的值 incr 将 key 中储存的数字值增1 只能对数字值操作，如果为空，新增值为1 decr 将 key 中储存的数字值减1 只能对数字值操作，如果为空，新增值为-1 incrby / decrby 将 key 中储存的数字值增减。自定义步长。 原子性所谓原子操作是指不会被线程调度机制打断的操作；这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch （切换到另一个线程）。（1）在单线程中， 能够在单条指令中完成的操作都可以认为是\"原子操作\"，因为中断只能发生于指令之间。（2）在多线程中，不能被其它进程（线程）打断的操作就叫原子操作。Redis单命令的原子性主要得益于Redis的单线程。案例：java中的i++是否是原子操作？不是i=0;两个线程分别对i进行++100次,值是多少？ 2~200 mset ..... 同时设置一个或多个 key-value对 mget ..... 同时获取一个或多个 value msetnx ..... 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。 原子性，有一个失败则都失败 getrange 获得值的范围，类似java中的substring，前包，后包 setrange 用 覆写所储存的字符串值，从开始(索引从0开始)。 setex 设置键值的同时，设置过期时间，单位秒。 getset 以新换旧，设置了新值同时获得旧值。 数据结构 String的数据结构为简单动态字符串(Simple Dynamic String,缩写SDS)。是可以修改的字符串，内部结构实现上类似于Java的ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配. 如图中所示，内部为当前字符串实际分配的空间capacity一般要高于实际字符串长度len。当字符串长度小于1M时，扩容都是加倍现有的空间，如果超过1M，扩容时一次只会多扩1M的空间。需要注意的是字符串最大长度为512M。 3.3Redis列表(List) 简介 单键多值 Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。 它的底层实际是个双向链表，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差。 常用命令 lpush/rpush .... 从左边/右边插入一个或多个值。 lpop/rpop 从左边/右边吐出一个值。值在键在，值光键亡。 rpoplpush 从列表右边吐出一个值，插到列表左边。 lrange 按照索引下标获得元素(从左到右) lrange mylist 0 -1 0左边第一个，-1右边第一个，（0-1表示获取所有） lindex 按照索引下标获得元素(从左到右) llen 获得列表长度 linsert before 在的后面插入插入值 lrem 从左边删除n个value(从左到右) lset将列表key下标为index的值替换成value 数据结构 List的数据结构为快速链表quickList。 首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是ziplist，也即是压缩列表。 它将所有的元素紧挨着一起存储，分配的是一块连续的内存。 当数据量比较多的时候才会改成quicklist。 因为普通的链表需要的附加指针空间太大，会比较浪费空间。比如这个列表里存的只是int类型的数据，结构上还需要两个额外的指针prev和next。 Redis将链表和ziplist结合起来组成了quicklist。也就是将多个ziplist使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。 3.4Redis集合(Set) 简介 Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。 Redis的Set是string类型的无序集合。它底层其实是一个value为null的hash表，所以添加，删除，查找的复杂度都是O(1)。 一个算法，随着数据的增加，执行时间的长短，如果是O(1)，数据增加，查找数据的时间不变 常用命令 sadd ..... 将一个或多个 member 元素加入到集合 key 中，已经存在的 member 元素将被忽略 smembers 取出该集合的所有值。 sismember 判断集合是否为含有该值，有1，没有0 scard返回该集合的元素个数。 srem .... 删除集合中的某个元素。 spop 随机从该集合中吐出一个值。 srandmember 随机从该集合中取出n个值。不会从集合中删除 。 smove value把集合中一个值从一个集合移动到另一个集合 sinter 返回两个集合的交集元素。 sunion 返回两个集合的并集元素。 sdiff 返回两个集合的差集元素(key1中的，不包含key2中的) 数据结构 Set数据结构是dict字典，字典是用哈希表实现的。 Java中HashSet的内部实现使用的是HashMap，只不过所有的value都指向同一个对象。Redis的set结构也是一样，它的内部也使用hash结构，所有的value都指向同一个内部值。 3.5Redis哈希(Hash) 简介 Redis hash 是一个键值对集合。 Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。 类似Java里面的Map 用户ID为查找的key，存储的value用户对象包含姓名，年龄，生日等信息，如果用普通的key/value结构来存储 主要有以下2种存储方式： 每次修改用户的某个属性需要，先反序列化改好后再序列化回去。开销较大。 用户ID数据冗余 通过 key(用户ID) + field(属性标签) 就可以操作对应属性数据了，既不需要重复存储数据，也不会带来序列化和并发修改控制的问题 :---- 常用命令 hset 给集合中的 键赋值 hget 从集合取出 value hmset ... 批量设置hash的值 hexists查看哈希表 key 中，给定域 field 是否存在。 hkeys 列出该hash集合的所有field hvals 列出该hash集合的所有value hincrby 为哈希表 key 中的域 field 的值加上增量 1 -1 hsetnx 将哈希表 key 中的域 field 的值设置为 value ，当且仅当域 field 不存在 . 数据结构 Hash类型对应的数据结构是两种：ziplist（压缩列表），hashtable（哈希表）。当field-value长度较短且个数较少时，使用ziplist，否则使用hashtable。 3.6Redis有序集合Zset(sorted set) 简介 Redis有序集合zset与普通集合set非常相似，是一个没有重复元素的字符串集合。 不同之处是有序集合的每个成员都关联了一个评分（score）,这个评分（score）被用来按照从最低分到最高分的方式排序集合中的成员。集合的成员是唯一的，但是评分可以是重复了 。 因为元素是有序的, 所以你也可以很快的根据评分（score）或者次序（position）来获取一个范围的元素。 访问有序集合的中间元素也是非常快的,因此你能够使用有序集合作为一个没有重复成员的智能列表。 常用命令 zadd … 将一个或多个 member 元素及其 score 值加入到有序集 key 当中。 zrange [WITHSCORES] 返回有序集 key 中，下标在之间的元素 带WITHSCORES，可以让分数一起和值返回到结果集。 zrangebyscore key minmax [withscores] [limit offset count] 返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列。 zrevrangebyscore key maxmin [withscores] [limit offset count] 同上，改为从大到小排列。 zincrby 为元素的score加上增量 zrem 删除该集合下，指定值的元素 zcount 统计该集合，分数区间内的元素个数 zrank 返回该值在集合中的排名，从0开始。 案例：如何利用zset实现一个文章访问量的排行榜？ 数据结构 SortedSet(zset)是Redis提供的一个非常特别的数据结构，一方面它等价于Java的数据结构Map，可以给每一个元素value赋予一个权重score，另一方面它又类似于TreeSet，内部的元素会按照权重score进行排序，可以得到每个元素的名次，还可以通过score的范围来获取元素的列表。 zset底层使用了两个数据结构 （1）hash，hash的作用就是关联元素value和权重score，保障元素value的唯一性，可以通过元素value找到相应的score值。 （2）跳跃表，跳跃表的目的在于给元素value排序，根据score的范围获取元素列表。 跳跃表（跳表） 1、简介 有序集合在生活中比较常见，例如根据成绩对学生排名，根据得分对玩家排名等。对于有序集合的底层实现，可以用数组、平衡树、链表等。数组不便元素的插入、删除；平衡树或红黑树虽然效率高但结构复杂；链表查询需要遍历所有效率低。Redis采用的是跳跃表。跳跃表效率堪比红黑树，实现远比红黑树简单。 2、实例 对比有序链表和跳跃表，从链表中查询出51 有序链表 要查找值为51的元素，需要从第一个元素开始依次查找、比较才能找到。共需要6次比较。 跳跃表 从第2层开始，1节点比51节点小，向后比较。 21节点比51节点小，继续向后比较，后面就是NULL了，所以从21节点向下到第1层 在第1层，41节点比51节点小，继续向后，61节点比51节点大，所以从41向下 在第0层，51节点为要查找的节点，节点被找到，共查找4次。 从此可以看出跳跃表比有序链表效率要高 4.Redis配置文件介绍 自定义目录：/myredis/redis.conf Units单位 配置大小单位,开头定义了一些基本的度量单位，只支持bytes，不支持bit 大小写不敏感 INCLUDES包含 类似jsp中的include，多实例的情况可以把公用的配置文件提取出来 网络相关配置 bind 默认情况bind=127.0.0.1只能接受本机的访问请求 不写的情况下，无限制接受任何ip地址的访问 生产环境肯定要写你应用服务器的地址；服务器是需要远程访问的，所以需要将其注释掉 如果开启了protected-mode，那么在没有设定bind ip且没有设密码的情况下，Redis只允许接受本机的响应 保存配置，停止服务，重启启动查看进程，不再是本机访问了。 protected-mode 将本机访问保护模式设置no Port 端口号，默认 6379 tcp-backlog 设置tcp的backlog，backlog其实是一个连接队列，backlog队列总和=未完成三次握手队列 + 已经完成三次握手队列。 在高并发环境下你需要一个高backlog值来避免慢客户端连接问题。 注意Linux内核会将这个值减小到/proc/sys/net/core/somaxconn的值（128），所以需要确认增大/proc/sys/net/core/somaxconn和/proc/sys/net/ipv4/tcp_max_syn_backlog（128）两个值来达到想要的效果 timeout 一个空闲的客户端维持多少秒会关闭，0表示关闭该功能。即永不关闭。 tcp-keepalive 对访问客户端的一种心跳检测，每个n秒检测一次。 单位为秒，如果设置为0，则不会进行Keepalive检测，建议设置成60 GENERAL通用 daemonize 是否为后台进程，设置为yes 守护进程，后台启动 pidfile 存放pid文件的位置，每个实例会产生一个不同的pid文件 loglevel 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为notice 四个级别根据使用阶段来选择，生产环境选择notice 或者warning logfile 日志文件名称 databases 16 设定库的数量 默认16，默认数据库为0，可以使用SELECT 命令在连接上指定数据库id SECURITY安全 设置密码 访问密码的查看、设置和取消 在命令中设置密码，只是临时的。重启redis服务器，密码就还原了。 永久设置，需要再配置文件中进行设置。 # LIMITS限制 maxclients 设置redis同时可以与多少个客户端进行连接。 默认情况下为10000个客户端。 如果达到了此限制，redis则会拒绝新的连接请求，并且向这些连接请求方发出“max number of clients reached”以作回应。 maxmemory 建议必须设置，否则，将内存占满，造成服务器宕机 设置redis可以使用的内存量。一旦到达内存使用上限，redis将会试图移除内部数据，移除规则可以通过maxmemory-policy来指定。 如果redis无法根据移除规则来移除内存中的数据，或者设置了“不允许移除”，那么redis则会针对那些需要申请内存的指令返回错误信息，比如SET、LPUSH等。 但是对于无内存申请的指令，仍然会正常响应，比如GET等。如果你的redis是主redis（说明你的redis有从redis），那么在设置内存使用上限时，需要在系统中留出一些内存空间给同步队列缓存，只有在你设置的是“不移除”的情况下，才不用考虑这个因素。 maxmemory-policy volatile-lru：使用LRU算法移除key，只对设置了过期时间的键；（最近最少使用） allkeys-lru：在所有集合key中，使用LRU算法移除key volatile-random：在过期集合中移除随机的key，只对设置了过期时间的键 allkeys-random：在所有集合key中，移除随机的key volatile-ttl：移除那些TTL值最小的key，即那些最近要过期的key noeviction：不进行移除。针对写操作，只是返回错误信息 maxmemory-samples 设置样本数量，LRU算法和最小TTL算法都并非是精确的算法，而是估算值，所以你可以设置样本的大小，redis默认会检查这么多个key并选择其中LRU的那个。 一般设置3到7的数字，数值越小样本越不准确，但性能消耗越小。 5.Redis的发布和订阅 什么是发布和订阅 Redis 发布订阅 (pub/sub) 是一种消息通信模式：发送者 (pub) 发送消息，订阅者 (sub) 接收消息。 Redis 客户端可以订阅任意数量的频道。 Redis的发布和订阅 1、客户端可以订阅频道如下图 2、当给这个频道发布消息后，消息就会发送给订阅的客户端 发布订阅命令行实现 打开一个客户端订阅channel1 SUBSCRIBE channel1 2、打开另一个客户端，给channel1发布消息hello publish channel1 hello 返回的1是订阅者数量 3、打开第一个客户端可以看到发送的消息 注：发布的消息没有持久化，如果在订阅的客户端收不到hello，只能收到订阅后发布的消息 6.Redis新数据类型 Bitmaps 简介 现代计算机用二进制（位） 作为信息的基础单位， 1个字节等于8位， 例如“abc”字符串是由3个字节组成， 但实际在计算机存储时将其用二进制表示， “abc”分别对应的ASCII码分别是97、 98、 99， 对应的二进制分别是01100001、 01100010和01100011，如下图 合理地使用操作位能够有效地提高内存使用率和开发效率。 Redis提供了Bitmaps这个“数据类型”可以实现对位的操作： Bitmaps本身不是一种数据类型， 实际上它就是字符串（key-value） ， 但是它可以对字符串的位进行操作。 Bitmaps单独提供了一套命令， 所以在Redis中使用Bitmaps和使用字符串的方法不太相同。 可以把Bitmaps想象成一个以位为单位的数组， 数组的每个单元只能存储0和1， 数组的下标在Bitmaps中叫做偏移量。 命令 1、setbit （1）格式 setbit设置Bitmaps中某个偏移量的值（0或1） *offset:偏移量从0开始 （2）实例 每个独立用户是否访问过网站存放在Bitmaps中， 将访问的用户记做1， 没有访问的用户记做0， 用偏移量作为用户的id。 设置键的第offset个位的值（从0算起） ， 假设现在有20个用户，userid=1， 6， 11， 15， 19的用户对网站进行了访问， 那么当前Bitmaps初始化结果如图 unique:users:20201106代表2020-11-06这天的独立访问用户的Bitmaps 注： 很多应用的用户id以一个指定数字（例如10000） 开头， 直接将用户id和Bitmaps的偏移量对应势必会造成一定的浪费， 通常的做法是每次做setbit操作时将用户id减去这个指定数字。 在第一次初始化Bitmaps时， 假如偏移量非常大， 那么整个初始化过程执行会比较慢， 可能会造成Redis的阻塞。 2、getbit （1）格式 getbit获取Bitmaps中某个偏移量的值 获取键的第offset位的值（从0开始算） （2）实例 获取id=8的用户是否在2020-11-06这天访问过， 返回0说明没有访问过： 注：因为100根本不存在，所以也是返回0 3、bitcount 统计字符串被设置为1的bit数。一般情况下，给定的整个字符串都会被进行计数，通过指定额外的 start 或 end 参数，可以让计数只在特定的位上进行。start 和 end 参数的设置，都可以使用负数值：比如 -1 表示最后一个位，而 -2 表示倒数第二个位，start、end 是指bit组的字节的下标数，二者皆包含。 （1）格式 bitcount[start end] 统计字符串从start字节到end字节比特值为1的数量 （2）实例 计算2022-11-06这天的独立访问用户数量 start和end代表起始和结束字节数， 下面操作计算用户id在第1个字节到第3个字节之间的独立访问用户数， 对应的用户id是11， 15， 19。 举例： K1 【01000001 01000000 00000000 00100001】，对应【0，1，2，3】 bitcount K1 1 2 ： 统计下标1、2字节组中bit=1的个数，即01000000 00000000 --》bitcount K1 1 2 　　--》1 bitcount K1 1 3 ： 统计下标1、2字节组中bit=1的个数，即01000000 00000000 00100001 --》bitcount K1 1 3　　--》3 bitcount K1 0 -2 ： 统计下标0到下标倒数第2，字节组中bit=1的个数，即01000001 01000000 00000000 --》bitcount K1 0 -2　　--》3 注意：redis的setbit设置或清除的是bit位置，而bitcount计算的是byte位置。 4、bitop (1)格式 bitop and(or/not/xor) [key…] bitop是一个复合操作， 它可以做多个Bitmaps的and（交集） 、 or（并集） 、 not（非） 、 xor（异或） 操作并将结果保存在destkey中。 (2)实例 2020-11-04 日访问网站的userid=1,2,5,9。 setbit unique:users:20201104 1 1 setbit unique:users:20201104 2 1 setbit unique:users:20201104 5 1 setbit unique:users:20201104 9 1 2020-11-03 日访问网站的userid=0,1,4,9。 setbit unique:users:20201103 0 1 setbit unique:users:20201103 1 1 setbit unique:users:20201103 4 1 setbit unique:users:20201103 9 1 计算出两天都访问过网站的用户数量 bitop and unique:users:and:20201104_03 unique:users:20201103unique:users:20201104 计算出任意一天都访问过网站的用户数量（例如月活跃就是类似这种） ， 可以使用or求并集 Bitmaps与set对比 假设网站有1亿用户， 每天独立访问的用户有5千万， 如果每天用集合类型和Bitmaps分别存储活跃用户可以得到表 set和Bitmaps存储一天活跃用户对比 数据类型 每个用户id占用空间 需要存储的用户量 全部内存量 集合类型 64位 50000000 64位*50000000 = 400MB Bitmaps 1位 100000000 1位*100000000 = 12.5MB 很明显， 这种情况下使用Bitmaps能节省很多的内存空间， 尤其是随着时间推移节省的内存还是非常可观的 set和Bitmaps存储独立用户空间对比 数据类型 一天 一个月 一年 集合类型 400MB 12GB 144GB Bitmaps 12.5MB 375MB 4.5GB 但Bitmaps并不是万金油， 假如该网站每天的独立访问用户很少， 例如只有10万（大量的僵尸用户） ， 那么两者的对比如下表所示， 很显然， 这时候使用Bitmaps就不太合适了， 因为基本上大部分位都是0。 set和Bitmaps存储一天活跃用户对比（独立用户比较少） 数据类型 每个userid占用空间 需要存储的用户量 全部内存量 集合类型 64位 100000 64位*100000 = 800KB Bitmaps 1位 100000000 1位*100000000 = 12.5MB HyperLogLog 简介 在工作当中，我们经常会遇到与统计相关的功能需求，比如统计网站PV（PageView页面访问量）,可以使用Redis的incr、incrby轻松实现。 但像UV（UniqueVisitor，独立访客）、独立IP数、搜索记录数等需要去重和计数的问题如何解决？这种求集合中不重复元素个数的问题称为基数问题。 解决基数问题有很多种方案： （1）数据存储在MySQL表中，使用distinct count计算不重复个数 （2）使用Redis提供的hash、set、bitmaps等数据结构来处理 以上的方案结果精确，但随着数据不断增加，导致占用空间越来越大，对于非常大的数据集是不切实际的。 能否能够降低一定的精度来平衡存储空间？Redis推出了HyperLogLog Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。 在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。 但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。 什么是基数? 比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)为5。 基数估计就是在误差可接受的范围内，快速计算基数。 命令 1、pfadd （1）格式 pfadd [element ...] 添加指定元素到 HyperLogLog 中 （2）实例 将所有元素添加到指定HyperLogLog数据结构中。如果执行命令后HLL估计的近似基数发生变化，则返回1，否则返回0。 2、pfcount （1）格式 pfcount [key ...] 计算HLL的近似基数，可以计算多个HLL，比如用HLL存储每天的UV，计算一周的UV可以使用7天的UV合并计算即可 （2）实例 3、pfmerge （1）格式 pfmerge [sourcekey ...] 将一个或多个HLL合并后的结果存储在另一个HLL中，比如每月活跃用户可以使用每天的活跃用户来合并计算可得 （2）实例 Geospatial 简介 Redis 3.2 中增加了对GEO类型的支持。GEO，Geographic，地理信息的缩写。该类型，就是元素的2维坐标，在地图上就是经纬度。redis基于该类型，提供了经纬度设置，查询，范围查询，距离查询，经纬度Hash等常见操作。 命令 1、geoadd （1）格式 geoadd [longitude latitude member...] 添加地理位置（经度，纬度，名称） （2）实例 geoadd china:city121.47 31.23 shanghai geoadd china:city 106.50 29.53 chongqing 114.05 22.52 shenzhen 116.38 39.90 beijing 两极无法直接添加，一般会下载城市数据，直接通过 Java 程序一次性导入。 有效的经度从 -180 度到 180 度。有效的纬度从 -85.05112878 度到 85.05112878 度。 当坐标位置超出指定范围时，该命令将会返回一个错误。 已经添加的数据，是无法再次往里面添加的。 2、geopos （1）格式 geopos [member...] 获得指定地区的坐标值 （2）实例 3、geodist （1）格式 geodist [m|km|ft|mi ] 获取两个位置之间的直线距离 （2）实例 获取两个位置之间的直线距离 单位： m 表示单位为米[默认值]。 km 表示单位为千米。 mi 表示单位为英里。 ft 表示单位为英尺。 如果用户没有显式地指定单位参数， 那么 GEODIST 默认使用米作为单位 4、georadius （1）格式 georadiusradius m|km|ft|mi 以给定的经纬度为中心，找出某一半径内的元素 经度 纬度 距离 单位 （2）实例 7.RedisJedis测试 Jedis所需要的jar包 redis.clientsjedis3.2.0 连接Redis注意事项 禁用Linux的防火墙：Linux(CentOS7)里执行命令 systemctl stop/disable firewalld.service redis.conf中注释掉bind 127.0.0.1 ,然后 protected-mode no Jedis常用操作 创建动态的工程 创建测试程序 package com.atguigu.jedis;import redis.clients.jedis.Jedis;public class Demo01 {public static void main(String[] args) {Jedis jedis = new Jedis(\"192.168.137.3\",6379);String pong = jedis.ping();System.out.println(\"连接成功：\"+pong);jedis.close();}} 测试相关数据类型 Jedis-API: Key jedis.set(\"k1\", \"v1\");jedis.set(\"k2\", \"v2\");jedis.set(\"k3\", \"v3\");Set keys = jedis.keys(\"*\");System.out.println(keys.size());for (String key : keys) {System.out.println(key);}System.out.println(jedis.exists(\"k1\"));System.out.println(jedis.ttl(\"k1\"));System.out.println(jedis.get(\"k1\")); Jedis-API: String jedis.mset(\"str1\",\"v1\",\"str2\",\"v2\",\"str3\",\"v3\");System.out.println(jedis.mget(\"str1\",\"str2\",\"str3\")); Jedis-API: List List list = jedis.lrange(\"mylist\",0,-1);for (String element : list) {System.out.println(element);} Jedis-API: set jedis.sadd(\"orders\", \"order01\");jedis.sadd(\"orders\", \"order02\");jedis.sadd(\"orders\", \"order03\");jedis.sadd(\"orders\", \"order04\");Set smembers = jedis.smembers(\"orders\");for (String order : smembers) {System.out.println(order);}jedis.srem(\"orders\", \"order02\"); Jedis-API: hash jedis.hset(\"hash1\",\"userName\",\"lisi\");System.out.println(jedis.hget(\"hash1\",\"userName\"));Map map = new HashMap();map.put(\"telphone\",\"13810169999\");map.put(\"address\",\"atguigu\");map.put(\"email\",\"abc@163.com\");jedis.hmset(\"hash2\",map);List result = jedis.hmget(\"hash2\", \"telphone\",\"email\");for (String element : result) {System.out.println(element);} Jedis-API: zset jedis.zadd(\"zset01\", 100d, \"z3\");jedis.zadd(\"zset01\", 90d, \"l4\");jedis.zadd(\"zset01\", 80d, \"w5\");jedis.zadd(\"zset01\", 70d, \"z6\");Set zrange = jedis.zrange(\"zset01\", 0, -1);for (String e : zrange) {System.out.println(e);} 8.RedisJedis实例 完成一个手机验证码功能 要求： 1、输入手机号，点击发送后随机生成6位数字码，2分钟有效 2、输入验证码，点击验证，返回成功或失败 3、每个手机号每天只能输入3次 9.Redis与Spring Boot整合 Spring Boot整合Redis非常简单，只需要按如下步骤整合即可 整合步骤 在pom.xml文件中引入redis相关依赖 org.springframework.bootspring-boot-starter-data-redisorg.apache.commonscommons-pool22.6.0 application.properties配置redis配置 #Redis服务器地址spring.redis.host=192.168.140.136#Redis服务器连接端口spring.redis.port=6379#Redis数据库索引（默认为0）spring.redis.database= 0#连接超时时间（毫秒）spring.redis.timeout=1800000#连接池最大连接数（使用负值表示没有限制）spring.redis.lettuce.pool.max-active=20#最大阻塞等待时间(负数表示没限制)spring.redis.lettuce.pool.max-wait=-1#连接池中的最大空闲连接spring.redis.lettuce.pool.max-idle=5#连接池中的最小空闲连接spring.redis.lettuce.pool.min-idle=0 添加redis配置类 @EnableCaching@Configurationpublic class RedisConfig extends CachingConfigurerSupport {@Beanpublic RedisTemplate redisTemplate(RedisConnectionFactory factory) {RedisTemplate template = new RedisTemplate<>();RedisSerializer redisSerializer = new StringRedisSerializer();Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);ObjectMapper om = new ObjectMapper();om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);jackson2JsonRedisSerializer.setObjectMapper(om);template.setConnectionFactory(factory);//key序列化方式template.setKeySerializer(redisSerializer);//value序列化template.setValueSerializer(jackson2JsonRedisSerializer);//value hashmap序列化template.setHashValueSerializer(jackson2JsonRedisSerializer);return template;}@Beanpublic CacheManager cacheManager(RedisConnectionFactory factory) {RedisSerializer redisSerializer = new StringRedisSerializer();Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);//解决查询缓存转换异常的问题ObjectMapper om = new ObjectMapper();om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);jackson2JsonRedisSerializer.setObjectMapper(om);//配置序列化（解决乱码的问题）,过期时间600秒RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig().entryTtl(Duration.ofSeconds(600)).serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(redisSerializer)).serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(jackson2JsonRedisSerializer)).disableCachingNullValues();RedisCacheManager cacheManager = RedisCacheManager.builder(factory).cacheDefaults(config).build();return cacheManager;}} 4、测试一下 RedisTestController中添加测试方法 @RestController@RequestMapping(\"/redisTest\")public class RedisTestController {@Autowiredprivate RedisTemplate redisTemplate;null@GetMappingpublic String testRedis() {//设置值到redisredisTemplate.opsForValue().set(\"name\",\"lucy\");//从redis获取值String name = (String)redisTemplate.opsForValue().get(\"name\");return name;}} 10.Redis事务锁机制_秒杀 Redis的事务定义 Redis事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 Redis事务的主要作用就是串联多个命令防止别的命令插队。 Multi、Exec、discard 从输入Multi命令开始，输入的命令都会依次进入命令队列中，但不会执行，直到输入Exec后，Redis会将之前的命令队列中的命令依次执行。 组队的过程中可以通过discard来放弃组队。 案例： 组队成功，提交成功 组队阶段报错，提交失败 组队成功，提交有成功有失败情况 事务的错误处理 组队中某个命令出现了报告错误，执行时整个的所有队列都会被取消。 如果执行阶段某个命令报出了错误，则只有报错的命令不会被执行，而其他的命令都会执行，不会回滚。 为什么要做成事务 想想一个场景：有很多人有你的账户,同时去参加双十一抢购 事务冲突的问题 例子 一个请求想给金额减8000 一个请求想给金额减5000 一个请求想给金额减1000 悲观锁 悲观锁(Pessimistic Lock), 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。 乐观锁 乐观锁(Optimistic Lock), 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量。Redis就是利用这种check-and-set机制实现事务的。 WATCH key [key ...] 在执行multi之前，先执行watch key1 [key2],可以监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。 unwatch 取消 WATCH 命令对所有 key 的监视。 如果在执行 WATCH 命令之后，EXEC 命令或DISCARD 命令先被执行了的话，那么就不需要再执行UNWATCH 了。 http://doc.redisfans.com/transaction/exec.html Redis事务三特性 单独的隔离操作 事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 没有隔离级别的概念 队列中的命令没有提交之前都不会实际被执行，因为事务提交前任何指令都不会被实际执行 不保证原子性 事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚 11.Redis事务秒杀案例 解决计数器和人员记录的事务操作 Redis事务--秒杀并发模拟 使用工具ab模拟测试 CentOS6 默认安装 CentOS7需要手动安装 联网：yum install httpd-tools 无网络 （1） 进入cd /run/media/root/CentOS 7 x86_64/Packages（路径跟centos6不同） （2） 顺序安装 apr-1.4.8-3.el7.x86_64.rpm apr-util-1.5.2-6.el7.x86_64.rpm httpd-tools-2.4.6-67.el7.centos.x86_64.rpm 测试及结果 通过ab测试 vim postfile 模拟表单提交参数,以&符号结尾;存放当前目录。 内容：prodid=0101& ab -n 2000 -c 200 -k -p ~/postfile -T application/x-www-form-urlencoded http://192.168.2.115:8081/Seckill/doseckill 超卖 超卖问题 利用乐观锁淘汰用户，解决超卖问题。 //增加乐观锁jedis.watch(qtkey);//3.判断库存String qtkeystr = jedis.get(qtkey);if(qtkeystr==null \\ \\ \"\".equals(qtkeystr.trim())) {System.out.println(\"未初始化库存\");jedis.close();return false ;}int qt = Integer.parseInt(qtkeystr);if(qtSystem.err.println(\"已经秒光\");jedis.close();return false;}//增加事务Transaction multi = jedis.multi();//4.减少库存//jedis.decr(qtkey);multi.decr(qtkey);//5.加人//jedis.sadd(usrkey, uid);multi.sadd(usrkey, uid);//执行事务List list = multi.exec();//判断事务提交是否失败if(list==null \\ \\ list.size()==0) {System.out.println(\"秒杀失败\");jedis.close();return false;}System.err.println(\"秒杀成功\");jedis.close(); 继续增加并发测试 连接有限制 ab -n 2000 -c 200 -k -p postfile -T 'application/x-www-form-urlencoded'http://192.168.140.1:8080/seckill/doseckill 增加-r参数，-r Don't exit on socket receive errors. ab -n 2000 -c 100 -r -p postfile -T 'application/x-www-form-urlencoded'http://192.168.140.1:8080/seckill/doseckill 已经秒光，可是还有库存 ab -n 2000 -c 100 -p postfile -T 'application/x-www-form-urlencoded'http://192.168.137.1:8080/seckill/doseckill 已经秒光，可是还有库存。原因，就是乐观锁导致很多请求都失败。先点的没秒到，后点的可能秒到了。 连接超时，通过连接池解决 连接池 节省每次连接redis服务带来的消耗，把连接好的实例反复利用。 通过参数管理连接的行为 代码见项目中 链接池参数 MaxTotal：控制一个pool可分配多少个jedis实例，通过pool.getResource()来获取；如果赋值为-1，则表示不限制；如果pool已经分配了MaxTotal个jedis实例，则此时pool的状态为exhausted。 maxIdle：控制一个pool最多有多少个状态为idle(空闲)的jedis实例； MaxWaitMillis：表示当borrow一个jedis实例时，最大的等待毫秒数，如果超过等待时间，则直接抛JedisConnectionException； testOnBorrow：获得一个jedis实例的时候是否检查连接可用性（ping()）；如果为true，则得到的jedis实例均是可用的； 解决库存遗留问题 LUA脚本 Lua 是一个小巧的脚本语言，Lua脚本可以很容易的被C/C++ 代码调用，也可以反过来调用C/C++的函数，Lua并没有提供强大的库，一个完整的Lua解释器不过200k，所以Lua不适合作为开发独立应用程序的语言，而是作为嵌入式脚本语言。 很多应用程序、游戏使用LUA作为自己的嵌入式脚本语言，以此来实现可配置性、可扩展性。 这其中包括魔兽争霸地图、魔兽世界、博德之门、愤怒的小鸟等众多游戏插件或外挂。 https://www.w3cschool.cn/lua/ LUA脚本在Redis中的优势 将复杂的或者多步的redis操作，写为一个脚本，一次提交给redis执行，减少反复连接redis的次数。提升性能。 LUA脚本是类似redis事务，有一定的原子性，不会被其他命令插队，可以完成一些redis事务性的操作。 但是注意redis的lua脚本功能，只有在Redis 2.6以上的版本才可以使用。 利用lua脚本淘汰用户，解决超卖问题。 redis 2.6版本以后，通过lua脚本解决争抢问题，实际上是redis 利用其单线程的特性，用任务队列的方式解决多任务并发问题。 Redis事务秒杀案例_代码 项目结构 第一版：简单版 老师点10次，正常秒杀 同学一起点试一试，秒杀也是正常的。这是因为还达不到并发的效果。 使用工具ab模拟并发测试，会出现超卖情况。查看库存会出现负数。 第二版：加事务-乐观锁(解决超卖),但出现遗留库存和连接超时 第三版：连接池解决超时问题 第四版：解决库存依赖问题，LUA脚本 local userid=KEYS[1];local prodid=KEYS[2];localqtkey=\"sk:\"..prodid..\":qt\";localusersKey=\"sk:\"..prodid.\":usr';local userExists=redis.call(\"sismember\",usersKey,userid);if tonumber(userExists)==1 thenreturn 2;endlocal num= redis.call(\"get\" ,qtkey);if tonumber(num)return 0;elseredis.call(\"decr\",qtkey);redis.call(\"sadd\",usersKey,userid);endreturn 1; 12.Redis持久化之RDB 总体介绍 官网介绍：http://www.redis.io Redis 提供了2个不同形式的持久化方式。 RDB（Redis DataBase） AOF（Append Of File） RDB（Redis DataBase） 官网介绍 是什么 在指定的时间间隔内将内存中的数据集快照写入磁盘， 也就是行话讲的Snapshot快照，它恢复时是将快照文件直接读到内存里 备份是如何执行的 Redis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到 一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。 整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能 如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。 Fork Fork的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等） 数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程 在Linux程序中，fork()会产生一个和父进程完全相同的子进程，但子进程在此后多会exec系统调用，出于效率考虑，Linux中引入了“写时复制技术” 一般情况父进程和子进程会共用同一段物理内存，只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程。 RDB持久化流程 dump.rdb文件 在redis.conf中配置文件名称，默认为dump.rdb 配置位置 rdb文件的保存路径，也可以修改。默认为Redis启动时命令行所在的目录下 dir \"/myredis/\" 如何触发RDB快照；保持策略 配置文件中默认的快照配置 命令save VS bgsave save ：save时只管保存，其它不管，全部阻塞。手动保存。不建议。 bgsave：Redis会在后台异步进行快照操作， 快照同时还可以响应客户端请求。 可以通过lastsave 命令获取最后一次成功执行快照的时间 flushall命令 执行flushall命令，也会产生dump.rdb文件，但里面是空的，无意义 SNAPSHOTTING快照 Save 格式：save 秒钟 写操作次数 RDB是整个内存的压缩过的Snapshot，RDB的数据结构，可以配置复合的快照触发条件， 默认是1分钟内改了1万次，或5分钟内改了10次，或15分钟内改了1次。 禁用 不设置save指令，或者给save传入空字符串 stop-writes-on-bgsave-error 当Redis无法写入磁盘的话，直接关掉Redis的写操作。推荐yes. rdbcompression 压缩文件 对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算法进行压缩。 如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能。推荐yes. rdbchecksum 检查完整性 在存储快照后，还可以让redis使用CRC64算法来进行数据校验， 但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能 推荐yes. rdb的备份 先通过config get dir 查询rdb文件的目录 将*.rdb的文件拷贝到别的地方 rdb的恢复 关闭Redis 先把备份的文件拷贝到工作目录下 cp dump2.rdb dump.rdb 启动Redis, 备份数据会直接加载 优势 适合大规模的数据恢复 对数据完整性和一致性要求不高更适合使用 节省磁盘空间 恢复速度快 劣势 Fork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑 虽然Redis在fork时使用了写时拷贝技术,但是如果数据庞大时还是比较消耗性能。 在备份周期在一定间隔时间做一次备份，所以如果Redis意外down掉的话，就会丢失最后一次快照后的所有修改。 如何停止 动态停止RDB：redis-cli config set save \"\"#save后给空值，表示禁用保存策略 小总结 13.Redis持久化之AOF AOF（Append Only File） 是什么 以日志的形式来记录每个写操作（增量保存），将Redis执行过的所有写指令记录下来(读操作不记录)， 只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据，换言之，redis 重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作 AOF持久化流程 （1）客户端的请求写命令会被append追加到AOF缓冲区内； （2）AOF缓冲区根据AOF持久化策略[always,everysec,no]将操作sync同步到磁盘的AOF文件中； （3）AOF文件大小超过重写策略或手动重写时，会对AOF文件rewrite重写，压缩AOF文件容量； （4）Redis服务重启时，会重新load加载AOF文件中的写操作达到数据恢复的目的； AOF默认不开启 可以在redis.conf中配置文件名称，默认为 appendonly.aof AOF文件的保存路径，同RDB的路径一致。 AOF和RDB同时开启，redis听谁的？ AOF和RDB同时开启，系统默认取AOF的数据（数据不会存在丢失） AOF启动/修复/恢复 AOF的备份机制和性能虽然和RDB不同, 但是备份和恢复的操作同RDB一样，都是拷贝备份文件，需要恢复时再拷贝到Redis工作目录下，启动系统即加载。 正常恢复 修改默认的appendonly no，改为yes 将有数据的aof文件复制一份保存到对应目录(查看目录：config get dir) 恢复：重启redis然后重新加载 异常恢复 修改默认的appendonly no，改为yes 如遇到AOF文件损坏，通过/usr/local/bin/redis-check-aof--fix appendonly.aof进行恢复 备份被写坏的AOF文件 恢复：重启redis，然后重新加载 AOF同步频率设置 appendfsync always 始终同步，每次Redis的写入都会立刻记入日志；性能较差但数据完整性比较好 appendfsync everysec 每秒同步，每秒记入日志一次，如果宕机，本秒的数据可能丢失。 appendfsync no redis不主动进行同步，把同步时机交给操作系统。 Rewrite压缩 1是什么： AOF采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制, 当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩， 只保留可以恢复数据的最小指令集.可以使用命令bgrewriteaof 2重写原理，如何实现重写 AOF文件持续增长而过大时，会fork出一条新进程来将文件重写(也是先写临时文件最后再rename)，redis4.0版本后的重写，是指上就是把rdb 的快照，以二级制的形式附在新的aof头部，作为已有的历史数据，替换掉原来的流水账操作。 no-appendfsync-on-rewrite： 如果 no-appendfsync-on-rewrite=yes ,不写入aof文件只写入缓存，用户请求不会阻塞，但是在这段时间如果宕机会丢失这段时间的缓存数据。（降低数据安全性，提高性能） 如果 no-appendfsync-on-rewrite=no, 还是会把数据往磁盘里刷，但是遇到重写操作，可能会发生阻塞。（数据安全，但是性能降低） 触发机制，何时重写 Redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发 重写虽然可以节约大量磁盘空间，减少恢复时间。但是每次重写还是有一定的负担的，因此设定Redis要满足一定条件才会进行重写。 auto-aof-rewrite-percentage：设置重写的基准值，文件达到100%时开始重写（文件是原来重写后文件的2倍时触发） auto-aof-rewrite-min-size：设置重写的基准值，最小文件64MB。达到这个值开始重写。 例如：文件达到70MB开始重写，降到50MB，下次什么时候开始重写？100MB 系统载入时或者上次重写完毕时，Redis会记录此时AOF大小，设为base_size, 如果Redis的AOF当前大小>= base_size +base_size*100% (默认)且当前大小>=64mb(默认)的情况下，Redis会对AOF进行重写。 3、重写流程 （1）bgrewriteaof触发重写，判断是否当前有bgsave或bgrewriteaof在运行，如果有，则等待该命令结束后再继续执行。 （2）主进程fork出子进程执行重写操作，保证主进程不会阻塞。 （3）子进程遍历redis内存中数据到临时文件，客户端的写请求同时写入aof_buf缓冲区和aof_rewrite_buf重写缓冲区保证原AOF文件完整以及新AOF文件生成期间的新的数据修改动作不会丢失。 （4）1).子进程写完新的AOF文件后，向主进程发信号，父进程更新统计信息。2).主进程把aof_rewrite_buf中的数据写入到新的AOF文件。 （5）使用新的AOF文件覆盖旧的AOF文件，完成AOF重写。 优势 备份机制更稳健，丢失数据概率更低。 可读的日志文本，通过操作AOF稳健，可以处理误操作。 劣势 比起RDB占用更多的磁盘空间。 恢复备份速度要慢。 每次读写都同步的话，有一定的性能压力。 存在个别Bug，造成恢复不能。 小总结 总结(Which one) 用哪个好 官方推荐两个都启用。 如果对数据不敏感，可以选单独用RDB。 不建议单独用 AOF，因为可能会出现Bug。 如果只是做纯内存缓存，可以都不用。 官网建议 RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储 AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾. Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大 只做缓存：如果你只希望你的数据在服务器运行的时候存在,你也可以不使用任何持久化方式. 同时开启两种持久化方式 在这种情况下,当redis重启的时候会优先载入AOF文件来恢复原始的数据, 因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整. RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件。那要不要只使用AOF呢？ 建议不要，因为RDB更适合用于备份数据库(AOF在不断变化不好备份)， 快速重启，而且不会有AOF可能潜在的bug，留着作为一个万一的手段。 性能建议 因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留save 900 1这条规则。如果使用AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了。代价,一是带来了持续的IO，二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少AOF rewrite的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上。默认超过原大小100%大小时重写可以改到适当的数值。 14.Redis_主从复制 是什么 主机数据更新后根据配置和策略， 自动同步到备机的master/slaver机制，Master以写为主，Slave以读为主 能干嘛 读写分离，性能扩展 容灾快速恢复 怎么玩：主从复制 拷贝多个redis.conf文件include(写绝对路径) 开启daemonize yes Pid文件名字pidfile 指定端口port Log文件名字 dump.rdb名字dbfilename Appendonly 关掉或者换名字 新建redis6379.conf，填写以下内容 include /myredis/redis.conf pidfile /var/run/redis_6379.pid port 6379 dbfilename dump6379.rdb 新建redis6380.conf，填写以下内容 新建redis6381.conf，填写以下内容 slave-priority 10 设置从机的优先级，值越小，优先级越高，用于选举主机时使用。默认100 启动三台redis服务器 查看系统进程，看看三台服务器是否启动 查看三台主机运行情况 info replication 打印主从复制的相关信息 配从(库)不配主(库) slaveof 成为某个实例的从服务器 1、在6380和6381上执行: slaveof 127.0.0.1 6379 2、在主机上写，在从机上可以读取数据 在从机上写数据报错 3、主机挂掉，重启就行，一切如初 4、从机重启需重设：slaveof 127.0.0.1 6379 可以将配置增加到文件中。永久生效。 常用3招 一主二仆 切入点问题？slave1、slave2是从头开始复制还是从切入点开始复制?比如从k4进来，那之前的k1,k2,k3是否也可以复制？ 从机是否可以写？set可否？ 主机shutdown后情况如何？从机是上位还是原地待命？ 主机又回来了后，主机新增记录，从机还能否顺利复制？ 其中一台从机down后情况如何？依照原有它能跟上大部队吗？ 薪火相传 上一个Slave可以是下一个slave的Master，Slave同样可以接收其他 slaves的连接和同步请求，那么该slave作为了链条中下一个的master, 可以有效减轻master的写压力,去中心化降低风险。 用 slaveof 中途变更转向:会清除之前的数据，重新建立拷贝最新的 风险是一旦某个slave宕机，后面的slave都没法备份 主机挂了，从机还是从机，无法写数据了 反客为主 当一个master宕机后，后面的slave可以立刻升为master，其后面的slave不用做任何修改。 用 slaveof no one 将从机变为主机。 复制原理 Slave启动成功连接到master后会发送一个sync命令 Master接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令， 在后台进程执行完毕之后，master将传送整个数据文件到slave,以完成一次完全同步 全量复制：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。 增量复制：Master继续将新的所有收集到的修改命令依次传给slave,完成同步 但是只要是重新连接master,一次完全同步（全量复制)将被自动执行 哨兵模式(sentinel) 是什么 反客为主的自动版，能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库 怎么玩(使用步骤) 调整为一主二仆模式，6379带着6380、6381 自定义的/myredis目录下新建sentinel.conf文件，名字绝不能错 配置哨兵,填写内容 sentinel monitor mymaster 127.0.0.1 6379 1 其中mymaster为监控对象起的服务器名称， 1 为至少有多少个哨兵同意迁移的数量。 启动哨兵 /usr/local/bin redis做压测可以用自带的redis-benchmark工具 执行redis-sentinel /myredis/sentinel.conf 当主机挂掉，从机选举中产生新的主机 (大概10秒左右可以看到哨兵窗口日志，切换了新的主机) 哪个从机会被选举为主机呢？根据优先级别：slave-priority 原主机重启后会变为从机。 复制延时 由于所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以从Master同步到Slave机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重。 故障恢复 优先级在redis.conf中默认：slave-priority 100，值越小优先级越高 偏移量是指获得原主机数据最全的 每个redis实例启动后都会随机生成一个40位的runid 主从复制 private static JedisSentinelPool jedisSentinelPool=null;public static Jedis getJedisFromSentinel(){if(jedisSentinelPool==null){Set sentinelSet=new HashSet<>();sentinelSet.add(\"192.168.11.103:26379\");JedisPoolConfig jedisPoolConfig =new JedisPoolConfig();jedisPoolConfig.setMaxTotal(10); //最大可用连接数jedisPoolConfig.setMaxIdle(5); //最大闲置连接数jedisPoolConfig.setMinIdle(5); //最小闲置连接数jedisPoolConfig.setBlockWhenExhausted(true); //连接耗尽是否等待jedisPoolConfig.setMaxWaitMillis(2000); //等待时间jedisPoolConfig.setTestOnBorrow(true); //取连接的时候进行一下测试ping pongjedisSentinelPool=new JedisSentinelPool(\"mymaster\",sentinelSet,jedisPoolConfig);return jedisSentinelPool.getResource();}else{return jedisSentinelPool.getResource();}} 15.Redis集群 问题 容量不够，redis如何进行扩容？ 并发写操作， redis如何分摊？ 另外，主从模式，薪火相传模式，主机宕机，导致ip地址发生变化，应用程序中配置需要修改对应的主机地址、端口等信息。 之前通过代理主机来解决，但是redis3.0中提供了解决方案。就是无中心化集群配置。 什么是集群 Redis 集群实现了对Redis的水平扩容，即启动N个redis节点，将整个数据库分布存储在这N个节点中，每个节点存储总数据的1/N。 Redis 集群通过分区（partition）来提供一定程度的可用性（availability）： 即使集群中有一部分节点失效或者无法进行通讯， 集群也可以继续处理命令请求。 删除持久化数据 将rdb,aof文件都删除掉。 制作6个实例，6379,6380,6381,6389,6390,6391 配置基本信息 开启daemonize yes Pid文件名字 指定端口 Log文件名字 Dump.rdb名字 Appendonly 关掉或者换名字 redis cluster配置修改 cluster-enabled yes 打开集群模式 cluster-config-file nodes-6379.conf 设定节点配置文件名 cluster-node-timeout 15000 设定节点失联时间，超过该时间（毫秒），集群自动进行主从切换。 include /home/bigdata/redis.confport 6379pidfile \"/var/run/redis_6379.pid\"dbfilename \"dump6379.rdb\"dir \"/home/bigdata/redis_cluster\"logfile \"/home/bigdata/redis_cluster/redis_err_6379.log\"cluster-enabled yescluster-config-file nodes-6379.confcluster-node-timeout 15000 修改好redis6379.conf文件，拷贝多个redis.conf文件 使用查找替换修改另外5个文件 例如：:%s/6379/6380 启动6个redis服务 将六个节点合成一个集群 组合之前，请确保所有redis实例启动后，nodes-xxxx.conf文件都生成正常。 合体： cd /opt/redis-6.2.1/src redis-cli --cluster create --cluster-replicas 1 192.168.11.101:6379192.168.11.101:6380 192.168.11.101:6381 192.168.11.101:6389 192.168.11.101:6390 192.168.11.101:6391 此处不要用127.0.0.1， 请用真实IP地址 --replicas 1 采用最简单的方式配置集群，一台主机，一台从机，正好三组。 普通方式登录 可能直接进入读主机，存储数据时，会出现MOVED重定向操作。所以，应该以集群方式登录。 -c 采用集群策略连接，设置数据会自动切换到相应的写主机 通过 cluster nodes 命令查看集群信息 redis cluster 如何分配这六个节点? 一个集群至少要有三个主节点。 选项 --cluster-replicas 1 表示我们希望为集群中的每个主节点创建一个从节点。 分配原则尽量保证每个主数据库运行在不同的IP地址，每个从库和主库不在一个IP地址上。 什么是slots [OK] All nodes agree about slots configuration. Check for open slots... Check slots coverage... [OK] All16384slots covered. 一个 Redis 集群包含 16384 个插槽（hash slot）， 数据库中的每个键都属于这 16384 个插槽的其中一个， 集群使用公式 CRC16(key) % 16384 来计算键 key 属于哪个槽， 其中 CRC16(key) 语句用于计算键 key 的 CRC16 校验和 。 集群中的每个节点负责处理一部分插槽。 举个例子， 如果一个集群可以有主节点， 其中： 节点 A 负责处理 0 号至 5460 号插槽。 节点 B 负责处理 5461 号至 10922 号插槽。 节点 C 负责处理 10923 号至 16383 号插槽。 在集群中录入值 在redis-cli每次录入、查询键值，redis都会计算出该key应该送往的插槽，如果不是该客户端对应服务器的插槽，redis会报错，并告知应前往的redis实例地址和端口。 redis-cli客户端提供了 –c 参数实现自动重定向。 如 redis-cli-c–p 6379 登入后，再录入、查询键值对可以自动重定向。 不在一个slot下的键值，是不能使用mget,mset等多键操作。 可以通过{}来定义组的概念，从而使key中{}内相同内容的键值对放到一个slot中去。 查询集群中的值 CLUSTER GETKEYSINSLOT 返回 count 个 slot 槽中的键。 故障恢复 如果主节点下线？从节点能否自动升为主节点？注意：15秒超时 主节点恢复后，主从关系会如何？主节点回来变成从机。 如果所有某一段插槽的主从节点都宕掉，redis服务是否还能继续? 如果某一段插槽的主从都挂掉，而cluster-require-full-coverage 为yes ，那么 ，整个集群都挂掉 如果某一段插槽的主从都挂掉，而cluster-require-full-coverage 为no ，那么，该插槽数据全都不能使用，也无法存储。 redis.conf中的参数 cluster-require-full-coverage 集群的Jedis开发 即使连接的不是主机，集群会自动切换主机存储。主机写，从机读。 无中心化主从集群。无论从哪台主机写的数据，其他主机上都能读到数据。 public class JedisClusterTest {public static void main(String[] args) {Setset =new HashSet();set.add(new HostAndPort(\"192.168.31.211\",6379));JedisCluster jedisCluster=new JedisCluster(set);jedisCluster.set(\"k1\", \"v1\");System.out.println(jedisCluster.get(\"k1\"));}} Redis 集群提供了以下好处 实现扩容 分摊压力 无中心配置相对简单 Redis 集群的不足 多键操作是不被支持的 多键的Redis事务是不被支持的。lua脚本不被支持 由于集群方案出现较晚，很多公司已经采用了其他的集群方案，而代理或者客户端分片的方案想要迁移至redis cluster，需要整体迁移而不是逐步过渡，复杂度较大。 16.Redis应用问题解决 16.1缓存穿透 问题描述 key对应的数据在数据源并不存在，每次针对此key的请求从缓存获取不到，请求都会压到数据源，从而可能压垮数据源。比如用一个不存在的用户id获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。 解决方案 一个一定不存在缓存及查询不到的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。 解决方案： 对空值缓存：如果一个查询返回的数据为空（不管是数据是否不存在），我们仍然把这个空结果（null）进行缓存，设置空结果的过期时间会很短，最长不超过五分钟 设置可访问的名单（白名单）： 使用bitmaps类型定义一个可以访问的名单，名单id作为bitmaps的偏移量，每次访问和bitmap里面的id进行比较，如果访问id不在bitmaps里面，进行拦截，不允许访问。 采用布隆过滤器：(布隆过滤器（Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量(位图)和一系列随机映射函数（哈希函数）。 布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。) 将所有可能存在的数据哈希到一个足够大的bitmaps中，一个一定不存在的数据会被 这个bitmaps拦截掉，从而避免了对底层存储系统的查询压力。 进行实时监控：当发现Redis的命中率开始急速降低，需要排查访问对象和访问的数据，和运维人员配合，可以设置黑名单限制服务 17.2缓存击穿 问题描述 key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。 解决方案 key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题。 解决问题： （1）预先设置热门数据：在redis高峰访问之前，把一些热门数据提前存入到redis里面，加大这些热门数据key的时长 （2）实时调整：现场监控哪些数据热门，实时调整key的过期时长 （3）使用锁： 就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db。 先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX）去set一个mutex key 当操作返回成功时，再进行load db的操作，并回设缓存,最后删除mutex key； 当操作返回失败，证明有线程在load db，当前线程睡眠一段时间再重试整个get缓存的方法。 17.3缓存雪崩 问题描述 key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。 缓存雪崩与缓存击穿的区别在于这里针对很多key缓存，前者则是某一个key 正常访问 缓存失效瞬间 解决方案 缓存失效时的雪崩效应对底层系统的冲击非常可怕！ 解决方案： 构建多级缓存架构：nginx缓存 + redis缓存 +其他缓存（ehcache等） 使用锁或队列： 用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。不适用高并发情况 设置过期标志更新缓存： 记录缓存数据是否过期（设置提前量），如果过期会触发通知另外的线程在后台去更新实际key的缓存。 将缓存失效时间分散开： 比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。 17.4分布式锁 问题描述 随着业务发展的需要，原单体单机部署的系统被演化成分布式集群系统后，由于分布式系统多线程、多进程并且分布在不同机器上，这将使原单机部署情况下的并发控制锁策略失效，单纯的Java API并不能提供分布式锁的能力。为了解决这个问题就需要一种跨JVM的互斥机制来控制共享资源的访问，这就是分布式锁要解决的问题！ 分布式锁主流的实现方案： 基于数据库实现分布式锁 基于缓存（Redis等） 基于Zookeeper 每一种分布式锁解决方案都有各自的优缺点： 性能：redis最高 可靠性：zookeeper最高 这里，我们就基于redis实现分布式锁。 解决方案：使用redis实现分布式锁 redis:命令 set sku:1:info “OK” NX PX 10000 EX second ：设置键的过期时间为 second 秒。 SET key value EX second 效果等同于 SETEX key second value 。 PX millisecond ：设置键的过期时间为 millisecond 毫秒。 SET key value PX millisecond 效果等同于 PSETEX key millisecond value 。 NX ：只在键不存在时，才对键进行设置操作。 SET key value NX 效果等同于 SETNX key value 。 XX ：只在键已经存在时，才对键进行设置操作。 多个客户端同时获取锁（setnx） 获取成功，执行业务逻辑{从db获取数据，放入缓存}，执行完成释放锁（del） 其他客户端等待重试 编写代码 Redis: set num 0 @GetMapping(\"testLock\")public void testLock(){//1获取锁，setneBoolean lock = redisTemplate.opsForValue().setIfAbsent(\"lock\", \"111\");//2获取锁成功、查询num的值if(lock){Object value = redisTemplate.opsForValue().get(\"num\");//2.1判断num为空returnif(StringUtils.isEmpty(value)){return;}//2.2有值就转成成intint num = Integer.parseInt(value+\"\");//2.3把redis的num加1redisTemplate.opsForValue().set(\"num\", ++num);//2.4释放锁，delredisTemplate.delete(\"lock\");}else{//3获取锁失败、每隔0.1秒再获取try {Thread.sleep(100);testLock();} catch (InterruptedException e) {e.printStackTrace();}}} 重启，服务集群，通过网关压力测试： ab -n 1000 -c 100 http://192.168.140.1:8080/test/testLock 查看redis中num的值： 基本实现。 问题：setnx刚好获取到锁，业务逻辑出现异常，导致锁无法释放 解决：设置过期时间，自动释放锁。 优化之设置锁的过期时间 设置过期时间有两种方式： 首先想到通过expire设置过期时间（缺乏原子性：如果在setnx和expire之间出现异常，锁也无法释放） 在set时指定过期时间（推荐） 设置过期时间： 压力测试肯定也没有问题。自行测试 问题：可能会释放其他服务器的锁。 场景：如果业务逻辑的执行时间是7s。执行流程如下 index1业务逻辑没执行完，3秒后锁被自动释放。 index2获取到锁，执行业务逻辑，3秒后锁被自动释放。 index3获取到锁，执行业务逻辑 index1业务逻辑执行完成，开始调用del释放锁，这时释放的是index3的锁，导致index3的业务只执行1s就被别人释放。 最终等于没锁的情况。 解决：setnx获取锁时，设置一个指定的唯一值（例如：uuid）；释放前获取这个值，判断是否自己的锁 优化之UUID防误删 问题：删除操作缺乏原子性。 场景： index1执行删除时，查询到的lock值确实和uuid相等 uuid=v1 set(lock,uuid)； index1执行删除前，lock刚好过期时间已到，被redis自动释放 在redis中没有了lock，没有了锁。 index2获取了lock index2线程获取到了cpu的资源，开始执行方法 uuid=v2 set(lock,uuid)； index1执行删除，此时会把index2的lock删除 index1 因为已经在方法中了，所以不需要重新上锁。index1有执行的权限。index1已经比较完成了，这个时候，开始执行 删除的index2的锁！ 优化之LUA脚本保证删除的原子性 @GetMapping(\"testLockLua\")public void testLockLua() {//1声明一个uuid ,将做为一个value放入我们的key所对应的值中String uuid = UUID.randomUUID().toString();//2定义一个锁：lua脚本可以使用同一把锁，来实现删除！String skuId = \"25\"; //访问skuId为25号的商品100008348542String locKey = \"lock:\" + skuId; //锁住的是每个商品的数据// 3获取锁Boolean lock = redisTemplate.opsForValue().setIfAbsent(locKey, uuid, 3, TimeUnit.SECONDS);//第一种：lock与过期时间中间不写任何的代码。// redisTemplate.expire(\"lock\",10, TimeUnit.SECONDS);//设置过期时间//如果trueif (lock) {//执行的业务逻辑开始//获取缓存中的num数据Object value = redisTemplate.opsForValue().get(\"num\");//如果是空直接返回if (StringUtils.isEmpty(value)) {return;}//不是空如果说在这出现了异常！那么delete就删除失败！也就是说锁永远存在！int num = Integer.parseInt(value + \"\");//使num每次+1放入缓存redisTemplate.opsForValue().set(\"num\", String.valueOf(++num));/使用lua脚本来锁///定义lua脚本String script = \"if redis.call('get', KEYS[1]) == ARGV[1] then returnredis.call('del', KEYS[1]) else return 0 end\";//使用redis执行lua执行DefaultRedisScript redisScript = new DefaultRedisScript<>();redisScript.setScriptText(script);//设置一下返回值类型为Long//因为删除判断的时候，返回的0,给其封装为数据类型。如果不封装那么默认返回String类型，//那么返回字符串与0会有发生错误。redisScript.setResultType(Long.class);//第一个要是script脚本，第二个需要判断的key，第三个就是key所对应的值。redisTemplate.execute(redisScript, Arrays.asList(locKey), uuid);} else {//其他线程等待try {//睡眠Thread.sleep(1000);//睡醒了之后，调用方法。testLockLua();} catch (InterruptedException e) {e.printStackTrace();}}} Lua 脚本详解： 项目中正确使用： 定义key，key应该是为每个sku定义的，也就是每个sku有一把锁。String locKey =\"lock:\"+skuId; //锁住的是每个商品的数据Boolean lock = redisTemplate.opsForValue().setIfAbsent(locKey, uuid,3,TimeUnit.SECONDS); 总结 1、加锁 // 1.从redis中获取锁,set k1 v1 px 20000 nxString uuid = UUID.randomUUID().toString();Boolean lock = this.redisTemplate.opsForValue().setIfAbsent(\"lock\", uuid, 2, TimeUnit.SECONDS); 使用lua释放锁 // 2.释放锁delString script = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\";//设置lua脚本返回的数据类型DefaultRedisScript redisScript = new DefaultRedisScript<>();//设置lua脚本返回类型为LongredisScript.setResultType(Long.class);redisScript.setScriptText(script);redisTemplate.execute(redisScript, Arrays.asList(\"lock\"),uuid); 重试 Thread.sleep(500);testLock(); 为了确保分布式锁可用，我们至少要确保锁的实现同时满足以下四个条件： 互斥性。在任意时刻，只有一个客户端能持有锁。 不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。 解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。 加锁和解锁必须具有原子性。 17.Redis6.0新功能 17.1ACL 简介 Redis ACL是Access Control List（访问控制列表）的缩写，该功能允许根据可以执行的命令和可以访问的键来限制某些连接。 在Redis 5版本之前，Redis 安全规则只有密码控制 还有通过rename 来调整高危命令比如 flushdb ， KEYS* ， shutdown 等。Redis 6 则提供ACL的功能对用户进行更细粒度的权限控制 ： （1）接入权限:用户名和密码 （2）可以执行的命令 （3）可以操作的 KEY 参考官网：https://redis.io/topics/acl 命令 1、使用acl list命令展现用户权限列表 （1）数据说明 2、使用acl cat命令 （1）查看添加权限指令类别 （2）加参数类型名可以查看类型下具体命令 3、使用acl whoami命令查看当前用户 4、使用aclsetuser命令创建和编辑用户ACL （1）ACL规则 下面是有效ACL规则的列表。某些规则只是用于激活或删除标志，或对用户ACL执行给定更改的单个单词。其他规则是字符前缀，它们与命令或类别名称、键模式等连接在一起。 ACL规则 类型 参数 说明 启动和禁用用户 on 激活某用户账号 off 禁用某用户账号。注意，已验证的连接仍然可以工作。如果默认用户被标记为off，则新连接将在未进行身份验证的情况下启动，并要求用户使用AUTH选项发送AUTH或HELLO，以便以某种方式进行身份验证。 权限的添加删除 + 将指令添加到用户可以调用的指令列表中 - 从用户可执行指令列表移除指令 +@ 添加该类别中用户要调用的所有指令，有效类别为@admin、@set、@sortedset…等，通过调用ACL CAT命令查看完整列表。特殊类别@all表示所有命令，包括当前存在于服务器中的命令，以及将来将通过模块加载的命令。 -@ 从用户可调用指令中移除类别 allcommands +@all的别名 nocommand -@all的别名 可操作键的添加或删除 ~ 添加可作为用户可操作的键的模式。例如~*允许所有的键 （2）通过命令创建新用户默认权限 acl setuser user1 在上面的示例中，我根本没有指定任何规则。如果用户不存在，这将使用just created的默认属性来创建用户。如果用户已经存在，则上面的命令将不执行任何操作。 （3）设置有用户名、密码、ACL权限、并启用的用户 acl setuser user2 on >password ~cached:* +get (4)切换用户，验证权限 17.2IO多线程 简介 Redis6终于支撑多线程了，告别单线程了吗？ IO多线程其实指客户端交互部分的网络IO交互处理模块多线程，而非执行命令多线程。Redis6执行命令依然是单线程。 原理架构 Redis 6 加入多线程,但跟 Memcached 这种从 IO处理到数据访问多线程的实现模式有些差异。Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。之所以这么设计是不想因为多线程而变得复杂，需要去控制 key、lua、事务，LPUSH/LPOP 等等的并发问题。整体的设计大体如下: 另外，多线程IO默认也是不开启的，需要再配置文件中配置 io-threads-do-reads yes io-threads 4 工具支持 Cluster 之前老版Redis想要搭集群需要单独安装ruby环境，Redis 5 将 redis-trib.rb 的功能集成到 redis-cli 。另外官方 redis-benchmark 工具开始支持 cluster 模式了，通过多线程的方式对多个分片进行压测。 Redis新功能持续关注 Redis6新功能还有： 1、RESP3新的 Redis 通信协议：优化服务端与客户端之间通信 2、Client side caching客户端缓存：基于 RESP3 协议实现的客户端缓存功能。为了进一步提升缓存的性能，将客户端经常访问的数据cache到客户端。减少TCP网络交互。 3、Proxy集群代理模式：Proxy 功能，让 Cluster 拥有像单实例一样的接入方式，降低大家使用cluster的门槛。不过需要注意的是代理不改变 Cluster 的功能限制，不支持的命令还是不会支持，比如跨 slot 的多Key操作。 4、Modules API Redis 6中模块API开发进展非常大，因为Redis Labs为了开发复杂的功能，从一开始就用上Redis模块。Redis可以变成一个框架，利用Modules来构建不同系统，而不需要从头开始写然后还要BSD许可。Redis一开始就是一个向编写各种系统开放的平台。 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-20 11:38:37 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/shardingsphere/":{"url":"distributed/shardingsphere/","title":"shardingsphere","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/elk/":{"url":"distributed/elk/","title":"elk","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/elk/shell.html":{"url":"distributed/elk/shell.html","title":"1.启停脚本","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 ! /bin/bash #! /bin/bash case $1 in \"start\"){ for i in hadoop101 hadoop102 hadoop103 do echo \" --------启动 $i Kafka-------\" # 用于KafkaManager监控 ssh $i \"export JMX_PORT=9988 && /usr/local/software/kafka_2.12-2.6.0/bin/kafka-server-start.sh -daemon /usr/local/software/kafka_2.12-2.6.0/config/server.properties \" done };; \"stop\"){ for i in hadoop101 hadoop102 hadoop103 do echo \" --------停止 $i Kafka-------\" ssh $i \"/usr/local/software/kafka_2.12-2.6.0/bin/kafka-server-stop.sh stop\" done };; esac Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:36:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/elk/elk.html":{"url":"distributed/elk/elk.html","title":"2.分布式之ELK","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.Elasticsearch 1.1配置文件elasticsearch.yml 1.2启动 1.3访问 2.Logstash 2.1创建配置文件logstash.conf 2.2启动 3.Kibana 3.1配置kibana.yml 3.2启动 3.3访问 1.Elasticsearch 1.1配置文件elasticsearch.yml (如果是单机测试可以不用配置直接默认启动就可以了) 配置集群名称，保证每个节点的名称相同，如此就能都处于一个集群之内了 cluster.name: elasticsearch-cluster # 每一个节点的名称，必须不一样 node.name: es-node1 # http端口（使用默认即可） http.port: 9200 # 主节点，作用主要是用于来管理整个集群，负责创建或删除索引，管理其他非master节点（相当于企业老总） node.master: true # 数据节点，用于对文档数据的增删改查 node.data: true # 集群列表 discovery.seed_hosts: [\"192.168.0.100\", \"192.168.0.101\", \"192.168.0.102\"] # 启动的时候使用一个master节点 cluster.initial_master_nodes: [\"es-node1\"] 1.2启动 ./bin/elasticSearch –d 启动。-d表示后台启动 1.3访问 127.0.0.1:9200 2.Logstash 2.1创建配置文件logstash.conf input { file { type => \"log\" path => [\"/export/home/tomcat/domains/*/*/logs/*.out\"] start_position => \"end\" ignore_older => 0 codec=> multiline { //配置log换行问题 pattern => \"^%{TIMESTAMP_ISO8601}\" negate => true what => \"previous\" } } beats { port => 5044 } } output { if [type] == \"log\" { elasticsearch { hosts => [\"http://127.0.0.1:9200\"] index => \"log-%{+YYYY.MM}\" } } } 2.2启动 ./logstash -f ../config/logstash.conf 后台启动：nohup ./bin/logstash -f config/log.conf > log.log & 配置多个文件：./logstash -f ../config 指定启动目录，然后启动目录下配置多个*.conf文件。里面指定不同的logpath。 3.Kibana 3.1配置kibana.yml elasticsearch.url: http://localhost:9200 server.host: 0.0.0.0 3.2启动 启动命令：./kibana 后台启动：nohup ./bin/kibana & 3.3访问 http://localhost:5601 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:55:52 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"micro/":{"url":"micro/","title":"六、微服务框架专题","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"micro/fast.html":{"url":"micro/fast.html","title":"1.快速开始","keywords":"","body":"第一节:springboot快速开始(对三篇) 一:springboot微服务开发利器 1.1)什么是微服务，微服务和微服务架构的区别? 目前而已，对于微服务业界没有一个统一的标准定义,但是通常而言提倡把一个单一的应用程序划分为一组小 的服务， 每个小的服务都会运行在自己的进程中，服务之间通过轻量级的通信机制（http的rest api）进行通信,那么一个个的 小服务就是微服务。 ①：单体架构与微服务架构图示 传统的的单一电商应用来说，订单，支付，用户，商品，库存等模块都在一个项目中，若某一个模块出现线上bug，会导致整个版本发布回退. 若把单一应用拆分为一个一微服务，比如订单微服务，用户微服务，商品微服务，积分微服务等，若某一个微服务出错不会导致整个版本回退。 1.2）什么是微服务架构 微服务架构是一种架构模式（用于服务管理微服务的），它把一组小的服务互相协调、互相配合，并且完成功能。每个服务运行在其独立的进程中，服务与服务间采用轻量级的通信机制互相协作（通常是基于HTTP协议的RESTfulAPI）。每个服务都围绕着具体业务进行构建，并且能够被独立的部署到生产环境、类生产环境等。另外，应当尽量避免统一的、集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的语言、工具对其进行构建。 1.3微服务的优缺点: 优点: ①:优点每个服务足够内聚，足够小，代码容易理解这样能聚焦一个指定的业务功能或业务需求(职责单 一) ②:开发简单、开发效率提高，一个服务可能就是专一的只干一件事,微服务能够被小团队单独开发，这个小团队是2到5人的开发人员组成。 ③:微服务能使用不同的语言开发。 ④:易于和第三方集成，微服务允许容易且灵活的方式集成自动部署，通过持续集成工具，如Jenkins,Hudson,bamboo。 ⑤:微服务只是业务逻辑的代码，不会和HTML,CSS或其他界面组件混合。 ⑥:每个微服务都有自己的存储能力，可以有自己的数据库。也可以有统一数据库。 ......................................... ......................................... 缺点: 开发人员要处理分布式系统的复杂性(分布式事物) 多服务运维难度，随着服务的增加，运维的压力也在增大 系统部署依赖 服务间通信成本 数据一致性 ................................................. ................................................. 二:springboot快速开始 2.1)(基于mavne版本构建) 2.1)先把maven的配置文件设置为如下配置 jdk‐1.8 true 1.8 1.8 1.8 1.8 2.1)配置IDE的环境（maven配置） 2.2)创建一个空的maven工程，然后导入springboot相关的jar包 //父工程依赖 org.springframework.boot spring-boot-starter-parent 2.0.8.RELEASE spring mvc-web的依赖 org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-maven-plugin ①：编写主入口程序 /** * Created by smlz on 2019/3/18. */ @SpringBootApplication public class TulingStartMain { public static void main(String[] args) { SpringApplication.run(TulingStartMain.class,args); } } ②:其他业务组件 比如controller service repository compent注解标示的组件 **********自己写的组件必须放在主启动类(TulingStartMain)在所包的及其子包下????????将源码分析时候探究原理 /** * Created by smlz on 2019/3/18. */ @RestController public class TulingController { @RequestMapping(\"/tuling\") public String tulingHelloWorld() { return \"tuling,hello\"; } } ③:运行main函数启动程序，访问[http://localhost:8080/](http://localhost:8080/hello?fileGuid=DnEDhh3KIyMoGVBP)tuling，或者执行mvn package将项目打成jar包，用java -jar XXX.jar直接运行 ![图片](https://uploader.shimo.im/f/3PZXinbItnJHhIr7.jpeg!thumbnail?fileGuid=DnEDhh3KIyMoGVBP) 2.3)通过sts/idea创建 一个springboot项目 ![图片](https://uploader.shimo.im/f/4r85ihaUCMXt4W3C.png!thumbnail?fileGuid=DnEDhh3KIyMoGVBP) 编写自己的业务代码就maven构建springboot工程版本的一样 这里就不做累赘讲诉. 三:helloworld的探究，为啥我只要引入spring-boot-starter-parent和spring-boot-starter-web就可以快速开发mvc的项目 3.1）pom分析 org.springframework.boot spring-boot-starter-parent 2.0.8.RELEASE 真正的版本管理仲裁中心来决定应用的版本 org.springframework.boot spring-boot-dependencies 2.0.8.RELEASE ../../spring-boot-dependencies 以后我们导入依赖默认是不需要写版本；（没有在dependencies里面管理的依赖自然需要声明版本号） 3.2)我们来分析看下spring-boot-starter-web（场景启动器）为我项目中导入web开发需要的jar包依赖 4)多profile切换 我们在开发应用时，通常一个项目会被部署到不同的环境中，比如：开发、测试、生产等。其中每个环境的数据库地址、服务器端口等等配置都会不同，对于多环境的配置，大部分构建工具或是框架解决的基本思路是一致的，通过配置多份不同环境的配置文件，再通过打包命令指定需要打包的内容之后进行区分打包 4.1)yml支持多模块文档块 server: port: 8081 servlet: context-path: /tuling01 spring: profiles: active: dev 开发环境配置 spring: profiles: dev server: port: 8082 生产环境配置 spring: profiles: prod server: port: 8083 从上图看出，我们激活的配置是开发环境的配置,但是现在 我们还看到了servlet:context-path的配置形成互补配置 4.2)多yml|properties文件的环境切换 application.yml (用于激活不同环境的配置文件) spring: profiles: active: dev application-dev.yml server: port: 8081 servlet: context-path: /tl_dev application-prod.yml server: port: 8082 servlet: context-path: /tl_prod 4.3)激活指定环境配置的方法 ①:直接在application.yml的配置文件中使用spring.profiles.active=dev|prod|test ②:设置虚拟机参数-Dspring.profiles.active=dev|prod|test ③:命令行参数启动(打成Jar包时候) java -jar tuling-vip-springboot-02-0.0.1-SNAPSHOT.jar -- spring.profiles.active=prod 4.4)设置jvm参数 然后我们看是否设置成功 java -Xms128m -Xmx128m -jar tuling-vip-springboot-02-0.0.1-SNAPSHOT.jar -- server.port=8888 第一步:在cmd窗口中使用jps来看我们主进程的 第二步:使用jinfo命令+进程号来查看具体信息 4.5) springboot关于打包问题总结 4.5.1):打成指定的jar名称的 指定打包的文件名称 tulingVipSpringboot org.springframework.boot spring-boot-maven-plugin 4.5.2)若出现工程中出现多个mainclass的时候需要指定主启动类 tulingVipSpringboot org.springframework.boot spring-boot-maven-plugin com.tuling.TulingVipSpringboot02Application repackage 4.5.3）如何打出一个war包 第一步:指定springboot pom中的打包方式 由jar改为war 第二步:在spring-boot-starter-web模块打包比依赖与tomcat 第三步:主启动类上 实现SpringBootServletInitializer从写confiure方法(原理第三节课节讲) @SpringBootApplication public class TulingVipSpringboot03Application extends SpringBootServletInitializer { public static void main(String[] args) { SpringApplication.run(TulingVipSpringboot03Application.class, args); } @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) { return application.sources(TulingVipSpringboot03Application.class); } } 第四步:打成war包 放在tomcat上运行. 6)springboot的web开发（） 6.1）什么是webJar：以jar包的形式来引入前端资源,比如jquery或者是BootStrap https://www.webjars.org/ 6.1.1）引入对应的jar包 org.webjars jquery 3.3.1-2 6.1.2)映射规则/webjars/**都会被映射到classpath:/META-INF/resources/webjars/目录下去处理 6.1.3)前端资源映射规则 核心源代码: public void addResourceHandlers(ResourceHandlerRegistry registry) { if(!this.resourceProperties.isAddMappings()) { logger.debug(\"Default resource handling disabled\"); } else { Duration cachePeriod = this.resourceProperties.getCache().getPeriod(); CacheControl cacheControl = this.resourceProperties.getCache().getCachecontrol().toHttpCacheControl(); //处理映射webjar的请求的 if(!registry.hasMappingForPattern(\"/webjars/**\")) { this.customizeResourceHandlerRegistration(registry.addResourceHandler(new String[]{\"/webjars/**\"}).addRes } //处理静态资源文件的 String staticPathPattern = this.mvcProperties.getStaticPathPattern(); if(!registry.hasMappingForPattern(staticPathPattern)) { this.customizeResourceHandlerRegistration(registry.addResourceHandler(new String[]{staticPathPattern}).add } } } 6.1.4）http://localhost:8080/webjars/jquery/3.3.1-2/jquery.js 请求如何拦截处理请求的 ①根据日志打印，我们发现如下突破口 ②:第二步: org.springframework.web.servlet.resource.ResourceHttpRequestHandler#handleRequest方法 org.springframework.web.servlet.resource.ResourceHttpRequestHandler#getResource org.springframework.web.servlet.resource.ResourceResolverChain#resolveResource org.springframework.web.servlet.resource.PathResourceResolver#resolveResourceInternal org.springframework.web.servlet.resource.PathResourceResolver#getResource(真正的资源映射 处理逻辑) private Resource getResource(String resourcePath, @Nullable HttpServletRequest request, List locations) { for (Resource location : locations) { try { if (logger.isTraceEnabled()) { logger.trace(\"Checking location: \" + location); } String pathToUse = encodeIfNecessary(resourcePath, request, location); //真正的处理逻辑把jquery/3.3.1-2/jquery.js映射到 Resource resource = getResource(pathToUse, location); if (resource != null) { if (logger.isTraceEnabled()) { logger.trace(\"Found match: \" + resource); } return resource; } else if (logger.isTraceEnabled()) { logger.trace(\"No match for location: \" + location); } } catch (IOException ex) { logger.trace(\"Failure checking for relative resource - trying next location\", ex); } } return null; } 6.1.5)访问静态html页面 我们直接把静态页面放在static的目录下，直接可以在路径直接访问 6.1.6)映射原理/**请求都会被映射到 private static final String[] CLASSPATH_RESOURCE_LOCATIONS = { \"classpath:/META-INF/resources/\", \"classpath:/resources/\", \"classpath:/static/\", \"classpath:/public/\" }; public void addResourceHandlers(ResourceHandlerRegistry registry) { ..... ...... ...... String staticPathPattern = this.mvcProperties.getStaticPathPattern(); if (!registry.hasMappingForPattern(staticPathPattern)) { customizeResourceHandlerRegistration( registry.addResourceHandler(staticPathPattern) .addResourceLocations(getResourceLocations( this.resourceProperties.getStaticLocations())) .setCachePeriod(getSeconds(cachePeriod)) .setCacheControl(cacheControl)); } } 6.1.7)欢迎页； 静态资源文件夹下的所有index.html页面；被\"/**\"映射； 6.1.8)使用webjar的方式修前端页面修改引用路径 6.2)springboot是如何整合springmvc功能的（WebMvcAutoConfiguration） 6.2.1）自动装配的组件 ①:ContentNegotiatingViewResolver和BeanNameViewResolver视图解析器 视图解析器的作用:根据方法的值找到对应的视图 ②:Support for serving static resources, including support for WebJars支持静态资源和webJars ③:Converter ,日期格式化器Formatter ④:消息装换器:HttpMessageConverters ⑤:首页设置index.html ⑥:图标支持Favicon 6.2.2)如何扩展springmvc的配置（springboot提我们自己配置的springmvc的功能不丢失的情况下） 比如我需要使用自己定义的拦截器 我们需要自己写一个配置类 继承WebMvcConfigurerAdapter需要什么组件 就注册什么组件 A:如何往容器中添加一个拦截器 第一步:创建一个拦截器 @Component public class TulingInterceptor implements HandlerInterceptor { public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)throws Exception System.out.println(\"我是TulingInterceptor的preHandle方法\"); return true; } public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler,@Nullable ModelAn System.out.println(\"我是TulingInterceptor的postHandle方法\"); } public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler,@Nullable Exce System.out.println(\"我是TulingInterceptor的afterCompletion方法\"); } } 第二步:注册拦截器 @Configuration public class TulingConfig extends WebMvcConfigurerAdapter { @Autowired private TulingInterceptor tulingInterceptor; /** 注册拦截器 @param registry */ public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(tulingInterceptor).addPathPatterns(\"/**\").excludePathPatterns(\"/index.html\",\"/\"); } } B:往容器中增加一个过滤器 public class TulingFilter implements Filter { @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOE System.out.println(\"TulingFilter的doFilter方法\"); filterChain.doFilter(servletRequest,servletResponse); } @Override public void destroy() { } } /** 注册一个filter @return */ @Bean public FilterRegistrationBean tulingFilter(){ FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(); filterRegistrationBean.setFilter(new TulingFilter()); filterRegistrationBean.addUrlPatterns(\"/*\"); return filterRegistrationBean; } C:往容器中增加一个servlet public class TulingServlet extends HttpServlet { protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { resp.getWriter().write(\"hello......\"); } protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { doPost(req,resp); } } public class TulingServlet extends HttpServlet { protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { resp.getWriter().write(\"hello......\"); } protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { doPost(req,resp); } } 7）如何全面接管springboot的mvc配置(让springboot给我们自动配置的功能失效,自己像如何整合ssm一样的整合springmvc,不推荐) 官网原话: If you want to keep Spring Boot MVC features and you want to add additional MVCconfiguration (interceptors, formatters, view controllers, and other features), you canadd your own@Configurationclass of typeWebMvcConfigurerbut without@EnableWebMvc. If you wish to provide custom instances ofRequestMappingHandlerMapping,RequestMappingHandlerAdapter, orExceptionHandlerExceptionResolver, you can declare aWebMvcRegistrationsAdapterinstance to provide such components. 大概意思说，在配置文件中使用一个@EnableWebMvc来标识到配置类上,就会导致配置失效why?为什么会失 效????????????????? 原理: @EnableWebMvc为容器中导入了DelegatingWebMvcConfiguration的组件 @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) @Documented @Import(DelegatingWebMvcConfiguration.class) public @interface EnableWebMvc { } 1)我们来分析一下DelegatingWebMvcConfiguration是一个什么东西？？？？？ 我们发现DelegatingWebMvcConfiguration是WebMvcConfiurationSupport（只保证了springmvc的基本功能）类型的 @Configuration public class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport 2)我们来看下WebMvcAutoConfiguration上的注解 @Configuration @ConditionalOnWebApplication(type = Type.SERVLET) @ConditionalOnClass({ Servlet.class, DispatcherServlet.class, WebMvcConfigurer.class }) //容器中没有WebMvcConfigurationSupport该配置文件才生生效,但是我们使用了@EnableWebMvc导入了WebMvcConfiuratio //只保存了springmvc的最基本的功能 @ConditionalOnMissingBean(WebMvcConfigurationSupport.class) @AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10) @AutoConfigureAfter({ DispatcherServletAutoConfiguration.class, ValidationAutoConfiguration.class }) public class WebMvcAutoConfiguration 3)我们的webJar欢迎页 等全部失效 8)springboot错误处理机制?如何定制错误页面？ 案例:浏览器模拟发送的错误请求http://localhost:8080/aaaaaaaaaaaaaa 案例2:通过postman或者restlet发送的请求http://localhost:8080/testTuling/dddd 我们可以看出 不同的终端发送的请求 会返回不同的错误异常类容是根据什么原理？ 原理:是根据不同客户端发送的请求的请求头来区分是 返回页面还是json数据 8.1）我们来看springboot为我们自动配置的异常处理的一些bean org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration @Bean @ConditionalOnMissingBean(value = ErrorAttributes.class, search = SearchStrategy.CURRENT) public DefaultErrorAttributes errorAttributes() { return new DefaultErrorAttributes( this.serverProperties.getError().isIncludeException()); } @Bean @ConditionalOnMissingBean(value = ErrorController.class, search = SearchStrategy.CURRENT) public BasicErrorController basicErrorController(ErrorAttributes errorAttributes) { return new BasicErrorController(errorAttributes, this.serverProperties.getError(), this.errorViewResolvers); } @Bean public ErrorPageCustomizer errorPageCustomizer() { return new ErrorPageCustomizer(this.serverProperties, this.dispatcherServletPath); } @Bean @ConditionalOnBean(DispatcherServlet.class) @ConditionalOnMissingBean public DefaultErrorViewResolver conventionErrorViewResolver() { return new DefaultErrorViewResolver(this.applicationContext, this.resourceProperties); } @Configuration @ConditionalOnProperty(prefix = \"server.error.whitelabel\", name = \"enabled\", matchIfMissing = true) @Conditional(ErrorTemplateMissingCondition.class) protected static class WhitelabelErrorViewConfiguration { private final SpelView defaultErrorView = new SpelView( \"Whitelabel Error Page\" \"This application has no explicit mapping for /error, so you are seeing this as a fall \"${timestamp}\" \"There was an unexpected error (type=${error}, status=${status}).\" \"${message}\"); @Bean(name = \"error\") @ConditionalOnMissingBean(name = \"error\") public View defaultErrorView() { return this.defaultErrorView; } 我们具体来分析上诉源代码的组件 A: org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration.ErrorPageCustomizer（错误页面定制器） 作用：系统出现错误以后来到/error请求进行处理； /** Path of the error controller. */ @Value(\"${error.path:/error}\") private String path = \"/error\"; 那么当我们 发生错误，需要/error的请求映射来请求 接下来就会引出另外一个组件 来处理/error请求 B：org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController（基础错误控制器） @Controller @RequestMapping(\"${server.error.path:${error.path:/error}}\") public class BasicErrorController extends AbstractErrorController { //处理浏览器页面异常 @RequestMapping(produces = \"text/html\") public ModelAndView errorHtml(HttpServletRequest request, HttpServletResponse response) { HttpStatus status = getStatus(request); Map model = Collections.unmodifiableMap(getErrorAttributes( request, isIncludeStackTrace(request, MediaType.TEXT_HTML))); response.setStatus(status.value()); ModelAndView modelAndView = resolveErrorView(request, response, status, model); return (modelAndView != null) ? modelAndView : new ModelAndView(\"error\", model); } //处理postman请求的Json数据异常错误 @RequestMapping @ResponseBody public ResponseEntity> error(HttpServletRequest request) { Map body = getErrorAttributes(request, isIncludeStackTrace(request, MediaType.ALL)); HttpStatus status = getStatus(request); return new ResponseEntity<>(body, status); } } B1:我们来看下浏览器的响应过程怎么来处理请求异常信息的？ public ModelAndView errorHtml(HttpServletRequest request, HttpServletResponse response) { //获取状态码 HttpStatus status = getStatus(request); //获取页面的模型数据 Map model = Collections.unmodifiableMap(getErrorAttributes( request, isIncludeStackTrace(request, MediaType.TEXT_HTML))); response.setStatus(status.value()); //解析错误视图 ModelAndView modelAndView = resolveErrorView(request, response, status, model); return (modelAndView != null) ? modelAndView : new ModelAndView(\"error\", model); } protected ModelAndView resolveErrorView(HttpServletRequest request, HttpServletResponse response, HttpStatus status, Map model) { //获取容器中的所有错误视图解析器DefaultErrorViewResolver for (ErrorViewResolver resolver : this.errorViewResolvers) { ModelAndView modelAndView = resolver.resolveErrorView(request, status, model); if (modelAndView != null) { return modelAndView; } } return null; } B2:我们接着分析 org.springframework.boot.autoconfigure.web.servlet.error.DefaultErrorViewResolver#DefaultErrorViewResolver 错误视图解析器 @Override public ModelAndView resolveErrorView(HttpServletRequest request, HttpStatus status, Map model) { //解析视图 ModelAndView modelAndView = resolve(String.valueOf(status), model); //没有对应的解析精确匹配的状态码 使用模糊匹配比如4XX 5XX if (modelAndView == null && SERIES_VIEWS.containsKey(status.series())) { //返回4XX 5XX的页面 modelAndView = resolve(SERIES_VIEWS.get(status.series()), model); } return modelAndView; } private ModelAndView resolve(String viewName, Map model) { error/404 String errorViewName = \"error/\" + viewName; //视图是否有模版引擎解析 TemplateAvailabilityProvider provider = this.templateAvailabilityProviders .getProvider(errorViewName, this.applicationContext); //有模版引擎解析直接返回 if (provider != null) { return new ModelAndView(errorViewName, model); } //静态html的页面解析 return resolveResource(errorViewName, model); } private ModelAndView resolveResource(String viewName, Map model) { for (String location : this.resourceProperties.getStaticLocations()) { try { //在static模版下需要创建一个error/404.html Resource resource = this.applicationContext.getResource(location); resource = resource.createRelative(viewName + \".html\"); //存在该页面直接返回 if (resource.exists()) { return new ModelAndView(new HtmlResourceView(resource), model); } } catch (Exception ex) { } } return null; } 浏览器模拟发送异常请求的流程视图解析过程 org.springframework.boot.autoconfigure.web.servlet.error.AbstractErrorController#resolveErrorView 开始解析视图，获取所有的异常错误视图解析器 org.springframework.boot.autoconfigure.web.servlet.error.DefaultErrorViewResolver#resolveErrorView默认错误视图解析器解析视图 org.springframework.boot.autoconfigure.web.servlet.error.DefaultErrorViewResolver#resolve响应码精准匹配视图 1)判断模版引擎是否能够处理错误视图,能处理就处理，不能处理交给静态页面解析处理 org.springframework.boot.autoconfigure.web.servlet.error.DefaultErrorViewResolver#resolveResour html资源视图 若不能精准匹配，那么就进行4XX 5XX模糊匹配 若不能精准匹配(error/状态码.html)的错误页面，也没有（error/状态码开头xx.html错误页面那就使用默认的错误空白页面） private final SpelView defaultErrorView = new SpelView( \"Whitelabel Error Page\" \"This application has no explicit mapping for /error, so you are seeing this as a fall \"${timestamp}\" \"There was an unexpected error (type=${error}, status=${status}).\" \"${message}\"); @Bean(name = \"error\") @ConditionalOnMissingBean(name = \"error\") public View defaultErrorView() { return this.defaultErrorView; } 我们怎么包含一个自己的错误异常信息的 自适应的效果 浏览器效果:(需要返回自己定义的错误页面 包含了自定义的错误异常信息) 其他客户端的效果: 第一步:我们定义一个全局异常处理器，然后返回看执行效果 @ControllerAdvice public class TulingExceptionHanlder { /** 浏览器和其他客户端都返回了json数组，不满足自适应 @param e @param request @return */ @ExceptionHandler(value= TulingException.class) @ResponseBody public Map dealException(TulingException e, HttpServletRequest request){ Map retInfo = new HashMap<>(); retInfo.put(\"code\",e.getCode()); retInfo.put(\"msg\",e.getMsg()); return retInfo; } } 效果:浏览器不满足 自适应效果返回的是一个json字符串,而不是一个页面 其他客户端满足要求，返回自己定义的错误异常信息 第二步:在异常处理器中 进行重定向 根据第一步的效果来看 浏览器不能满足自适应效果,那么我们看下BasicErrorController的类 @Controller @RequestMapping(\"${server.error.path:${error.path:/error}}\") public class BasicErrorController extends AbstractErrorController 他处理的请求是/error的请求，那么我们就想到 在全局异常处理器进行重定向 @ControllerAdvice public class TulingExceptionHanlder { @ExceptionHandler(value= TulingException.class) public String dealException(TulingException e, HttpServletRequest request){ Map retInfo = new HashMap<>(); retInfo.put(\"code\",e.getCode()); retInfo.put(\"msg\",e.getMsg()); //重定向，把请求转发到BasicErrorController来处理/error return \"forward:/error\"; } 执行效果: 分析过程 ①:根据上述执行效果我们发现 进行转发后 他的http状态码变为200那么错误异常处理就不能进行正常流程的处理 ②:那么我们需要分析错误异常处理器看下是如何获取异常状态码的. org.springframework.boot.autoconfigure.web.servlet.error.AbstractErrorController#getStatus 很明显，BasicErrorController的getStatus的过程中，都是从request中获取javax.servlet.error.status_code属性 protected HttpStatus getStatus(HttpServletRequest request) { Integer statusCode = (Integer) request .getAttribute(\"javax.servlet.error.status_code\"); if (statusCode == null) { return HttpStatus.INTERNAL_SERVER_ERROR; } try { return HttpStatus.valueOf(statusCode); } catch (Exception ex) { return HttpStatus.INTERNAL_SERVER_ERROR; } } 那么我们需要在我们的全局异常处理器中request中设置该属性 页面返回的属性字段是在哪里配置的？？？ 那我们来着重分析一下 org.springframework.boot.web.servlet.error.DefaultErrorAttributes#getErrorAttributes 疑问:我们来看下这个类的自动装配原理,发现容器中有ErrorAttributes主键，那么就不进行自动装配,我们可以来自己写一个类来继承他 @Component public class TulingErrorAttribute extends DefaultErrorAttributes { public Map getErrorAttributes(WebRequest webRequest, boolean includeStackTrace) { //获取父类的封装字段结果 Map retInfo = super.getErrorAttributes(webRequest,includeStackTrace); //获取全局异常自定义的结果 Map ext = (Map) webRequest.getAttribute(\"ext\",0); //封装自定义的错误信息 retInfo.put(\"company\",\"tuling\"); retInfo.put(\"ext\",ext); return retInfo; } } Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-20 10:32:49 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"micro/tomcat.html":{"url":"micro/tomcat.html","title":"2.Springboot启动Tomcat热身","keywords":"","body":"Springboot启动Tomcat热身 不得不说的后置处理器org.springframework.beans.factory.config.BeanPostProcessor 调用时机:在每个Bean调用构造方法之后，初始化前后进行工作 public interface BeanPostProcessor { default Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { } default Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { return bean; } ｝ 关键触发时机: org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#doCreateBean org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#initializeBean org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#applyBeanPostProcessorsBeforeIni org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#invokeInitMethods org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#applyBeanPostProcessorsAfterIniti 那我们就来大致看下applyBeanPostProcessorsBeforeInitialization方法 调用所有后置处理器的postProcessAfterInitialization方法对当前bean进行拦截 public Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws BeansException { Object result = existingBean; for (BeanPostProcessor processor : getBeanPostProcessors()) { Object current = processor.postProcessAfterInitialization(result, beanName); if (current == null) { return result; } result = current; } return result; } invokeInitMethods方法 boolean isInitializingBean = (bean instanceof InitializingBean); if (isInitializingBean && (mbd == null || !mbd.isExternallyManagedInitMethod(\"afterPropertiesSet\"))) { if (logger.isDebugEnabled()) { logger.debug(\"Invoking afterPropertiesSet() on bean with name '\" + beanName + \"'\"); } if (System.getSecurityManager() != null) { try { AccessController.doPrivileged((PrivilegedExceptionAction) () -> { ((InitializingBean) bean).afterPropertiesSet(); return null; }, getAccessControlContext()); } catch (PrivilegedActionException pae) { throw pae.getException(); } } //调用InitializingBean的afterPropertiesSet方法 else { ((InitializingBean) bean).afterPropertiesSet(); } } //调用自定义的init方法 if (mbd != null && bean.getClass() != NullBean.class) { String initMethodName = mbd.getInitMethodName(); if (StringUtils.hasLength(initMethodName) && !(isInitializingBean && \"afterPropertiesSet\".equals(initMethodName)) && !mbd.isExternallyManagedInitMethod(initMethodName)) { invokeCustomInitMethod(beanName, bean, mbd); } } 然后再看下:applyBeanPostProcessorsAfterInitialization //调用所有后置处理器的postProcessAfterInitialization方法 public Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws BeansException { Object result = existingBean; for (BeanPostProcessor processor : getBeanPostProcessors()) { Object current = processor.postProcessAfterInitialization(result, beanName); if (current == null) { return result; } result = current; } return result; } BeanPostProcessor是什么时候注册到容器中去的? org.springframework.context.support.AbstractApplicationContext#registerBeanPostProcessors org.springframework.context.support.PostProcessorRegistrationDelegate#registerBeanPostProcessors public static void registerBeanPostProcessors( ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) { //找到所有的后置处理器的名称 String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false); Register BeanPostProcessorChecker that logs an info message when a bean is created during BeanPostProcessor instantiation, i.e. when a bean is not eligible for getting processed by all BeanPostProcessors. int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount)) Separate between BeanPostProcessors that implement PriorityOrdered, Ordered, and the rest. List priorityOrderedPostProcessors = new ArrayList<>(); List internalPostProcessors = new ArrayList<>(); List orderedPostProcessorNames = new ArrayList<>(); List nonOrderedPostProcessorNames = new ArrayList<>(); //把后置处理器区分开来(出分包括创建bean对象) for (String ppName : postProcessorNames) { if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) { BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); priorityOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) { internalPostProcessors.add(pp); } } else if (beanFactory.isTypeMatch(ppName, Ordered.class)) { orderedPostProcessorNames.add(ppName); } else { nonOrderedPostProcessorNames.add(ppName); } } //按照上面区分的后置处理器来进行注册(加入到容器中) //注册实现PriorityOrderd接口的 sortPostProcessors(priorityOrderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors); //注册实现Ordered接口的 List orderedPostProcessors = new ArrayList<>(); for (String ppName : orderedPostProcessorNames) { BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); orderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) { internalPostProcessors.add(pp); } } sortPostProcessors(orderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, orderedPostProcessors); // Now, register all regular BeanPostProcessors. List nonOrderedPostProcessors = new ArrayList<>(); for (String ppName : nonOrderedPostProcessorNames) { BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); nonOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) { internalPostProcessors.add(pp); } } registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors); re-register all internal BeanPostProcessors. sortPostProcessors(internalPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, internalPostProcessors); Re-register post-processor for detecting inner beans as ApplicationListeners, moving it to the end of the processor chain (for picking up proxies etc). beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext)); } SpringBoot依靠 自动装配 来如何装配Tomcat的 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-20 10:32:49 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"micro/springboot-auto.html":{"url":"micro/springboot-auto.html","title":"3.springboot自动装配原理","keywords":"","body":"springboot自动装配原理详解 1)传统ssm整合redis的时候 需要在xml的配置文件中 进行大量的配置Bean 我们在这里使用springboot来代替ssm的整合，只是通过xml的形式来整合redis 第一步:加入配置 org.springframework.data spring-data-redis 2.0.9.RELEASE redis.clients jedis 2.9.0 第二步:配置xml的bean的配置 //配置连接池 //配置连接工厂 //配置redisTemplate模版类 第三步:导入配置 @ImportResource(locations = \"classpath:beans.xml\")可以导入xml的配置文件 @SpringBootApplication @ImportResource(locations = \"classpath:beans.xml\") @RestController public class TulingOpenAutoconfigPrincipleApplication { @Autowired private RedisTemplate redisTemplate; public static void main(String[] args) { SpringApplication.run(TulingOpenAutoconfigPrincipleApplication.class, args); } @RequestMapping(\"/testRedis\") public String testRedis() { redisTemplate.opsForValue().set(\"smlz\",\"smlz\"); return \"OK\"; } } 2)综上所述 我们发现，若整合redis的时候通过传统的整合，进行了大量的配置,那么我们来看下通过springboot自动装配整合的对比 导入依赖: org.springframework.boot spring-boot-starter-data-redis 修改yml配置文件 spring.redis.host=47.104.128.12 spring.redis.port=6379 spring.redis.password=123456 直接使用(下述代码可以不要配置，为了解决保存使用jdk的序列方式才配置的) @Bean public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory) { RedisTemplate template = new RedisTemplate<>(); template.setDefaultSerializer(new Jackson2JsonRedisSerializer(Object.class)); template.setConnectionFactory(redisConnectionFactory); return template; } 3）传统整合和springboot自动装配 优劣势分析。。。。。。。。。。。。 4）自动装配原理前的不得不说的几个注解 4.1)通过@Import注解来导入ImportSelector组件 ①:写一个配置类在配置类上标注一个@Import的注解， @Configuration @Import(value = {TulingSelector.class}) public class TulingConfig { } ②：在@Import注解的value值 写自己需要导入的组件 在selectImports方法中 就是你需要导入组件的全类名 public class TulingSelector implements ImportSelector { @Override public String[] selectImports(AnnotationMetadata annotationMetadata) { return new String[]{\"com.tuling.service.TulingServiceImpl\"}; } } 核心代码: @RestController public class TulingController { //自动注入tulingServiceImpl @Autowired private TulingServiceImpl tulingServiceImpl; @RequestMapping(\"testTuling\") public String testTuling() { tulingServiceImpl.testService(); return \"tulingOk\"; } } 这里是没有标注其他注解提供给spring包扫描的 public class TulingServiceImpl { public void testService() { System.out.println(\"我是通过importSelector导入进来的service\"); } } 1.2）通过@Import导入ImportBeanDefinitionRegistrar从而进来导入组件 核心代码: public class TulingImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar { @Override public void registerBeanDefinitions(AnnotationMetadata annotationMetadata, BeanDefinitionRegistry beanDefinitionReg //定义一个BeanDefinition RootBeanDefinition rootBeanDefinition = new RootBeanDefinition(TulingDao.class); //把自定义的bean定义导入到容器中 beanDefinitionRegistry.registerBeanDefinition(\"tulingDao\",rootBeanDefinition); } } 通过ImportSelector功能导入进来的 public class TulingServiceImpl { @Autowired private TulingDao tulingDao; public void testService() { tulingDao.testTulingDao(); System.out.println(\"我是通过importSelector导入进来的service\"); } } 通过ImportBeanDefinitionRegistar导入进来的 public class TulingDao { public void testTulingDao() { System.out.println(\"我是通过ImportBeanDefinitionRegistrar导入进来tulingDao组件\"); } } 测试结果: 1.3)spring底层条件装配的原理@Conditional 应用要求:比如我有二个组件,一个是TulingLog一个是TulingAspect 而TulingLog是依赖TulingAspect的 只有容器中有TulingAspect组件才会加载TulingLog tulingLog组件 依赖TulingAspect组件 public class TulingLog { } tulingAspect组件 public class TulingAspect { } ①:自定义条件组件条件 public class TulingConditional implements Condition { @Override public boolean matches(ConditionContext conditionContext, AnnotatedTypeMetadata annotatedTypeMetadata) { //容器中包含tulingAspect组件才返回Ture if(conditionContext.getBeanFactory().containsBean(\"tulingAspect\")){ return true; }else{ return false; } } } -------------------------------------该情况下会加载二个组件-------------------------------------------- @Bean public TulingAspect tulingAspect() { System.out.println(\"TulingAspect组件自动装配到容器中\"); return new TulingAspect(); @Bean @Conditional(value = TulingConditional.class) public TulingLog tulingLog() { System.out.println(\"TulingLog组件自动装配到容器中\"); return new TulingLog(); } -------------------------------------二个组件都不会被加载---------------------------------------- /@Bean*/ public TulingAspect tulingAspect() { System.out.println(\"TulingAspect组件自动装配到容器中\"); return new TulingAspect(); } @Bean @Conditional(value = TulingConditional.class) public TulingLog tulingLog() { System.out.println(\"TulingLog组件自动装配到容器中\"); return new TulingLog(); } 自动装配原理分析 从@SpringbootApplication入手分析 那我们仔细分析 org.springframework.boot.autoconfigure.AutoConfigurationImportSelector#selectImports public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware, ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered { @Override public String[] selectImports(AnnotationMetadata annotationMetadata) { if (!isEnabled(annotationMetadata)) { return NO_IMPORTS; } AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); AnnotationAttributes attributes = getAttributes(annotationMetadata); //去mata-info/spring.factories文件中查询EnableAutoConfiguration对于值List configurations = getCandidateConfigurations(annotationMetadata, attributes); //去除重复的配置类，若我们自己写的starter可能存主重复的 configurations = removeDuplicates(configurations); Set exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); //根据maven导入的启动器过滤出需要导入的配置类 configurations = filter(configurations, autoConfigurationMetadata); fireAutoConfigurationImportEvents(configurations, exclusions); return StringUtils.toStringArray(configurations); } } //去spring.factories中去查询EnableAutoConfirution类 private static Map> loadSpringFactories(@Nullable ClassLoader classLoader) { MultiValueMap result = cache.get(classLoader); if (result != null) { return result; } try { Enumeration urls = (classLoader != null ? classLoader.getResources(FACTORIES_RESOURCE_LOCATION) : ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION)); result = new LinkedMultiValueMap<>(); while (urls.hasMoreElements()) { URL url = urls.nextElement(); UrlResource resource = new UrlResource(url); Properties properties = PropertiesLoaderUtils.loadProperties(resource); for (Map.Entry entry : properties.entrySet()) { List factoryClassNames = Arrays.asList( StringUtils.commaDelimitedListToStringArray((String) entry.getValue())); result.addAll((String) entry.getKey(), factoryClassNames); } } cache.put(classLoader, result); return result; } catch (IOException ex) { throw new IllegalArgumentException(\"Unable to load factories from location [\" + FACTORIES_RESOURCE_LOCATION + \"]\", ex); } } 然后我们分析RedisAutoConfiguration类 导入了三个组件RedisTemplateStringRedisTemplate JedisConnectionConfiguration @Configuration @ConditionalOnClass(RedisOperations.class) @EnableConfigurationProperties(RedisProperties.class) @Import({ LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class }) public class RedisAutoConfiguration { //导入redisTemplate @Bean @ConditionalOnMissingBean(name = \"redisTemplate\") public RedisTemplate redisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { RedisTemplate template = new RedisTemplate<>(); template.setConnectionFactory(redisConnectionFactory); return template; } @Bean @ConditionalOnMissingBean public StringRedisTemplate stringRedisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; } } =====================================JedisConnectionConfiguration=================== @Configuration @ConditionalOnClass({ GenericObjectPool.class, JedisConnection.class, Jedis.class }) class JedisConnectionConfiguration extends RedisConnectionConfiguration { private final RedisProperties properties; private final List builderCustomizers; JedisConnectionConfiguration(RedisProperties properties, ObjectProvider sentinelConfiguration, ObjectProvider clusterConfiguration, ObjectProvider> builderCustomizers) { super(properties, sentinelConfiguration, clusterConfiguration); this.properties = properties; this.builderCustomizers = builderCustomizers .getIfAvailable(Collections::emptyList); } @Bean @ConditionalOnMissingBean(RedisConnectionFactory.class) public JedisConnectionFactory redisConnectionFactory() throws UnknownHostException { return createJedisConnectionFactory(); } private JedisConnectionFactory createJedisConnectionFactory() { JedisClientConfiguration clientConfiguration = getJedisClientConfiguration(); if (getSentinelConfig() != null) { return new JedisConnectionFactory(getSentinelConfig(), clientConfiguration); } if (getClusterConfiguration() != null) { return new JedisConnectionFactory(getClusterConfiguration(), clientConfiguration); } return new JedisConnectionFactory(getStandaloneConfig(), clientConfiguration); } private JedisClientConfiguration getJedisClientConfiguration() { JedisClientConfigurationBuilder builder = applyProperties( JedisClientConfiguration.builder()); RedisProperties.Pool pool = this.properties.getJedis().getPool(); if (pool != null) { applyPooling(pool, builder); } if (StringUtils.hasText(this.properties.getUrl())) { customizeConfigurationFromUrl(builder); } customize(builder); return builder.build(); } private JedisClientConfigurationBuilder applyProperties( JedisClientConfigurationBuilder builder) { if (this.properties.isSsl()) { builder.useSsl(); } if (this.properties.getTimeout() != null) { Duration timeout = this.properties.getTimeout(); builder.readTimeout(timeout).connectTimeout(timeout); } return builder; } private void applyPooling(RedisProperties.Pool pool, JedisClientConfiguration.JedisClientConfigurationBuilder builder) { builder.usePooling().poolConfig(jedisPoolConfig(pool)); } private JedisPoolConfig jedisPoolConfig(RedisProperties.Pool pool) { JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(pool.getMaxActive()); config.setMaxIdle(pool.getMaxIdle()); config.setMinIdle(pool.getMinIdle()); if (pool.getMaxWait() != null) { config.setMaxWaitMillis(pool.getMaxWait().toMillis()); } return config; } } Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-20 10:32:49 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"micro/Springboot-source.html":{"url":"micro/Springboot-source.html","title":"4.SpringBoot源码分析","keywords":"","body":"第三节:springboot源码解析(王炸篇) 今天内容 1:spring注解 热身 2:springboot自动装配原理 3:springboot启动原理(jar包启动) 4:springboot启动原理(War包启动) 5:作业:springboot的自定义启动器 一:spring注解之如何导入Bean的几种方式 1）@Bean注解，不做讲解 包扫描来加载Bean比如标识@Controller @Service @Repository @Compent不做讲解 @Import几种取值来注册bean ①：实现ImportSelector接口的类 ②：实现ImportBeanDefinitionRegistrar接口來注冊bean 4）实现factoryBean的方式来导入组件(不做讲解) 1.1)通过@Import注解来导入ImportSelector组件 ①:写一个配置类在配置类上标注一个@Import的注解， @Configuration @Import(value = {TulingSelector.class}) public class TulingConfig { } ②：在@Import注解的value值 写自己需要导入的组件 在selectImports方法中 就是你需要导入组件的全类名 public class TulingSelector implements ImportSelector { @Override public String[] selectImports(AnnotationMetadata annotationMetadata) { return new String[]{\"com.tuling.service.TulingServiceImpl\"}; } } 核心代码: @RestController public class TulingController { //自动注入tulingServiceImpl @Autowired private TulingServiceImpl tulingServiceImpl; @RequestMapping(\"testTuling\") public String testTuling() { tulingServiceImpl.testService(); return \"tulingOk\"; } } 这里是没有标注其他注解提供给spring包扫描的 public class TulingServiceImpl { public void testService() { System.out.println(\"我是通过importSelector导入进来的service\"); } } 1.2）通过@Import导入ImportBeanDefinitionRegistrar从而进来导入组件 核心代码: public class TulingImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar { @Override public void registerBeanDefinitions(AnnotationMetadata annotationMetadata, BeanDefinitionRegistry beanDefinitionReg //定义一个BeanDefinition RootBeanDefinition rootBeanDefinition = new RootBeanDefinition(TulingDao.class); //把自定义的bean定义导入到容器中 beanDefinitionRegistry.registerBeanDefinition(\"tulingDao\",rootBeanDefinition); } } 通过ImportSelector功能导入进来的 public class TulingServiceImpl { @Autowired private TulingDao tulingDao; public void testService() { tulingDao.testTulingDao(); System.out.println(\"我是通过importSelector导入进来的service\"); } } 通过ImportBeanDefinitionRegistar导入进来的 public class TulingDao { public void testTulingDao() { System.out.println(\"我是通过ImportBeanDefinitionRegistrar导入进来tulingDao组件\"); } } 测试结果: 1.3)spring底层条件装配的原理@Conditional 应用要求:比如我有二个组件,一个是TulingLog一个是TulingAspect 而TulingLog是依赖TulingAspect的 只有容器中有TulingAspect组件才会加载TulingLog tulingLog组件 依赖TulingAspect组件 public class TulingLog { } tulingAspect组件 public class TulingAspect { } ①:自定义条件组件条件 public class TulingConditional implements Condition { @Override public boolean matches(ConditionContext conditionContext, AnnotatedTypeMetadata annotatedTypeMetadata) { //容器中包含tulingAspect组件才返回Ture if(conditionContext.getBeanFactory().containsBean(\"tulingAspect\")){ return true; }else{ return false; } } } -------------------------------------该情况下会加载二个组件-------------------------------------------- @Bean public TulingAspect tulingAspect() { System.out.println(\"TulingAspect组件自动装配到容器中\"); return new TulingAspect(); } @Bean @Conditional(value = TulingConditional.class) public TulingLog tulingLog() { System.out.println(\"TulingLog组件自动装配到容器中\"); return new TulingLog(); } -------------------------------------二个组件都不会被加载---------------------------------------- /@Bean*/ public TulingAspect tulingAspect() { System.out.println(\"TulingAspect组件自动装配到容器中\"); return new TulingAspect(); } @Bean @Conditional(value = TulingConditional.class) public TulingLog tulingLog() { System.out.println(\"TulingLog组件自动装配到容器中\"); return new TulingLog(); } ==================================到此结束spring自层注解 ============================== 二:springboot自动装配原理 2.1)@Springboot注解组合图 根据上面的@SpringBootApplication注解 我们来着重分析如下二个类 ①：AutoConfigurationImportSelector.class ②：AutoConfigurationPackages.Registrar.class 先分析AutoConfigurationImportSelector为我们干了什么活 ？？ public String[] selectImports(AnnotationMetadata annotationMetadata) { if (!isEnabled(annotationMetadata)) { return NO_IMPORTS; } AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); AnnotationAttributes attributes = getAttributes(annotationMetadata); //获取候选的配置类 List configurations = getCandidateConfigurations(annotationMetadata, attributes); //移除重复的 configurations = removeDuplicates(configurations); Set exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = filter(configurations, autoConfigurationMetadata); fireAutoConfigurationImportEvents(configurations, exclusions); //返回出去 return StringUtils.toStringArray(configurations); } //获取候选的配置类 protected List getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) { List configurations = SpringFactoriesLoader.loadFactoryNames( getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, \"No auto configuration classes found in META-INF/spring.factories. If you \" \"are using a custom packaging, make sure that file is correct.\"); return configurations; } //加载配置类 public static List loadFactoryNames(Class factoryClass, @Nullable ClassLoader classLoader) { String factoryClassName = factoryClass.getName(); return loadSpringFactories(classLoader).getOrDefault(factoryClassName, Collections.emptyList()); } private static Map> loadSpringFactories(@Nullable ClassLoader classLoader) { MultiValueMap result = cache.get(classLoader); if (result != null) { return result; } try { //\"META-INF/spring.factories\"去类路径下该文件中加载EnableAutoConfiguration.class Enumeration urls = (classLoader != null ? classLoader.getResources(FACTORIES_RESOURCE_LOCATION) : ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION)); result = new LinkedMultiValueMap<>(); //遍历解析出来的集合 while (urls.hasMoreElements()) { URL url = urls.nextElement(); UrlResource resource = new UrlResource(url); //放在Properties中 Properties properties = PropertiesLoaderUtils.loadProperties(resource); for (Map.Entry entry : properties.entrySet()) { String factoryClassName = ((String) entry.getKey()).trim(); for (String factoryName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue()) result.add(factoryClassName, factoryName.trim()); } } } cache.put(classLoader, result); //返回 return result; } catch (IOException ex) { throw new IllegalArgumentException(\"Unable to load factories from location [\" + FACTORIES_RESOURCE_LOCATION + \"]\", ex); } } 主要是扫描spring-boot-autoconfigure\\2.0.8.RELEASE\\spring-boot-autoconfigure- 2.0.8.RELEASE.jar!\\META-INF\\spring.factories中EnableAutoConfiguration对应的全类名 org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\ org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\ org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\ org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\\ org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\\ org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\\ org.springframework.boot.autoconfigure.cloud.CloudAutoConfiguration,\\ org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\\ org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\\ org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\\ org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\\ org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.couchbase.CouchbaseDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.couchbase.CouchbaseReactiveDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.couchbase.CouchbaseReactiveRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.couchbase.CouchbaseRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.ldap.LdapDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.ldap.LdapRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.mongo.MongoReactiveDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.mongo.MongoReactiveRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.neo4j.Neo4jDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.neo4j.Neo4jRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.solr.SolrRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.redis.RedisReactiveAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\\ org.springframework.boot.autoconfigure.elasticsearch.jest.JestAutoConfiguration,\\ org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\\ org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\\ org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\\ org.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration,\\ org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\\ org.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration,\\ org.springframework.boot.autoconfigure.hazelcast.HazelcastJpaDependencyAutoConfiguration,\\ org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration,\\ org.springframework.boot.autoconfigure.http.codec.CodecsAutoConfiguration,\\ org.springframework.boot.autoconfigure.influx.InfluxDbAutoConfiguration,\\ org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration,\\ org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\\ org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\\ org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\\ org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\\ org.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\\ org.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\\ org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\\ org.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\\ org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\\ org.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\\ org.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\\ org.springframework.boot.autoconfigure.jms.artemis.ArtemisAutoConfiguration,\\ org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\\ org.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\\ org.springframework.boot.autoconfigure.jooq.JooqAutoConfiguration,\\ org.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration,\\ org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration,\\ org.springframework.boot.autoconfigure.ldap.embedded.EmbeddedLdapAutoConfiguration,\\ org.springframework.boot.autoconfigure.ldap.LdapAutoConfiguration,\\ org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\\ org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\\ org.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration,\\ org.springframework.boot.autoconfigure.mongo.embedded.EmbeddedMongoAutoConfiguration,\\ org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\\ org.springframework.boot.autoconfigure.mongo.MongoReactiveAutoConfiguration,\\ org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\\ org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\\ org.springframework.boot.autoconfigure.quartz.QuartzAutoConfiguration,\\ org.springframework.boot.autoconfigure.reactor.core.ReactorCoreAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.servlet.SecurityRequestMatcherProviderAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.reactive.ReactiveSecurityAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.reactive.ReactiveUserDetailsServiceAutoConfiguration,\\ org.springframework.boot.autoconfigure.sendgrid.SendGridAutoConfiguration,\\ org.springframework.boot.autoconfigure.session.SessionAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.oauth2.client.OAuth2ClientAutoConfiguration,\\ org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\\ org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\\ org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration,\\ org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration,\\ org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.client.RestTemplateAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.reactive.HttpHandlerAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.reactive.ReactiveWebServerFactoryAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.reactive.error.ErrorWebFluxAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.reactive.function.client.WebClientAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.servlet.MultipartAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration,\\ org.springframework.boot.autoconfigure.websocket.reactive.WebSocketReactiveAutoConfiguration,\\ org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration,\\ org.springframework.boot.autoconfigure.websocket.servlet.WebSocketMessagingAutoConfiguration,\\ org.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration 上面的一些个XXXAutoConfiguration都是一个个自动配置类 我们就拿二个来分析一下 这些自动配置类是如何工作的??? 分析源码1: org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration @Configuration//标识是一个自动配置类 @EnableConfigurationProperties(HttpEncodingProperties.class)启动指定类的配置功能，并且把配置文件中的属性和HttpEncodi @ConditionalOnWebApplication(type = ConditionalOnWebApplication.Type.SERVLET) //spring底层的@Conditional注解的变@ConditionalOnClass(CharacterEncodingFilter.class) ,判断环境中是否没有这个类 判断配置文件中是否存在某个配置spring.http.encoding.enabled；如果不存在，判断也是成立的//即使我们配置文件中不配置pring.http.encoding.enabled=true，也是默认生效的@ConditionalOnProperty(prefix = \"spring.http.encoding\", value = \"enabled\", matchIfMissing = true) public class HttpEncodingAutoConfiguration { 自动配置类的属性映射 private final HttpEncodingProperties properties; public HttpEncodingAutoConfiguration(HttpEncodingProperties properties) { this.properties = properties; } //配置一个CharacterEncodingFilter是springmvc解决乱码的，若容器中没有该组件，那么就会创建该组件 @Bean @ConditionalOnMissingBean public CharacterEncodingFilter characterEncodingFilter() { CharacterEncodingFilter filter = new OrderedCharacterEncodingFilter(); filter.setEncoding(this.properties.getCharset().name()); filter.setForceRequestEncoding(this.properties.shouldForce(Type.REQUEST)); filter.setForceResponseEncoding(this.properties.shouldForce(Type.RESPONSE)); return filter; } @Bean public LocaleCharsetMappingsCustomizer localeCharsetMappingsCustomizer() { return new LocaleCharsetMappingsCustomizer(this.properties); } private static class LocaleCharsetMappingsCustomizer implements WebServerFactoryCustomizer, Ordered { private final HttpEncodingProperties properties; LocaleCharsetMappingsCustomizer(HttpEncodingProperties properties) { this.properties = properties; } @Override public void customize(ConfigurableServletWebServerFactory factory) { if (this.properties.getMapping() != null) { factory.setLocaleCharsetMappings(this.properties.getMapping()); } } @Override public int getOrder() { return 0; } } } 我们来看下HttpEncodingProperties，这个类是用来什么的？ 就是我们yml中能配置什么类，在这个类中都会有一个属性一一对应 @ConfigurationProperties(prefix = \"spring.http.encoding\") //从配置文件中获取指定的值和bean的属 性进行绑定 public class HttpEncodingProperties { public static final Charset DEFAULT_CHARSET = Charset.forName(\"UTF‐8\"); 我们对应的配置文件(yml)中就会有对应属性来配置 以上 就是AutoConfigurationImportSelector为我们容器中注册了那些组件，然后根据maven依赖导入的jar包，根据条件装配来指定哪些组件 起作用 哪些组件不起作用。 三:上面我们分析了springboot自动装配原理，接下来我们依靠 自动装配原理来分析出spring Boot的jar包的启动流程. 3.1)我们先来看springboot怎么来自动装配tomcat相关的组件 EmbeddedWebServerFactoryCustomizerAutoConfiguration(内嵌web容器工厂自定义定制器装配类)? 疑问1？：定制器是用来干什么的？ 疑问2？:定制器何时工作？ 类的继承关系 我们就以tomcat作为内嵌容器来分析 @Configuration @ConditionalOnWebApplication @EnableConfigurationProperties(ServerProperties.class) public class EmbeddedWebServerFactoryCustomizerAutoConfiguration { //配置tomcat的 @Configuration @ConditionalOnClass({ Tomcat.class, UpgradeProtocol.class }) public static class TomcatWebServerFactoryCustomizerConfiguration { @Bean public TomcatWebServerFactoryCustomizer tomcatWebServerFactoryCustomizer( Environment environment, ServerProperties serverProperties) { return new TomcatWebServerFactoryCustomizer(environment, serverProperties); } } //配置jetty @Configuration @ConditionalOnClass({ Server.class, Loader.class, WebAppContext.class }) public static class JettyWebServerFactoryCustomizerConfiguration { @Bean public JettyWebServerFactoryCustomizer jettyWebServerFactoryCustomizer( Environment environment, ServerProperties serverProperties) { return new JettyWebServerFactoryCustomizer(environment, serverProperties); } } 配置undertow的 @Configuration @ConditionalOnClass({ Undertow.class, SslClientAuthMode.class }) public static class UndertowWebServerFactoryCustomizerConfiguration { @Bean public UndertowWebServerFactoryCustomizer undertowWebServerFactoryCustomizer( Environment environment, ServerProperties serverProperties) { return new UndertowWebServerFactoryCustomizer(environment, serverProperties); } } } 我们来看下tomat工厂定制器 是用来修改设置容器的内容的(把serverProperties的属性设置到tomcat的创建工厂中) public class TomcatWebServerFactoryCustomizer implements WebServerFactoryCustomizer ..........................其他代码省略。。。。。。。。。。。。。。 @Override public void customize(ConfigurableTomcatWebServerFactory factory) { ServerProperties properties = this.serverProperties; ServerProperties.Tomcat tomcatProperties = properties.getTomcat(); PropertyMapper propertyMapper = PropertyMapper.get(); propertyMapper.from(tomcatProperties::getBasedir).whenNonNull() .to(factory::setBaseDirectory); propertyMapper.from(tomcatProperties::getBackgroundProcessorDelay).whenNonNull() .as(Duration::getSeconds).as(Long::intValue) .to(factory::setBackgroundProcessorDelay); customizeRemoteIpValve(factory); propertyMapper.from(tomcatProperties::getMaxThreads).when(this::isPositive) .to((maxThreads) -> customizeMaxThreads(factory, tomcatProperties.getMaxThreads())); propertyMapper.from(tomcatProperties::getMinSpareThreads).when(this::isPositive) .to((minSpareThreads) -> customizeMinThreads(factory, minSpareThreads)); propertyMapper.from(() -> determineMaxHttpHeaderSize()).when(this::isPositive) .to((maxHttpHeaderSize) -> customizeMaxHttpHeaderSize(factory, maxHttpHeaderSize)); propertyMapper.from(tomcatProperties::getMaxHttpPostSize) .when((maxHttpPostSize) -> maxHttpPostSize != 0) .to((maxHttpPostSize) -> customizeMaxHttpPostSize(factory, maxHttpPostSize)); propertyMapper.from(tomcatProperties::getAccesslog) .when(ServerProperties.Tomcat.Accesslog::isEnabled) .to((enabled) -> customizeAccessLog(factory)); propertyMapper.from(tomcatProperties::getUriEncoding).whenNonNull() .to(factory::setUriEncoding); propertyMapper.from(properties::getConnectionTimeout).whenNonNull() .to((connectionTimeout) -> customizeConnectionTimeout(factory, connectionTimeout)); propertyMapper.from(tomcatProperties::getMaxConnections).when(this::isPositive) .to((maxConnections) -> customizeMaxConnections(factory, maxConnections)); propertyMapper.from(tomcatProperties::getAcceptCount).when(this::isPositive) .to((acceptCount) -> customizeAcceptCount(factory, acceptCount)); customizeStaticResources(factory); customizeErrorReportValve(properties.getError(), factory); } ServletWebServerFactoryAutoConfigurationServletweb工厂自动配置类 很重要*:@Import({ ServletWebServerFactoryAutoConfiguration.BeanPostProcessorsRegistrar.class}** @Configuration @AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE) @ConditionalOnClass(ServletRequest.class) @ConditionalOnWebApplication(type = Type.SERVLET) @EnableConfigurationProperties(ServerProperties.class) @Import({ ServletWebServerFactoryAutoConfiguration.BeanPostProcessorsRegistrar.class, ServletWebServerFactoryConfiguration.EmbeddedTomcat.class, ServletWebServerFactoryConfiguration.EmbeddedJetty.class, ServletWebServerFactoryConfiguration.EmbeddedUndertow.class }) public class ServletWebServerFactoryAutoConfiguration { @Bean public ServletWebServerFactoryCustomizer servletWebServerFactoryCustomizer( ServerProperties serverProperties) { return new ServletWebServerFactoryCustomizer(serverProperties); } @Bean @ConditionalOnClass(name = \"org.apache.catalina.startup.Tomcat\") public TomcatServletWebServerFactoryCustomizer tomcatServletWebServerFactoryCustomizer( ServerProperties serverProperties) { return new TomcatServletWebServerFactoryCustomizer(serverProperties); } } .....................................................ServletWebServerFactoryCustomizer核心代码........................................... public void customize(ConfigurableServletWebServerFactory factory) { PropertyMapper map = PropertyMapper.get().alwaysApplyingWhenNonNull(); map.from(this.serverProperties::getPort).to(factory::setPort); map.from(this.serverProperties::getAddress).to(factory::setAddress); map.from(this.serverProperties.getServlet()::getContextPath) .to(factory::setContextPath); map.from(this.serverProperties.getServlet()::getApplicationDisplayName) .to(factory::setDisplayName); map.from(this.serverProperties.getServlet()::getSession).to(factory::setSession); map.from(this.serverProperties::getSsl).to(factory::setSsl); map.from(this.serverProperties.getServlet()::getJsp).to(factory::setJsp); map.from(this.serverProperties::getCompression).to(factory::setCompression); map.from(this.serverProperties::getHttp2).to(factory::setHttp2); map.from(this.serverProperties::getServerHeader).to(factory::setServerHeader); map.from(this.serverProperties.getServlet()::getContextParameters) .to(factory::setInitParameters); } ---------------------------------------------TomcatServletWebServerFactoryCustomizer核心定制代码---------- public void customize(TomcatServletWebServerFactory factory) { ServerProperties.Tomcat tomcatProperties = this.serverProperties.getTomcat(); if (!ObjectUtils.isEmpty(tomcatProperties.getAdditionalTldSkipPatterns())) { factory.getTldSkipPatterns() .addAll(tomcatProperties.getAdditionalTldSkipPatterns()); } if (tomcatProperties.getRedirectContextRoot() != null) { customizeRedirectContextRoot(factory, tomcatProperties.getRedirectContextRoot()); } if (tomcatProperties.getUseRelativeRedirects() != null) { customizeUseRelativeRedirects(factory, tomcatProperties.getUseRelativeRedirects()); } } ServletWebServerFactoryConfiguration容器工厂配置类 @Configuration class ServletWebServerFactoryConfiguration { @Configuration @ConditionalOnClass({ Servlet.class, Tomcat.class, UpgradeProtocol.class }) @ConditionalOnMissingBean(value = ServletWebServerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedTomcat { //配置tomcat容器工厂 @Bean public TomcatServletWebServerFactory tomcatServletWebServerFactory() { return new TomcatServletWebServerFactory(); } } 现在我们来分析一下启动流程。。。。。。。。。。。。。。。。。。。。 1)com.tuling.TulingvipSpringbootAutoconfigPrincipleApplication#main运行main方法 2)org.springframework.boot.SpringApplication#run(java.lang.Class, java.lang.String...) 2.1）传入主配置类，以及命令行参数 2.2)创建SpringApplication对象 ①:保存主配置类 ②：保存web应用的配置类型 ③：去mate-info/spring.factories文件中获取ApplicationContextInitializer(容器初始 化器)保存到springapplication对象中 ④：去mate-info/spring.factories文件中获取ApplicationListener(容器监听器)保存到springapplication对象中 ⑤：保存选取 主配置类 public SpringApplication(ResourceLoader resourceLoader, Class... primarySources) { this.resourceLoader = resourceLoader; Assert.notNull(primarySources, \"PrimarySources must not be null\"); //保存主配置类 this.primarySources = new LinkedHashSet<>(Arrays.asList(primarySources)); //保存web应用的类型 this.webApplicationType = WebApplicationType.deduceFromClasspath(); //保存容器初始化器(ApplicationContextInitializer类型的) setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); //把监听器保存到SpringApplication中[ApplicationListener] setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); //保存主配置类 this.mainApplicationClass = deduceMainApplicationClass(); } //还是去META-INFO/spring.factories中获取ApplicationContextInitializer类型，用于初始化容器private Collection getSpringFactoriesInstances(Class type, Class[] parameterTypes, Object... args) { ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); Use names and ensure unique to protect against duplicates Set names = new LinkedHashSet<>( SpringFactoriesLoader.loadFactoryNames(type, classLoader)); List instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances; } //查找主配置类查询的依据就是看哪个方法是否有main方法 private Class deduceMainApplicationClass() { try { StackTraceElement[] stackTrace = new RuntimeException().getStackTrace(); for (StackTraceElement stackTraceElement : stackTrace) { if (\"main\".equals(stackTraceElement.getMethodName())) { return Class.forName(stackTraceElement.getClassName()); } } } catch (ClassNotFoundException ex) { // Swallow and continue } return null; } 3)运行SpringbootApplication的run方法 public ConfigurableApplicationContext run(String... args) { StopWatch stopWatch = new StopWatch(); stopWatch.start(); //创建一个容器对象 ConfigurableApplicationContext context = null; Collection exceptionReporters = new ArrayList<>(); configureHeadlessProperty(); //去meta-info/spring.factories中获取SpringApplicationRunListener监听器(事件发布监听器) SpringApplicationRunListeners listeners = getRunListeners(args); //发布容器starting事件(通过spring的事件多播器) listeners.starting(); try { //封装命令行参数 ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); //准备容器环境 1:获取或者创建环境 2：把命令行参数设置到环境中 3：通过监听器发布环境准备事件 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); //打印springboot的图标 Banner printedBanner = printBanner(environment); //创建容器根据webApplicationType来创建容器通过反射创建context = createApplicationContext(); //去meta-info类中获取异常报告exceptionReporters = getSpringFactoriesInstances( SpringBootExceptionReporter.class, new Class[] { ConfigurableApplicationContext.class }, context); //准备环境 1：把环境设置到容器中 循环调用AppplicationInitnazlier进行容器初始化工作 3:发布容器上下文准备完成事件 4:注册关于springboot特性的相关单例Bean 5:发布容器上下文加载完毕事件 prepareContext(context, environment, listeners, applicationArguments,printedBanner); refreshContext(context); //运行ApplicationRunner和CommandLineRunner afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) { new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); } //发布容器启动事件listeners.started(context); //运行ApplicationRunner和CommandLineRunner callRunners(context, applicationArguments); } catch (Throwable ex) { //出现异常；调用异常分析保护类进行分析 handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); } try { //发布容器运行事件 listeners.running(context); } catch (Throwable ex) { handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); } return context; } 5)org.springframework.boot.SpringApplication#refreshContext 6)org.springframework.context.support.AbstractApplicationContext#refresh 7)org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext#onRefresh 8)org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext#createWebServer 8.1)org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext#getWebServer获取web服务器工厂 以下是springioc容器启动的核心流程，在这里不做详细解释,大概步骤为如下: .................................. 8.2)org.springframework.boot.web.server.WebServerFactoryCustomizerBeanPostProcessor#postProces 8.3)org.springframework.boot.web.server.WebServerFactoryCustomizerBeanPostProcessor#postProcessBeforeInitializati 8.3.1)WebServerFactoryCustomizerBeanPostProcessor是一个什么东西？ 在哪里注册到容器中的??? 我们往容器中导入了BeanPostProcessorsRegistrar他实现了ImportBeanDefinitionRegistrar在他的registerBeanDefinitions注册Bean定义的时候 注册 webServerFactoryCustomizerBeanPostProcessor 想知道webServerFactoryCustomizerBeanPostProcessor何时在容器中注册的么？？？？？ public static class BeanPostProcessorsRegistrar implements ImportBeanDefinitionRegistrar, BeanFactoryAware { private ConfigurableListableBeanFactory beanFactory; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException { if (beanFactory instanceof ConfigurableListableBeanFactory) { this.beanFactory = (ConfigurableListableBeanFactory) beanFactory; } } @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { if (this.beanFactory == null) { return; } registerSyntheticBeanIfMissing(registry, \"webServerFactoryCustomizerBeanPostProcessor\", WebServerFactoryCustomizerBeanPostProcessor.class); registerSyntheticBeanIfMissing(registry, \"errorPageRegistrarBeanPostProcessor\", ErrorPageRegistrarBeanPostProcessor.class); } org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory#getWebServer 创建tomcat并且容器启动 public WebServer getWebServer(ServletContextInitializer... initializers) { Tomcat tomcat = new Tomcat(); File baseDir = (this.baseDirectory != null) ? this.baseDirectory createTempDir(\"tomcat\"); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) { tomcat.getService().addConnector(additionalConnector); } prepareContext(tomcat.getHost(), initializers); return getTomcatWebServer(tomcat); } protected TomcatWebServer getTomcatWebServer(Tomcat tomcat) { //端口大于0启动启动 return new TomcatWebServer(tomcat, getPort() >= 0); } public TomcatWebServer(Tomcat tomcat, boolean autoStart) { Assert.notNull(tomcat, \"Tomcat Server must not be null\"); this.tomcat = tomcat; this.autoStart = autoStart; initialize(); } tomcat启动流程 private void initialize() throws WebServerException { TomcatWebServer.logger .info(\"Tomcat initialized with port(s): \" + getPortsDescription(false)); synchronized (this.monitor) { try { addInstanceIdToEngineName(); Context context = findContext(); context.addLifecycleListener((event) -> { if (context.equals(event.getSource()) * Lifecycle.START_EVENT.equals(event.getType())) { Remove service connectors so that protocol binding doesn't happen when the service is started. removeServiceConnectors(); } }); Start the server to trigger initialization listeners this.tomcat.start(); We can re-throw failure exception directly in the main thread rethrowDeferredStartupExceptions(); try { ContextBindings.bindClassLoader(context, context.getNamingToken(), getClass().getClassLoader()); } catch (NamingException ex) { // Naming is not enabled. Continue } Unlike Jetty, all Tomcat threads are daemon threads. We create a blocking non-daemon to stop immediate shutdown startDaemonAwaitThread(); } catch (Exception ex) { stopSilently(); throw new WebServerException(\"Unable to start embedded Tomcat\", ex); } } } 在IOC容器中的org.springframework.context.support.AbstractApplicationContext#refresh的 onReFresh（）带动tomcat启动 然后在接着执行ioc容器的其他步骤。 疑问？？？？？ 1）AutoConfigurationImportSelector#selectImports的方法是怎么触发 的？ 2）我们自己定义的一些@Controller @Service怎么到容器中去的？？？ 接下来 我们就一一解答你们的疑问?还是以debug的方式来为大家解答 1>AbstractApplicationContext#refresh(容器的刷新) 2>AbstractApplicationContext#invokeBeanFactoryPostProcessors调用bean工厂的后置处理器 3>PostProcessorRegistrationDelegate#invokeBeanDefinitionRegistryPostProcessors 4>ConfigurationClassPostProcessor#postProcessBeanDefinitionRegistry配置类的后置处理器5>ConfigurationClassPostProcessor#processConfigBeanDefinitions处理配置的bean定义 5.1）找到候选的配置类(tulingvipSpringbootAutoconfigPrincipleApplication)我们自己项目中的配 置类 5.2 )创建配置类解析器 6>ConfigurationClassParser#parse解析我们自己的配置类 (tulingvipSpringbootAutoconfigPrincipleApplication) 7>ConfigurationClassParser#processConfigurationClass处理配置类 7.1)处理配置类上的@PropertySource注解 ConfigurationClassParser#processPropertySource 7.2）处理@ComponentScan注解的ComponentScanAnnotationParser#parse ①:创建 类路径下的bean定义扫描器ClassPathBeanDefinitionScanner ..多个步骤 解析@ComponentScan注解的属性 ②:ClassPathBeanDefinitionScanner#doScan真正的扫描 (tulingvipSpringbootAutoconfigPrincipleApplication所在的包) ③:返回我们标志了@Controller @Service @Response @compent注解的bean定 义 7.3)处理@Import注解ConfigurationClassParser#processImports 7.4）处理@ImportSource注解 7.5)处理@Bean注解的 8>ConfigurationClassParser#processDeferredImportSelectors处理实现了 ImportSelectors接口的 9>AutoConfigurationGroup#process (获取 容器中的所有ImportSelector包含了AutoConfigurationImportSelector) 10>ImportSelector#selectImports回 AutoConfigurationImportSelector.selectImports ConfigurationClassBeanDefinitionReader#loadBeanDefinitions把解析出来的类的bean定 义 注册到容器中 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-20 10:32:49 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"micro/Eureka-source.html":{"url":"micro/Eureka-source.html","title":"5.Eureka源码分析","keywords":"","body":"为什么要看源码： 1、提升技术功底：学习源码里的优秀设计思想，比如一些疑难问题的解决思路，还有一些优秀的设计模式，整体提升自己的技术功底 2、深度掌握技术框架：源码看多了，对于一个新技术或框架的掌握速度会有大幅提升，看下框架demo大致就能知道底层的实现，技术框架更新再快也不怕 3、快速定位线上问题：遇到线上问题，特别是框架源码里的问题(比如bug)，能够快速定位，这就是相比其他没看过源码的人的优势 4、对面试大有裨益：面试一线互联网公司对于框架技术一般都会问到源码级别的实现 5、技术追求：对技术有追求的人必做之事，使用了一个好的框架，很想知道底层是如何实现的 看源码方法： 1、先使用：先看官方文档快速掌握框架的基本使用 2、抓主线：找一个demo入手，顺藤摸瓜快速静态看一遍框架的主线源码(抓大放小)，画出源码主流程图，切勿一开始就陷入源码的细枝末节，否则会把自己绕晕 3、画图做笔记：总结框架的一些核心功能点，从这些功能点入手深入到源码的细节，边看源码边画源码走向图，并对关键源码的理解做笔记，把源码里的闪光点都记录下来，后续借鉴到工作项目中，理解能力强的可以直接看静态源码，也可以边看源码边debug源码执行过程，观察一些关键变量的值 4、整合总结：所有功能点的源码都分析完后，回到主流程图再梳理一遍，争取把自己画的所有图都在脑袋里做一个整合 1、Eureka架构图 2、Eureka核心功能点 服务注册(register)：Eureka Client会通过发送REST请求的方式向Eureka Server注册自己的服务，提供自身的元数据，比如ip地址、端口、运行状况指标的url、主页地址等信息。Eureka Server接收到注册请求后，就会把这些元数据信息存储在一个双层的Map中。 服务续约(renew)：在服务注册后，Eureka Client会维护一个心跳来持续通知Eureka Server，说明服务一直处于可用状态，防止被剔除。Eureka Client在默认的情况下会每隔30秒 (eureka.instance.leaseRenewallIntervalInSeconds)发送一次心跳来进行服务续约。 服务同步(replicate)：Eureka Server之间会互相进行注册，构建Eureka Server集群，不同Eureka Server之间会进行服务同步，用来保证服务信息的一致性。 获取服务(get registry)：服务消费者（Eureka Client）在启动的时候，会发送一个REST请求给Eureka Server，获取上面注册的服务清单，并且缓存在Eureka Client本地，默认缓存30秒(eureka.client.registryFetchIntervalSeconds)。同时，为了性能考虑，Eureka Server也会维护一份只读的服务清单缓存，该缓存每隔30秒更新一次。 服务调用：服务消费者在获取到服务清单后，就可以根据清单中的服务列表信息，查找到其他服务的地址，从而进行远程调用。Eureka有Region和Zone的概念，一个Region可以包含多个Zone，在进行服务调用时，优先访问处于同一个Zone中的服务提供者。 服务下线(cancel)：当Eureka Client需要关闭或重启时，就不希望在这个时间段内再有请求进来，所以，就需要提前先发送REST请求给Eureka Server，告诉Eureka Server自己要下线了，Eureka Server在收到请求后，就会把该服务状态置为下线（DOWN），并把该下线事件传播出去。 服务剔除(evict)：有时候，服务实例可能会因为网络故障等原因导致不能提供服务，而此时该实例也没有发送请求给Eureka Server来进行服务下线，所以，还需要有服务剔除的机制。Eureka Server在启动的时候会创建一个定时任务，每隔一段时间（默认60秒），从当前服务清单中把超时没有续约（默认90秒，eureka.instance.leaseExpirationDurationInSeconds）的服务剔除。 自我保护：既然Eureka Server会定时剔除超时没有续约的服务，那就有可能出现一种场景，网络一段时间内发生了异常，所有的服务都没能够进行续约，Eureka Server就把所有的服务都剔除了，这样显然不太合理。所以，就有了自我保护机制，当短时间内，统计续约失败的比例，如果达到一定阈值，则会触发自我保护的机制，在该机制下， Eureka Server不会剔除任何的微服务，等到正常后，再退出自我保护机制。自我保护开关(eureka.server.enable-self-preservation: false) 3、Eureka Server端源码分析 源码流程图参考： @Configuration @Import(EurekaServerInitializerConfiguration.class) @ConditionalOnBean(EurekaServerMarkerConfiguration.Marker.class) 4@EnableConfigurationProperties({EurekaDashboardProperties.class, 5InstanceRegistryProperties.class}) 6@PropertySource(\"classpath:/eureka/server.properties\") 7public classEurekaServerAutoConfigurationextendsWebMvcConfigurerAdapter{ 8 //此处省略大部分代码，仅抽取一些关键的代码片段 10 //加载EurekaController, spring‐cloud提供了一些额外的接口，用来获取eurekaServer的信息 @Bean @ConditionalOnProperty(prefix=\"eureka.dashboard\",name=\"enabled\",matchIfMissing=true) publicEurekaControllereurekaController() { return newEurekaController(this.applicationInfoManager); } 17 //初始化集群注册表 @Bean publicPeerAwareInstanceRegistrypeerAwareInstanceRegistry( ServerCodecs serverCodecs) { this.eurekaClient.getApplications();// force initialization return newInstanceRegistry(this.eurekaServerConfig,this.eurekaClientConfig, serverCodecs,this.eurekaClient, this.instanceRegistryProperties.getExpectedNumberOfRenewsPerMin(), this.instanceRegistryProperties.getDefaultOpenForTrafficCount()); } 28 //配置服务节点信息，这里的作用主要是为了配置Eureka的peer节点，也就是说当有收到有节点注册上来 //的时候，需要通知给那些服务节点， （互为一个集群） @Bean @ConditionalOnMissingBean publicPeerEurekaNodespeerEurekaNodes(PeerAwareInstanceRegistry registry, ServerCodecs serverCodecs) { return newPeerEurekaNodes(registry,this.eurekaServerConfig, this.eurekaClientConfig,serverCodecs,this.applicationInfoManager); } // EurekaServer的上下文 @Bean publicEurekaServerContexteurekaServerContext(ServerCodecs serverCodecs, PeerAwareInstanceRegistry registry,PeerEurekaNodes peerEurekaNodes) { return newDefaultEurekaServerContext(this.eurekaServerConfig,serverCodecs, registry,peerEurekaNodes,this.applicationInfoManager); } //这个类的作用是spring‐cloud和原生eureka的胶水代码，通过这个类来启动EurekaSever //后面这个类会在EurekaServerInitializerConfiguration被调用，进行eureka启动 @Bean publicEurekaServerBootstrapeurekaServerBootstrap(PeerAwareInstanceRegistry registry, EurekaServerContext serverContext) { return newEurekaServerBootstrap(this.applicationInfoManager, this.eurekaClientConfig,this.eurekaServerConfig,registry, serverContext); } //配置拦截器，ServletContainer里面实现了jersey框架，通过他来实现eurekaServer对外的restFull接口 @Bean publicFilterRegistrationBeanjerseyFilterRegistration( javax.ws.rs.core.Application eurekaJerseyApp) { FilterRegistrationBean bean=newFilterRegistrationBean(); bean.setFilter(newServletContainer(eurekaJerseyApp)); bean.setOrder(Ordered.LOWEST_PRECEDENCE); bean.setUrlPatterns( Collections.singletonList(EurekaConstants.DEFAULT_PREFIX+\"/*\")); 63 returnbean; } } EurekaServerAutoConfiguration会导入EurekaServerInitializerConfiguration /** *@author Dave Syer */ @Configuration 5@CommonsLog public classEurekaServerInitializerConfiguration implementsServletContextAware,SmartLifecycle,Ordered{ 8 @Autowired privateEurekaServerConfig eurekaServerConfig; 11 privateServletContext servletContext; 13 @Autowired privateApplicationContext applicationContext; 16 @Autowired privateEurekaServerBootstrap eurekaServerBootstrap; 19 privateboolean running; 21 privateint order=1; 23 @Override public voidsetServletContext(ServletContext servletContext) { this.servletContext=servletContext; } 28 @Override public voidstart() { //启动一个线程 newThread(newRunnable() { @Override public voidrun() { try{ //初始化EurekaServer，同时启动Eureka Server eurekaServerBootstrap.contextInitialized(EurekaServerInitializerConfiguration.this.servletCont xt); log.info(\"Started Eureka Server\"); //发布EurekaServer的注册事件 publish(newEurekaRegistryAvailableEvent(getEurekaServerConfig())); //设置启动的状态为true EurekaServerInitializerConfiguration.this.running=true; //发送Eureka Start事件 ， 其他还有各种事件，我们可以监听这种时间，然后做一些特定的业务需求 publish(newEurekaServerStartedEvent(getEurekaServerConfig())); } catch(Exception ex) { // Help! log.error(\"Could not initialize Eureka servlet context\",ex); } } }).start(); } 53 privateEurekaServerConfiggetEurekaServerConfig() { return this.eurekaServerConfig; } 57 private voidpublish(ApplicationEvent event) { this.applicationContext.publishEvent(event); } 61 @Override public voidstop() { this.running=false; eurekaServerBootstrap.contextDestroyed(this.servletContext); } 67 @Override publicbooleanisRunning() { return this.running; } 72 @Override publicintgetPhase() { return0; } 77 @Override publicbooleanisAutoStartup() { returntrue; } 82 @Override public voidstop(Runnable callback) { callback.run(); } 87 @Override publicintgetOrder() { return this.order; } 92 } EurekaServerBootstrap的contextInitialized初始化方法 //初始化EurekaServer的运行环境和上下文 public voidcontextInitialized(ServletContext context) {3try{ initEurekaEnvironment(); initEurekaServerContext(); 6 context.setAttribute(EurekaServerContext.class.getName(),this.serverContext); } catch(Throwable e) { log.error(\"Cannot bootstrap eureka server :\",e); throw newRuntimeException(\"Cannot bootstrap eureka server :\",e); } } 14 初始化EurekaServer的上下文 protected voidinitEurekaServerContext()throws Exception{ // For backward compatibility JsonXStream.getInstance().registerConverter(newV1AwareInstanceInfoConverter(), XStream.PRIORITY_VERY_HIGH); XmlXStream.getInstance().registerConverter(newV1AwareInstanceInfoConverter(), XStream.PRIORITY_VERY_HIGH); 22 if(isAws(this.applicationInfoManager.getInfo())) { this.awsBinder=newAwsBinderDelegate(this.eurekaServerConfig, this.eurekaClientConfig,this.registry,this.applicationInfoManager); this.awsBinder.start(); } 28 //初始化eureka server上下文 EurekaServerContextHolder.initialize(this.serverContext); 31 log.info(\"Initialized server context\"); 33 // Copy registry from neighboring eureka node //从相邻的eureka节点复制注册表 int registryCount=this.registry.syncUp(); //默认每30秒发送心跳，1分钟就是2次 //修改eureka状态为up //同时，这里面会开启一个定时任务，用于清理60秒没有心跳的客户端。自动下线 this.registry.openForTraffic(this.applicationInfoManager,registryCount); 41 // Register all monitoring statistics. EurekaMonitors.registerAllStats(); } 45 @Override publicintsyncUp() { // Copy entire entry from neighboring DS node int count=0; 50 for(int i=0; ((i if(i>0) { try{ Thread.sleep(serverConfig.getRegistrySyncRetryWaitMs()); }catch(InterruptedException e) { logger.warn(\"Interrupted during registry transfer..\"); break; } } Applications apps=eurekaClient.getApplications(); for(Application app:apps.getRegisteredApplications()) { for(InstanceInfo instance:app.getInstances()) { try{ if(isRegisterable(instance)) { //将其他节点的实例注册到本节点 register(instance,instance.getLeaseInfo().getDurationInSecs(),true); count++; } }catch(Throwable t) { logger.error(\"During DS init copy\",t); } } } } returncount; } 77 @Override public voidopenForTraffic(ApplicationInfoManager applicationInfoManager,int count) { // Renewals happen every 30 seconds and for a minute it should be a factor of 2. //计算每分钟最大续约数 this.expectedNumberOfRenewsPerMin=count*2; //每分钟最小续约数 this.numberOfRenewsPerMinThreshold= (int) (this.expectedNumberOfRenewsPerMin*serverConfig.getRenewalPercentThreshold()); logger.info(\"Got \"+count+\" instances from neighboring DS node\"); logger.info(\"Renew threshold is: \"+numberOfRenewsPerMinThreshold); this.startupTime=System.currentTimeMillis(); if(count>0) { this.peerInstancesTransferEmptyOnStartup=false; } DataCenterInfo.Name selfName=applicationInfoManager.getInfo().getDataCenterInfo().getName(); boolean isAws=Name.Amazon==selfName; if(isAws&&serverConfig.shouldPrimeAwsReplicaConnections()) { logger.info(\"Priming AWS connections for all replicas..\"); primeAwsReplicas(applicationInfoManager); } logger.info(\"Changing status to UP\"); //设置实例的状态为UP applicationInfoManager.setInstanceStatus(InstanceStatus.UP); //开启定时任务，默认60秒执行一次，用于清理60秒之内没有续约的实例 super.postInit(); } 104 protected voidpostInit() { renewsLastMin.start(); if(evictionTaskRef.get()!=null) { evictionTaskRef.get().cancel(); } evictionTaskRef.set(newEvictionTask()); //服务剔除任务 evictionTimer.schedule(evictionTaskRef.get(), serverConfig.getEvictionIntervalTimerInMs(), serverConfig.getEvictionIntervalTimerInMs()); } 从上面的EurekaServerAutoConfiguration类，我们可以看到有个初始化EurekaServerContext的方法 @Bean publicEurekaServerContexteurekaServerContext(ServerCodecs serverCodecs,3PeerAwareInstanceRegistry registry,PeerEurekaNodes peerEurekaNodes) { 4return newDefaultEurekaServerContext(this.eurekaServerConfig,serverCodecs,5registry,peerEurekaNodes,this.applicationInfoManager); } DefaultEurekaServerContext 这个类里面的的initialize()方法是被@PostConstruct 这个注解修饰的,在应用加载的时候，会执行这个方法 public voidinitialize()throws Exception{2logger.info(\"Initializing ...\"); 3//启动一个线程，读取其他集群节点的信息，后面后续复制 peerEurekaNodes.start(); // registry.init(peerEurekaNodes); logger.info(\"Initialized\"); } peerEurekaNodes.start()主要是启动一个只拥有一个线程的线程池，第一次进去会更新一下集群其他节点信息然后启动了一个定时线程，每60秒更新一次，也就是说后续可以根据配置动态的修改节点配置。（原生的spring cloud config支持） public voidstart() { taskExecutor=Executors.newSingleThreadScheduledExecutor( 3newThreadFactory() { @Override publicThreadnewThread(Runnable r) { Thread thread=newThread(r,\"Eureka‐PeerNodesUpdater\"); thread.setDaemon(true); 8returnthread; } } ); try{ //首次进来，更新集群节点信息 updatePeerEurekaNodes(resolvePeerUrls()); //搞个线程 Runnable peersUpdateTask=newRunnable() { @Override public voidrun() { try{ updatePeerEurekaNodes(resolvePeerUrls()); }catch(Throwable e) { logger.error(\"Cannot update the replica Nodes\",e); } 24 } }; taskExecutor.scheduleWithFixedDelay( peersUpdateTask, serverConfig.getPeerEurekaNodesUpdateIntervalMs(), serverConfig.getPeerEurekaNodesUpdateIntervalMs(), TimeUnit.MILLISECONDS ); }catch(Exception e) { throw newIllegalStateException(e); } for(PeerEurekaNode node:peerEurekaNodes) { logger.info(\"Replica node URL: \"+node.getServiceUrl()); } } //根据URL构建PeerEurekaNode信息 protectedPeerEurekaNodecreatePeerEurekaNode(String peerEurekaNodeUrl) { HttpReplicationClient replicationClient=JerseyReplicationClient.createReplicationClient(serv rConfig,serverCodecs,peerEurekaNodeUrl); String targetHost=hostFromUrl(peerEurekaNodeUrl); if(targetHost==null) { targetHost=\"host\"; } return newPeerEurekaNode(registry,targetHost,peerEurekaNodeUrl,replicationClient,serverConfig); } 4、Eureka Client端源码分析 源码流程图参考： client初始化 @Inject DiscoveryClient(ApplicationInfoManager applicationInfoManager,EurekaClientConfig config,AbstractDiscoveryClientOptionalArgs args, ProviderbackupRegistryProvider) { 4//省略非关键代码。。。 5 logger.info(\"Initializing Eureka in region {}\",clientConfig.getRegion()); 7 //省略非关键代码。。。 9 try{ // default size of 2 ‐ 1 each for heartbeat and cacheRefresh scheduler=Executors.newScheduledThreadPool(2, newThreadFactoryBuilder() .setNameFormat(\"DiscoveryClient‐%d\") .setDaemon(true) .build()); 17 heartbeatExecutor=newThreadPoolExecutor( 1,clientConfig.getHeartbeatExecutorThreadPoolSize(),0,TimeUnit.SECONDS, newSynchronousQueue(), newThreadFactoryBuilder() .setNameFormat(\"DiscoveryClient‐HeartbeatExecutor‐%d\") .setDaemon(true) .build() );// use direct handoff 26 cacheRefreshExecutor=newThreadPoolExecutor( 1,clientConfig.getCacheRefreshExecutorThreadPoolSize(),0,TimeUnit.SECONDS, newSynchronousQueue(), newThreadFactoryBuilder() .setNameFormat(\"DiscoveryClient‐CacheRefreshExecutor‐%d\") .setDaemon(true) .build() );// use direct handoff 35 eurekaTransport=newEurekaTransport(); scheduleServerEndpointTask(eurekaTransport,args); 38 AzToRegionMapper azToRegionMapper; if(clientConfig.shouldUseDnsForFetchingServiceUrls()) { azToRegionMapper=newDNSBasedAzToRegionMapper(clientConfig); }else{ azToRegionMapper=newPropertyBasedAzToRegionMapper(clientConfig); } if(null!=remoteRegionsToFetch.get()) { azToRegionMapper.setRegionsToFetch(remoteRegionsToFetch.get().split(\",\")); } instanceRegionChecker=newInstanceRegionChecker(azToRegionMapper,clientConfig.getRegion()); }catch(Throwable e) { throw newRuntimeException(\"Failed to initialize DiscoveryClient!\",e); } 52 if(clientConfig.shouldFetchRegistry()&& !fetchRegistry(false)) { fetchRegistryFromBackup(); } 56 // call and execute the pre registration handler before all background tasks (inc registration) is started if(this.preRegistrationHandler!=null) { this.preRegistrationHandler.beforeRegistration(); } 61 if(clientConfig.shouldRegisterWithEureka()&&clientConfig.shouldEnforceRegistrationAtInit()) { try{ if(!register() ) { throw newIllegalStateException(\"Registration error at startup. Invalid server response.\"); } }catch(Throwable th) { logger.error(\"Registration error at startup: {}\",th.getMessage()); throw newIllegalStateException(th); } } 72 //最核心代码 // finally, init the schedule tasks (e.g. cluster resolvers, heartbeat, instanceInfo replicator fetch initScheduledTasks(); 76 try{ Monitors.registerObject(this); }catch(Throwable e) { logger.warn(\"Cannot register timers\",e); } 82 // This is a bit of hack to allow for existing code using DiscoveryManager.getInstance() // to work with DI'd DiscoveryClient DiscoveryManager.getInstance().setDiscoveryClient(this); DiscoveryManager.getInstance().setEurekaClientConfig(config); 87 initTimestampMs=System.currentTimeMillis(); logger.info(\"Discovery Client initialized at timestamp {} with initial instances count: {}\", initTimestampMs,this.getApplications().size()); } 初始化时启动核心功能定时任务 private voidinitScheduledTasks() { //获取服务注册列表信息 if(clientConfig.shouldFetchRegistry()) { //服务注册列表更新的周期时间 int registryFetchIntervalSeconds=clientConfig.getRegistryFetchIntervalSeconds(); int expBackOffBound=clientConfig.getCacheRefreshExecutorExponentialBackOffBound(); 7//定时更新服务注册列表 scheduler.schedule( newTimedSupervisorTask(10\"cacheRefresh\", 11scheduler, 12cacheRefreshExecutor, 13registryFetchIntervalSeconds, 14TimeUnit.SECONDS, 15expBackOffBound, 16newCacheRefreshThread()//该线程执行更新的具体逻辑 ), registryFetchIntervalSeconds,TimeUnit.SECONDS); } 20 if(clientConfig.shouldRegisterWithEureka()) { //服务续约的周期时间 int renewalIntervalInSecs=instanceInfo.getLeaseInfo().getRenewalIntervalInSecs(); int expBackOffBound=clientConfig.getHeartbeatExecutorExponentialBackOffBound(); //应用启动可见此日志，内容是：Starting heartbeat executor: renew interval is: 30 logger.info(\"Starting heartbeat executor: \"+\"renew interval is: \"+renewalIntervalInSecs); //服务定时续约 scheduler.schedule( newTimedSupervisorTask( \"heartbeat\", scheduler, heartbeatExecutor, renewalIntervalInSecs, TimeUnit.SECONDS, expBackOffBound, newHeartbeatThread()//该线程执行续约的具体逻辑 ), renewalIntervalInSecs,TimeUnit.SECONDS); 39 //这个Runable中含有服务注册的逻辑 instanceInfoReplicator=newInstanceInfoReplicator( this, instanceInfo, clientConfig.getInstanceInfoReplicationIntervalSeconds(), 2);// burstSize 46 statusChangeListener=newApplicationInfoManager.StatusChangeListener() { @Override publicStringgetId() { return\"statusChangeListener\"; } 52 @Override public voidnotify(StatusChangeEvent statusChangeEvent) { if(InstanceStatus.DOWN==statusChangeEvent.getStatus()|| InstanceStatus.DOWN==statusChangeEvent.getPreviousStatus()) { // log at warn level if DOWN was involved logger.warn(\"Saw local status change event {}\",statusChangeEvent); }else{ logger.info(\"Saw local status change event {}\",statusChangeEvent); } instanceInfoReplicator.onDemandUpdate(); } }; 65 if(clientConfig.shouldOnDemandUpdateStatusChange()) { applicationInfoManager.registerStatusChangeListener(statusChangeListener); } //服务注册 instanceInfoReplicator.start(clientConfig.getInitialInstanceInfoReplicationIntervalSeconds()); }else{ logger.info(\"Not registering with Eureka server per configuration\"); } } TimedSupervisorTask是一个Runnable接口实现，看下它的run方法 @Override public voidrun() { Futurefuture=null; 4try{ 5future=executor.submit(task); threadPoolLevelGauge.set((long)executor.getActiveCount()); //指定等待子线程的最长时间 future.get(timeoutMillis,TimeUnit.MILLISECONDS);// block until done or timeout 9//delay是个关键变量，后面会用到，这里记得每次执行任务成功都会将delay重置 10delay.set(timeoutMillis); 11threadPoolLevelGauge.set((long)executor.getActiveCount());12}catch(TimeoutException e) { 13logger.warn(\"task supervisor timed out\",e);14timeoutCounter.increment(); 15 long currentDelay=delay.get(); //任务线程超时的时候，就把delay变量翻倍，但不会超过外部调用时设定的最大延时时间 long newDelay=Math.min(maxDelay,currentDelay*2); //设置为最新的值，考虑到多线程，所以用了CAS delay.compareAndSet(currentDelay,newDelay); }catch(RejectedExecutionException e) { //一旦线程池的阻塞队列中放满了待处理任务，触发了拒绝策略，就会将调度器停掉 if(executor.isShutdown()||scheduler.isShutdown()) { logger.warn(\"task supervisor shutting down, reject the task\",e); }else{ logger.warn(\"task supervisor rejected the task\",e); } 28 rejectedCounter.increment(); }catch(Throwable e) { if(executor.isShutdown()||scheduler.isShutdown()) { logger.warn(\"task supervisor shutting down, can't accept the task\"); }else{ logger.warn(\"task supervisor threw an exception\",e); } 36 throwableCounter.increment(); }finally{ //这里任务要么执行完毕，要么发生异常，都用cancel方法来清理任务； if(future!=null) { future.cancel(true); } //只要调度器没有停止，就再指定等待时间之后在执行一次同样的任务 if(!scheduler.isShutdown()) { //假设外部调用时传入的超时时间为30秒（构造方法的入参timeout），最大间隔时间为50秒(构造方法的入参expBac kOffBound) //如果最近一次任务没有超时，那么就在30秒后开始新任务， //如果最近一次任务超时了，那么就在50秒后开始新任务（异常处理中有个乘以二的操作，乘以二后的60秒超过了最大间隔50秒） scheduler.schedule(this,delay.get(),TimeUnit.MILLISECONDS); } } } scheduler.schedule(this, delay.get(), TimeUnit.MILLISECONDS)，从代码注释上可以看出这个方法是一次性调用方法，但是实际上这个方法执行的任务会反复执行，秘密就在this对应的这个类TimedSupervisorTask的run方法 里，run方法任务执行完最后，会再次调用schedule方法，在指定的时间之后执行一次相同的任务，这个间隔时间和最近一次任务是否超时有关，如果超时了则下一次执行任务的间隔时间就会变大； 源码精髓： 从整体上看，TimedSupervisorTask是固定间隔的周期性任务，一旦遇到超时就会将下一个周期的间隔时间调大，如果连续超时，那么每次间隔时间都会增大一倍，一直到达外部参数设定的上限为止，一旦新任务不再超时，间隔时间又会自动恢复为初始值，另外还有CAS来控制多线程同步，这些是我们看源码需要学习到的设计技巧 定时更新服务注册列表线程CacheRefreshThread /** *The task that fetches the registry information at specified intervals. * */ classCacheRefreshThreadimplementsRunnable{6public voidrun() { refreshRegistry(); } } 10 @VisibleForTesting voidrefreshRegistry() { try{ boolean isFetchingRemoteRegionRegistries=isFetchingRemoteRegionRegistries(); 15 boolean remoteRegionsModified=false; // This makes sure that a dynamic change to remote regions to fetch is honored. String latestRemoteRegions=clientConfig.fetchRegistryForRemoteRegions(); //不做aws环境的配置这个if逻辑不会执行 if(null!=latestRemoteRegions) { String currentRemoteRegions=remoteRegionsToFetch.get(); if(!latestRemoteRegions.equals(currentRemoteRegions)) { // Both remoteRegionsToFetch and AzToRegionMapper.regionsToFetch need to be in sync synchronized(instanceRegionChecker.getAzToRegionMapper()) { if(remoteRegionsToFetch.compareAndSet(currentRemoteRegions,latestRemoteRegions)) { String[]remoteRegions=latestRemoteRegions.split(\",\"); remoteRegionsRef.set(remoteRegions); instanceRegionChecker.getAzToRegionMapper().setRegionsToFetch(remoteRegions); remoteRegionsModified=true; }else{ logger.info(\"Remote regions to fetch modified concurrently,\"+ \" ignoring change from {} to {}\",currentRemoteRegions,latestRemoteRegions); } } }else{ // Just refresh mapping to reflect any DNS/Property change instanceRegionChecker.getAzToRegionMapper().refreshMapping(); } } 40 //获取注册信息方法 boolean success=fetchRegistry(remoteRegionsModified); if(success) { registrySize=localRegionApps.get().size(); lastSuccessfulRegistryFetchTimestamp=System.currentTimeMillis(); } 47 //省略非关键代码。。。 }catch(Throwable e) { logger.error(\"Cannot fetch registry from server\",e); } } 53 privatebooleanfetchRegistry(boolean forceFullRegistryFetch) { Stopwatch tracer=FETCH_REGISTRY_TIMER.start(); 56 try{ // If the delta is disabled or if it is the first time, get all // applications //取出本地缓存之前获取的服务列表信息 Applications applications=getApplications(); 62 //判断多个条件，确定是否触发全量更新，如下任一个满足都会全量更新： //1.是否禁用增量更新； //2.是否对某个region特别关注； //3.外部调用时是否通过入参指定全量更新； //4.本地还未缓存有效的服务列表信息； if(clientConfig.shouldDisableDelta() ||(!Strings.isNullOrEmpty(clientConfig.getRegistryRefreshSingleVipAddress())) ||forceFullRegistryFetch ||(applications==null) ||(applications.getRegisteredApplications().size()==0) ||(applications.getVersion()== ‐1))//Client application does not have latest library supporting delta { logger.info(\"Disable delta property : {}\",clientConfig.shouldDisableDelta()); logger.info(\"Single vip registry refresh property : {}\",clientConfig.getRegistryRefreshSingleipAddress()); logger.info(\"Force full registry fetch : {}\",forceFullRegistryFetch); logger.info(\"Application is null : {}\", (applications==null)); logger.info(\"Registered Applications size is zero : {}\", (applications.getRegisteredApplications().size()==0)); logger.info(\"Application version is ‐1: {}\", (applications.getVersion()== ‐1)); //全量更新 getAndStoreFullRegistry(); }else{ //增量更新 getAndUpdateDelta(applications); } //重新计算和设置一致性hash码 applications.setAppsHashCode(applications.getReconcileHashCode()); logTotalInstances(); }catch(Throwable e) { logger.error(PREFIX+\"{} ‐ was unable to refresh its cache! status = {}\",appPathIdentifier,e.getMessage(),e); returnfalse; }finally{ if(tracer!=null) { tracer.stop(); } } 99 // Notify about cache refresh before updating the instance remote status //将本地缓存更新的事件广播给所有已注册的监听器，注意该方法已被CloudEurekaClient类重写 onCacheRefreshed(); 103 // Update remote status based on refreshed data held in the cache //检查刚刚更新的缓存中，有来自Eureka server的服务列表，其中包含了当前应用的状态， //当前实例的成员变量lastRemoteInstanceStatus，记录的是最后一次更新的当前应用状态， //上述两种状态在updateInstanceRemoteStatus方法中作比较 ，如果不一致，就更新lastRemoteInstanceStatu s，并且广播对应的事件 updateInstanceRemoteStatus(); 109 // registry was fetched successfully, so return true returntrue; } 全量更新getAndStoreFullRegistry private voidgetAndStoreFullRegistry()throws Throwable{ long currentUpdateGeneration=fetchRegistryGeneration.get(); 3 logger.info(\"Getting all instance registry info from the eureka server\"); 5 Applications apps=null; //由于并没有配置特别关注的region信息，因此会调用eurekaTransport.queryClient.getApplications方法从服务端获取服务列表 EurekaHttpResponsehttpResponse=clientConfig.getRegistryRefreshSingleVipAddress()==null ?eurekaTransport.queryClient.getApplications(remoteRegionsRef.get()) :eurekaTransport.queryClient.getVip(clientConfig.getRegistryRefreshSingleVipAddress(),remoteRegionsRef.get()); if(httpResponse.getStatusCode()==Status.OK.getStatusCode()) { //返回对象就是服务列表 apps=httpResponse.getEntity(); } logger.info(\"The response status is {}\",httpResponse.getStatusCode()); 16 if(apps==null) { logger.error(\"The application is null for some reason. Not storing this information\"); } //考虑到多线程同步，只有CAS成功的线程，才会把自己从Eureka server获取的数据来替换本地缓存 else if(fetchRegistryGeneration.compareAndSet(currentUpdateGeneration,currentUpdateGeneration+1)){ //localRegionApps就是本地缓存，是个AtomicReference实例 localRegionApps.set(this.filterAndShuffle(apps)); logger.debug(\"Got full registry with apps hashcode {}\",apps.getAppsHashCode()); }else{ logger.warn(\"Not updating applications as another thread is updating it already\"); } } 其中最重要的一段代码eurekaTransport.queryClient.getApplications(remoteRegionsRef.get())，和Eureka server交互的逻辑都在这里面，方法getApplications的具体实现是在EurekaHttpClientDecorator类 @Override publicEurekaHttpResponsegetApplications(final String...regions) {3returnexecute(newRequestExecutor() { @Override publicEurekaHttpResponseexecute(EurekaHttpClient delegate) { 6returndelegate.getApplications(regions); } 8 @Override publicRequestTypegetRequestType() { //本次向Eureka server请求的类型：获取服务列表 returnRequestType.GetApplications; } }); } debug进去delegate.getApplications(regions)方法会发现delegate实际用的是 AbstractJerseyEurekaHttpClient，里面都是具体的jersey实现的网络接口请求 @Override publicEurekaHttpResponsegetApplications(String...regions) {3//取全量数据的path是\"apps\" 4returngetApplicationsInternal(\"apps/\",regions); } 6 @Override publicEurekaHttpResponsegetDelta(String...regions) {9//取增量数据的path是\"apps/delta\" 10returngetApplicationsInternal(\"apps/delta\",regions); } 12 //具体的请求响应处理都在此方法中 privateEurekaHttpResponsegetApplicationsInternal(String urlPath,String[]regions) { ClientResponse response=null; String regionsParamValue=null; try{ //jersey、resource这些关键词都预示着这是个restful请求 WebResource webResource=jerseyClient.resource(serviceUrl).path(urlPath); if(regions!=null&&regions.length>0) { regionsParamValue=StringUtil.join(regions); webResource=webResource.queryParam(\"regions\",regionsParamValue); } Builder requestBuilder=webResource.getRequestBuilder(); addExtraHeaders(requestBuilder); //发起网络请求，将响应封装成ClientResponse实例 response=requestBuilder.accept(MediaType.APPLICATION_JSON_TYPE).get(ClientResponse.class); 28 Applications applications=null; if(response.getStatus()==Status.OK.getStatusCode()&&response.hasEntity()) { //取得全部应用信息 applications=response.getEntity(Applications.class); } returnanEurekaHttpResponse(response.getStatus(),Applications.class) .headers(headersOf(response)) .entity(applications) .build(); }finally{ if(logger.isDebugEnabled()) { logger.debug(\"Jersey HTTP GET {}/{}?{}; statusCode={}\", serviceUrl,urlPath, regionsParamValue==null?\"\":\"regions=\"+regionsParamValue, response==null?\"N/A\":response.getStatus() ); } if(response!=null) { response.close(); } } } 获取全量数据，是通过jersey-client库的API向Eureka server发起restful请求http://localhost:8761/eureka/apps实现的，并将响应的服务列表数据放在一个成员变量中作为本地缓存 1 UP_1_ 4 5MICROSERVICE‐PROVIDER‐USER6 7localhost:microservice‐provider‐user:80028192.168.101.1 9MICROSERVICE‐PROVIDER‐USER10192.168.101.1 11UP 12UNKNOWN138002 14443151 16 17MyOwn 18 19 2030 2190 221554360812763 231554360812763 0 1554360812763 8002 61822 http://192.168.101.1:8002/ http://192.168.101.1:8002/actuator/info http://192.168.101.1:8002/actuator/health microservice‐provider‐user microservice‐provider‐user false 1554360812764 1554360812649 ADDED 获取服务列表信息的增量更新getAndUpdateDelta private voidgetAndUpdateDelta(Applications applications)throws Throwable{2long currentUpdateGeneration=fetchRegistryGeneration.get(); 3 Applications delta=null; //增量信息是通过eurekaTransport.queryClient.getDelta方法完成的 EurekaHttpResponsehttpResponse=eurekaTransport.queryClient.getDelta(remoteRegi onsRef.get()); if(httpResponse.getStatusCode()==Status.OK.getStatusCode()) { 8//delta中保存了Eureka server返回的增量更新 9delta=httpResponse.getEntity(); } 11 if(delta==null) { logger.warn(\"The server does not allow the delta revision to be applied because it is not safe \" +\"Hence got the full registry.\"); //如果增量信息为空，就直接发起一次全量更新 getAndStoreFullRegistry(); } //考虑到多线程同步问题，这里通过CAS来确保请求发起到现在是线程安全的， //如果这期间fetchRegistryGeneration变了，就表示其他线程也做了类似操作，因此放弃本次响应的数据 else if(fetchRegistryGeneration.compareAndSet(currentUpdateGeneration,currentUpdateGeneration+1)){ logger.debug(\"Got delta update with apps hashcode {}\",delta.getAppsHashCode()); String reconcileHashCode=\"\"; if(fetchRegistryUpdateLock.tryLock()) { try{ //用Eureka返回的增量数据和本地数据做合并操作，这个方法稍后会细说 updateDelta(delta); //用合并了增量数据之后的本地数据来生成一致性哈希码 reconcileHashCode=getReconcileHashCode(applications); }finally{ fetchRegistryUpdateLock.unlock(); } }else{ logger.warn(\"Cannot acquire update lock, aborting getAndUpdateDelta\"); } //Eureka server在返回增量更新数据时，也会返回服务端的一致性哈希码， //理论上每次本地缓存数据经历了多次增量更新后，计算出的一致性哈希码应该是和服务端一致的， //如果发现不一致，就证明本地缓存的服务列表信息和Eureka server不一致了，需要做一次全量更新 if(!reconcileHashCode.equals(delta.getAppsHashCode())||clientConfig.shouldLogDeltaDiff()) { //一致性哈希码不同，就在reconcileAndLogDifference方法中做全量更新 reconcileAndLogDifference(delta,reconcileHashCode);// this makes a remoteCall } }else{ logger.warn(\"Not updating application delta as another thread is updating it already\"); logger.debug(\"Ignoring delta update with apps hashcode {}, as another thread is updating it aleady\",delta.getAppsHashCode()); } } updateDelta方法将增量更新数据和本地数据做合并 private voidupdateDelta(Applications delta) {2int deltaCount=0; 3//遍历所有服务 4for(Application app:delta.getRegisteredApplications()) { 5//遍历当前服务的所有实例 6for(InstanceInfo instance:app.getInstances()) { 7//取出缓存的所有服务列表，用于合并 8Applications applications=getApplications(); 9String instanceRegion=instanceRegionChecker.getInstanceRegion(instance); 10//判断正在处理的实例和当前应用是否在同一个region 11if(!instanceRegionChecker.isLocalRegion(instanceRegion)) { //如果不是同一个region，接下来合并的数据就换成专门为其他region准备的缓存 Applications remoteApps=remoteRegionVsApps.get(instanceRegion); if(null==remoteApps) { remoteApps=newApplications(); remoteRegionVsApps.put(instanceRegion,remoteApps); } applications=remoteApps; } 20 ++deltaCount; 22 if(ActionType.ADDED.equals(instance.getActionType())) {//对新增的实例的处理 Application existingApp=applications.getRegisteredApplications(instance.getAppName()); if(existingApp==null) { applications.addApplication(app); } logger.debug(\"Added instance {} to the existing apps in region {}\",instance.getId(),instanceR egion); applications.getRegisteredApplications(instance.getAppName()).addInstance(instance); }else if(ActionType.MODIFIED.equals(instance.getActionType())) {//对修改实例的处理 Application existingApp=applications.getRegisteredApplications(instance.getAppName()); if(existingApp==null) { applications.addApplication(app); } logger.debug(\"Modified instance {} to the existing apps \",instance.getId()); 36 applications.getRegisteredApplications(instance.getAppName()).addInstance(instance); 38 }else if(ActionType.DELETED.equals(instance.getActionType())) {//对删除实例的处理 Application existingApp=applications.getRegisteredApplications(instance.getAppName()); if(existingApp==null) { applications.addApplication(app); } logger.debug(\"Deleted instance {} to the existing apps \",instance.getId()); applications.getRegisteredApplications(instance.getAppName()).removeInstance(instance); } } } logger.debug(\"The total number of instances fetched by the delta processor : {}\",deltaCount); 50 getApplications().setVersion(delta.getVersion()); //整理数据，使得后续使用过程中，这些应用的实例总是以相同顺序返回 getApplications().shuffleInstances(clientConfig.shouldFilterOnlyUpInstances()); 54 //和当前应用不在同一个region的应用，其实例数据也要整理 for(Applications applications:remoteRegionVsApps.values()) { applications.setVersion(delta.getVersion()); applications.shuffleInstances(clientConfig.shouldFilterOnlyUpInstances()); } } 服务续约 //服务定时续约 scheduler.schedule( newTimedSupervisorTask( \"heartbeat\", scheduler, heartbeatExecutor, renewalIntervalInSecs, TimeUnit.SECONDS, 9expBackOffBound, 10newHeartbeatThread()//该线程执行续约的具体逻辑，会调用下面的renew()方法 ), renewalIntervalInSecs,TimeUnit.SECONDS); 13 private classHeartbeatThreadimplementsRunnable{ public voidrun() { if(renew()) { lastSuccessfulHeartbeatTimestamp=System.currentTimeMillis(); } } } 21 booleanrenew() { EurekaHttpResponsehttpResponse; try{ httpResponse=eurekaTransport.registrationClient.sendHeartBeat(instanceInfo.getAppName(),inst anceInfo.getId(),instanceInfo,null); logger.debug(PREFIX+\"{} ‐ Heartbeat status: {}\",appPathIdentifier,httpResponse.getStatusCode()); if(httpResponse.getStatusCode()==404) { REREGISTER_COUNTER.increment(); logger.info(PREFIX+\"{} ‐ Re‐registering apps/{}\",appPathIdentifier, instanceInfo.getAppName()); long timestamp=instanceInfo.setIsDirtyWithTime(); boolean success=register(); if(success) { instanceInfo.unsetIsDirty(timestamp); } returnsuccess; } returnhttpResponse.getStatusCode()==200; }catch(Throwable e) { logger.error(PREFIX+\"{} ‐ was unable to send heartbeat!\",appPathIdentifier,e); returnfalse; } } 服务注册 //服务注册 instanceInfoReplicator.start(clientConfig.getInitialInstanceInfoReplicationIntervalSeconds()); 3 public voidstart(int initialDelayMs) { if(started.compareAndSet(false,true)) { instanceInfo.setIsDirty();// for initial register Future next=scheduler.schedule(this,initialDelayMs,TimeUnit.SECONDS); scheduledPeriodicRef.set(next); } } 11 public voidrun() { try{ discoveryClient.refreshInstanceInfo(); 15 Long dirtyTimestamp=instanceInfo.isDirtyWithTime(); if(dirtyTimestamp!=null) { discoveryClient.register(); instanceInfo.unsetIsDirty(dirtyTimestamp); } }catch(Throwable t) { logger.warn(\"There was a problem with the instance info replicator\",t); }finally{ Future next=scheduler.schedule(this,replicationIntervalSeconds,TimeUnit.SECONDS); scheduledPeriodicRef.set(next); } } 5、Eureka Server服务端Jersey接口源码分析 服务端Jersey接口处理类ApplicationResource 其中有一个addInstance方法就是用来接收客户端的注册请求接口 //ApplicationResource.java 2@POST 3@Consumes({\"application/json\",\"application/xml\"}) 4publicResponseaddInstance(InstanceInfo info, 5@HeaderParam(PeerEurekaNode.HEADER_REPLICATION)String isReplication) { 6logger.debug(\"Registering instance {} (replication={})\",info.getId(),isReplication);7// validate that the instanceinfo contains all the necessary required fields //参数校验，不符合验证规则的，返回400状态码，此处不做详解 9if(isBlank(info.getId())) { 10returnResponse.status(400).entity(\"Missing instanceId\").build();11}else if(isBlank(info.getHostName())) { 12returnResponse.status(400).entity(\"Missing hostname\").build();13}else if(isBlank(info.getAppName())) { 14returnResponse.status(400).entity(\"Missing appName\").build();15}else if(!appName.equals(info.getAppName())) { returnResponse.status(400).entity(\"Mismatched appName, expecting \"+appName+\" but was \"+info.getAppName()).build(); }else if(info.getDataCenterInfo()==null) { returnResponse.status(400).entity(\"Missing dataCenterInfo\").build(); }else if(info.getDataCenterInfo().getName()==null) { returnResponse.status(400).entity(\"Missing dataCenterInfo Name\").build(); } 22 // handle cases where clients may be registering with bad DataCenterInfo with missing data DataCenterInfo dataCenterInfo=info.getDataCenterInfo(); if(dataCenterInfoinstanceofUniqueIdentifier) { String dataCenterInfoId=((UniqueIdentifier)dataCenterInfo).getId(); if(isBlank(dataCenterInfoId)) { boolean experimental=\"true\".equalsIgnoreCase(serverConfig.getExperimental(\"registration.validation.dataCenterInfoId\")); if(experimental) { String entity=\"DataCenterInfo of type \"+dataCenterInfo.getClass()+\" must contain a validid\"; returnResponse.status(400).entity(entity).build(); }else if(dataCenterInfoinstanceofAmazonInfo) { AmazonInfo amazonInfo=(AmazonInfo)dataCenterInfo; String effectiveId=amazonInfo.get(AmazonInfo.MetaDataKey.instanceId); if(effectiveId==null) { amazonInfo.getMetadata().put(AmazonInfo.MetaDataKey.instanceId.getName(),info.getId()); } }else{ logger.warn(\"Registering DataCenterInfo of type {} without an appropriate id\",dataCenterInfo.etClass()); } } } //重点在这里 registry.register(info,\"true\".equals(isReplication)); returnResponse.status(204).build();// 204 to be backwards compatible } AbstractInstanceRegistry的注册方法 public voidregister(InstanceInfo registrant,int leaseDuration,boolean isReplication) {2try{ 3//上只读锁 read.lock(); //从本地MAP里面获取当前实例的信息。 Map>gMap=registry.get(registrant.getAppName()); //增加注册次数到监控信息里面去。 REGISTER.increment(isReplication); 9if(gMap==null) { 10//如果第一次进来，那么gMap为空，则创建一个ConcurrentHashMap放入到registry里面去 final ConcurrentHashMap>gNewMap=newConcurrentHashMap>(); // putIfAbsent方法主要是在向ConcurrentHashMap中添加键—值对的时候，它会先判断该键值对是否已经存在。 //如果不存在（新的entry），那么会向map中添加该键值对，并返回null。 //如果已经存在，那么不会覆盖已有的值，直接返回已经存在的值。 gMap=registry.putIfAbsent(registrant.getAppName(),gNewMap); if(gMap==null) { //表明map中确实不存在，则设置gMap为最新创建的那个 gMap=gNewMap; } } //从MAP中查询已经存在的Lease信息 （比如第二次来） LeaseexistingLease=gMap.get(registrant.getId()); //当Lease的对象不为空时。 if(existingLease!=null&&(existingLease.getHolder()!=null)) { //当instance已经存在是，和客户端的instance的信息做比较，时间最新的那个，为有效instance信息 Long existingLastDirtyTimestamp=existingLease.getHolder().getLastDirtyTimestamp();// server Long registrationLastDirtyTimestamp=registrant.getLastDirtyTimestamp();// client logger.debug(\"Existing lease found (existing={}, provided={}\",existingLastDirtyTimestamp,reg strationLastDirtyTimestamp); if(existingLastDirtyTimestamp>registrationLastDirtyTimestamp) { logger.warn(\"There is an existing lease and the existing lease's dirty timestamp {} is greater + \" than the one that is being registered {}\",existingLastDirtyTimestamp,registrationLastDirtyimestamp); logger.warn(\"Using the existing instanceInfo instead of the new instanceInfo as theregistrant\"); registrant=existingLease.getHolder(); } }else{ //这里只有当existinglease不存在时，才会进来。 像那种恢复心跳，信息过期的，都不会进入这里。 // Eureka‐Server的自我保护机制做的操作，为每分钟最大续约数+2，同时重新计算每分钟最小续约数 synchronized(lock) { if(this.expectedNumberOfRenewsPerMin>0) { // Since the client wants to cancel it, reduce the threshold // (1 for 30 seconds, 2 for a minute) this.expectedNumberOfRenewsPerMin=this.expectedNumberOfRenewsPerMin+2; this.numberOfRenewsPerMinThreshold= (int) (this.expectedNumberOfRenewsPerMin*serverConfig.getRenewalPercentThreshold()); } } logger.debug(\"No previous lease information found; it is new registration\"); } //构建一个最新的Lease信息 Leaselease=newLease(registrant,leaseDuration); if(existingLease!=null) { //当原来存在Lease的信息时，设置他的serviceUpTimestamp,保证服务开启的时间一直是第一次的那个 lease.setServiceUpTimestamp(existingLease.getServiceUpTimestamp()); } //放入本地Map中 gMap.put(registrant.getId(),lease); //添加到最近的注册队列里面去，以时间戳作为Key， 名称作为value，主要是为了运维界面的统计数据。 synchronized(recentRegisteredQueue) { recentRegisteredQueue.add(newPair( System.currentTimeMillis(), registrant.getAppName()+\"(\"+registrant.getId()+\")\")); } // This is where the initial state transfer of overridden status happens //分析instanceStatus if(!InstanceStatus.UNKNOWN.equals(registrant.getOverriddenStatus())) { logger.debug(\"Found overridden status {} for instance {}. Checking to see if needs to be add tthe \" +\"overrides\",registrant.getOverriddenStatus(),registrant.getId()); if(!overriddenInstanceStatusMap.containsKey(registrant.getId())) { logger.info(\"Not found overridden id {} and hence adding it\",registrant.getId()); overriddenInstanceStatusMap.put(registrant.getId(),registrant.getOverriddenStatus()); } } InstanceStatus overriddenStatusFromMap=overriddenInstanceStatusMap.get(registrant.getId()); if(overriddenStatusFromMap!=null) { logger.info(\"Storing overridden status {} from map\",overriddenStatusFromMap); registrant.setOverriddenStatus(overriddenStatusFromMap); } 78 // Set the status based on the overridden status rules InstanceStatus overriddenInstanceStatus=getOverriddenInstanceStatus(registrant,existingLease,isReplication); registrant.setStatusWithoutDirty(overriddenInstanceStatus); 82 // If the lease is registered with UP status, set lease service up timestamp //得到instanceStatus，判断是否是UP状态， if(InstanceStatus.UP.equals(registrant.getStatus())) { lease.serviceUp(); } //设置注册类型为添加 registrant.setActionType(ActionType.ADDED); //租约变更记录队列，记录了实例的每次变化， 用于注册信息的增量获取、 recentlyChangedQueue.add(newRecentlyChangedItem(lease)); registrant.setLastUpdatedTimestamp(); //清理缓存 ，传入的参数为key invalidateCache(registrant.getAppName(),registrant.getVIPAddress(),registrant.getSecureVipAdd ress()); logger.info(\"Registered instance {}/{} with status {} (replication={})\", registrant.getAppName(),registrant.getId(),registrant.getStatus(),isReplication); }finally{ read.unlock(); } } 理解上面的register还需要先了解下注册实例信息存放的的map，这是个两层的ConcurrentHashMap>>，外层map的key是appName，也就是服务名，内层map的key是 instanceId，也就是实例名 注册表map数据示例如下： { MICROSERVICE - PROVIDER - USER = { DESKTOP - 1 SLJLB7: microservice - provider - user: 8002 = com.netflix.eureka.lease.Lease @2cd36af6, DESKTOP - 1 SLJLB7: microservice - provider - user: 8001 = com.netflix.eureka.lease.Lease @600b7073 } } 内层map的value对应的类Lease需要重点理解下 public classLease{ 2 enumAction{ Register,Cancel,Renew }; 6 public staticfinal intDEFAULT_DURATION_IN_SECS=90; 8 privateTholder; privatelong evictionTimestamp; privatelong registrationTimestamp; privatelong serviceUpTimestamp; // Make it volatile so that the expiration task would see this quicker privatevolatile long lastUpdateTimestamp; privatelong duration; 16 publicLease(Tr,int durationInSecs) { holder=r; registrationTimestamp=System.currentTimeMillis(); lastUpdateTimestamp=registrationTimestamp; duration=(durationInSecs*1000); 22 } 24 /** *Renew the lease,use renewal durationifit was specified by the *associated{@linkT}during registration,otherwisedefaultduration is *{@link #DEFAULT_DURATION_IN_SECS}. */ public voidrenew() { lastUpdateTimestamp=System.currentTimeMillis()+duration;//有个小bug，不应该加duration 32 } 34 /** *Cancels the lease by updating the eviction time. */ public voidcancel() { if(evictionTimestamp evictionTimestamp=System.currentTimeMillis(); } } 43 /** *Mark the serviceasup.This will only take affect the first time called, *subsequent calls will be ignored. */ public voidserviceUp() { if(serviceUpTimestamp==0) { serviceUpTimestamp=System.currentTimeMillis(); } } 53 /** *Set the leases serviceUPtimestamp. */ public voidsetServiceUpTimestamp(long serviceUpTimestamp) { this.serviceUpTimestamp=serviceUpTimestamp; } 60 /** *Checksifthe leaseofa given{@link com.netflix.appinfo.InstanceInfo}has expired or not. */ publicbooleanisExpired() { returnisExpired(0l); } 67 /** *Checksifthe leaseofa given{@link com.netflix.appinfo.InstanceInfo}has expired or not. * *Note that due torenew()doing the 'wrong\" thing and setting lastUpdateTimestamp to+duratiomore than what it should be,the expiry will actually be2duration.This is a minor bug and shouldnly affect *instances that ungracefully shutdown.Due to possible wide ranging impact to existing usage,thiswill *not be fixed. * *@param additionalLeaseMs any additional lease time to add to the lease evaluationinms. */ publicbooleanisExpired(long additionalLeaseMs) { return(evictionTimestamp>0||System.currentTimeMillis()>(lastUpdateTimestamp+duration+additionalLeaseMs)); } 81 /** *Gets the milliseconds since epoch when the lease was registered. * *@returnthe milliseconds since epoch when the lease was registered. */ publiclonggetRegistrationTimestamp() { returnregistrationTimestamp; } 90 /** *Gets the milliseconds since epoch when the lease was last renewed. *Note that the value returned here is actually not the last lease renewal time but the renewa+duration. * *@returnthe milliseconds since epoch when the lease was last renewed. */ publiclonggetLastRenewalTimestamp() { returnlastUpdateTimestamp; } 100 /** *Gets the milliseconds since epoch when the lease was evicted. * *@returnthe milliseconds since epoch when the lease was evicted. */ publiclonggetEvictionTimestamp() { returnevictionTimestamp; } 109 /** *Gets the milliseconds since epoch when the serviceforthe lease was markedasup. * *@returnthe milliseconds since epoch when the serviceforthe lease was markedasup. */ publiclonggetServiceUpTimestamp() { returnserviceUpTimestamp; } 118 /** *Returns the holderofthe lease. */ publicTgetHolder() { returnholder; } 125 } DEFAULT_DURATION_IN_SECS : 租约过期的时间常量，默认未90秒，也就说90秒没有心跳过来，那么这边将会自动剔除该节点 holder ：这个租约是属于谁的，目前占用这个属性的是 instanceInfo，也就是客户端实例信息。 evictionTimestamp ：租约是啥时候过期的，当服务下线的时候，会过来更新这个时间戳registrationTimestamp ：租约的注册时间 serviceUpTimestamp ：服务启动时间，当客户端在注册的时候，instanceInfo的status 为UP的时候，则更新这个时间戳 lastUpdateTimestamp ：最后更新时间，每次续约的时候，都会更新这个时间戳，在判断实例 是否过期时，需要用到这个属性。 duration：过期时间，毫秒单位 服务端Jersey接口处理类ApplicationsResource 其中有一个getContainers方法就是用来获取所有注册实例信息的接口 @GET publicResponsegetContainers(@PathParam(\"version\")String version,3@HeaderParam(HEADER_ACCEPT)String acceptHeader, 4@HeaderParam(HEADER_ACCEPT_ENCODING)String acceptEncoding, 5@HeaderParam(EurekaAccept.HTTP_X_EUREKA_ACCEPT)String eurekaAccept,6@Context UriInfo uriInfo, 7@Nullable @QueryParam(\"regions\")String regionsStr) { 8 boolean isRemoteRegionRequested=null!=regionsStr&& !regionsStr.isEmpty();10String[]regions=null; 11if(!isRemoteRegionRequested) { 12EurekaMonitors.GET_ALL.increment(); 13}else{ 14regions=regionsStr.toLowerCase().split(\",\"); Arrays.sort(regions);// So we don't have different caches for same regions queried in differet order. EurekaMonitors.GET_ALL_WITH_REMOTE_REGIONS.increment(); } 18 // Check if the server allows the access to the registry. The server can // restrict access if it is not // ready to serve traffic depending on various reasons. if(!registry.shouldAllowAccess(isRemoteRegionRequested)) { returnResponse.status(Status.FORBIDDEN).build(); } CurrentRequestVersion.set(Version.toEnum(version)); KeyType keyType=Key.KeyType.JSON; String returnMediaType=MediaType.APPLICATION_JSON; if(acceptHeader==null|| !acceptHeader.contains(HEADER_JSON_VALUE)) { keyType=Key.KeyType.XML; returnMediaType=MediaType.APPLICATION_XML; } 32 //获取服务实例对应的缓存key Key cacheKey=newKey(Key.EntityType.Application, ResponseCacheImpl.ALL_APPS, keyType,CurrentRequestVersion.get(),EurekaAccept.fromString(eurekaAccept),regions ); 38 Response response; if(acceptEncoding!=null&&acceptEncoding.contains(HEADER_GZIP_VALUE)) { response=Response.ok(responseCache.getGZIP(cacheKey)) .header(HEADER_CONTENT_ENCODING,HEADER_GZIP_VALUE) .header(HEADER_CONTENT_TYPE,returnMediaType) .build(); }else{ //从缓存里获取服务实例注册信息 response=Response.ok(responseCache.get(cacheKey)) .build(); } returnresponse; } 52 responseCache.get(cacheKey)对应的源码如下： @VisibleForTesting Stringget(final Key key,boolean useReadOnlyCache) { //从多级缓存里获取注册实例信息 Value payload=getValue(key,useReadOnlyCache); if(payload==null||payload.getPayload().equals(EMPTY_PAYLOAD)) { return null; }else{ returnpayload.getPayload(); } } 64 @VisibleForTesting ValuegetValue(final Key key,boolean useReadOnlyCache) { Value payload=null; try{ if(useReadOnlyCache) { final Value currentPayload=readOnlyCacheMap.get(key); if(currentPayload!=null) { payload=currentPayload; }else{ payload=readWriteCacheMap.get(key); readOnlyCacheMap.put(key,payload); } }else{ payload=readWriteCacheMap.get(key); } }catch(Throwable t) { logger.error(\"Cannot get value for key : {}\",key,t); } returnpayload; } 85 86 ResponseCacheImpl(EurekaServerConfig serverConfig,ServerCodecs serverCodecs,AbstractInstanceRgistry registry) { this.serverConfig=serverConfig; this.serverCodecs=serverCodecs; this.shouldUseReadOnlyResponseCache=serverConfig.shouldUseReadOnlyResponseCache(); this.registry=registry; 92 long responseCacheUpdateIntervalMs=serverConfig.getResponseCacheUpdateIntervalMs(); this.readWriteCacheMap= CacheBuilder.newBuilder().initialCapacity(1000) //读写缓存默认180秒会自动定时过期 .expireAfterWrite(serverConfig.getResponseCacheAutoExpirationInSeconds(),TimeUnit.SECONDS) .removalListener(newRemovalListener() { @Override public voidonRemoval(RemovalNotificationnotification) { Key removedKey=notification.getKey(); if(removedKey.hasRegions()) { Key cloneWithNoRegions=removedKey.cloneWithoutRegions(); regionSpecificKeys.remove(cloneWithNoRegions,removedKey); } } }) .build(newCacheLoader() { @Override publicValueload(Key key)throws Exception{ if(key.hasRegions()) { Key cloneWithNoRegions=key.cloneWithoutRegions(); regionSpecificKeys.put(cloneWithNoRegions,key); } Value value=generatePayload(key); returnvalue; } }); 119 if(shouldUseReadOnlyResponseCache) { //默认30秒用读写缓存的数据更新只读缓存的数据 timer.schedule(getCacheUpdateTask(), newDate(((System.currentTimeMillis()/responseCacheUpdateIntervalMs)*responseCacheUpdateIntervalMs) +responseCacheUpdateIntervalMs), responseCacheUpdateIntervalMs); } 127 try{ Monitors.registerObject(this); }catch(Throwable e) { logger.warn(\"Cannot register the JMX monitor for the InstanceRegistry\",e); } } 134 //初始化直接从注册表registry里那数据放入readWriteCacheMap privateValuegeneratePayload(Key key) { Stopwatch tracer=null; try{ String payload; switch(key.getEntityType()) { caseApplication: boolean isRemoteRegionRequested=key.hasRegions(); 143 if(ALL_APPS.equals(key.getName())) { if(isRemoteRegionRequested) { tracer=serializeAllAppsWithRemoteRegionTimer.start(); payload=getPayLoad(key,registry.getApplicationsFromMultipleRegions(key.getRegions())); }else{ tracer=serializeAllAppsTimer.start(); payload=getPayLoad(key,registry.getApplications()); } }else if(ALL_APPS_DELTA.equals(key.getName())) { if(isRemoteRegionRequested) { tracer=serializeDeltaAppsWithRemoteRegionTimer.start(); versionDeltaWithRegions.incrementAndGet(); versionDeltaWithRegionsLegacy.incrementAndGet(); payload=getPayLoad(key, registry.getApplicationDeltasFromMultipleRegions(key.getRegions())); }else{ tracer=serializeDeltaAppsTimer.start(); versionDelta.incrementAndGet(); versionDeltaLegacy.incrementAndGet(); payload=getPayLoad(key,registry.getApplicationDeltas()); } }else{ tracer=serializeOneApptimer.start(); payload=getPayLoad(key,registry.getApplication(key.getName())); } break; caseVIP: caseSVIP: tracer=serializeViptimer.start(); payload=getPayLoad(key,getApplicationsForVip(key,registry)); break; default: logger.error(\"Unidentified entity type: {} found in the cache key.\",key.getEntityType()); payload=\"\"; break; } return newValue(payload); }finally{ if(tracer!=null) { tracer.stop(); } } } 187 //用读写缓存的数据更新只读缓存的数据 privateTimerTaskgetCacheUpdateTask() { return newTimerTask() { @Override public voidrun() { logger.debug(\"Updating the client cache from response cache\"); for(Key key:readOnlyCacheMap.keySet()) { if(logger.isDebugEnabled()) { logger.debug(\"Updating the client cache from response cache for key : {} {} {} {}\", key.getEntityType(),key.getName(),key.getVersion(),key.getType()); } try{ CurrentRequestVersion.set(key.getVersion()); Value cacheValue=readWriteCacheMap.get(key); Value currentCacheValue=readOnlyCacheMap.get(key); if(cacheValue!=currentCacheValue) { readOnlyCacheMap.put(key,cacheValue); } }catch(Throwable th) { logger.error(\"Error while updating the client cache from response cache for key {}\",key.toStringCompact(),th); } } } }; } 源码精髓：多级缓存设计思想 在拉取注册表的时候： 首先从ReadOnlyCacheMap里查缓存的注册表。 若没有，就找ReadWriteCacheMap里缓存的注册表。 如果还没有，就从内存中获取实际的注册表数据。 在注册表发生变更的时候： 会在内存中更新变更的注册表数据，同时过期掉ReadWriteCacheMap。 此过程不会影响ReadOnlyCacheMap提供人家查询注册表。 默认每30秒Eureka Server会将ReadWriteCacheMap更新到ReadOnlyCacheMap里 默认每180秒Eureka Server会将ReadWriteCacheMap里是数据失效 下次有服务拉取注册表，又会从内存中获取最新的数据了，同时填充各级缓存。 多级缓存机制的优点： 尽可能保证了内存注册表数据不会出现频繁的读写冲突问题。 并且进一步保证对Eureka Server的大量请求，都是快速从纯内存走，性能极高（可以稍微估计下对于一线互联网公司，内部上千个eureka client实例，每分钟对eureka上千次的访问，一天就是上千万次的访问） 看源码彻底搞懂一些诡异的问题： 看完多级缓存这块源码我们可以搞清楚一个常见的问题，就是当我们eureka服务实例有注册或下线或有实例发生故障，内存注册表虽然会及时更新数据，但是客户端不一定能及时感知到，可能会过30秒才能感知到，因为客户端拉取注册表实例这里面有一个多级缓存机制 还有服务剔除的不是默认90秒没心跳的实例，剔除的是180秒没心跳的实例(eureka的bug导致) Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-20 10:32:49 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"micro/Hystrix-source.html":{"url":"micro/Hystrix-source.html","title":"10.Hystrix&Zuul源码分析","keywords":"","body":"Hystrix方法执行与降级方法执行源码分析 主要对加了@HystrixCommand注解的方法用AOP拦截实现类HystrixCommandAspect去拦截，主要拦截执行方法如下 publicObjectmethodsAnnotatedWithHystrixCommand(final ProceedingJoinPoint joinPoint)throwshrowable{ //被@HystrixCommand标记的hello()方法 Method method=getMethodFromTarget(joinPoint); MetaHolderFactory metaHolderFactory= ...get(HystrixPointcutType.of(method)); 5MetaHolder metaHolder=metaHolderFactory.create(joinPoint); 6//准备各种材料后，创建HystrixInvokable 7HystrixInvokable invokable=HystrixCommandFactory.getInstance().create(metaHolder);8Object result; 9try{ 10if(!metaHolder.isObservable()) { 11//利用工具CommandExecutor来执行具体的方法 12result=CommandExecutor.execute(invokable,executionType,metaHolder); } } returnresult; } HystrixInvokable 只是一个空接口，没有任何方法，只是用来标记具备可执行的能力。 那 HystrixInvokable 又是如何创建的？它具体的实现类又是什么？先看 看H ystrixC om m andFactory.getInstance().create()的代码。 1publicHystrixInvokablecreate(MetaHolder metaHolder) { 2return newGenericCommand(...create(metaHolder)); } GenericCommand 负责执行具体的方法和fallback时的方法 //执行具体的方法，如：OrderController的findById() 2protectedObjectrun()throws Exception{ 3returnprocess(newAction() { @Override Objectexecute() { returngetCommandAction().execute(getExecutionType()); } }); } //执行fallback方法，如：OrderController的findByIdFallback() protectedObjectgetFallback() { final CommandAction commandAction=getFallbackAction(); returnprocess(newAction() { @Override Objectexecute() { MetaHolder metaHolder=commandAction.getMetaHolder(); Object[]args=createArgsForFallback(...); returncommandAction.executeWithArgs(...,args); } }); } toObservable()核心源码解析 publicObservabletoObservable() {2final AbstractCommand_cmd=this; 3//命令执行结束后的清理者 4final Action0 terminateCommandCleanup=newAction0() {...}; 5//取消订阅时处理者 6final Action0 unsubscribeCommandCleanup=newAction0() {...}; 7//重点：Hystrix核心逻辑:断路器、隔离 8final Func0>applyHystrixSemantics=newFunc0>() {...}; 9//发射数据(OnNext表示发射数据)时的Hook 10final Func1wrapWithAllOnNextHooks=newFunc1() {...}; 11//命令执行完成的Hook 12final Action0 fireOnCompletedHook=newAction0() {...};13//通过Observable.defer()创建一个Observable 14returnObservable.defer(newFunc0>() {15@Override 16publicObservablecall() { 17final boolean requestCacheEnabled=isRequestCachingEnabled(); 18final String cacheKey=getCacheKey(); 19//首先尝试从请求缓存中获取结果 20if(requestCacheEnabled) { HystrixCommandResponseFromCachefromCache=(HystrixCommandResponseFromCache)requestC ache.get(cacheKey); if(fromCache!=null) { isResponseFromCache=true; returnhandleRequestCacheHitAndEmitValues(fromCache,_cmd); } } //使用上面的Func0：applyHystrixSemantics来创建Observable ObservablehystrixObservable= Observable.defer(applyHystrixSemantics) .map(wrapWithAllOnNextHooks); ObservableafterCache; //如果启用请求缓存，将Observable包装成HystrixCachedObservable并进行相关处理 if(requestCacheEnabled&&cacheKey!=null) { HystrixCachedObservabletoCache=HystrixCachedObservable.from(hystrixObservable,_cmd); ... }else{ afterCache=hystrixObservable; } //返回Observable returnafterCache .doOnTerminate(terminateCommandCleanup) .doOnUnsubscribe(unsubscribeCommandCleanup) .doOnCompleted(fireOnCompletedHook); } }); } 断路器、隔离核心代码applyHystrixSemantics() // Semantics译为语义,应用Hystrix语义很拗口，其实就是应用Hystrix的断路器、隔离特性 2privateObservableapplyHystrixSemantics(final AbstractCommand_cmd) { //源码中有很多executionHook、eventNotifier的操作，这是Hystrix拓展性的一种体现。这里面啥事也没做，留了个口子，开发人员可以拓展 executionHook.onStart(_cmd); //判断断路器是否开启 if(circuitBreaker.attemptExecution()) { 7//获取执行信号 8final TryableSemaphore executionSemaphore=getExecutionSemaphore(); 9final AtomicBoolean semaphoreHasBeenReleased=newAtomicBoolean(false);10final Action0 singleSemaphoreRelease=newAction0() {...}; 11final Action1markExceptionThrown=newAction1() {...}; 12//判断是否信号量拒绝 13if(executionSemaphore.tryAcquire()) { 14try{ 15//重点：处理隔离策略和Fallback策略 16returnexecuteCommandAndObserve(_cmd) 17.doOnError(markExceptionThrown) 18.doOnTerminate(singleSemaphoreRelease) 19.doOnUnsubscribe(singleSemaphoreRelease); 20}catch(RuntimeException e) { 21returnObservable.error(e); } }else{ returnhandleSemaphoreRejectionViaFallback(); } } //开启了断路器,执行Fallback else{ returnhandleShortCircuitViaFallback(); } } executeCommandAndObserve()处理隔离策略和各种Fallback privateObservableexecuteCommandAndObserve(final AbstractCommand_cmd) { final HystrixRequestContext currentRequestContext=HystrixRequestContext.getContextForCurretThread(); final Action1markEmits=newAction1() {...}; 4final Action0 markOnCompleted=newAction0() {...};5//利用Func1获取处理Fallback的Observable final Func1>handleFallback=newFunc1>() { @Override publicObservablecall(Throwable t) { 9circuitBreaker.markNonSuccess(); Exception e=getExceptionFromThrowable(t); executionResult=executionResult.setExecutionException(e); //拒绝处理 if(einstanceofRejectedExecutionException) { returnhandleThreadPoolRejectionViaFallback(e); //超时处理 }else if(tinstanceofHystrixTimeoutException) { returnhandleTimeoutViaFallback(); }else if(tinstanceofHystrixBadRequestException) { returnhandleBadRequestByEmittingError(e); }else{ ... returnhandleFailureViaFallback(e); } } }; final Action1>setRequestContext... Observableexecution; //利用特定的隔离策略来处理 if(properties.executionTimeoutEnabled().get()) { execution=executeCommandWithSpecifiedIsolation(_cmd) .lift(newHystrixObservableTimeoutOperator(_cmd)); }else{ execution=executeCommandWithSpecifiedIsolation(_cmd); } returnexecution.doOnNext(markEmits) .doOnCompleted(markOnCompleted) //绑定Fallback的处理者 .onErrorResumeNext(handleFallback) .doOnEach(setRequestContext); } 隔离特性的处理：executeCommandWithSpecifiedIsolation() privateObservableexecuteCommandWithSpecifiedIsolation(final AbstractCommand_cmd) { 2//线程池隔离 3if(properties.executionIsolationStrategy().get()==ExecutionIsolationStrategy.THREAD) {4//再次使用Observable.defer(),通过执行Func0来得到Observable 5returnObservable.defer(newFunc0>() { @Override publicObservablecall() { 8//收集metric信息 9metrics.markCommandStart(commandKey,threadPoolKey,ExecutionIsolationStrategy.THREAD);10... 11try{ 12...//获取真正的用户Task 13returngetUserExecutionObservable(_cmd); 14}catch(Throwable ex) { 15returnObservable.error(ex); } ... } //绑定各种处理者 }).doOnTerminate(newAction0() {...}) .doOnUnsubscribe(newAction0() {...}) //线程隔离，绑定超时处理者 .subscribeOn(threadPool.getScheduler(newFunc0() { @Override publicBooleancall() { returnproperties.executionIsolationThreadInterruptOnTimeout().get()&&_cmd.isCommandTimedOut.get()==TimedOutStatus.TIMED_OUT; } })); } //信号量隔离，和线程池大同小异 else{ returnObservable.defer(newFunc0>() {...} } } 线程隔离threadPool.getScheduler //隔离线程池初始化 private staticHystrixThreadPoolinitThreadPool(HystrixThreadPool fromConstructor,HystrixThradPoolKey threadPoolKey,HystrixThreadPoolProperties.Setter threadPoolPropertiesDefaults) { if(fromConstructor==null) { // get the default implementation of HystrixThreadPool returnHystrixThreadPool.Factory.getInstance(threadPoolKey,threadPoolPropertiesDefaults); 6}else{ 7returnfromConstructor; } } 10 11 staticHystrixThreadPoolgetInstance(HystrixThreadPoolKey threadPoolKey,HystrixThreadPoolProperties.Setter propertiesBuilder) { // get the key to use instead of using the object itself so that if people forget to impleme nt equals/hashcode things will still work String key=threadPoolKey.name(); 15 // this should find it for all but the first time HystrixThreadPool previouslyCached=threadPools.get(key); if(previouslyCached!=null) { returnpreviouslyCached; } 21 // if we get here this is the first time so we need to initialize synchronized(HystrixThreadPool.class) { if(!threadPools.containsKey(key)) { threadPools.put(key,newHystrixThreadPoolDefault(threadPoolKey,propertiesBuilder)); } } returnthreadPools.get(key); } 30 publicHystrixThreadPoolDefault(HystrixThreadPoolKey threadPoolKey,HystrixThreadPoolProperties.Setter propertiesDefaults) { this.properties=HystrixPropertiesFactory.getThreadPoolProperties(threadPoolKey,propertiesDefaults); HystrixConcurrencyStrategy concurrencyStrategy=HystrixPlugins.getInstance().getConcurrencyStrategy(); this.queueSize=properties.maxQueueSize().get(); 35 this.metrics=HystrixThreadPoolMetrics.getInstance(threadPoolKey, concurrencyStrategy.getThreadPool(threadPoolKey,properties), properties); this.threadPool=this.metrics.getThreadPool(); this.queue=this.threadPool.getQueue(); 41 / strategy: HystrixMetricsPublisherThreadPool / HystrixMetricsPublisherFactory.createOrRetrievePublisherForThreadPool(threadPoolKey,this.me trics,this.properties); } 命令真正的调用逻辑入口getUserExecutionObservable privateObservablegetUserExecutionObservable(final AbstractCommand_cmd) { 2ObservableuserObservable; 3 try{ userObservable=getExecutionObservable(); 6}catch(Throwable ex) { // the run() method is a user provided implementation so can throw instead of using Observab e.onError // so we catch it here and turn it into Observable.error 9userObservable=Observable.error(ex); } 11 returnuserObservable .lift(newExecutionHookApplication(_cmd)) .lift(newDeprecatedOnRunHookApplication(_cmd)); } 16 finalprotectedObservablegetExecutionObservable() { returnObservable.defer(newFunc0>() { @Override publicObservablecall() { try{ //调用命令的真正方法run()入口 returnObservable.just(run()); }catch(Throwable ex) { returnObservable.error(ex); } } }).doOnSubscribe(newAction0() { @Override public voidcall() { // Save thread on which we get subscribed so that we can interrupt it later if needed executionThread.set(Thread.currentThread()); } }); } 上面方法层层调用，倒过来看，就是先创建一个Observable，然后绑定各种事件对应的处理者，如下图 断路器源码分析 Hystrix 有点类似，例如：以秒为单位来统计请求的处理情况(成功请求数量、失败请求数、超时请求数、被拒绝的请求数)，然后每次取最近10秒的数据来进行计算，如果失败率超过50%，就进行熔断，不再处理任何请求。这是Hystrix官网的一张图： 它演示了 Hystrix 滑动窗口 策略，假定以秒为单位来统计请求处理情况，上面每个格子代表1秒，格子中的数据就是1秒内各处理结果的请求数量，格子称为 Bucket(译为桶)。 若每次的决策都以10个Bucket的数据为依据，计算10个Bucket的请求处理情况，当失败率超过50%时就熔断。 10个Bucket就是10秒，这个10秒就是一个 滑动窗口(Rolling window)。 为什么叫滑动窗口？因为在没有熔断时，每当收集好一个新的Bucket后，就会丢弃掉最旧的一个Bucket。上图中的深色的(23 5 2 0)就是被丢弃的桶。 下面是官方完整的流程图，策略是：不断收集数据，达到条件就熔断；熔断后拒绝所有请求一段时间(sleepWindow)；然后放一个请求过去，如果请求成功，则关闭熔断器，否则继续打开熔断器。 相关配置 默认配置都在H ystrixC om m andProperties类中。 先看两个metrics收集的配置。 metrics.rollingStats.timeInMilliseconds 表示滑动窗口的时间(the duration of the statistical rolling window)，默认10000(10s)，也是熔断器计算的基 本单位。 metrics.rollingStats.numBuckets 滑动窗口的Bucket数量(the number of buckets the rolling statistical window is divided into)，默认10. 通过timeInMilliseconds和numBuckets可以计算出每个Bucket的时长。 metrics.rollingStats.timeInMilliseconds % metrics.rollingStats.numBuckets 必须等于 0，否则将抛异常。再看看熔断器的配置。 circuitBreaker.requestVolumeThreshold 滑动窗口触发熔断的最小请求数。如果值是20，但滑动窗口的时间内请求数只有19，那即使19个请求全部失败，也不会熔断，必须达到这个值才行，否则样本太少，没有意义。 circuitBreaker.sleepWindowInMilliseconds 这个和熔断器自动恢复有关，为了检测后端服务是否恢复，可以放一个请求过去试探一下。sleepWindow指的发生熔断后，必须隔sleepWindow这么长的时间，才能放请求过去试探下服务是否恢复。默认是5s circuitBreaker.errorThresholdPercentage 错误率阈值，表示达到熔断的条件。比如默认的50%，当一个滑动窗口内，失败率达到50%时就会触发熔断。 断路器的初始化是在AbstractCommand构造器中做的初始化 private staticHystrixCircuitBreakerinitCircuitBreaker(boolean enabled,HystrixCircuitBreakefromConstructor,HystrixCommandKey commandKey...) { //如果启用了熔断器 if(enabled) { //若commandKey没有对应的CircuitBreaker,则创建 5if(fromConstructor==null) { 6returnHystrixCircuitBreaker.Factory.getInstance(commandKey,groupKey,properties,metrics);7}else{ //如果有则返回现有的 returnfromConstructor; } }else{ return newNoOpCircuitBreaker(); } } 再看看 HystrixCircuitBreaker.Factory.getInstance(commandKey, groupKey, properties, metrics) 如何 创建circuit-breakder？ circuitBreaker以commandKey为维度，每个commandKey都会有对应的circuitBreaker public staticHystrixCircuitBreakergetInstance(HystrixCommandKey key,HystrixCommandGroupKeygroup,HystrixCommandProperties properties,HystrixCommandMetrics metrics) { //如果有则返回现有的, key.name()即command的name作为检索条件 HystrixCircuitBreaker previouslyCached=circuitBreakersByCommand.get(key.name()); 4if(previouslyCached!=null) { 5returnpreviouslyCached; } //如果没有则创建并cache HystrixCircuitBreaker cbForCommand=circuitBreakersByCommand.putIfAbsent(key.name(),newHytrixCircuitBreakerImpl(key,group,properties,metrics)); if(cbForCommand==null) { returncircuitBreakersByCommand.get(key.name()); }else{ returncbForCommand; } } 15 16 //初始化断路器 protectedHystrixCircuitBreakerImpl(HystrixCommandKey key,HystrixCommandGroupKey commandGroup,final HystrixCommandProperties properties,HystrixCommandMetrics metrics) { this.properties=properties; //这是Command中的metrics对象,metrics对象也是commandKey维度的 this.metrics=metrics; //重点:订阅事件流 Subscription s=subscribeToStream(); activeSubscription.set(s); } //订阅事件流,各事件以结构化数据汇入了Stream中 privateSubscriptionsubscribeToStream() { // HealthCountsStream是重点 returnmetrics.getHealthCountsStream() .observe() //利用数据统计的结果HealthCounts,实现熔断器 .subscribe(newSubscriber() { @Override public voidonCompleted() {} @Override public voidonError(Throwable e) {} @Override public voidonNext(HealthCounts hc) { //检查是否达到最小请求数,默认20个;未达到的话即使请求全部失败也不会熔断 if(hc.getTotalRequests() //啥也不做 }else{ //错误百分比未达到设定的阀值 if(hc.getErrorPercentage() }else{ //错误率过高,进行熔断 if(status.compareAndSet(Status.CLOSED,Status.OPEN)) { circuitOpened.set(System.currentTimeMillis()); } } } } }); } Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-20 10:32:49 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"micro/docker.html":{"url":"micro/docker.html","title":"14.Docker快速入门","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 uname -r yum -y update yum remove docker docker-common docker-selinux docker-engine yum list docker-ce --showduplicates | sort -r docker version yum -y remove docker-engine docker search java docker search java cd /etc/docker docker pull java:8 docker images docker rmi java docker run -d -p 91:80 nginx docker ps docker stop f0b1c8ab3633 docker kill f0b1c8ab3633 docker start f0b1c8ab3633 docker inspect f0b1c8ab3633 docker topf0b1c8ab3633 docker exec -it f0b1c8ab3633 /bin/bash docker rm f0b1c8ab3633 docker build -t nginx:tuling . docker run -d -p 92:80 nginx:tuling 作者：诸葛老师 2013年发布至今，Docker 一直广受瞩目，被认为可能会改变软件行业。 但是，许多人并不清楚 Docker 到底是什么，要解决什么问题，好处又在哪里？今天就来详细解释，帮助大家理解它，还带有简单易懂的实例，教你如何将它用于日常开发。 Docker简介 Docker是一个开源的容器引擎，它有助于更快地交付应用。 Docker可将应用程序和基础设施层隔离，并且能将基础设施当作程序一样进行管理。使用 Docker可更快地打包、测试以及部署应用程序，并可以缩短从编写到部署运行代码的周期。 Docker的优点如下： 1、简化程序 Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化。Docker改变了虚拟化的方式，使开发者可以直接将自己的成果放入Docker中进行管理。方便快捷已经是 Docker的最大优势，过去需要用数天乃至数周的任务，在Docker容器的处理下，只需要数秒就能完成。 2、避免选择恐惧症 如果你有选择恐惧症，还是资深患者。Docker 帮你打包你的纠结！比如 Docker 镜像； Docker 镜像中包含了运行环境和配置，所以 Docker 可以简化部署多种应用实例工作。比如 Web 应用、后台应用、数据库应用、大数据应用比如 Hadoop 集群、消息队列等等都可以打包成一个镜像部署。 3、节省开支 一方面，云计算时代到来，使开发者不必为了追求效果而配置高额的硬件，Docker 改变了高性能必然高价格的思维定势。Docker 与云的结合，让云空间得到更充分的利用。不仅解决了硬件管理的问题，也改变了虚拟化的方式。 Docker的架构 Docker daemon（ Docker守护进程） Docker daemon是一个运行在宿主机（ DOCKER-HOST）的后台进程。可通过 Docker 客户端与之通信。 Client（ Docker客户端） Docker客户端是 Docker的用户界面，它可以接受用户命令和配置标识，并与 Docker daemon通信。图中， docker build等都是 Docker的相关命令。 Images（ Docker镜像） Docker镜像是一个只读模板，它包含创建 Docker容器的说明。它和系统安装光盘有点像，使用系统安装光盘可以安装系统，同理，使用Docker镜像可以运行 Docker镜像中的程序。 Container（容器） 容器是镜像的可运行实例。镜像和容器的关系有点类似于面向对象中，类和对象的关系。 可通过 Docker API或者 CLI命令来启停、移动、删除容器。 Registry Docker Registry是一个集中存储与分发镜像的服务。构建完 Docker镜像后，就可在当前宿主机上运行。但如果想要在其他机器上运行这个镜像，就需要手动复制。此时可借助 Docker Registry来避免镜像的手动复制。 一个 Docker Registry可包含多个 Docker仓库，每个仓库可包含多个镜像标签，每个标签对应一个 Docker镜像。这跟 Maven的仓库有点类似，如果把 Docker Registry比作Maven仓库的话，那么 Docker仓库就可理解为某jar包的路径，而镜像标签则可理解为jar包的版本号。 Docker Registry可分为公有Docker Registry和私有Docker Registry。 最常⽤的Docker Registry莫过于官⽅的Docker Hub，这也是默认的Docker Registry。 Docker Hub上存放着⼤量优秀的镜像，我们可使⽤Docker命令下载并使⽤。 Docker 的安装 Docker 是一个开源的商业产品，有两个版本：社区版（Community Edition，缩写为 CE）和企业版（Enterprise Edition，缩写为 EE）。企业版包含了一些收费服务，个人开发者一般用不到。下面的介绍都针对社区版。 Docker CE 的安装请参考官方文档，我们这里以CentOS为例： 1、Docker 要求 CentOS 系统的内核版本高于 3.10 通过 uname -r 命令查看你当前的内核版本 uname -r 2、使用 root 权限登录 Centos。确保 yum 包更新到最新。 yum -y update 3、卸载旧版本(如果安装过旧版本的话) yum remove docker docker-common docker-selinux docker-engine 4、安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的 yum install -y yum-utils device-mapper-persistent-data lvm2 5、设置yum源，并更新yum的包索引 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo yum makecache fast 6、可以查看所有仓库中所有docker版本，并选择特定版本安装 yum list docker-ce --showduplicates | sort -r 7、安装docker yum install docker-ce #由于repo中默认只开启stable仓库，故这里安装的是最新稳定版 18.03.1 yum install # 例如：yum -y install docker-ce-18.03.1.ce 8、启动并加入开机启动 systemctl start docker systemctl enable docker 9、验证安装是否成功(有client和service两部分表示docker安装启动都成功了) docker version 10、卸载docker yum -y remove docker-engine Docker常用命令 镜像相关命令 1、搜索镜像 可使用 docker search命令搜索存放在 Docker Hub中的镜像。执行该命令后， Docker就会在Docker Hub中搜索含有 java这个关键词的镜像仓库。 docker search java 以上列表包含五列，含义如下： NAME:镜像仓库名称。 DESCRIPTION:镜像仓库描述。 STARS：镜像仓库收藏数，表示该镜像仓库的受欢迎程度，类似于 GitHub的 stars0 OFFICAL:表示是否为官方仓库，该列标记为[0K]的镜像均由各软件的官方项目组创建和维护。 AUTOMATED：表示是否是自动构建的镜像仓库。 注意：需要配置镜像加速器 docker search java Error response from daemon: Get https://index.docker.io/v1/search?q=java: read tcp 52.200.132.201:443:i/o timeout 我们可以借助阿里云的镜像加速器，登录阿里云 (https://cr.console.aliyun.com/#/accelerator)可以看到镜像加速地址如下图： cd /etc/docker 查看有没有 daemon.json。这是docker默认的配置文件。 如果没有新建，如果有，则修改。 vim daemon.json { \"registry-mirrors\": [\"https://m9r2r2uj.mirror.aliyuncs.com\"] } 保存退出。 重启docker服务 service docker restart 成功！ 2、下载镜像 使用命令docker pull命令即可从 Docker Registry上下载镜像，执行该命令后，Docker会从 Docker Hub中的 java仓库下载最新版本的 Java镜像。如果要下载指定版本则在java后面加冒号指定版本，例如：docker pull java:8 docker pull java:8 3、列出镜像 使用 docker images命令即可列出已下载的镜像 docker images 以上列表含义如下 REPOSITORY：镜像所属仓库名称。 TAG:镜像标签。默认是 latest,表示最新。 IMAGE ID：镜像 ID，表示镜像唯一标识。 CREATED：镜像创建时间。 SIZE: 镜像大小。 4、删除本地镜像 使用 docker rmi命令即可删除指定镜像 docker rmi java 容器相关命令 1、新建并启动容器 使用以下docker run命令即可新建并启动一个容器，该命令是最常用的命令，它有很多选项，下面将列举一些常用的选项。 -d选项：表示后台运行 -P选项：随机端口映射 -p选项：指定端口映射，有以下四种格式。 ip:hostPort:containerPort ip::containerPort hostPort:containerPort containerPort --net选项：指定网络模式，该选项有以下可选参数：--net=bridge:默认选项，表示连接到默认的网桥。--net=host:容器使用宿主机的网络。 --net=container:NAME-or-ID：告诉 Docker让新建的容器使用已有容器的网络配置。 --net=none：不配置该容器的网络，用户可自定义网络配置。 docker run -d -p 91:80 nginx 这样就能启动一个 Nginx容器。在本例中，为 docker run添加了两个参数，含义如下： -d 后台运行 -p 宿主机端口:容器端口 #开放容器端口到宿主机端口 访问 http://Docker宿主机 IP:91/，将会看到nginx的主界面如下： 需要注意的是，使用 docker run命令创建容器时，会先检查本地是否存在指定镜像。如果本地不存在该名称的镜像， Docker就会自动从 Docker Hub下载镜像并启动一个 Docker容器。 2、列出容器 docker ps命令即可列出运行中的容器 docker ps 如需列出所有容器（包括已停止的容器），可使用-a参数。该列表包含了7列，含义如下 CONTAINER_ID：表示容器 ID。 IMAGE:表示镜像名称。 COMMAND：表示启动容器时运行的命令。 CREATED：表示容器的创建时间。 STATUS：表示容器运行的状态。UP表示运行中， Exited表示已停止。 PORTS:表示容器对外的端口号。 NAMES:表示容器名称。该名称默认由 Docker自动生成，也可使用 docker run命令的-- name选项自行指定。 3、停止容器 使用 docker stop命令，即可停止容器 docker stop f0b1c8ab3633 其中f0b1c8ab3633是容器 ID,当然也可使用 docker stop容器名称来停止指定容器 4、强制停止容器 可使用 docker kill命令发送 SIGKILL信号来强制停止容器 docker kill f0b1c8ab3633 5、启动已停止的容器 使用docker run命令，即可新建并启动一个容器。对于已停止的容器，可使用 docker start命令来启动 docker start f0b1c8ab3633 6、查看容器所有信息 docker inspect f0b1c8ab3633 7、查看容器日志 docker container logsf0b1c8ab3633 8、查看容器里的进程 docker topf0b1c8ab3633 9、进入容器 使用docker exec命令用于进入一个正在运行的docker容器。如果docker run命令运行容器的时候，没有使用-it参数，就要用这个命令进入容器。一旦进入了容器，就可以在容器的 Shell 执行命令了 docker exec -it f0b1c8ab3633 /bin/bash 9、删除容器 使用 docker rm命令即可删除指定容器 docker rm f0b1c8ab3633 该命令只能删除已停止的容器，如需删除正在运行的容器，可使用-f参数 将微服务运行在docker上 使用Dockerfile构建Docker镜像 Dockerfile是一个文本文件，其中包含了若干条指令，指令描述了构建镜像的细节 先来编写一个最简单的Dockerfile，以前文下载的Nginx镜像为例，来编写一个Dockerfile修改该Nginx镜像的首页 1、新建文件夹/app，在app目录下新建一个名为Dockerfile的文件，在里面增加如下内容： FROM nginx RUN echo 'This is Tuling Nginx!!!' > /usr/share/nginx/html/index.html该Dockerfile非常简单，其中的 FORM、 RUN都是 Dockerfile的指令。 FROM指令用于指定基础镜像， RUN指令用于执行命令。 2、在Dockerfile所在路径执行以下命令构建镜像： docker build -t nginx:tuling . 其中，-t指定镜像名字，命令最后的点（.）表示Dockerfile文件所在路径 3、执行以下命令，即可使用该镜像启动一个 Docker容器 docker run -d -p 92:80 nginx:tuling 4、访问 http://Docker宿主机IP:92/，可看到下图所示界面 Dockerfile常用指令 注意：RUN命令在 image 文件的构建阶段执行，执行结果都会打包进入 image 文件；CMD命令则是在容器启动后执行。另外，一个 Dockerfile 可以包含多个RUN命令，但是只能有一个CMD命令。 注意，指定了CMD命令以后，docker container run命令就不能附加命令了（比如前面的/bin/bash），否则它会覆盖CMD命令。 使用Dockerfile构建微服务镜像 以项目05-ms-eureka-server为例，将该微服务的可运行jar包构建成docker镜像 1、将jar包上传linux服务器/app/eureka目录，在jar包所在目录创建名为Dockerfile的文件 2、在Dockerfile中添加以下内容 基于哪个镜像 From java:8 复制文件到容器 声明需要暴露的端口 EXPOSE 8761 配置容器启动后执行的命令 ENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"]3、使用docker build命令构建镜像 docker build -t microservice-eureka-server:0.0.1 . 格式： docker build -t 镜像名称:标签 Dockerfile的相对位置 在这里，使用-t选项指定了镜像的标签。执行该命令后，终端将会输出如下的内容 4、启动镜像，加-d可在后台启动 docker run -p 8761:8761 microservice-eureka-server:0.0.1 使用 -v 可以挂载一个主机上的目录到容器的目录 docker run -p 8761:8761 -v /tmp:/tmp microservice-eureka-server:0.0.1 5、访问http://Docker宿主机IP:8761/，可正常显示Eureka Server首页 Docker虚拟化原理 传统虚拟化和容器技术结构比较：传统虚拟化技术是在硬件层面实现虚拟化，增加了系统调用链路的环节，有性能损耗；容器虚拟化技术以共享Kernel的方式实现，几乎没有性能损耗 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-20 10:32:49 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"micro/Docker-Compose.html":{"url":"micro/Docker-Compose.html","title":"15.DockerCompose微服务编排","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 pip install docker-compose docker-compose version docker-compose up Just specify a path and let the Engine create a volume Specify an absolute path mapping Path on the host, relative to the Compose file User-relative path Named volume docker-compose up docker-compose up 作者：诸葛老师 Docker Compose介绍 使用微服务架构的应用系统一般包含若干个微服务，每个微服务一般都会部署多个实例。如果每个微服务都要手动启停，那么效率之低、维护量之大可想而知。本节课将讨论如何使用 Docker Compose来轻松、高效地管理容器。为了简单起见将 Docker Compose简称为Compose。 Compose 是一个用于定义和运行多容器的Docker应用的工具。使用Compose，你可以在一个配置文件（yaml格式）中配置你应用的服务，然后使用一个命令，即可创建并启动配置中引用的所有服务。下面我们进入Compose的实战吧 Docker Compose的安装 Compose的安装有多种方式，例如通过shell安装、通过pip安装、以及将compose作为容器安装等等。本文讲解通过pip安装的方式。其他安装方式如有兴趣，可以查看Docker的官方文档：https://docs.docker.com/compose/install/ 1、安装python-pip yum -y install epel-release yum -y install python-pip 2、安装docker-compose pip install docker-compose 3、待安装完成后，执行查询版本的命令 docker-compose version Docker Compose入门示例 Compose的使用非常简单，只需要编写一个docker-compose.yml，然后使用docker-compose 命令操作即可。docker-compose.yml描述了容器的配置，而docker-compose 命令描述了对容器的操作。我们首先通过一个示例快速入门： 还记得上节课，我们使用Dockerfile为项目microservice-eureka-server构建Docker镜像吗？我们还以此项目为例测试 我们在microservice-eureka-server-0.0.1-SNAPSHOT.jar所在目录的上一级目录，创建docker-compose.yml文件。 目录树结构如下： ├── docker-compose.yml └── eureka ├── Dockerfile └── microservice-eureka-server-0.0.1-SNAPSHOT.jar 然后在docker-compose.yml中添加内容如下： 在docker-compose.yml所在路径执行： docker-compose up Compose就会自动构建镜像并使用镜像启动容器。也可使用 docker-compose up -d后台启动并运行这些容器 访问：http://宿主机IP:8761/，发现可以正常启动。 Docker Compose管理容器的结构 Docker Compose将所管理的容器分为三层，分别是工程（ project），服务（service）以及容器（ container）。 Docker Compose运行目录下的所有文件（ docker-compose.yml、 extends文件或环境变量文件等）组成一个工程（默认为 docker-compose.yml所在目录的目录名称）。一个工程可包含多个服务，每个服务中定义了容器运行的镜像、参数和依赖，一个服务可包括多个容器实例。 上节示例里工程名称是 docker-compose.yml所在的目录名。该工程包含了1个服务，服务名称是 eureka，执行 docker-compose up 时，启动了eureka服务的1个容器实例 docker­compose.yml常用指令 image 指定镜像名称或者镜像id，如果该镜像在本地不存在，Compose会尝试pull下来。 示例： image: java build 指定Dockerfile文件的路径。可以是一个路径，例如： build: ./dir 也可以是一个对象，用以指定Dockerfile和参数，例如： build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1 command 覆盖容器启动后默认执行的命令。 示例： command: bundle exec thin -p 3000 也可以是一个list，类似于Dockerfile总的CMD指令，格式如下： command: [bundle, exec, thin, -p, 3000] links 链接到其他服务中的容器。可以指定服务名称和链接的别名使用SERVICE:ALIAS的形式，或者只指定服务名称，示例： web: links: db db:database redis external_links 表示链接到docker­compose.yml外部的容器，甚至并非Compose管理的容器，特别是对于那些提供共享容器或共同服务。格式跟links类似，示例： external_links: redis_1 project_db_1:mysql project_db_1:postgresql ports 暴露端口信息。使用宿主端口:容器端口的格式，或者仅仅指定容器的端口（此时宿主机将会随机指定端口），类似于docker run -p，示例： ports: \"3000\" \"3000-3005\" \"8000:8000\" \"9090-9091:8080-8081\" \"49100:22\" \"127.0.0.1:8001:8001\" \"127.0.0.1:5000-5010:5000-5010\" expose 暴露端口，只将端口暴露给连接的服务，而不暴露给宿主机，示例： expose: \"3000\" \"8000\" volumes 卷挂载路径设置。可以设置宿主机路径（HOST:CONTAINER）或加上访问模式（HOST:CONTAINER:ro）。示例： volumes: Just specify a path and let the Engine create a volume /var/lib/mysql Specify an absolute path mapping /opt/data:/var/lib/mysql Path on the host, relative to the Compose file ./cache:/tmp/cache User-relative path ~/configs:/etc/configs/:ro Named volume datavolume:/var/lib/mysql volumes_from 从另一个服务或者容器挂载卷。可以指定只读或者可读写，如果访问模式没有指定，则默认是可读写。示例： volumes_from: service_name service_name:ro container:container_name container:container_name:rw environment 设置环境变量。可以使用数组或者字典两种方式。只有一个key的环境变量可以在运行Compose的机器上找到对应的值，这有助于加密的或者特殊主机的值。示例： environment: RACK_ENV: development SHOW: 'true' SESSION_SECRET: environment: RACK_ENV=development SHOW=true SESSION_SECRET env_file 从文件中获取环境变量，可以为单独的文件路径或列表。如果通过docker-compose -f FILE指定了模板文件，则env_file中路径会基于模板文件路径。如果有变量名称与environment指令冲突，则以envirment为准。示例： env_file: .env env_file: ./common.env ./apps/web.env /opt/secrets.env extends 继承另一个服务，基于已有的服务进行扩展。 net 设置网络模式。示例： net: \"bridge\" net: \"host\" net: \"none\" net: \"container:[service name or container name/id]\" dns 配置dns服务器。可以是一个值，也可以是一个列表。示例： dns: 8.8.8.8 dns: 8.8.8.8 9.9.9.9 dns_search 配置DNS的搜索域，可以是一个值，也可以是一个列表，示例： dns_search: example.com dns_search: dc1.example.com dc2.example.com 其他 docker­compose.yml还有很多其他命令，本文仅挑选常用命令进行讲解，其他不不作赘述。如果感兴趣的，可以参考docker­ compose.yml文件官方文档：https://docs.docker.com/compose/compose­file/ 用Docker Compose编排Spring Cloud微服务 如果微服务较多，则可以用docker compose来统一编排，我们打算用docker compose来统一编排三个微服务：eureka服务(项目05-ms-eureka-server)，user服务(项目05-ms-provider-user)，order服务(项目05-ms-consumer-order-ribbon) 编排微服务 1、在根目录创建文件夹/app 2、在app目录下新建docker-compose.yml文件和三个文件夹eureka，user，order 3、在eureka，user，order三个文件夹下分别构建eureka服务镜像，user服务镜像，order服务镜像，以构建eureka服务镜像为例，在eureka文件夹下新建dockerfile文件并且将eureka服务的可运行jar包上传到该目录(注意：需要将配置eureka.client.serviceUrl.defaultZone的值改为http://eureka:8761/eureka/，默认情况下Compose以服务名称作为hostname被其他容器访问)，dockerfile文件内容如下 基于哪个镜像 From java:8 将本地文件夹挂载到当前容器 VOLUME /tmp 复制文件到容器 声明需要暴露的端口 EXPOSE 8761 配置容器启动后执行的命令 ENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"]4、docker-compose.yml内容如下 version: '2'#docker的文件格式版本 services: eureka:#docker服务名 image: eureka #docker镜像 ports: \"8761:8761\" user: image: user ports: \"8000:8000\" order: image: order ports: \"8010:8010\" 5、启动所有微服务，在命令后面加-d可以后台启动： docker-compose up 6、访问三个微服务是否正常 编排高可用微服务 1、在根目录创建文件夹/app-ha 2、在app-ha目录下新建docker-compose.yml文件和三个文件夹eureka-ha，user-ha，order-ha 3、在eureka-ha，user-ha，order-ha三个文件夹下分别构建eureka-ha服务镜像，user-ha服务镜像，order-ha服务镜像，eureka-ha服务参考项目08-ms-eureka-server-ha，（注意：需要修改user服务和order服务配置文件eureka.client.serviceUrl.defaultZone的值为http://peer1:8761/eureka/,http://peer2:8762/eureka/) 4、docker-compose.yml内容如下 version: '2'#docker的文件格式版本 services: peer1:#docker微服务名称 image: eureka-ha #docker镜像 ports: \"8761:8761\" environment: spring.profiles.active=peer1 peer2: image: eureka-ha ports: \"8762:8762\" environment: spring.profiles.active=peer2 user: image: user-ha ports: \"8000:8000\" order: image: order-ha ports: \"8010:8010\" 5、启动所有微服务，在命令后面加-d可以后台启动： docker-compose up 6、访问三个微服务是否正常 动态扩容微服务 有时我们需要扩容微服务，比如我们想把用户和订单微服务各部署两个微服务，则docker-compose.yml文件应该如下配置docker-compose.yml内容如下 version: '2'#docker的文件格式版本 services: peer1:#docker微服务名称 image: eureka-ha #docker镜像 ports: \"8761:8761\" environment: spring.profiles.active=peer1 peer2: image: eureka-ha ports: \"8762:8762\" environment: spring.profiles.active=peer2 user: image: user-ha order: image: order-ha 执行如下扩容命令： docker-compose up #必须先正常编排微服务，然后才能动态扩容 docker-compose scale user=2 order=2 注意：如果是在同一台物理机上做动态扩容，则需要在docker-compose.yml里去掉除了eureka其它微服务ports端口映射运行完查看eureka注册中心如下图所示： Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-20 10:32:49 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"micro/SpringCloudDocker.html":{"url":"micro/SpringCloudDocker.html","title":"16.Docker整体编排SpringCloud","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 Docker容器中间件部署 erureka-server config-server service-member service-product service-order mall-portal 项目模块简介 名称 介绍 说明 config-server 远程配置管理服务 spring cloud config配置中心，演示基本的config功能 erureka-server cloud微服务注册中心 基于REST的定位服务，以实现云端中间层服务发现和故障转移 mall-portal mall商城入口服务 用于演示 feign+ribbon+hystrix+zuul 等组件基本的使用和配置 service-member mall会员微服务(仅演示) SpringBoot+MybatisPlus框架的业务模块微服务，可随意扩展重建，附带feign+config+bus等组件的演示，整合Redis+RabbitMQ中间件的基本使用 service-order mall订单微服务(仅演示) SpringBoot+MybatisPlus框架的业务模块微服务，可随意扩展重建，附带feign+config+bus等组件的演示，整合Redis+RabbitMQ中间件的基本使用 service-product mall商品微服务(仅演示) SpringBoot+MybatisPlus框架的业务模块微服务，可随意扩展重建，附带feign+config+bus等组件的演示，整合Redis+RabbitMQ中间件的基本使用 Docker容器中间件部署 Mysql docker pull mysql:5.7 sudo docker run --name pwc-mysql -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql:5.7 Redis docker pull redis:3.2 docker run -p 6379:6379 --name redis -v /etc/localtime:/etc/localtime:ro -v /mnt/docker/redis/data:/data -d redis:3.2 Rabbitmq docker pull rabbitmq:management docker run -p 5672:5672 -p 15672:15672 --name rabbitmq -v /etc/localtime:/etc/localtime:ro -d rabbitmq:management Service启动后的测试地址 erureka-server http://localhost:1001/ config-server http://localhost:2001/service-member-dev.yml http://localhost:2001/service-member-test.yml http://localhost:2001/service-member-prd.yml http://localhost:2001/service-product-dev.yml http://localhost:2001/service-product-test.yml http://localhost:2001/service-product-prd.yml http://localhost:2001/service-order-dev.yml http://localhost:2001/service-order-test.yml http://localhost:2001/service-order-prd.yml http://localhost:2001/actuator/bus-refreshPOST service-member http://localhost:8001/profile http://localhost:8001/api/user?username=baicai http://localhost:8001/api/user/cache?username=baicai service-product http://localhost:8003/profile http://localhost:8003/api/product?sn=SN123456 http://localhost:8003/api/product/cache?sn=SN123456 service-order http://localhost:8002/profile http://localhost:8002/api/order?sn=Q123456 http://localhost:8002/api/order/cache?sn=Q123456 http://localhost:8002/api/order/tx?sn=Q123456&productId=1&memberId=1 mall-portal http://localhost:9001/api/find/data?username=baicai&productSn=SN123456&orderSn=Q123456 http://localhost:9001/apigateway/member/api/user?username=baicai http://localhost:9001/apigateway/product/api/product?sn=SN123456 http://localhost:9001/apigateway/order/api/order?sn=Q123456 Docker Compose编排项目 注意： 1、因为order，member和product服务启动需要读取config服务，所以需要将docker-compose拆分，让eureka和config先启动 2、因为容器没法直接访问宿主机的真实ip，只能访问宿主机给容器映射的ip(用ifconfig命令查出来的docker0网卡的ip)，所以容器要访问安装在宿主机上的那些基础服务必须用宿主机的映射ip docker-compose.yml内容如下， version: '2' #docker的文件格式版本 services: eureka-server: #docker服务名 image: eureka-server #docker镜像 ports: \"1001:1001\" config-server: image: config-server command: \"--mysql.address=172.17.0.1\" ports: \"2001:2001\" service-member: image: service-member command: \"--mysql.address=172.17.0.1\" \"--redis.address=172.17.0.1\" \"--rabbitmq.address=172.17.0.1\" ports: \"8001:8001\" service-order: image: service-order command: \"--mysql.address=172.17.0.1\" \"--redis.address=172.17.0.1\" \"--rabbitmq.address=172.17.0.1\" ports: \"8002:8002\" service-product: image: service-product command: \"--mysql.address=172.17.0.1\" \"--redis.address=172.17.0.1\" \"--rabbitmq.address=172.17.0.1\" ports: \"8003:8003\" mall-portal: image: mall-portal ports: \"9001:9001\" Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-20 10:32:49 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"project/":{"url":"project/","title":"七、项目实战专题","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"project/SystemArchitecture.html":{"url":"project/SystemArchitecture.html","title":"1.系统架构","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.电商演变 2.运行效果 3.环境详解 4.架构详解 1.电商演变 2.运行效果 项目下载地址：http://git.jiagouedu.com/java-vip/tuling-shop.git 前端：wukong/ aaa111 后端：admin/123456 前提条件：Redis、mysql、zookeeper 创建数据库脚本 代码下载来之后编译。 启动顺序：shop-goods、shop-member、shop-trade、shop-pay、 shop-admin、shop-web 3.环境详解 192.168.0.15：base 服务 192.168.0.16：app 服务 Depoly.sh 下载、解压 env-set.sh 赋值、杀进程、启动 Pom.sh 每次解压会从 app-conf 目录下 copy 环境的配置 第三方 jar 包如何上传到私服。 mvn deploy:deploy-file -DgroupId=com.alipay -DartifactId=alipay-sdk-java -Dversion=3.3.0 -Dpackaging=jar -Dfile=F:\\workspace\\vipdev\\tuling-shop\\alipay-sdk-java-3.3.0.jar -Durl=http://192.168.0.15:7777/nexus/content/repositories/thirdparty/ 4.架构详解 新增加能： 1、完善部分模块(shop-web 和 shop-admin) 2、冗余代码 3、模块分离（shop-admin、shop-web） 4、支付功能（shop-pay、shop-pay-client） 5、分布式事务 6、版本模块 Jeeshop 开源网站改过来的 单体应用 半个时间 分布式网站 秒杀、商品详细、库存、分库分表、分布式事务。 *Client 都是 dubbo 对外暴露接口 问题？为什么要这么设计？解耦 对外接口（不需要业务） 并且我们接口升级之后 不会影响我们的服务 Dubbo 所有接口模块 不同的业务按不同的 dubbo 模块 优点：解耦，不会暴露给调用方具体的业务代码、职责单一。 缺点：带来一定工作量 繁琐 拆的还不够细。 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 16:08:59 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"project/member.html":{"url":"project/member.html","title":"2.商品&会员模块","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.商品中心 1.1分类+商品（1对多） 1.2分类+商品+品牌： 1.3分类+商品+品牌+属性： 1.4分类+商品+品牌+属性+规格： 1.5技术点 2.会员中心 2.1t_account会员表 2.2t_accountRank会员级别表 2.3t_address配送地址信息表 1.商品中心 商品中心： 1.1分类+商品（1对多） t_catalog商品分类表 参数 名称 类型 备注 id 自增长 int 唯一 name 分类名称 String code 编码，简码 String 唯一 pid 父ID Int order1 排序 Int type 类型 String 类型，a:文章目录；p:产品目录 showInNav 是否显示在首页的导航条上 String y:显示,n:不显示；默认n。仅对type=p有效 t_product商品表 字段名 数据类型 默认值 描述 id int 唯一，商品ID catalogID varchar 商品类别catalog表id name varchar 商品名称 introduce text 商品简介 price DECIMAL(9,2) 定价 nowPrice DECIMAL(9,2) 现价 picture String 小图片地址 score Int 0 赠送积分 maxPicture String 大图片地址 isnew String n 是否新品。n：否，y：是 sale String n 是否特价。n：否，y：是 activityID String 绑定的活动ID giftID String 绑定的礼品ID hit int 0 浏览次数 unit String 商品单位。默认“item:件” createAccount String 录入人账号 createtime datetime 录入时间 updateAccount String 最后修改人账号 updatetime String 最后修改时间 isTimePromotion String n 是否限时促销。n：否，y：是 status Int 0 商品状态。1：新增，2：已上架，3：已下架 productHTML LONGTEXT 商品介绍 images String 商品多张图片集合，逗号分割 sellcount Int 销售数量 默认：0 stock Int 剩余库存数 默认：0 searchKey String 搜索关键词 title String 页面标题 description String 页面描述 keywords String 页面关键词 1.2分类+商品+品牌： 我要查看苹果所有的产品（手机苹果、电脑苹果）需求 1.3分类+商品+品牌+属性： 更加快速找到我们想购买的商品 t_attribute商品属性(参数)表 参数 名称 类型 备注 id 自增长 int 唯一 name 属性/参数名称 String catalogID 类别ID Int pid 父ID Int 该字段具有双重含义。0表示属性大类，一般情况下产品只有两层attribute，一层为属性名称类别，一层为属性；-1：参数 order1 排序 Int t_attribute_link商品属性(参数)中间表 参数 名称 类型 备注 id 自增长 int 唯一 attrID 属性(参数)ID Int productID 商品ID Int value 商品参数值 String 名称从属性表中取得 1.4分类+商品+品牌+属性+规格： t_spec商品规格表 字段名 数据类型 默认值 描述 id int 唯一 productID String 商品ID specColor String 颜色 specSize String 尺寸 specStock Int 此规格的商品库存数 specPrice Double 此规格的商品价格 specStatus String y:显示规格；n:不显示规格 SPU ：SPU(Standard Product Unit)：标准化产品单元。是商品信息聚合的最小单位，是一组可复用、易检索的标准化信息的集合，该集合描述了一个产品的特性。通俗点讲，属性值、特性相同的商品就可以称为一个SPU。 举例：Iphone6 SKU： SKU=Stock Keeping Unit（库存量单位）。即库存进出计量的基本单元，可以是以件，盒，托盘等为单位。 举例：Iphone6+土豪金+32G C2C店铺 1.5技术点 商品检索：ES、SOLR （数据源来自数据库，那就意味着同步）、分词 商品展示：商品+图片+库存+店铺+商品相关的信息 图片：GFS、TFS、FastDFs底层原理？特点：文件小、图片小 并发下问题 缓存：查询的速度、内存》硬盘（数据源来自数据库，那就意味着同步） 增量：增加、修改、下架 全量：预热数据（某个活动所有商品加载缓存中） 静态化: 把html+CDN 缺点:更新上需要更新HTML 2.会员中心 会员基础服务：登录、注册、购物、评价、晒单 会员成长体系：购物、评价、晒单 会员等级（注册会员、铜牌会员、银牌会员、金牌会员、钻石会员 ） 2.1t_account会员表 字段名 数据类型 主键 唯一 描述 id int Y 会员ID nickname varchar y 昵称 account varchar y 用户名out当前时间戳 password varchar 密码 accountType String 会员类型。qq,sinawb,alipay trueName String 真实姓名 sex String 性别。m:男,f：女,s:保密 birthday Date 出生年月日 province String 省份 city varchar 所在城市 address varchar 联系地址 postcode varchar 邮政编码 cardNO varchar 证件号码 cardType varchar 证件类型 grade int 等级 amount money 消费额 tel varchar 电话 email varchar y Email地址 emailIsActive String 邮箱是否已激活。y:已激活,n:未激活。默认n freeze String 是否冻结 n：未冻结，y：已冻结；默认n freezeStartdate Date 冻结的开始日期 freezeEnddate Date 冻结的结束日期 lastLoginTime Date 最后登录时间 lastLoginIp String 最后登录IP lastLoginArea String 最后登陆地点 diffAreaLogin String 是否是异地登陆y:是,n:否 regeistDate Date 注册日期 addressID Int 配送信息ID openId String y QQ登陆返回 accessToken String QQ登陆返回 alipayUseId String y 支付宝快捷登陆返回的用户ID sinaWeiboID String y 新浪微博登陆返回的用户ID rank String 会员等级。和t_accountType.code进行挂钩。默认R1 score Int 会员积分。默认0 2.2t_accountRank会员级别表 字段名 数据类型 是否主键 描述 id int 是 自增 code String 级别编码R1：普通会员，0-499R2：铜牌会员，积分范围500-999R3：银牌会员，1000-1999R4：金牌会员，2000-4000R5：钻石会员，大于4000 name String 级别名称 minScore Int 最小积分 maxScore Int 最大积分 remark String 备注 2.3t_address配送地址信息表 字段名 数据类型 是否主键 描述 id Int 是 自增 account String 会员账号 name String 收货人姓名 province String 省份 city String 城市 area String 区域 pcadetail String 省市区的地址中文合并 address String 收货人详细地址 zip String 收货人邮编 phone String 收货人电话号码 mobile String 收货人手机号码 isdefault String 默认n 是否默认；n=不是,y=默认 技术点： 单点登录、业务功能、会员迁移（分库分表） Login.jd.com item.jd.com 分布式会话解决方案 分库：hash取模、list、range 16个库（800万数据量） hash、不好扩展 1.28亿用户 均匀（解决热点数据） 分库分库 如何设计一个不扩容方案。 可视化的黑客小工具 调式bug比较有用 测试排查问题（查看最新0代码） 系统比较庞大 不需要重启 Admin admin 会员部门 xxx部门 非常非常简单 原理 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 16:09:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"project/order.html":{"url":"project/order.html","title":"3.交易&营销模块","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.交易模块 1.1t_order 订单表 1.2t_orderdetail订单明细表 1.3t_discount折扣表 1.4t_orderpay 支付记录表 1.5t_ordership 订单配送表 1.6t_orderlog订单日志表 1.7t_express快递配送表 2.营销 交易中心 交易中心业务 技术难点 营销 营销中心业务 技术难点1.交易模块 1.1t_order 订单表 字段名 数据类型 是否主键 描述 id int 是 订单编号。 account String 账号 payType varchar 付款方式 carry varchar 运送方式 rebate DECIMAL(9,2) 折扣 createdate datetime 创建日期 remark varchar 备注、支付宝的WIDsubject status String init:未审核；pass:已审核；send：已发货；sign：已签收；cancel:已取消；file:已归档；finish：交易完成； refundStatus String 退款状态(直接借用了支付宝的退款状态)。WAIT_SELLER_AGREE：等待卖家同意退款；WAIT_BUYER_RETURN_GOODS：卖家同意退款，等待买家退货；WAIT_SELLER_CONFIRM_GOODS：买家已退货，等待卖家收到退货；REFUND_SUCCESS：卖家收到退货，退款成功，交易关闭 paystatus String n:未支付；p:部分支付；y:全部支付 lowStocks String n:库存不足；y:库存充足。默认n amount Double 订单总金额 amountExchangeScore Int 订单总兑换积分 fee Double 运费总金额 ptotal Double 商品总金额 quantity Int 商品总数量 updateAmount String n:没有修改过；y:修改过；默认:n expressCode String 配送方式编码 expressName String 配送方式名称 expressNo String 快递运单号 expressCompanyName String 快递公司名称 confirmSendProductRemark String 确认发货备注 otherRequirement String 客户的附加要求 closedComment String 此订单的所有订单项对应的商品都进行了评论，则此值为y，表示此订单的评论功能已经关闭，默认为null，在订单状态为已发货后，则用户可以对订单进行评价。 score Int 订单获赠的积分 1.2t_orderdetail订单明细表 字段名 数据类型 是否主键 描述 ID int 是 ID号 orderID int 与t_order表的id字段关联 orderdetailID String 订单项ID productID int 商品ID giftID String 商品赠品ID productName String 商品名称 price money 价格 number int 数量 total0 Double 总金额（数量*价格） fee Double 配送费 isComment String 是否评价过。n:未评价,y:已评价；默认n lowStocks String n:库存不足；y:库存充足。默认n s String 商品规格信息 1.3t_discount折扣表 字段名 数据类型 是否主键 描述 ID int 是 ID号 discount decimal(9,1) 折扣,比如9.5折 name String 折扣宣传名称 1.4t_orderpay 支付记录表 字段名 数据类型 是否主键 描述 id int 是 自增 orderid String 订单ID paystatus String 支付状态。y:支付成功,n:支付失败 payamount Double 支付金额 createtime String 支付时间 paymethod String 支付方式 confirmdate String 确认日期 confirmuser String 确认人 remark String 备注 tradeNo String 支付宝交易号，以后用来发货 1.5t_ordership 订单配送表 字段名 数据类型 是否主键 描述 id int 是 自增 orderid String 订单ID shipname String 收货人姓名 shipaddress String 收货人详细地址 provinceCode String 省份代码 province String 省份 cityCode String 城市代码 city String 城市 areaCode String 区域代码 area String 区域 phone String 手机 tel String 座机 zip String 邮编 sex String 性别 remark String 备注 1.6t_orderlog订单日志表 字段名 数据类型 允许为空 描述 id int 自增 orderid String 订单ID account String 操作人 createdate date 记录时间，默认是当前时间 content String 日志内容 accountType String w:会员;m:后台管理人员;p:第三方支付系统异步通知 1.7t_express快递配送表 参数 名称 类型 备注 id 自增长 int 唯一 code 快递编码 String 三个值可选：EXPRESS（快递）、POST（平邮）、EMS（EMS） name 快递名称 String fee 物流费用 Double order1 排序 Int 交易中 库存（超卖）、重复支付、唯一主键、秒杀（库存） 、购物车 库存超卖、秒杀：锁、队列 for update 重复支付：幂等性（前端通知、后端通知）（下单 通知多次 调用多次 ）Redis incr 唯一主键：雪花算法、redis、数据库特性、UUID等等（分库分表实战） 下单：RPC调用 显示状态 订单状态 支付状态 发货状态 已付款 活动订单 已支付 未发货 已发货 活动订单 已支付 已发货 待自提 活动订单 已支付 自提点签收 已签收 活动订单 已支付 用户签收 已拒收 活动订单 已支付 用户拒收 配送成功 活动订单 已支付 配送成功 配送失败 活动订单 已支付 配送失败 交易成功 已完成 已支付 配送成功 交易失败 已完成 已支付 配送失败 取消中 取消中 已支付 未发货 已取消 订单取消 未发货 消息中间件：异步、解耦 购物车-技术点 面试题：不未登入时，购物车redis key该怎么做？ Userid+goodsid+shopid ?goodsid+shopid 未登录商品 购物车 Redis 同一台电脑上 跟换游览器没有关系 时序图 存储在redis+mysql redis存储的（shopid+goodsid） 增加一个商品购物车 插入一次数据库。 Userid xxxx id pc ios rpc调用goodsid 商品服务 下单 购物车清空 购物车数据结构：B2C(跨店铺) com.jiagouedu.web.action.front.orders.CartInfo com.jiagouedu.web.action.front.orders. CartGroup(一个店铺catgroup) cartPkg(一个店铺下可能会产生多个包裹) List(商品明细) 2个技术点： 排序的问题 排序（put数据）重写排序算法 实时性的问题 10点 5% 10：1 10% xxx奶粉 囤货 1千奶粉 羊毛党（抓）结算 查一次海关系统（下单） 拆单 业务上问题 2个iphone 长沙 仓库武汉（库存 1 个）（河南 1个 广州 1个） Goodsid+shopid+userid pkg（包裹） JD 充值 100 95 （9.5折）99. 总结： 师，上节课的 黑科技上传了麽 上传了 技术难点说了一大堆，解决方案一个没有 库存锁定、扣减 下单： U l 扣减 10 1 0 支付： 9 0 1 ERP系统 30分钟支付时间 锁定 2.营销 商品级别、订单级别、全站级别。 技术实现？ 营销活动存储（下节课 技术点） 数据的回滚 ，用户手上 订单 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 16:09:21 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"project/pay.html":{"url":"project/pay.html","title":"4.支付模块","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.营销系统 2.支付宝对接 3.微信对接 4.技术注意点： 4.1接口的幂等性 4.2后台系统 4.2.1t_user用户表 4.2.2t_role角色表 4.2.3t_privilege权限表 4.2.4t_systemsetting系统设置表 4.2.5t_systemlog系统日志表 1.营销系统 技术如何去实现？ 一个商品会对应多个活动 购物车N个商品N个活动 100个商品 300个活动（300条记录 数据库查询） 100个悟空人 3w条记录 缓存？Redis mysql Jvm map 数据同步的 在分布式下 不同的jvm 缓存数据不一样？ 活动优先级问题：怎么解决？权重 jvm 也是内存 redis也是内存 那就不要redis了 将来发生 job 执行的 计划 时间 2.支付宝对接 https://openhome.alipay.com/platform/demoManage.htm#/alipay.trade.pay 3.微信对接 4.技术注意点： 4.1接口的幂等性 4.2后台系统 后台管理： 电商没有关系、很多系统的权限这块 公共。 权限系统一般有：账号、角色、权限、资源。 权限可以分为三种：页面权限，操作权限，数据权限。 页面权限： 控制你可以看到哪个页面，看不到哪个页面。 很多系统都只做到了控制页面这一层级，它实现起来比较简单，一些系统会这样设计，但是比较古板，控制的权限不精细，难以在页面上对权限进行更下一层级的划分。 If else 操作权限： 则控制你可以在页面上操作哪些按妞。 延伸：当我们进入一个页面，我们的目的无非是在这个页面上进行增删改查，那在页面上对应的操作可能是：查询，删除，编辑，新增四个按钮。 可能你在某个页面上，只能查询数据，而不能修改数据。 数据权限： 数据权限则是控制你可以看到哪些数据，比如市场A部的人只能看到或者修改A部创建的数据，他看不到或者不能修改B部的数据。 延伸：数据的控制我们一般通过部门去实现，每条记录都有一个创建人，而每一个创建人都属于某个部门，因此部门分的越细，数据的控制层级也就越精细，这里是否有其他好的方式除了部门这个维度还有其他什么方式可以控制数据权限。 4.2.1t_user用户表 t_user用户表 参数 名称 类型 备注 id 自增长 int 唯一 username 帐号 String 唯一 password 密码 string MD5加密 createtime 创建时间 String createAccount 创建人 String updatetime 最后修改时间 String updateAccount 最后修改人 String status 状态 String y:启用,n:禁用；默认y rid 角色ID Int nickname 昵称 String email 邮箱 String 4.2.2t_role角色表 t_role角色表 参数 名称 类型 备注 id 自增长 int 唯一 role_name 角色名称 String role_desc 角色描述 string role_dbPrivilege 数据库权限 String status 角色状态，如果角色被禁用，则该角色下的所有的账号都不能使用，除非角色被解禁。 String y:启用，n:禁用；默认y 4.2.3t_privilege权限表 参数 名称 类型 备注 id 自增长 int 唯一 rid 角色ID int mid 资源ID int t_menu资源表 参数 名称 类型 备注 id 自增长 int 唯一 pid 父ID Int url 资源 String name 资源名称 string orderNum 序号 int type 功能类型 String module：模块page：页面button：功能 4.2.4t_systemsetting系统设置表 字段名 数据类型 允许为空 描述 基本设置 id int ID号 systemCode String 系统代号 name String 网站名称 www String 门户地址根http路径 manageHttp String 后台地址根http路径 log String 网站门户的Log图标地址 title String 网站标题 description String 网站的描述 keywords String 网站的关键字 shortcuticon String 网站的图标 address String 联系地址 tel String 联系电话 email String 邮箱 qqHelpHtml String Qq沟通组建的HTML内容 icp String 备案号 isopen String 是否开放网站。y:开放,n不开放 closeMsg String 网站关闭消息 qq String Qq号码 statisticsCode String 站长统计代码 version String 系统版本相关信息 显示设置 openResponsive String y:启用响应式；n:禁用响应式。默认y imageRootPath String 图片根路径，以后可以专门弄个图片服务器，图片和项目分离，提高站点访问速度。 defaultProductImg String 商品的默认图片 images 图集 String 多张图片之间用分号分割。如果广告的useImagesRandom为n，则优先显示html；否则显示images图集的图片，每一次都会从图集中随机选取一张图片来显示。 manageLeftTreeLeafIcon String 后台左侧菜单叶子节点的图标 4.2.5t_systemlog系统日志表 字段名 数据类型 允许为空 描述 id int 自增 title String 日志标题 content String 日志内容 type Int 日志类型。1：登陆日志，2：版本日志， createdate date 记录时间，默认是当前时间 account String 操作人 loginIP String 登陆人IP地址 logintime String 登陆时间 loginArea String 登陆区域 diffAreaLogin String 是否是异地登陆y:是;n:否 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 16:09:32 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"project/Depots-table-1.html":{"url":"project/Depots-table-1.html","title":"5.分库分表一","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.数据库的压力 2.如何优化？有什么方式 3.问题 4.如何优化：散列+增量（数据热点+扩容） 5.总结 1.数据库的压力 订单相关表都已经是超大表，最大表的数据量已经是几十亿，数据库处理能力已经到了极限； 单库包含多个超大表，占用的硬盘空间已经接近了服务器的硬盘极限，很快将无空间可用； 过度解决：我们可以考虑到最直接的方式是增加大容量硬盘，或者对IO有更高要求，还可以考虑增加SSD硬盘来解决容量的问题。此方法无法解决单表数据量问题。 可以对数据表历史数据进行归档，但也需要频繁进行归档操作，而且不能解决性能问题 硬件上（大小）、单表容量（性能） 2.如何优化？有什么方式 读写分离、换mysql》oracle、分库分表。 分库分表： 散列hash：hashmap可以很好的去解决数据热点的问题，但是扩容 短板 Range增量：他的库容很多好，但是他就是没法解决数据热点的问题。 实战： 老的版本：不支持spring管理（分布式主键） 新的版本:支持（分布式主键） 3.问题 表增加是可以通过创建，但是有一个地方我们改了也会有问题 面对这两种方案都是比较难的处境，shard扩容显得难了、 扩容的问题？ 分库扩容理想状态： 最好不数据迁移（给团队带来的工作压力） 可以达到1的要求，并且数据热点的问题。 根据硬件资源设置不同阈值（判定） 4.如何优化：散列+增量（数据热点+扩容） 热点：解决数据热点的问题（因为我们局部用了散列） 扩容： 5.总结 多查一次数据库（字典表） 依赖全局的ID生成（美团+业务ID在区间自增） 其他： 前端：吞吐量高、并发高、相应速度快、但是业务简单（我） 我的订单 全部订单（我） userid=1 商品表（shopid） 后端：(并发不高、业务逻辑复杂、相应不快) 后台（另外）业务复杂、吞吐量不高 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 16:09:43 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"project/Depots-table-2.html":{"url":"project/Depots-table-2.html","title":"6.分库分表二","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.分库分表难点 2.分布式唯一ID解决方案 2.1Uuid: 2.2Snowflke 2.3Mysql 2.4Redis: 3.分布式事务解决方案 1.分库分表难点 分布式事务。 分布式主键。 跨库的查询。 数据迁移的问题。2.分布式唯一ID解决方案 2.1Uuid: 通用唯一识别码 组成部分：当前日期和时间+时钟序列+全局唯一网卡 mac 地址获取 执行任务数：10000 所有线程共耗时：91.292 s 并发执行完耗时：1.221 s 单任务平均耗时：9.1292 ms 单线程最小耗时：0.0 ms 单线程最大耗时：470.0 ms 优点： 代码实现简单、不占用宽带、数据迁移不影响 缺点： 无序、无法保证趋势递增、字符存储、传输、查询慢 2.2Snowflke snowflake 是 Twitter 开源的分布式 ID 生成算法。 传统数据库软件开发中，主键自动生成技术是基本需求。而各个数据库对于该需求也提供了相应的支持，比如 MySQL 的自增键，Oracle 的自增序列等。 数据分片后，不同数据节点生成全局唯一主键是非常棘手的问题。同一个逻辑表内的不同实际表之间的自增键由于无法互相感知而产生重复主键。 虽然可通过约束自增主键初始值和步长的方式避免碰撞，但需引入额外的运维规则，使解决方案缺乏完整性和可扩展性。 io.shardingsphere.core.keygen.DefaultKeyGenerator 执行任务数：10000 所有线程共耗时：15.111 s 并发执行完耗时：217.0 ms 单任务平均耗时：1.5111 ms 单线程最小耗时：0.0 ms 单线程最大耗时：97.0 ms 优点： 不占用宽带、本地生成、高位是毫秒，低位递增 缺点： 强依赖时钟，如果时间回拨，数据递增不安全 2.3Mysql 利用数据库的步长来做的。 CREATE TABLE bit_table ( id varchar(255) NOT NULL,//字符 PRIMARY KEY (id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; CREATE TABLE bit_num ( id bigint(11) NOT NULL AUTO_INCREMENT, KEY (id) USING BTREE ) ENGINE=InnoDB auto_increment=1 DEFAULT CHARSET=utf8; SET global auto_increment_offset=1; --初始化 SET global auto_increment_increment=100; --初始步长 show global variables; 缺点: 受限数据库、单点故障、扩展麻烦 优点： 性能可以、可读性强、数字排序 2.4Redis: redis 原子性：对存储在指定 key 的数值执行原子的加 1 操作。如果指定的 key 不存在，那么在执行 incr 操作之前，会先将它的值设定为 0 组成部分：年份+当天当年第多少天+天数+小时+redis 自增 执行任务数：10000 所有线程共耗时：746.767 s 并发执行完耗时：9.381 s 单任务平均耗时：74.6767 ms 单线程最小耗时：0.0 ms 单线程最大耗时：4.119 s 优点： 有序递增、可读性强、符合刚才我们那个扩容方案的 id 缺点： 占用宽带（网络）、依赖第三方、redis 一个小时内生产 99 万的订单 ？ 场景： 名称 场景 适用指数 Uuid Token、图片 id ★★ Snowflake ELK、MQ、业务系统 ★★★★ 数据库 非大型电商系统 ★★★ Redis 大型系统 ★★★★★ 3.分布式事务解决方案 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 16:09:57 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"}}