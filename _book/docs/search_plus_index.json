{"./":{"url":"./","title":"前言","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"automation/":{"url":"automation/","title":"一、互联网专题","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"automation/git/":{"url":"automation/git/","title":"Git版本控制","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"automation/git/git-base-use.html":{"url":"automation/git/git-base-use.html","title":"1.Git基本概念与核心命令掌握","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.GIT体系概述 1.1GIT 与 svn 主要区别： 1.1.1存储方式区别 1.1.2使用方式区别 1.1.3版本管理模式区别 2.GIT 核心命令使用 2.1安装git客户端安装 2.2认识git的基本使用 快捷提交至本地仓库 2.3分支管理 2.4远程仓库管理 2.5tag 管理 2.6日志管理 3.git 底层原理 3.1GIT存储对像(hashMap) 3.2GIT树对像 3.3git提交对象 3.4GIT引用 4.基于 gogs 快速搭建企业私有 GIT 服务 4.1gogs 介绍安装 前台运行 后台运行 4.2gogs 基础配置 4.3gogs 定时备份与恢复 查看备份相关参数 默认备份,备份在当前目录 参数化备份 --target 输出目录 --database-only 只备份 db 恢复。执行该命令前要先删除 custom.bak 自动备份脚本 !/bin/sh -e 执行备份命令 查找并删除 7 天前的备份 添加定时任务 每天 4：00 执行备份 打开任务编辑器 输入如下命令 00 04 * * * 每天凌晨 4 点执行 do-backup.sh 并输出日志至 #backup.log 4、客户端公钥配置与添加 Git 安装完之后，需做最后一步配置。打开 git bash，分别执行以下两句命令 git 自动记住用户和密码操作 概要： GIT体系概述 GIT 核心命令使用 GIT 底层原理 基于 gogs 搭建 WEB 管理服务1.GIT体系概述 提问： 大家公司是用什么工具来管理代码版本？SVN、CVS、GIT GIT 和 SVN 有什么区别呢？ 1.1GIT 与 svn 主要区别： 存储方式不一样 使用方式不一样 管理模式不一样1.1.1存储方式区别 GIT 把内容按元数据方式存储类似k/v 数据库，而 SVN 是按文件(新版 svn 已改成元数据存储) 1.1.2使用方式区别 从本地把文件推送远程服务，SVN 只需要commint而 GIT 需要add、commint、push 三个步骤 SVN 基本使用过程 Git 基本使用过程 1.1.3**版本管理模式区别** git 是一个分布式的版本管理系统，而要 SVN 是一个远程集中式的管理系统 集中式 分布式 2.GIT 核心命令使用 主要内容: git 客户端安装配置 整体认识 GIT 的基本使用 分支管理 标签管理 远程仓库配置2.1安装git客户端安装 官方客户端： httpsd://git-scm.com/downloads 其它客户端： https://tortoisegit.org/download/ 2.2认识git的基本使用 git 项目创建与克隆 文件提交与推送 完整模拟从项目添加到 push 过程 创建项目 初始化 git 仓库 提交文件 远程关联 push 至远程仓库 本地初始化 GIT 仓库: 基于远程仓库克隆至本地 git clone 当前目录初始化为 git 本地仓库 git init 基于 mvn 模板创建项目 mvn archetype:generate 本地添加 添加指定文件至暂存区 git add 添加指定目录至暂存区 git add 添加所有 git add -A 将指定目录及子目录移除出暂存区 git rm --cached target -r 添加勿略配置文件 .gitignore 本地提交 提交至本地仓库 git commit file -m '提交评论' 快捷提交至本地仓库 git commit -am '快添加与提交' 2.3分支管理 查看当前分支 git branch [-avv] 基于当前分支新建分支 git branch 基于提交新建分支 git branch git branch -d {dev} 切换分支 git checkout 合并分支 git merge 解决冲突，如果因冲突导致自动合并失败，此时 status 为 mergeing 状态. 需要手动修改后重新提交（commit） 2.4远程仓库管理 查看远程配置 git remote [-v] 添加远程地址 git remote add origin http:xxx.xxx 删除远程地址 git remote remove origin 上传新分支至远程 git push --set-upstream origin master 将本地分支与远程建立关联 git branch --track --set-upstream-to=origin/test test 2.5tag 管理 查看当前 git tag 创建分支 git tag 删除分支 git tag -d 2.6日志管理 查看当前分支下所有提交日志 git log 查看当前分支下所有提交日志 git log {branch} 单行显示日志 git log --oneline 比较两个版本的区别 git log master..experiment 以图表的方式显示提交合并网络 git log --pretty=format:'%h %s' --graph 3.git 底层原理 GIT 存储对像 GIT 树对像 GIT 提交对像 GIT 引用3.1GIT存储对像(hashMap) Git 是一个内容寻址文件系统，其核心部分是一个简单的键值对数据库（key-value data store），你可以向数据库中插入任意内容，它会返回一个用于取回该值的 hash 键。 git 键值库中插入数据 echo 'luban is good man' | git hash-object -w --stdin 79362d07cf264f8078b489a47132afbc73f87b9a 基于键获取指定内容 git cat-file -p 79362d07cf264f8078b489a47132afbc73f87b9a Git 基于该功能 把每个文件的版本中内容都保存在数据库中，当要进行版本回滚的时候就通过其中一个键将期取回并替换。 模拟演示 git 版写入与回滚过程 查找所有的 git 对像 find .git/objects/ -type f 写入版本 1 echo 'version1' > README.MF; git hash-object -w README.MF; 写入版本 2 echo 'version2' > README.MF; git hash-object -w README.MF; 写入版本 3 echo 'version3' > README.MF; git hash-object -w README.MF; 回滚指定版本 git cat-file -p c11e96db44f7f3bc4c608aa7d7cd9ba4ab25066e > README.MF 所以我们平常用的 git add 其实就是把修改之后的内容 插入到键值库中。当我们执行git add README.MF等同于执行了git hash-object -w README.MF把文件写到数据库中。 我们解决了存储的问题，但其只能存储内容同并没有存储文件名，如果要进行回滚 怎么知道哪个内容对应哪个文件呢？接下要讲的就是树对象，它解决了文件名存储的问题 。 3.2GIT树对像 树对像解决了文件名的问题，它的目的将多个文件名组织在一起，其内包含多个文件名称与其对应的 Key 和其它树对像的用引用，可以理解成操作系统当中的文件夹，一个文件夹包含多个文件和多个其它文件夹。 每一个分支当中都关联了一个树对像，他存储了当前分支下所有的文件名及对应的 key. 通过以下命令即可查看 查看分支树 git cat-file -p master^{tree} 3.3git提交对象 一次提交即为当前版本的一个快照，该快照就是通过提交对像保存，其存储的内容为：一个顶级树对象、上一次提交的对像啥希、提交者用户名及邮箱、提交时间戳、提交评论。 git cat-file -p b2395925b5f1c12bf8cb9602f05fc8d580311836 tree 002adb8152f7cd49f400a0480ef2d4c09b060c07 parent 8be903f5e1046b851117a21cdc3c80bdcaf97570 author tommy 1532959457 +0800 committer tommy 1532959457 +0800 通过上面的知识，我们可以推测出从修改一个文件到提交的过程总共生成了三个对像： 一个内容对象 ==> 存储了文件内容 一个树对像 ==> 存储了文件名及内容对像的 key 一个提交对像 ==> 存储了树对像的 key 及提交评论。 演示文件提交过程3.4GIT引用 当我们执行 git branch {branchName} 时创建了一个分支，其本质就是在 git 基于指定提交创建了一个引用文件，保存在 .git\\refs\\heads\\ 下。 演示分支的创建 git branch dev cat.git\\refs\\heads\\dev git 总共 有三种类型的引用： 分支引用 远程分支引用 标签引用 查询比较两个版本 git log master..experiment 版本提交历史网络 git log --pretty=format:'%h %s' --graph 查看分支树 git cat-file -p master^{tree} 4.基于 gogs 快速搭建企业私有 GIT 服务 概要： gogs 介绍与安装 gogs 基础配置 gogs 定时备份与恢复 gitlab ==> 功能多一些 4.1gogs 介绍安装 Gogs 是一款开源的轻量级 Git web 服务，其特点是简单易用完档齐全、国际化做的相当不错。其主要功能如下: 提供 Http 与 ssh 两种协议访问源码服务 提供可 WEB 界面可查看修改源码代码 提供较完善的权限管理功能、其中包括组织、团队、个人等仓库权限 提供简单的项目 viki 功能 提供工单管理与里程碑管理。 下载安装 官网：https://gogs.io 下载：https://gogs.io/docs/installation选择 linx amd64 下载安装 文档：https://gogs.io/docs/installation/install_from_binary 安装： 解压之后目录： 运行： 前台运行 ./gogs web 后台运行 $nohup ./gogs web & 默认端口：3000 初次访问 http://:3000 会进到初始化页,进行引导配置。 可选择 mysql 或 sqlite 等数据。这里选的是 sqllite 注：mysql 索引长度的问题没有安装成功,需要用 mysql5.7 以上版本 4.2gogs 基础配置 邮件配置说明： 邮件配置是用于注册时邮件确认，和找回密码时候的验证邮件发送。其配置分为两步： 第一：创建一个开通了 smtp 服务的邮箱帐号，一般用公司管理员邮箱。我这里用的是 QQ 邮箱。 第二：在{gogs_home/custom/conf/app.ini 文件中配置。 QQ 邮箱开通 smtp 服务 1、点击设置 2、开启 smtp 邮件设置 设置文件：{gogs_home/custom/conf/app.ini ENABLED = true HOST=smtp.qq.com:465 FROM=tuling2877438881@qq.com USER= PASSWD= ENABLED=true 表示启用邮件服务 host为 smtp 服务器地址，（需要对应邮箱开通 smtp 服务 且必须为 ssl 的形式访问） from发送人名称地址 user发送帐号 passwd开通 smtp 帐户时会有对应的授权码 重启后可直接测试 管理员登录==》控制面版==》应用配置管理==》邮件配置==》发送测试邮件 4.3gogs 定时备份与恢复 备份与恢复： 查看备份相关参数 ./gogs backup -h 默认备份,备份在当前目录 ./gogs backup 参数化备份 --target 输出目录 --database-only 只备份 db ./gogs backup --target=./backupes --database-only --exclude-repos 恢复。执行该命令前要先删除 custom.bak ./gogs restore --from=gogs-backup-20180411062712.zip 自动备份脚本 !/bin/sh -e gogs_home=\"/home/apps/svr/gogs/\" backup_dir=\"$gogs_home/backups\" cd dirname $0 执行备份命令 ./gogs backup --target=$backup_dir echo 'backup sucess' day=7 查找并删除 7 天前的备份 find $backup_dir -name '*.zip' -mtime +7 -type f |xargs rm -f; echo 'delete expire back data!' 添加定时任务 每天 4：00 执行备份 打开任务编辑器 crontab -e 输入如下命令 00 04 * 每天凌晨 4 点执行 do-backup.sh 并输出日志至 #backup.log 00 04 * /home/apps/svr/gogs/do-backup.sh >> /home/apps/svr/gogs/backup.log 2>&1 4、客户端公钥配置与添加 Git 配置 Git 安装完之后，需做最后一步配置。打开 git bash，分别执行以下两句命令 git config --global user.name “用户名” git config --global user.email “邮箱” git 自动记住用户和密码操作 git config --global credential.helper store SSH 公钥创建 1、打开 git bash 2、执行生成公钥和私钥的命令：ssh-keygen -t rsa 并按回车 3 下 3、执行查看公钥的命令：cat ~/.ssh/id_rsa.pub 4、拷贝 id_rsa.pub 内容至至服务~~/.ssh/authorized_keys 中 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:51:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"automation/maven/":{"url":"automation/maven/","title":"Maven依赖管理","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"automation/maven/maven-base-use.html":{"url":"automation/maven/maven-base-use.html","title":"1.Maven基本概念与核心配置 ","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.maven 安装与核心概念 1.1安装： 1.2maven 编译 1.3Maven打包 1.4maven 单元测试演示 创建测试目录 编写 测试类 测试类代码------------------------ 执行测试 1.5maven 依赖管理 2.maven核心配置 项目依懒 **2.1依赖传播特性: 2.2依赖优先原则 2.3可选依赖 2.4排除依赖 2.5依赖范围 手动加入本地仓库 项目聚合与继承 1、聚合 2、继承 3、依赖管理 项目构建配置 3.maven 生命周期 知识点概要： 3.1生命周期的概念与意义 执行清理 phase 执行 compile phase 也可以同时执行 清理加编译 3.2maven 三大生命周期与其对应的 phase(阶段) 执行编译 执行打包就包含了编译指令的执行 3.3生命周期与插件的关系 3.4生命周期与插件的默认绑定 mvn compile 直接执行 compile 插件目标 4.maven 自定义插件开发 知识点： 4.1maven 插件相关概念 将插件依赖拷贝到指定目录 4.2常用插件的使用 展示 pom 的依赖关系树 也可以直接简化版的命令，但前提必须是 maven 官方插件 查看 pom 文件的最终配置 原型项目生成 快速创建一个 WEB 程序 快速创建一个 java 项目 4.3开发一个自定义插件 5.nexus 私服搭建与核心功能 知识点概要: 5.1私服使用场景 5.2nexus 下载安装 解压 在环境变量当中设置启动用户 添加 profile 文件。安全起见不建议使用 root 用户，如果使用其它用户需要加相应权限 端口号 启动 停止 5.3nexus 仓库介绍 5.4本地远程仓库配置 5.5发布项目至 nexus 远程仓库 概要： maven 基本概念 maven 核心配置 maven 生命周期 Maven 自定义插件开发 基于 nexus 构建企业私服1.maven 安装与核心概念 概要： maven 安装 maven 编译(compile) 执行测试用例(test) maven 打包 maven 依懒管理 1.1安装： 官网下载 Maven （http://maven.apache.org/download.cgi） 解压指定目录 配置环境变量 检查安装是否成功 （mvn -version） maven 是什么？它的基本功能是什么？编译、打包、测试、依赖管理直观感受一下 maven 编译打包的过程。 1.2maven 编译 maven 编译过程演示 创建 maven 项目。 创建 src 文件 编写 pom 文件 执行编译命令 编写 pom 文件基础配置 4.0.0 org.codehaus.mojo my-project 1.0.SNAPSHOT mvn 编译命令 mvn compile [INFO] No sources to compile [INFO] --------------------------------------------------------------- [INFO] BUILD SUCCESS [INFO] --------------------------------------------------------------- [INFO] Total time: 0.473 s [INFO] Finished at: 2018-08-05T15:55:44+08:00 [INFO] Final Memory: 6M/153M [INFO] --------------------------------------------------------------- 请注意，在上述配置和命令当中，我们并没有指定源码文件在哪里？最后编译到哪里去？在这里 maven 采用了约定的方式从指项目结构中获取源码与资源文件进行编译打包。 1. 主源码文件：${project}/src/main/java 2. 主资源文件：${project}/src/main/resources 3. 测试源码文件：${project}/src/test/java 4. 测试资源文件：${project}/src/test/resources 将 java 文件移至 src/main/java 目录，重新执行编译. mv src/hello.java /src/main/java/hello.java mvn compile; 1.3Maven打包 maven 打包演示 mvn 打包命令 mvn package 1.4maven 单元测试演示 编写测试类 执行测试命令 编译测试类 创建测试目录 mkdir -p /src/test/java 编写 测试类 vim TestHello.java 测试类代码------------------------ package com.test.tuling; public class TestHello{ public void sayHelloTest(){ System.out.println(\"run test .....\"); } } 执行测试指令: 执行测试 mvn test 执行完指令发现没有执行我们的测试方法，这是为何？原因在于 maven 当中的测试类又做了约定，约定必须是 Test 开头的类名与 test 开头的方法才会执行。 重新修改方法名后 在执行 mvn test 即可正常执行。 package com.test.tuling; public class TestHello{ public void testsayHelloTest(){ System.out.println(\"run test .....\"); } } 通常测试我们是通过 junit 来编译测试用例，这时就就需添加 junit 的依赖。 1.5maven 依赖管理 在 pom 文件中添加 junit 依赖 修改测试类，加入 junit 代码 执行测试命令 加入依懒配置 junit junit 4.0 test 修改测试类引入 junit 类. //引入 junit 类 import org.junit.Assert; import org.junit.Test; Assert.assertEquals(\"\",\"hi\"); 注意：当我们在 classPath 当中加入 junit，原来以 test 开头的方法不会被执行，必须加入 @Test 注解才能被执行。 提问： 在刚才的演示过程当中 ，junit jar 包在哪里？是怎么加入到 classPath 当中去的？maven 是在执行 test 命令的时间 动态从本地仓库中去引入 junit jar 包，如果找不到就会去远程仓库下载，然后在引入。 默认远程仓库： 默认远程仓库 maven central 其配置在 maven-model-builder-3.2.1.jar\\org\\apache\\maven\\model\\pom-4.0.0.xml 位置 本地仓库位置： 本地仓库位置默认在 ~/.m2/respository 下 要修改${M2_HOME}/conf/settings.xml 来指定仓库目录 G:\\.m2\\repository maven 核心功能总结： maven 核心作用是编译、测试、打包。 根目录下的 pom.xml 文件设置分组 ID 与 artifactId。 maven 基于约定的方式从项目中获取源码与资源文件进行编译打包。 对于项目所依懒的组件与会本地仓库引用，如果本地仓库不存在则会从中央仓库下载。2.maven核心配置 概要： 项目依懒(内部、外部) 项目聚合与继承 项目构建配置项目依懒 项目依赖是指 maven 通过依赖传播、依赖优先原则、可选依赖、排除依赖、依赖范围等特性来管理项目ClassPath。 **2.1依赖传播特性: 我们的项目通常需要依赖第三方组件，而第三方组件又会依赖其它组件遇到这种情况 Maven 会将依赖网络中的所有节点都会加入 ClassPath 当中，这就是 Maven 的依赖传播特性。 * 举例演示 Spring MVC 的依赖网络 org.springframework spring-webmvc 4.0.4.RELEASE 在刚刚的演示当中，项目直接依赖了 spring-webmvc 叫直接依赖，而对 commons-logging 依赖是通过 webmvc 传递的所以叫间接依赖。 2.2依赖优先原则 基于依赖传播特性，导致整个依赖网络会很复杂，难免会出现相同组件不同版本的情况。Maven 此时会基于依赖优先原则选择其中一个版本。 第一原则：最短路径优先。 第二原则：相同路径下配置在前的优先。 * 第一原则演示 commons-logging commons-logging 1.2 上述例子中 commons-logging 通过 spring-webmvc 依赖了 1.1.3，而项目中直接依赖了 1.2，基于最短路径原则项目最终引入的是 1.2 版本。 * 第二原则演示： 步骤： 添加一个新工程 Project B 配置 Project B 依赖 spring-web.3.2.9.RELEASE 当前工程直接依赖 Project B 配置完之后，当前工程 project A 有两条路径可以依赖 spring-web,选择哪一条 就取决于 对 webmvc 和 Project B 的配置先后顺序。 Project A==> spring-webmvc.4.0.0.RELEASE ==>spring-web.4.0.0.RELEASE Project A==> Project B 1.0.SNAPSHOT ==>spring-web.3.2.9.RELEASE 注意：在同一 pom 文件，第二原则不在适应。如下配置，最终引用的是 1.2 版本，而不是配置在前面的 1.1.1 版本. commons-logging commons-logging 1.1.1 commons-logging commons-logging 1.2 2.3可选依赖 可选依赖表示这个依赖不是必须的。通过在 添 true 表示，默认是不可选的。可选依赖不会被传递。 演示可选依赖的效果。2.4排除依赖 即排除指定的间接依赖。通过配置 配置排除指定组件。 org.springframework spring-web 演示排除依赖2.5依赖范围 像 junit 这个组件 我们只有在运行测试用例的时候去要用到，这就没有必要在打包的时候把 junit.jar 包过构建进去，可以通过 Mave 的依赖范围配置来达到这种目的。maven 总共支持以下四种依赖范围： compile(默认): 编译范围，编译和打包都会依赖。 provided：提供范围，编译时依赖，但不会打包进去。如：servlet-api.jar runtime：运行时范围，打包时依赖，编译不会。如：mysql-connector-java.jar test：测试范围，编译运行测试用例依赖，不会打包进去。如：junit.jar system：表示由系统中 CLASSPATH 指定。编译时依赖，不会打包进去。配合 一起使用。示例：java.home 下的 tool.jar system 除了可以用于引入系统 classpath 中包，也可以用于引入系统非 maven 收录的第三方 Jar，做法是将第三方 Jar 放置在 项目的 lib 目录下，然后配置 相对路径，但因 system 不会打包进去所以需要配合 maven-dependency-plugin 插件配合使用。当然推荐大家还是通过 将第三方 Jar 手动 install 到仓库。 com.sun tools ${java.version} system true ${java.home}/../lib/tools.jar jsr jsr 3.5 system true ${basedir}/lib/jsr305.jar org.apache.maven.plugins maven-dependency-plugin 2.10 copy-dependencies compile copy-dependencies ${project.build.directory}/${project.build.finalName}/WEB-INF/lib system com.sun 手动加入本地仓库 mvn install:install-file -Dfile=abc_client_v1.20.jar -DgroupId=tuling -DartifactId=tuling-client -Dversion=1.20 -Dpackaging=jar 项目聚合与继承 1、聚合 是指将多个模块整合在一起，统一构建，避免一个一个的构建。聚合需要个父工程，然后使用 进行配置其中对应的是子工程的相对路径 tuling-client tuling-server * 演示聚合的配置 2、继承 继承是指子工程直接继承父工程 当中的属性、依赖、插件等配置，避免重复配置。 属性继承： 依赖继承： 插件继承： 上面的三个配置子工程都可以进行重写，重写之后以子工程的为准。 3、依赖管理 通过继承的特性，子工程是可以间接依赖父工程的依赖，但多个子工程依赖有时并不一至，这时就可以在父工程中加入 声明该功程需要的 JAR 包，然后在子工程中引入。 junit junit 4.12 junit junit 4、项目属性： 通过 配置 属性参数，可以简化配置。 ddd ${proName} maven 默认的属性 ${basedir} 项目根目录 ${version}表示项目版本; ${project.basedir}同${basedir}; ${project.version}表示项目版本,与${version}相同; ${project.build.directory} 构建目录，缺省为 target ${project.build.sourceEncoding}表示主源码的编码格式; ${project.build.sourceDirectory}表示主源码路径; ${project.build.finalName}表示输出文件名称; ${project.build.outputDirectory} 构建过程输出目录，缺省为 target/classes 项目构建配置 构建资源配置 编译插件 profile 指定编译环境 构建资源配置 基本配置示例： package ${basedir}/target2 ${artifactId}-${version} 说明： defaultGoal，执行构建时默认的 goal 或 phase，如 jar:jar 或者 package 等 directory，构建的结果所在的路径，默认为${basedir}/target 目录 finalName，构建的最终结果的名字，该名字可能在其他 plugin 中被改变 配置示例 src/main/java **/*.MF **/*.XML true src/main/resources **/* * true 说明： resources，build 过程中涉及的资源文件 targetPath，资源文件的目标路径 directory，资源文件的路径，默认位于${basedir}/src/main/resources/目录下 includes，一组文件名的匹配模式，被匹配的资源文件将被构建过程处理 excludes，一组文件名的匹配模式，被匹配的资源文件将被构建过程忽略。同时被 includes 和 excludes 匹配的资源文件，将被忽略。 filtering： 默认 false，true 表示 通过参数 对 资源文件中 的${key} 在编译时进行动态变更。替换源可 紧 -Dkey 和 pom 中的 值 或 中指定的 properties 文件。3.maven 生命周期 知识点概要： 生命周期的概念与意义 maven 三大生命周期与其对应的 phase(阶段) 生命周期与插件的关系 生命周期与默认插件的绑定3.1生命周期的概念与意义 在项目构建时通常会包含清理、编译、测试、打包、验证、部署，文档生成等步骤，maven 统一对其进行了整理抽像成三个生命周期 (lifecycle)及各自对应的多个阶段(phase)。这么做的意义是： 每个阶段都成为了一个扩展点，可以采用不同的方式来实现，提高了扩展性与灵活性。 规范统一了 maven 的执行路径。 在执行项目构建阶段时可以采用 jar 方式构建也可以采用 war 包方式构建提高了灵活性。我们可以通过命令 mvn ${phase name}直接触发指定阶段的执行如： 演示 phase 的执行 执行清理 phase mvn clean 执行 compile phase mvn compile 也可以同时执行 清理加编译 mvn clean comile 3.2maven 三大生命周期与其对应的 phase(阶段) maven 总共包含三大生生命周期 clean Lifecycle：清理生命周期，用于于清理项目 default Lifecycle：默认生命周期，用于编译、打包、测试、部署等 site Lifecycle站点文档生成，用于构建站点文档 |生命周期(lifecycle)|阶段(phase)|描述(describe)| |:----|:----|:----|:----|:----|:----| |clean Lifecycle|pre-clean|预清理| | |clean|清理| | |post-clean|清理之后| |default Lifecycle|validate|验证| | |initialize|初始化| | |generate-sources| | | |process-sources| | | |generate-resources| | | |process-resources| | | |compile|编译| | |process-classes| | | |generate-test-sources| | | |process-test-sources| | | |generate-test-resources| | | |process-test-resources| | | |test-compile|编译测试类| | |process-test-classes| | | |test|执行测试| | |prepare-package|构建前准备| | |package|打包构建| | |pre-integration-test| | | |integration-test| | | |post-integration-test| | | |verify|验证| | |install|上传到本地仓库| | |deploy|上传到远程仓库| |site Lifecycle|pre-site|准备构建站点| | |site|构建站点| | |post-site|构建站点之后| | |site-deploy|站点部署| 三大生命周期其相互独立执行，也可以合在一起执行。但 lifecycle 中的 phase 是有严格执行的顺序的，比如必须是先执行完 compile 才能执行 pakcage 动作，此外 phase 还有包含逻辑存在，即当你执行一个 phase 时 其前面的 phase 会自动执行。 演示 phase 执行 执行编译 mvn compile 执行打包就包含了编译指令的执行 mvn package 3.3生命周期与插件的关系 生命周期的 phase 组成了项目过建的完整过程，但这些过程具体由谁来实现呢？这就是插件，maven 的核心部分代码量其实很少，其大部分实现都是由插件来完成的。比如：test 阶段就是由maven-surefire-plugin 实现。在 pom.xml 中我们可以设置指定插件目标(gogal)与 phase 绑定，当项目构建到达指定 phase 时就会触发些插件 gogal 的执行。 一个插件有时会实现多个 phas 比如：maven-compiler-plugin插件分别实现了 compile 和 testCompile。 总结： 生命周期的 阶段 可以绑定具体的插件及目标 不同配置下同一个阶段可以对应多个插件和目标 phase==>plugin==>goal(功能) 3.4生命周期与插件的默认绑定 在我们的项目当中并没有配置 maven-compiler-plugin 插件,但当我们执行 compile 阶段时一样能够执行编译操作，原因是 maven 默认为指定阶段绑定了插件实现。列如下以下两个操作在一定程度上是等价的。 演示 # mvn compile 直接执行 compile 插件目标 mvn org.apache.maven.plugins:maven-compiler-plugin:3.1:compile lifecycle phase 的默认绑定见下表：。 clean Lifecycle 默认绑定 pre-clean clean post-clean org.apache.maven.plugins:maven-clean-plugin:2.5:clean site Lifecycle 默认绑定 pre-site site post-site site-deploy org.apache.maven.plugins:maven-site-plugin:3.3:site org.apache.maven.plugins:maven-site-plugin:3.3:deploy Default Lifecycle JAR 默认绑定 注：不同的项目类型 其默认绑定是不同的，这里只指列举了 packaging 为 jar 的默认绑定，全部的默认绑定参见：https://maven.apache.org/ref/3.5.4/maven-core/default-bindings.html#。 org.apache.maven.plugins:maven-resources-plugin:2.6:resources org.apache.maven.plugins:maven-compiler-plugin:3.1:compile org.apache.maven.plugins:maven-resources-plugin:2.6:testResources org.apache.maven.plugins:maven-compiler-plugin:3.1:testCompile org.apache.maven.plugins:maven-surefire-plugin:2.12.4:test org.apache.maven.plugins:maven-jar-plugin:2.4:jar org.apache.maven.plugins:maven-install-plugin:2.4:install org.apache.maven.plugins:maven-deploy-plugin:2.7:deploy 4.maven 自定义插件开发 知识点： 插件的相关概念 常用插件的使用 开发一个自定义插件4.1maven 插件相关概念 插件坐标定位： 插件与普通 jar 包一样包含 一组件坐标定位属性即： groupId、artifactId、version，当使用该插件时会从本地仓库中搜索，如果没有即从远程仓库下载 org.apache.maven.plugins maven-dependency-plugin 2.10 插件执行 execution： execution 配置包含一组指示插件如何执行的属性： id： 执行器命名 phase：在什么阶段执行？ goals：执行一组什么目标或功能？ configuration：执行目标所需的配置文件？ 演示一个插件的配置与使用 将插件依赖拷贝到指定目录 org.apache.maven.plugins maven-dependency-plugin 3.1.1 copy-dependencies package copy-dependencies ${project.build.directory}/alternateLocation false true true 4.2常用插件的使用 除了通过配置的方式使用插件以外，Maven 也提供了通过命令直接调用插件目标其命令格式如下： mvn groupId:artifactId:version:goal -D{参数名} 演示通过命令执行插件 展示 pom 的依赖关系树 mvn org.apache.maven.plugins:maven-dependency-plugin:2.10:tree 也可以直接简化版的命令，但前提必须是 maven 官方插件 mvn dependency:tree 其它常用插件： 查看 pom 文件的最终配置 mvn help:effective-pom 原型项目生成 archetype:generate 快速创建一个 WEB 程序 mvn archetype:generate -DgroupId=tuling -DartifactId=simple-webbapp -DarchetypeArtifactId=maven-archetype-webapp -DinteractiveMode=false 快速创建一个 java 项目 mvn archetype:generate -DgroupId=tuling -DartifactId=simple-java -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false 4.3开发一个自定义插件 实现步骤： * 创建 maven 插件项目 * 设定 packaging 为 maven-plugin * 添加插件依赖 * 编写插件实现逻辑 * 打包构建插件 插件 pom 配置 4.0.0 tuling 1.0.SNAPSHOT tuling-maven-plugin maven-plugin org.apache.maven maven-plugin-api 3.0 org.apache.maven.plugin-tools maven-plugin-annotations 3.4 插件实现类： package com.tuling.maven; import javafx.beans.DefaultProperty; import org.apache.maven.plugin.AbstractMojo; import org.apache.maven.plugin.MojoExecutionException; import org.apache.maven.plugin.MojoFailureException; import org.apache.maven.plugins.annotations.LifecyclePhase; import org.apache.maven.plugins.annotations.Mojo; import org.apache.maven.plugins.annotations.Parameter; /** @author Tommy Created by Tommy on 2018/8/8 **/ @Mojo(name = \"luban\") public class LubanPlugin extends AbstractMojo { @Parameter String sex; @Parameter String describe; public void execute() throws MojoExecutionException, MojoFailureException { getLog().info(String.format(\"luban sex=%s describe=%s\",sex,describe)); } } 5.nexus 私服搭建与核心功能 知识点概要: 私服的使用场景 nexus 下载安装 nexus 仓库介绍 本地远程仓库配置 发布项目至 nexus 远程仓库 关于 SNAPSHOT(快照)与 RELEASE(释放) 版本说明5.1私服使用场景 私服使用场景如下： 1、公司不能连接公网，可以用一个私服务来统一连接 2、公司内部 jar 组件的共享 5.2nexus 下载安装 nexus 下载地址： https://sonatype-download.global.ssl.fastly.net/nexus/oss/nexus-2.14.5-02-bundle.tar.gz 解压并设置环境变量 解压 shell>tar -zxvf nexus-2.14.5-02-bundle.tar.gz 在环境变量当中设置启动用户 shell> vim /etc/profile 添加 profile 文件。安全起见不建议使用 root 用户，如果使用其它用户需要加相应权限 export RUN_AS_USER=root 配置启动参数： shell> vi ${nexusBase}/conf/nexus.properties 端口号 application-port=9999 启动与停止 nexus 启动 shell> ${nexusBase}/bin/nexus start 停止 shell> ${nexusBase}/bin/nexus stop 登录 nexus 界面 地址：http://{ip}:9999/nexus/ 用户名:admin 密码：admin123 5.3nexus 仓库介绍 3rd party：第三方仓库 Apache Snapshots：apache 快照仓库 Central: maven 中央仓库 Releases：私有发布版本仓库 Snapshots：私有 快照版本仓库 5.4本地远程仓库配置 在 pom 中配置远程仓库 nexus-public my nexus repository http://192.168.0.147:9999/nexus/content/groups/public/ 或者在 settings.xml 文件中配置远程仓库镜像 效果一样，但作用范围广了 nexus-aliyun * Nexus aliyun http://192.168.0.147:9999/nexus/content/groups/public/ 5.5发布项目至 nexus 远程仓库 配置仓库地址 nexus-release nexus release http://192.168.0.147:9999/nexus/content/repositories/releases/ nexus-snapshot nexus snapshot http://192.168.0.147:9999/nexus/content/repositories/snapshots/ 设置 setting.xml 中设置 server nexus-snapshot deployment deployment123 nexus-release deployment deployment123 执行 deploy 命令 mvn deploy Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:47:10 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"automation/jenkins/":{"url":"automation/jenkins/","title":"Jenkins自动化","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"automation/k8s/":{"url":"automation/k8s/","title":"K8s服务编排","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"automation/k8s/kubeadm-install-one.html":{"url":"automation/k8s/kubeadm-install-one.html","title":"1.快速部署一个K8s集群","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1. 安装要求 2. 准备环境 3. 所有节点安装 Docker/kubeadm/kubelet 3.1 安装 Docker 3.2 添加阿里云 YUM 软件源 3.3 安装 kubeadm，kubelet 和 kubectl 4. 部署 Kubernetes Master 5. 加入 Kubernetes Node 6. 部署 CNI 网络插件 7. 测试 kubernetes 集群 kubeadm 是官方社区推出的一个用于快速部署 kubernetes 集群的工具。 这个工具能通过两条指令完成一个 kubernetes 集群的部署： # 创建一个 Master 节点 $ kubeadm init # 将一个 Node 节点加入到当前集群中 $ kubeadm join 1. 安装要求 在开始之前，部署 Kubernetes 集群机器需要满足以下几个条件： 一台或多台机器，操作系统 CentOS7.x-86_x64 硬件配置：2GB 或更多 RAM，2 个 CPU 或更多 CPU，硬盘 30GB 或更多 可以访问外网，需要拉取镜像，如果服务器不能上网，需要提前下载镜像并导入节点 禁止 swap 分区2. 准备环境 角色 IP master 192.168.62.132 node1 192.168.62.133 node2 192.168.62.134 # 关闭防火墙 systemctl stop firewalld systemctl disable firewalld # 关闭selinux sed -i 's/enforcing/disabled/' /etc/selinux/config # 永久 setenforce 0 # 临时 # 关闭swap swapoff -a # 临时 sed -ri 's/.*swap.*/#&/' /etc/fstab # 永久 # 根据规划设置主机名 hostnamectl set-hostname # 在master添加hosts cat >> /etc/hosts /etc/sysctl.d/k8s.conf 3. 所有节点安装 Docker/kubeadm/kubelet Kubernetes 默认 CRI（容器运行时）为 Docker，因此先安装 Docker。 3.1 安装 Docker $ wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo $ yum -y install docker-ce-18.06.1.ce-3.el7 $ systemctl enable docker && systemctl start docker $ docker --version Docker version 18.06.1-ce, build e68fc7a $ cat > /etc/docker/daemon.json 3.2 添加阿里云 YUM 软件源 $ cat > /etc/yum.repos.d/kubernetes.repo 3.3 安装 kubeadm，kubelet 和 kubectl 由于版本更新频繁，这里指定版本号部署： $ yum install -y kubelet-1.18.0 kubeadm-1.18.0 kubectl-1.18.0 $ systemctl enable kubelet 4. 部署 Kubernetes Master 在 192.168.62.132（Master）执行。 $ kubeadm init \\ --apiserver-advertise-address=192.168.62.132 \\ --image-repository registry.aliyuncs.com/google_containers \\ --kubernetes-version v1.18.0 \\ --service-cidr=10.96.0.0/12 \\ --pod-network-cidr=10.244.0.0/16 由于默认拉取镜像地址 k8s.gcr.io 国内无法访问，这里指定阿里云镜像仓库地址。 使用 kubectl 工具： mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config kubectl get nodes 5. 加入 Kubernetes Node 在 192.168.62.133/134（Node）执行。 向集群添加新节点，执行在 kubeadm init 输出的 kubeadm join 命令： $ kubeadm join 192.168.62.132:6443 --token dcxghk.5zgiiw6yk7qf5wol \\ --discovery-token-ca-cert-hash sha256:aad826e486e6728e176b14e803199a42805572ed8b266269d7581f1e244df33c 默认 token 有效期为 24 小时，当过期之后，该 token 就不可用了。这时就需要重新创建 token，操作如下： kubeadm token create --print-join-command 6. 部署 CNI 网络插件 wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 默认镜像地址无法访问，sed 命令修改为 docker hub 镜像仓库。 kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 或者用啊里的源 kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel-aliyun.yml kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE kube-flannel-ds-amd64-2pc95 1/1 Running 0 72s 7. 测试 kubernetes 集群 在 Kubernetes 集群中创建一个 pod，验证是否正常运行： $ kubectl create deployment nginx --image=nginx $ kubectl expose deployment nginx --port=80 --type=NodePort $ kubectl get pod,svc 访问地址：http://NodeIP:Port Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:40:07 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"automation/k8s/kubeadm-install-all.html":{"url":"automation/k8s/kubeadm-install-all.html","title":"2搭建高可用的K8s集群","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1. 安装要求 2. 准备环境 3. 所有 master 节点部署 keepalived 3.1 安装相关包和 keepalived 3.2 配置 master 节点 3.3 启动和检查 4. 部署 haproxy 4.1 安装 4.2 配置 4.3 启动和检查 5. 所有节点安装 Docker/kubeadm/kubelet 5.1 安装 Docker 5.2 添加阿里云 YUM 软件源 5.3 安装 kubeadm，kubelet 和 kubectl 6. 部署 Kubernetes Master 6.1 创建 kubeadm 配置文件 6.2 在 master1 节点执行 7.安装集群网络 8、master2 节点加入集群 8.1 复制密钥及相关文件 8.2 master2 加入集群 5. 加入 Kubernetes Node 7. 测试 kubernetes 集群 kubeadm 是官方社区推出的一个用于快速部署 kubernetes 集群的工具。 这个工具能通过两条指令完成一个 kubernetes 集群的部署： # 创建一个 Master 节点 $ kubeadm init # 将一个 Node 节点加入到当前集群中 $ kubeadm join 1. 安装要求 在开始之前，部署 Kubernetes 集群机器需要满足以下几个条件： 一台或多台机器，操作系统 CentOS7.x-86_x64 硬件配置：2GB 或更多 RAM，2 个 CPU 或更多 CPU，硬盘 30GB 或更多 可以访问外网，需要拉取镜像，如果服务器不能上网，需要提前下载镜像并导入节点 禁止 swap 分区2. 准备环境 角色 IP master1 192.168.44.155 master2 192.168.44.156 node1 192.168.44.157 VIP（虚拟 ip） 192.168.44.158 # 关闭防火墙 systemctl stop firewalld systemctl disable firewalld # 关闭 selinux sed -i 's/enforcing/disabled/' /etc/selinux/config # 永久 setenforce 0 # 临时 # 关闭 swap swapoff -a # 临时 sed -ri 's/.*swap.*/#&/' /etc/fstab # 永久 # 根据规划设置主机名 hostnamectl set-hostname # 在 master 添加 hosts cat >> /etc/hosts /etc/sysctl.d/k8s.conf 3. 所有 master 节点部署 keepalived 3.1 安装相关包和 keepalived yum install -y conntrack-tools libseccomp libtool-ltdl yum install -y keepalived 3.2 配置 master 节点 master1 节点配置 cat > /etc/keepalived/keepalived.conf master2 节点配置 cat > /etc/keepalived/keepalived.conf 3.3 启动和检查 在两台 master 节点都执行 # 启动 keepalived $ systemctl start keepalived.service 设置开机启动 $ systemctl enable keepalived.service # 查看启动状态 $ systemctl status keepalived.service 启动后查看 master1 的网卡信息 ip a s ens33 4. 部署 haproxy 4.1 安装 yum install -y haproxy 4.2 配置 两台 master 节点的配置均相同，配置中声明了后端代理的两个 master 节点服务器，指定了 haproxy 运行的端口为 16443 等，因此 16443 端口为集群的入口 cat > /etc/haproxy/haproxy.cfg 4.3 启动和检查 两台 master 都启动 # 设置开机启动 $ systemctl enable haproxy # 开启 haproxy $ systemctl start haproxy # 查看启动状态 $ systemctl status haproxy 检查端口 netstat -lntup|grep haproxy 5. 所有节点安装 Docker/kubeadm/kubelet Kubernetes 默认 CRI（容器运行时）为 Docker，因此先安装 Docker。 5.1 安装 Docker $ wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo $ yum -y install docker-ce-18.06.1.ce-3.el7 $ systemctl enable docker && systemctl start docker $ docker --version Docker version 18.06.1-ce, build e68fc7a $ cat > /etc/docker/daemon.json 5.2 添加阿里云 YUM 软件源 $ cat > /etc/yum.repos.d/kubernetes.repo 5.3 安装 kubeadm，kubelet 和 kubectl 由于版本更新频繁，这里指定版本号部署： $ yum install -y kubelet-1.16.3 kubeadm-1.16.3 kubectl-1.16.3 $ systemctl enable kubelet 6. 部署 Kubernetes Master 6.1 创建 kubeadm 配置文件 在具有 vip 的 master 上操作，这里为 master1 $ mkdir /usr/local/kubernetes/manifests -p $ cd /usr/local/kubernetes/manifests/ $ vi kubeadm-config.yaml apiServer: certSANs: - master1 - master2 - master.k8s.io - 192.168.44.158 - 192.168.44.155 - 192.168.44.156 - 127.0.0.1 extraArgs: authorization-mode: Node,RBAC timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta1 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controlPlaneEndpoint: \"master.k8s.io:16443\" controllerManager: {} dns: type: CoreDNS etcd: local: dataDir: /var/lib/etcd imageRepository: registry.aliyuncs.com/google_containers kind: ClusterConfiguration kubernetesVersion: v1.16.3 networking: dnsDomain: cluster.local podSubnet: 10.244.0.0/16 serviceSubnet: 10.1.0.0/16 scheduler: {} 6.2 在 master1 节点执行 $ kubeadm init --config kubeadm-config.yaml 按照提示配置环境变量，使用 kubectl 工具： mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config $ kubectl get nodes $ kubectl get pods -n kube-system 按照提示保存以下内容，一会要使用： kubeadm join master.k8s.io:16443 --token jv5z7n.3y1zi95p952y9p65 \\ --discovery-token-ca-cert-hash sha256:403bca185c2f3a4791685013499e7ce58f9848e2213e27194b75a2e3293d8812 \\ --control-plane 查看集群状态 kubectl get cs kubectl get pods -n kube-system 7.安装集群网络 从官方地址获取到 flannel 的 yaml，在 master1 上执行 mkdir flannel cd flannel wget -c https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 安装 flannel 网络 kubectl apply -f kube-flannel.yml 检查 kubectl get pods -n kube-system 8、master2 节点加入集群 8.1 复制密钥及相关文件 从 master1 复制密钥及相关文件到 master2 # ssh root@192.168.44.156 mkdir -p /etc/kubernetes/pki/etcd # scp /etc/kubernetes/admin.conf root@192.168.44.156:/etc/kubernetes # scp /etc/kubernetes/pki/{ca.*,sa.*,front-proxy-ca.*} root@192.168.44.156:/etc/kubernetes/pki # scp /etc/kubernetes/pki/etcd/ca.* root@192.168.44.156:/etc/kubernetes/pki/etcd 8.2 master2 加入集群 执行在 master1 上 init 后输出的 join 命令,需要带上参数--control-plane表示把 master 控制节点加入集群 kubeadm join master.k8s.io:16443 --token ckf7bs.30576l0okocepg8b --discovery-token-ca-cert-hash sha256:19afac8b11182f61073e254fb57b9f19ab4d798b70501036fc69ebef46094aba --control-plane 检查状态 kubectl get node kubectl get pods --all-namespaces 5. 加入 Kubernetes Node 在 node1 上执行 向集群添加新节点，执行在 kubeadm init 输出的 kubeadm join 命令： kubeadm join master.k8s.io:16443 --token ckf7bs.30576l0okocepg8b --discovery-token-ca-cert-hash sha256:19afac8b11182f61073e254fb57b9f19ab4d798b70501036fc69ebef46094aba 集群网络重新安装，因为添加了新的 node 节点 检查状态 kubectl get node kubectl get pods --all-namespaces 7. 测试 kubernetes 集群 在 Kubernetes 集群中创建一个 pod，验证是否正常运行： $ kubectl create deployment nginx --image=nginx $ kubectl expose deployment nginx --port=80 --type=NodePort $ kubectl get pod,svc 访问地址：http://NodeIP:Port Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:39:43 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"source/":{"url":"source/","title":"二、源码框架专题","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"source/mybatis/":{"url":"source/mybatis/","title":"mybatis","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"source/mybatis/base-use.html":{"url":"source/mybatis/base-use.html","title":"1.基本使用","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 预编译，防止sql注入(推荐) 三节课： 熟悉mybatis 源码分析 带徒手mybatis 传统JDBC的弊端： 总结： 1、jdbc底层没有用连接池、操作数据库需要频繁的创建和关联链接。消耗很大的资源 2、写原生的jdbc代码在java中，一旦我们要修改sql的话，java需要整体编译，不利于系统维护 3、使用PreparedStatement预编译的话对变量进行设置123数字，这样的序号不利于维护 4、返回result结果集也需要硬编码。 mybatis介绍： Mybatyis:Object relation mapping对象关系映射 快速开始mybatis（xml方式）： 1、maven org.mybatis mybatis x.x.x 2、mybatis-config.xml 3、Mapper.xml Mybatis**全局配置详解：** Mybatis之annotation： public interfaceUserMapper { @Select(\"select * from user where id=#{id}\") publicUser selectUser(Integer id); } Mybatis之注解和xml优缺点: Xml：增加xml文件、麻烦、条件不确定、容易出错，特殊字符转义 注释：不适合复杂sql，收集sql不方便，重新编译 Mybatis之#与**$区别： 参数标记符号 预编译，防止sql注入(推荐) $可以sql注入，代替作用 Mybatis之parameterType与parameterMap区别： 通过parameterType指定输入参数的类型，类型可以是简单类型、hashmap、pojo的包装类型 Mybatis之resultType与resultMap区别： 使用resultType进行输出映射，只有查询出来的列名和pojo中的属性名一致，该列才可以映射成功。 mybatis中使用resultMap完成高级输出结果映射。 Mybatis之plugin： com.jiagouedu.mybatis.plugin.SqlPrintInterceptor 自定义**reusltMap**（逆向工程中讲）： Mybatis**逆向工程：** 什么是逆向工程**:** MyBatis的一个主要的特点就是需要程序员自己编写sql，那么如果表太多的话，难免会很麻烦，所以mybatis官方提供了一个逆向工程，可以针对单表自动生成mybatis执行所需要的代码（包括mapper.xml、mapper.java、po..）。一般在开发中，常用的逆向工程方式是通过数据库的表生成代码 1、引入jar plugin> groupId>org.mybatis.generatorgroupId> artifactId>mybatis-generator-maven-pluginartifactId> version>1.3.7version> dependencies> dependency> groupId>mysqlgroupId> artifactId>mysql-connector-javaartifactId> version>${mysql-connector-java.version}version> dependency> dependencies> plugin> 2、配置mybatis-genrtator.xml 3、mybatis-generator:generate XMLMAPPER|ANNOTATEDMAPPER 去掉注释： 生成注解方式**:** http://www.mybatis.org/generator/configreference/javaClientGenerator.html Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:38:28 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"source/mybatis/analysis.html":{"url":"source/mybatis/analysis.html","title":"2源码分析","keywords":"","body":"mybatis**核心概念** Configuration**、SqlSessionFactory、Session、Executor、MappedStatement、StatementHandler、**ResultSetHandler 整体认识**mybatis**源码包 Debug**一行行看代码** 宏观 微观 画图 Mybatis**之**Configuration org.apache.ibatis.builder.xml.XMLConfigBuilder#parseConfiguration Properties**文件解析：** org.apache.ibatis.builder.xml.XMLConfigBuilder#propertiesElement Setting 文件解析： org.apache.ibatis.builder.xml.XMLConfigBuilder#settingsElement environments 文件解析： org.apache.ibatis.builder.xml.XMLConfigBuilder#environmentsElement Mybatis**之**Session Mybatis**之**Mapper :Type interface com.jiagouedu.UserMapper is not known to the MapperRegistry. Mybatis**之**Sql txt.txt文件 Mybatis**之**Executor 其实是不干事情的 org.apache.ibatis.executor.statement.StatementHandler org.apache.ibatis.executor.statement.PreparedStatementHandler org.apache.ibatis.executor.resultset.ResultSetHandler org.apache.ibatis.executor.resultset.DefaultResultSetHandler Mybatis**之cache：** 每当我们使用MyBatis开启一次和数据库的会话，MyBatis会创建出一个SqlSession对象表示一次数据库会话。 在对数据库的一次会话中，我们有可能会反复地执行完全相同的查询语句，如果不采取一些措施的话，每一次查询都会查询一次数据库,而我们在极短的时间内做了完全相同的查询，那么它们的结果极有可能完全相同，由于查询一次数据库的代价很大，这有可能造成很大的资源浪费。 为了解决这一问题，减少资源的浪费，MyBatis会在表示会话的SqlSession对象中建立一个简单的缓存，将每次查询到的结果结果缓存起来，当下次查询的时候，如果判断先前有个完全一样的查询，会直接从缓存中直接将结果取出，返回给用户，不需要再进行一次数据库查询了。 cache key: id +sql+limit+offsetxxx 作用域：一级缓存session 全局：二级缓存 今天源码分析涉及到的模式是（学员整理）： 1.sqlSessionFactory工厂 2.build建造者 getInstance ，Cache 单例 委派 （单词忘了）装饰 5.InterceptorChain责任链 6Proxy代理 7.ExecuteCommand命令 8.doQuery模板 Mybatis**作业** annotations中的@select源码加载执行 提交地址： http://git.jiagouedu.com/java-vip/tuling-mybatis/issues/new 要求：流程图+找出代码调用流程 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:59:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"source/mybatis/realization.html":{"url":"source/mybatis/realization.html","title":"3.代码实现","keywords":"","body":"mybatis**核心概念** Configuration**、SqlSessionFactory、Session、Executor、MappedStatement、StatementHandler、**ResultSetHandler 整体认识**mybatis**源码包 Mybatis**集成**Spring MyBatis-Spring会帮助你将MyBatis代码无缝地整合到Spring中。 使用这个类库中的类, Spring将会加载必要的MyBatis工厂类和session类。 这个类库也提供一个简单的方式来注入MyBatis数据映射器和SqlSession到业务层的bean中。 而且它也会处理事务,翻译MyBatis的异常到Spring的DataAccessException异常(数据访问异常,译者注)中。最终,它并 不会依赖于MyBatis,Spring或MyBatis-Spring来构建应用程序代码。 配置 dependency> groupId>org.mybatisgroupId> artifactId>mybatis-springartifactId> version>1.3.0version> dependency> beanid**=\"sqlSessionFactory\"** class**=\"org.mybatis.spring.SqlSessionFactoryBean\">****property**![图片](https://uploader.shimo.im/f/pSPfc8T1af0mddbt.png!thumbnail?fileGuid=FuyY885vp30f4yOb)**name****=\"dataSource\"**![图片](https://uploader.shimo.im/f/m2fhbQQDwTzsScM7.png!thumbnail?fileGuid=FuyY885vp30f4yOb)**ref****=\"dataSource\"**![图片](https://uploader.shimo.im/f/jT1upyO3MtgrjwYf.png!thumbnail?fileGuid=FuyY885vp30f4yOb)/ value=\"classpath:mybatis/UserMapper.xml\" />-->*bean> **bean**![图片](https://uploader.shimo.im/f/eRqgEnFaJFJPYx1s.png!thumbnail?fileGuid=FuyY885vp30f4yOb)**class****=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"****propertyname**=\"basePackage\"value**=\"com.jiagouedu.mapper\"**/> bean> org.mybatis.spring.SqlSessionTemplate等同于SqlSession 通用**mapper&mybatis-plus** Mybatis增强 反射+泛型技术 通用CRUD 徒手实现**mybatis** 不健全，方便我们去了解mybatis 也就是以后你的简历上可以写你熟悉mybatis源码 不用必做的作业、mybatis的1：N N:N 熟悉mybatis、mybatis源码分析、徒手实现mybatis Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:59:34 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"source/spring/":{"url":"source/spring/","title":"spring","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"source/spring/ioc.html":{"url":"source/spring/ioc.html","title":"1.IOC容器设计理念与源码解读","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 知识点： 1、Ioc 理论概要 2、实体 Bean 的构建 3、bean 的基本特性 4、依赖注入 二、IOC 设计原理与实现 1、源码学习目标： 2、Bean 的构建过程 3、BeanFactory 与 ApplicationContext 区别 课程概要： IOC 核心知识点回顾 IOC 设计原理 一、IOC 核心理论回顾 知识点： Ioc 理念概要 实体 Bean 的创建 Bean 的基本特性 依赖注入 set 方法注入 构造方法注入 自动注入(byName、byType） 依赖检测1、Ioc 理论概要 在 JAVA 的世界中，一个对象 A 怎么才能调用对象 B？通常有以下几种方法。 类别 描述 时间点 外部传入 构造方法传入 属性设置传入 设置对象状态时 运行时做为参数传入 调用时 内部创建 属性中直接创建 创建引用对象时 初始化方法创建 创建引用对象时 运行时动态创建 调用时 上表可以看到， 引用一个对象可以在不同地点（其它引用者）、不同时间由不同的方法完成。如果 B 只是一个非常简单的对象 如直接 new B()，怎样都不会觉得复杂，比如你从来不会觉得创建一个 String 是一个件复杂的事情。但如果 B 是一个有着复杂依赖的 Service 对象，这时在不同时机引用 B 将会变得很复杂。 无时无刻都要维护 B 的复杂依赖关系，试想 B 对象如果项目中有上百过，系统复杂度将会成陪数增加。 IOC 容器 的出现正是为解决这一问题，其可以将对象的构建方式统一，并且自动维护对象的依赖关系，从而降低系统的实现成本。前提是需要提前对目标对象基于 XML 进行声明。 2、实体 Bean 的构建 基于 Class 构建 构造方法构建 静态工厂方法创建 FactoryBean 创建 1、基于 ClassName 构建 这是最常规的方法，其原理是在 spring 底层会基于 class 属性 通过反射进行构建。 2、构造方法构建 如果需要基于参数进行构建，就采用构造方法构建，其对应属性如下： name:构造方法参数变量名称 type:参数类型 index:参数索引，从 0 开始 value:参数值，spring 会自动转换成参数实际类型值 ref:引用容串的其它对象 3、静态工厂方法创建 如果你正在对一个对象进行 A/B 测试 ，就可以采用静态工厂方法的方式创建，其于策略创建不同的对像或填充不同的属性。 该模式下必须创建一个静态工厂方法，并且方法返回该实例，spring 会调用该静态方法创建对象。 public static HelloSpring build(String type) { if (type.equals(\"A\")) { return new HelloSpring(\"luban\", \"man\"); } else if (type.equals(\"B\")) { return new HelloSpring(\"diaocan\", \"woman\"); } else { throw new IllegalArgumentException(\"type must A or B\"); } } 4、FactoryBean 创建 指定一个 Bean 工厂来创建对象，对象构建初始化 完全交给该工厂来实现。配置 Bean 时指定该工厂类的类名。 public class LubanFactoryBean implements FactoryBean { @Override public Object getObject() throws Exception { return new HelloSpring(); } @Override public Class getObjectType() { return HelloSpring.class; } @Override public boolean isSingleton() { return false; } } 3、bean 的基本特性 作用范围 生命周期 装载机制 a、作用范围 很多时候 Bean 对象是无状态的 ，而有些又是有状态的 无状态的对象我们采用单例即可，而有状态则必须是多例的模式，通过 scope 即可创建 scope=“prototype” scope=“singleton” scope=“prototype 如果一个 Bean 设置成 prototype 我们可以 通过 BeanFactoryAware 获取 BeanFactory 对象即可每次获取的都是新对像。 b、生命周期 Bean 对象的创建、初始化、销毁即是 Bean 的生命周期。通过 init-method、destroy-method 属性可以分别指定期构建方法与初始方法。 如果觉得麻烦，可以让 Bean 去实现 InitializingBean.afterPropertiesSet()、DisposableBean.destroy()方法。分别对应 初始和销毁方法 c、加载机制 指示 Bean 在何时进行加载。设置 lazy-init 即可，其值如下： true: 懒加载，即延迟加载 false:非懒加载，容器启动时即创建对象 default:默认，采用 default-lazy-init 中指定值，如果 default-lazy-init 没指定就是 false 什么时候使用懒加载？ 懒加载会容器启动的更快，而非懒加载可以容器启动时更快的发现程序当中的错误 ，选择哪一个就看追求的是启动速度，还是希望更早的发现错误，一般我们会选 择后者。 4、依赖注入 试想 IOC 中如果没有依赖注入，那这个框架就只能帮助我们构建一些简单的 Bean，而之前所说的复杂 Bean 的构建问题将无法解决，spring 这个框架不可能会像现在这样成功。spring 中 ioc 如何依赖注入呢。有以下几种方式： set 方法注入 构造方法注入 自动注入(byName、byType） 方法注入(lookup-method) 2、set 方法注入 3、构造方法注入 4、自动注入（byName\\byType\\constructor) byName：基于变量名与 bean 名称相同作为依据插入 byType：基于变量类别与 bean 名称作 constructor：基于 IOC 中 bean 与构造方法进行匹配（语义模糊，不推荐） 5、依赖方法注入(lookup-method) 当一个单例的 Bean，依赖于一个多例的 Bean，用常规方法只会被注入一次，如果每次都想要获取一个全新实例就可以采用 lookup-method 方法来实现。 #编写一个抽像类 public abstract class MethodInject { public void handlerRequest() { // 通过对该抽像方法的调用获取最新实例 getFine(); } # 编写一个抽像方法 public abstract FineSpring getFine(); } // 设定抽像方法实现 该操作的原理是基于动态代理技术，重新生成一个继承至目标类，然后重写抽像方法到达注入目的。 前面说所单例 Bean 依赖多例 Bean 这种情况也可以通过实现 ApplicationContextAware、BeanFactoryAware 接口来获取 BeanFactory 实例，从而可以直接调用 getBean 方法获取新实例，推荐使用该方法，相比 lookup-method 语义逻辑更清楚一些。 二、IOC 设计原理与实现 1、源码学习的目标 2、Bean 的构建过程 3、BeanFactory 与 ApplicationContext 区别 1、源码学习目标： 不要为了读书而读书，同样不要为了阅读源码而读源码。没有目的一头扎进源码的黑森林当中很快就迷路了。到时就不是我们读源码了，而是源码‘毒’我们。毕竟一个框架是由专业团队，历经 N 次版本迭代的产物，我们不能指望像读一本书的方式去阅读它。 所以必须在读源码之前找到目标。是什么呢？ 大家会想，读源码的目标不就是为了学习吗？这种目标太过抽像，目标无法验证。通常我们会设定两类型目标：一种是对源码进行改造，比如添加修改某些功能，在实现这种目标的过程当中自然就会慢慢熟悉了解该项目。但然这个难度较大，耗费的成本也大。另一个做法是 自己提出一些问题，阅读源码就是为这些问题寻找答案。以下就是我们要一起在源码中寻找答案的问题： Bean 工厂是如何生产 Bean 的？ Bean 的依赖关系是由谁解来决的？ Bean 工厂和应用上文的区别？2、Bean 的构建过程 spring.xml 文件中保存了我们对Bean 的描述配置，BeanFactory 会读取这些配置然后生成对应的 Bean。这是我们对 ioc 原理的一般理解。但在深入一些我们会有更多的问题？ 配置信息最后是谁 JAVA 中哪个对象承载的？ 这些承载对象是谁业读取 XML 文件并装载的？ 这些承载对象又是保存在哪里？ BeanDefinition （Bean 定义） ioc 实现中 我们在 xml 中描述的 Bean 信息最后 都将保存至 BeanDefinition （定义）对象中，其中 xml bean 与 BeanDefinition 程一对一的关系。 由此可见，xml bean 中设置的属性最后都会体现在BeanDefinition中。如: XML-bean BeanDefinition class beanClassName scope scope lazy-init lazyInit constructor-arg ConstructorArgument property MutablePropertyValues factory-method factoryMethodName destroy-method AbstractBeanDefinition.destroyMethodName init-method AbstractBeanDefinition.initMethodName autowire AbstractBeanDefinition.autowireMode id name [ ] 演示查看 BeanDefinition 属性结构 BeanDefinitionRegistry（Bean 注册器） 在上表中我们并没有看到 xml bean 中的 id 和 name 属性没有体现在定义中，原因是 ID 其作为当前 Bean 的存储 key 注册到了 BeanDefinitionRegistry 注册器中。name 作为别名 key 注册到了 AliasRegistry 注册中心。其最后都是指向其对应的 BeanDefinition。 [ ] 演示查看 BeanDefinitionRegistry 属性结构 BeanDefinitionReader（Bean 定义读取） 至此我们学习了 BeanDefinition 中存储了 Xml Bean 信息，而 BeanDefinitionRegister 基于 ID 和 name 保存了 Bean 的定义。接下要学习的是从 xml Bean 到 BeanDefinition 然后在注册至 BeanDefinitionRegister 整个过程。 上图中可以看出 Bean 的定义是由 BeanDefinitionReader 从 xml 中读取配置并构建出 BeanDefinitionReader,然后在基于别名注册到 BeanDefinitionRegister 中。 [ ] 查看 BeanDefinitionReader 结构 方法说明： loadBeanDefinitions(Resource resource) 基于资源装载 Bean 定义并注册至注册器 int loadBeanDefinitions(String location) 基于资源路径装载 Bean 定义并注册至注册器 BeanDefinitionRegistry getRegistry() 获取注册器 ResourceLoader getResourceLoader() 获取资源装载器 [ ] 基于示例演示 BeanDefinitionReader 装载过程//创建一个简单注册器 BeanDefinitionRegistry register = new SimpleBeanDefinitionRegistry(); //创建 bean 定义读取器 BeanDefinitionReader reader = new XmlBeanDefinitionReader(register); // 创建资源读取器 DefaultResourceLoader resourceLoader = new DefaultResourceLoader(); // 获取资源 Resource xmlResource = resourceLoader.getResource(\"spring.xml\"); // 装载 Bean 的定义 reader.loadBeanDefinitions(xmlResource); // 打印构建的 Bean 名称 System.out.println(Arrays.toString(register.getBeanDefinitionNames()); Beanfactory(bean 工厂) 有了 Bean 的定义就相当于有了产品的配方，接下来就是要把这个配方送到工厂进行生产了。在 ioc 当中 Bean 的构建是由 BeanFactory 负责的。其结构如下： 方法说明： getBean(String) 基于 ID 或 name 获取一个 Bean T getBean(Class requiredType) 基于 Bean 的类别获取一个 Bean（如果出现多个该类的实例，将会报错。但可以指定 primary=“true” 调整优先级来解决该错误 ） Object getBean(String name, Object... args) 基于名称获取一个 Bean，并覆盖默认的构造参数 boolean isTypeMatch(String name, Class typeToMatch) 指定 Bean 与指定 Class 是否匹配 以上方法中重点要关注 getBean，当用户调用 getBean 的时候就会触发 Bean 的创建动作，其是如何创建的呢？ [ ] 演示基本 BeanFactory 获取一个 Bean#创建 Bean 堆栈 // 其反射实例化 Bean java.lang.reflect.Constructor.newInstance(Unknown Source:-1) BeanUtils.instantiateClass() //基于实例化策略 实例化 Bean SimpleInstantiationStrategy.instantiate() AbstractAutowireCapableBeanFactory.instantiateBean() // 执行 Bean 的实例化方法 AbstractAutowireCapableBeanFactory.createBeanInstance() AbstractAutowireCapableBeanFactory.doCreateBean() // 执行 Bean 的创建 AbstractAutowireCapableBeanFactory.createBean() // 缓存中没有，调用指定 Bean 工厂创建 Bean AbstractBeanFactory$1.getObject() // 从单例注册中心获取 Bean 缓存 DefaultSingletonBeanRegistry.getSingleton() AbstractBeanFactory.doGetBean() // 获取 Bean AbstractBeanFactory.getBean() // 调用的客户类 com.tuling.spring.BeanFactoryExample.main() Bean 创建时序图： 从调用过程可以总结出以下几点： 调用 BeanFactory.getBean() 会触发 Bean 的实例化。 DefaultSingletonBeanRegistry 中缓存了单例 Bean Bean 的创建与初始化是由AbstractAutowireCapableBeanFactory完成的。3、BeanFactory 与 ApplicationContext 区别 BeanFactory 看下去可以去做 IOC 当中的大部分事情，为什么还要去定义一个 ApplicationContext 呢？ ApplicationContext 结构图 从图中可以看到 ApplicationContext 它由 BeanFactory 接口派生而来，因而提供了 BeanFactory 所有的功能。除此之外 context 包还提供了以下的功能： MessageSource, 提供国际化的消息访问 资源访问，如 URL 和文件 事件传播，实现了 ApplicationListener 接口的 bean 载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的 web 层 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:13:00 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"source/spring/aop.html":{"url":"source/spring/aop.html","title":"2.AOP事物底层原理分析","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、数据库的事物的基本特性 查看mysql 的默认隔离级别 二、Spring 对事物的支持与使用 1、spring 事物相关API说明 2、声明示事物 3、事物传播机制 三、aop 事物底层实现原理 概要： 数据库的事物的基本特性 Sring 对事物的支持与使用 aop 事物底层实现原理一、数据库的事物的基本特性 事物是区分文件存储系统与Nosql数据库重要特性之一，其存在的意义是为了保证即使在并发情况下也能正确的执行crud操作。怎样才算是正确的呢？这时提出了事物需要保证的四个特性即ACID： A: 原子性(atomicity) 事物中各项操作，要么全做要么全不做，任何一项操作的失败都会导致整个事物的失败； C: 一致性(consistency) 事物结束后系统状态是一致的； I: 隔离性(isolation) 并发执行的事物彼此无法看到对方的中间状态； D: 持久性(durability) 事物完成后所做的改动都会被持久化，即使发生灾难性的失败。 在高并发的情况下，要完全保证其ACID特性是非常困难的，除非把所有的事物串行化执行，但带来的负面的影响将是性能大打折扣。很多时候我们有些业务对事物的要求是不一样的，所以数据库中设计了四种隔离级别，供用户基于业务进行选择。 隔离级别 脏读（Dirty Read） 不可重复读（NonRepeatable Read） 幻读（Phantom Read） 未提交读（Read uncommitted） 可能 可能 可能 已提交读（Read committed） 不可能 可能 可能 可重复读（Repeatable read） 不可能 不可能 可能 可串行化（SERIALIZABLE） 不可能 不可能 不可能 脏读 : 一个事物读取到另一事物未提交的更新数据 不可重复读 : 在同一事物中,多次读取同一数据返回的结果有所不同, 换句话说, 后续读取可以读到另一事物已提交的更新数据. 相反, “可重复读”在同一事物中多次读取数据时, 能够保证所读数据一样, 也就是后续读取不能读到另一事物已提交的更新数据。 幻读 : 查询表中一条数据如果不存在就插入一条，并发的时候却发现，里面居然有两条相同的数据。这就幻读的问题。 代码演示脏读、不可重复读、幻读的情况。 演示源码：http://git.jiagouedu.com/java-vip/tuling-spring/src/master/tuling-spring-transaction 数据库默认隔离级别： Oracle中默认级别是 Read committed mysql 中默认级别 Repeatable read。另外要注意的是mysql 执行一条查询语句默认是一个独立的事物，所以看上去效果跟Read committed一样。 查看mysql 的默认隔离级别 SELECT @@tx_isolation 二、Spring 对事物的支持与使用 要点： spring 事物相关API说明 声明式事物的使用 事物传播机制1、spring 事物相关API说明 spring 事物是在数据库事物的基础上进行封装扩展 其主要特性如下： 1. 支持原有的数据事物的隔离级别 2. 加入了事物传播的概念 提供多个事物的和并或隔离的功能 3. 提供声明式事物，让业务代码与事物分离，事物变得更易用。 怎么样去使用Spring事物呢？spring 提供了三个接口供使用事物。分别是： TransactionDefinition 事物定义 PlatformTransactionManager 事物管理 TransactionStatus 事物运行时状态 接口结构图： API说明： 基于API实现事物 public class SpringTransactionExample { private static String url = \"jdbc:mysql://192.168.0.147:3306/luban2\"; private static String user = \"root\"; private static String password = \"123456\"; public static Connection openConnection() throws ClassNotFoundException, SQLException { Class.forName(\"com.mysql.jdbc.Driver\"); Connection conn = DriverManager.getConnection(\"jdbc:mysql://192.168.0.147:3306/luban2\", \"root\", \"123456\"); return conn; } public static void main(String[] args) { final DataSource ds = new DriverManagerDataSource(url, user, password); final TransactionTemplate template = new TransactionTemplate(); template.setTransactionManager(new DataSourceTransactionManager(ds)); template.execute(new TransactionCallback() { @Override public Object doInTransaction(TransactionStatus status) { Connection conn = DataSourceUtils.getConnection(ds); Object savePoint = null; try { { // 插入 PreparedStatement prepare = conn. prepareStatement(\"insert INTO account (accountName,user,money) VALUES (?,?,?)\"); prepare.setString(1, \"111\"); prepare.setString(2, \"aaaa\"); prepare.setInt(3, 10000); prepare.executeUpdate(); } // 设置保存点 savePoint = status.createSavepoint(); { // 插入 PreparedStatement prepare = conn. prepareStatement(\"insert INTO account (accountName,user,money) VALUES (?,?,?)\"); prepare.setString(1, \"222\"); prepare.setString(2, \"bbb\"); prepare.setInt(3, 10000); prepare.executeUpdate(); } { // 更新 PreparedStatement prepare = conn. prepareStatement(\"UPDATE account SET money= money+1 where user=?\"); prepare.setString(1, \"asdflkjaf\"); Assert.isTrue(prepare.executeUpdate() > 0, \"\"); } } catch (SQLException e) { e.printStackTrace(); } catch (Exception e) { System.out.println(\"更新失败\"); if (savePoint != null) { status.rollbackToSavepoint(savePoint); } else { status.setRollbackOnly(); } } return null; } }); } } 2、声明示事物 我们前面是通过调用API来实现对事物的控制，这非常的繁琐，与直接操作JDBC事物并没有太多的改善，所以Spring提出了声明示事物，使我们对事物的操作变得非常简单，甚至不需要关心它。 演示声明示事物使用 spring-tx.xml 配置spring.xml 编写服务类 @Transactional public void addAccount(String name, int initMenoy) { String accountid = new SimpleDateFormat(\"yyyyMMddhhmmss\").format(new Date()); jdbcTemplate.update(\"insert INTO account (accountName,user,money) VALUES (?,?,?)\", accountid, name, initMenoy); // 人为报错 int i = 1 / 0; } 演示添加 @Transactional 注解和不添加注解的情况。3、事物传播机制 类别 事物传播类型 说明 支持当前事物 PROPAGATION_REQUIRED（必须的） 如果当前没有事物，就新建一个事物，如果已经存在一个事物中，加入到这个事物中。这是最常见的选择。 PROPAGATION_SUPPORTS（支持） 支持当前事物，如果当前没有事物，就以非事物方式执行。 PROPAGATION_MANDATORY（强制） 使用当前的事物，如果当前没有事物，就抛出异常。 不支持当前事物 PROPAGATION_REQUIRES_NEW(隔离) 新建事物，如果当前存在事物，把当前事物挂起。 PROPAGATION_NOT_SUPPORTED(不支持) 以非事物方式执行操作，如果当前存在事物，就把当前事物挂起。 PROPAGATION_NEVER(强制非事物) 以非事物方式执行，如果当前存在事物，则抛出异常。 套事物 PROPAGATION_NESTED（嵌套事物） 如果当前存在事物，则在嵌套事物内执行。如果当前没有事物，则执行与PROPAGATION_REQUIRED类似的操作。 常用事物传播机制： PROPAGATION_REQUIRED， 这个也是默认的传播机制； PROPAGATION_NOT_SUPPORTED 可以用于发送提示消息，站内信、短信、邮件提示等。不属于并且不应当影响主体业务逻辑，即使发送失败也不应该对主体业务逻辑回滚。 PROPAGATION_REQUIRES_NEW 总是新启一个事物，这个传播机制适用于不受父方法事物影响的操作，比如某些业务场景下需要记录业务日志，用于异步反查，那么不管主体业务逻辑是否完成，日志都需要记录下来，不能因为主体业务逻辑报错而丢失日志； 演示常用事物的传播机制 用例1: 创建用户时初始化一个帐户，表结构和服务类如下。 表结构 服务类 功能描述 user UserSerivce 创建用户，并添加帐户 account AccountService 添加帐户 UserSerivce.createUser(name) 实现代码 @Transactional public void createUser(String name) { // 新增用户基本信息 jdbcTemplate.update(\"INSERT INTO `user` (name) VALUES(?)\", name); //调用accountService添加帐户 accountService.addAccount(name, 10000); ｝ AccountService.addAccount(name,initMoney) 实现代码（方法的最后有一个异常） @Transactional(propagation = Propagation.REQUIRED) public void addAccount(String name, int initMoney) { String accountid = new SimpleDateFormat(\"yyyyMMddhhmmss\").format(new Date()); jdbcTemplate.update(\"insert INTO account (accountName,user,money) VALUES (?,?,?)\", accountid, name, initMenoy); // 出现分母为零的异常 int i = 1 / 0; } 实验预测一： createUser addAccount(异常) 预测结果 场景一 无事物 required user （成功） Account（不成功）正确 场景二 required 无事物 user （不成功） Account（不成功）正确 场景三 required not_supported user （不成功） Account（成功）正确 场景四 required required_new user （不成功） Account（不成功）正确 场景五 required(异常移至createUser方法未尾) required_new user （不成功） Account（成功）正确 场景六 required(异常移至createUser方法未尾)（addAccount 方法称至当前类） required_new user （不成功） Account（不成功） 三、aop 事物底层实现原理 讲事物原理之前我们先来做一个实验，当场景五的环境改变，把addAccount 方法移至UserService 类下，其它配置和代码不变： @Override @Transactional public void createUser(String name) { jdbcTemplate.update(\"INSERT INTO `user` (name) VALUES(?)\", name); addAccount(name, 10000); // 人为报错 int i = 1 / 0; } @Transactional(propagation = Propagation.REQUIRES_NEW) public void addAccount(String name, int initMoney) { String accountid = new SimpleDateFormat(\"yyyyMMddhhmmss\").format(new Date()); jdbcTemplate.update(\"insert INTO account (accountName,user,money) VALUES (?,?,?)\", accountid, name, initMoney); } 演示新场景 经过演示我们发现得出的结果与场景五并不 一至，required_new 没有起到其对应的作用。原因在于spring 声明示事物使用动态代理实现，而当调用同一个类的方法时，是会不会走代理逻辑的，自然事物的配置也会失效。 通过一个动态代理的实现来模拟这种场景 UserSerivce proxyUserSerivce = (UserSerivce) Proxy.newProxyInstance(LubanTransaction.class.getClassLoader(), new Class[]{UserSerivce.class}, new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { try { System.out.println(\"开启事物:\"+method.getName()); return method.invoke(userSerivce, args); } finally { System.out.println(\"关闭事物:\"+method.getName()); } } }); proxyUserSerivce.createUser(\"luban\"); 当我们调用createUser 方法时 仅打印了 createUser 的事物开启、关闭，并没有打印addAccount 方法的事物开启、关闭，由此可见addAccount 的事物配置是失效的。 如果业务当中上真有这种场景该如何实现呢？在spring xml中配置 暴露proxy 对象，然后在代码中用AopContext.currentProxy() 就可以获当前代理对象 // 基于代理对象调用创建帐户，事物的配置又生效了 ((UserSerivce) AopContext.currentProxy()).addAccount(name, 10000); Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:14:27 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"source/spring/mvc.html":{"url":"source/spring/mvc.html","title":"3.Spring mvc原理深度解析","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、spring mvc 设计思想与体系结构组成 1、回顾servlet 与jsp 执行过程 2、spring mvc 执行流程： 3、spring mvc 体系结构 二、mvc 执行流程解析 要点： 2、HandlerMapping 详解 3、HandlerAdapter详解 4、ViewResolver 与View 详解 5、HandlerExceptionResolver详解 6、HandlerInterceptor 详解 三、注解配置 课程概要 spring mvc 设计思想与体系结构组成 mvc 执行流程解析 注解配置 一、spring mvc 设计思想与体系结构组成 jsp 执行过程回顾 spring mvc执行流程解析 mvc 体系结构1、回顾servlet 与jsp 执行过程 流程说明： 请求Servlet 处理业务逻辑 设置业务Model forward jsp Servlet jsp Servlet 解析封装html 返回 提问：这个是一个MVC应用场景吗？ spring mvc本质上还是在使用Servlet处理，并在其基础上进行了封装简化了开发流程，提高易用性、并使用程序逻辑结构变得更清晰 基于注解的URL映谢 http表单参数转换 全局统一异常处理 拦截器的实现2、spring mvc 执行流程： 整个过程是如何实现的？ dispatchServlet 如何找到对应的Control？ 如何执行调用Control 当中的业务方法？ 回答这些问题之前我们先来认识一下spring mvc 体系结构 3、spring mvc 体系结构 HandlerMapping'hændlə 'mæpɪŋ url与控制器的映谢 HandlerAdapter'hændlə ə'dæptə 控制器执行适配器 ViewResolvervjuː riː'zɒlvə 视图仓库 view 具体解析视图 HandlerExceptionResolver'hændlə ɪk'sepʃ(ə)n riː'zɒlvə 异常捕捕捉器 HandlerInterceptor'hændlə ɪntə'septə 拦截器 配置一个spring mvc 示例演示 验证上述流程 - [ ] 创建一个Controller 类 - [ ] 配置DispatchServlet - [ ] 创建spring-mvc.xml 文件 - [ ] 配置SimpleUrlHandlerMapping - [ ] 配置InternalResourceViewResolver 体系结构UML 二、mvc 执行流程解析 要点： mvc 具体执行流程 HandlerMapping详解 HandlerAdapter 详解 ViewResolver与View详解 HandlerExceptionResolver详解 HandlerInterceptor 详解 mvc 各组件执行流程 2、HandlerMapping 详解 其为mvc 中url路径与Control对像的映射，DispatcherServlet 就是基于此组件来寻找对应的Control，如果找不到就会报Not Found mapping 的异常。 HandlerMapping 接口方法 HandlerMapping 接口结构 目前主流的三种mapping 如下： BeanNameUrlHandlerMapping: 基于ioc name 中已 \"/\" 开头的Bean时行 注册至映谢. SimpleUrlHandlerMapping：基于手动配置 url 与control 映谢 RequestMappingHandlerMapping：基于@RequestMapping注解配置对应映谢 [ ] 演示基于 BeanNameUrlHandlerMapping 配置映谢。 编写mvc 文件 // beanname control 控制器 public class BeanNameControl implements HttpRequestHandler { @Override public void handleRequest(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException { request.getRequestDispatcher(\"/WEB-INF/page/userView.jsp\").forward(request, response); } } 当IOC 中实例化这些类之后 DispatcherServlet 就会通过org.springframework.web.servlet.DispatcherServlet#getHandler() 方法基于request查找对应Handler。 但找到对应的Handler之后我们发现他是一个Object类型，并没有实现特定接口。如何调用Handler呢？ 3、HandlerAdapter详解 这里spring mvc 采用适配器模式来适配调用指定Handler，根据Handler的不同种类采用不同的Adapter,其Handler与 HandlerAdapter 对应关系如下: Handler类别 对应适配器 描述 Controller SimpleControllerHandlerAdapter 标准控制器，返回ModelAndView HttpRequestHandler HttpRequestHandlerAdapter 业务自行处理 请求，不需要通过modelAndView 转到视图 Servlet SimpleServletHandlerAdapter 基于标准的servlet 处理 HandlerMethod RequestMappingHandlerAdapter 基于@requestMapping对应方法处理 HandlerAdapter 接口方法 HandlerAdapter 接口结构图 [ ] 演示基于Servlet 处理 SimpleServletHandlerAdapter // 标准Servlet public class HelloServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { resp.getWriter().println(\"hello luban \"); } } 上述例子中当IOC 中实例化这些类之后 DispatcherServlet 就会通过 org.springframework.web.servlet.DispatcherServlet#getHandlerAdapter() 方法查找对应handler的适配器 ，如果找不到就会报 No adapter for handler 。 4、ViewResolver 与View 详解 找到应的Adapter 之后就会基于适配器调用业务处理，处理完之后业务方会返回一个ModelAndView ，在去查找对应的视图进行处理。其在org.springframework.web.servlet.DispatcherServlet#resolveViewName() 中遍历 viewResolvers 列表查找，如果找不到就会报一个 Could not resolve view with name 异常。 在下一步就是基于ViewResolver.resolveViewName() 获取对应View来解析生成Html并返回 。对应VIEW结构如下： 至此整个正向流程就已经走完了，如果此时程序处理异常 MVC 该如何处理呢？ 5、HandlerExceptionResolver详解 该组件用于指示 当出现异常时 mvc 该如何处理。 dispatcherServlet 会调用org.springframework.web.servlet.DispatcherServlet#processHandlerException() 方法，遍历 handlerExceptionResolvers 处理异常，处理完成之后返回errorView 跳转到异常视图。 - [ ] 演示自定义异常捕捉 public class SimpleExceptionHandle implements HandlerExceptionResolver { @Override public ModelAndView resolveException(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) { return new ModelAndView(\"error\"); } } HandlerExceptionResolver 结构 除了上述组件之外 spring 中还引入了 我Interceptor 拦截器 机制，类似于Filter。 6、HandlerInterceptor 详解 [ ] 演示HandlerInterceptorpublic class SimpleHandlerInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { System.out.println(\"preHandle\"); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { System.out.println(\"postHandle\"); } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { System.out.println(\"afterCompletion\"); } } 其实现机制是基于 HandlerExecutionChain 分别在 doDispatch 方法中执行以下方法： preHandle ：业务处理前执行 postHandle：业务处理后（异常则不执行） afterCompletion：视图处理后 具体逻辑源码参见：org.springframework.web.servlet.DispatcherServlet#doDispatch 方法。 三、注解配置 [ ] 演示基于注解配置mvc mapping // 注解方法 @RequestMapping(\"/hello.do\") public ModelAndView hello() { ModelAndView mv = new ModelAndView(\"userView\"); mv.addObject(\"name\", \"luban\"); return mv; } 提问 为什么基于 配置就能实现mvc 的整个配置了，之前所提到的 handlerMapping 、与handlerAdapter 组件都不适用了？ 只要查看以类的源就可以知晓其中原因： [ ] 认识 NamespaceHandler 接口 [ ] 查看 MvcNamespaceHandler [ ] 查看AnnotationDrivenBeanDefinitionParser 结论： 在 对应的解析器，自动向ioc 里面注册了两个BeanDefinition。分别是：RequestMappingHandlerMapping与BeanNameUrlHandlerMapping Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:15:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"concurrent/":{"url":"concurrent/","title":"三、并发编程专题","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"concurrent/executor.html":{"url":"concurrent/executor.html","title":"1.Executor线程池详解","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.什么是线程 2.线程实现的三种方式 3.线程的生命周期&状态 4.线程的执行顺序 5.线程与线程池对比 6.线程池体系介绍 7.线程池源码分析 1.什么是线程 线程是进程的一个实体，是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源 (如程序计数器，一组寄存器和栈 )，但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。 2.线程实现的三种方式 Runnable、 Thread、 Callable 总结 最后再来看看它们三个之间的总结。 实现 Runnable接口相比继承 Thread类有如下优势 1）可以避免由于 Java的单继承特性而带来的局限 2）增强程序的健壮性，代码能够被多个线程共享，代码与数据是独立的 3）线程池只能放入实现 Runable或 Callable类线程，不能直接放入继承 Thread的类 实现 Runnable接口和实现 Callable接口的区别 1）Runnable是自从 java1.1就有了，而 Callable是 1.5之后才加上去的 2）实现 Callable接口的任务线程能返回执行结果，而实现 Runnable接口的任务线程不能返回结果 3 Callable接口的 call()方法允许抛出异 常，而 Runnable接口的 run()方法的异常只能在内部消化，不能继 续上抛 4）加入线程池运行 Runnable使用 ExecutorService的 execute方法， Callable使用 submit方法 注： Callable接口支持返回执行结果，此时需要调用 FutureTask.get()方法实现，此方法会阻塞主线程直到获 取返回结果，当不调用此方法时，主线程不会阻塞 3.线程的生命周期&状态 4.线程的执行顺序 5.线程与线程池对比 6.线程池体系介绍 7.线程池源码分析 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:46:25 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"concurrent/JMM&Lock&Tools.html":{"url":"concurrent/JMM&Lock&Tools.html","title":"2.JMM&Lock&Tools详解","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.JMM 内存模型 2.Volatile 可见性 3.Synchronized 同步 4.Lock 锁 5.ReentrantLock 6.ReentrantReadWriteLock 7.AbstractQueuedSynchronizer 8.CountDownLatch Semaphore 要点： JMM Volatile Synchronized Lock ReentrantLock ReentrantReadWriteLock AbstractQueuedSynchronizer CountDownLatch Semaphore1.JMM 内存模型 2.Volatile 可见性 3.Synchronized 同步 4.Lock 锁 5.ReentrantLock 6.ReentrantReadWriteLock 7.AbstractQueuedSynchronizer 8.CountDownLatch Semaphore Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:46:37 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"concurrent/atomic&collections.html":{"url":"concurrent/atomic&collections.html","title":"3.atomic&collections详解","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.Atomic体系介绍 2.CAS源码分析 3.CAS的ABA问题 4.HashMap 5.HashTable 6.ConcurrenthHashMap 7.ArrayList 8.CopyOnWriteArrayList Copyright &copy ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 要点： Atomic体系介绍 CAS源码分析 CAS的ABA问题 HashMap HashTable ConcurrenthHashMap ArrayList CopyOnWriteArrayList1.Atomic体系介绍 2.CAS源码分析 3.CAS的ABA问题 4.HashMap 5.HashTable 6.ConcurrenthHashMap 7.ArrayList 8.CopyOnWriteArrayList Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:46:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"concurrent/Fork-join.html":{"url":"concurrent/Fork-join.html","title":"4.Fork-join框架原理解析","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.Fork-join编程介绍 2.Fork-join原理分析 3.Fork-join最佳实践 要点： Fork-join编程介绍 Fork-join原理分析 Fork-join最佳实践1.Fork-join编程介绍 2.Fork-join原理分析 3.Fork-join最佳实践 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:46:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"concurrent/BlockingQueue.html":{"url":"concurrent/BlockingQueue.html","title":"5.BlockingQueue框架原理解析","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.基本概念介绍/DIY 并发/阻塞队列 2.JDK 阻塞队列实战与原理分析 2.1ArrayBlockingQueue 2.2LinkedBlockingQueue 2.3LinkedTransferQueue 2.4LinkedBlockingDeque 2.5SynchronousQueue 2.6PriorityBlockingQueue 2.7DelayQueue 3.高性能并发队列讨论 要点： 基本概念介绍/DIY 并发/阻塞队列 JDK 阻塞队列实战与原理分析 高性能并发队列讨论1.基本概念介绍/DIY 并发/阻塞队列 2.JDK 阻塞队列实战与原理分析 2.1ArrayBlockingQueue 基于数组结构的有界阻塞队列（长度不可变） 2.2LinkedBlockingQueue 基于链表结构的有界阻塞队列（默认容量 Integer.MAX_VALUE） 2.3LinkedTransferQueue 基于链表结构的无界阻塞/传递队列 2.4LinkedBlockingDeque 基于链表结构的有界阻塞双端队列（默认容量 Integer.MAX_VALUE） 2.5SynchronousQueue 不存储元素的阻塞/传递队列 2.6PriorityBlockingQueue 支持优先级排序的无界阻塞队列 2.7DelayQueue 支持延时获取元素的无界阻塞队列 3.高性能并发队列讨论 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:47:08 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/":{"url":"performance/","title":"四、性能调优专题","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/jvm/":{"url":"performance/jvm/","title":"jvm","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/jvm/base.html":{"url":"performance/jvm/base.html","title":"1.JVM整体结构介绍","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.JVM整体架构 2.JVM类加载器 2.1类加载过程 2.2类加载器种类（4种） 2.3类加载机制 3.JVM内存结构 4.JVM执行引擎 1.JVM整体架构 JVM由三个主要的子系统构成 类加载器子系统 运行时数据区（内存结构） 执行引擎 2.JVM类加载器 2.1类加载过程 类加载：类加载器将class文件加载到虚拟机的内存 加载：在硬盘上查找并通过IO读入字节码文件 连接：执行校验、准备、解析（可选）步骤 校验：校验字节码文件的正确性 准备：给类的静态变量分配内存，并赋予默认值 解析：类装载器装入类所引用的其他所有类 初始化：对类的静态变量初始化为指定的值，执行静态代码块 2.2类加载器种类（4种） 启动类加载器：负责加载JRE的核心类库，如jre目标下的rt.jar,charsets.jar等 扩展类加载器：负责加载JRE扩展目录ext中JAR类包 系统类加载器：负责加载ClassPath路径下的类包 用户自定义加载器：负责加载用户自定义路径下的类包2.3类加载机制 全盘负责委托机制：当一个ClassLoader加载一个类时，除非显示的使用另一个ClassLoader，该类所依赖和引用的类也由这个ClassLoader载入 双亲委派机制：指先委托父类加载器寻找目标类，在找不到的情况下在自己的路径中查找并载入目标类 3.JVM内存结构 4.JVM执行引擎 执行引擎：读取运行时数据区的Java字节码并逐个执行 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:48:55 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/jvm/view.html":{"url":"performance/jvm/view.html","title":"2.JVM性能调优监控工具","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.Jinfo 2.Jstat 3.Jmap 4.Jstack 5.远程连接jvisualvm 6.jstack找出占用cpu最高的堆栈信息 1.**Jinfo** 查看正在运行的Java应用程序的扩展参数 查看jvm的参数 查看java系统参数 2.Jstat jstat命令可以查看堆内存各部分的使用量，以及加载类的数量。命令的格式如下： jstat [-命令选项] [vmid] [间隔时间/毫秒] [查询次数] 注意：使用的jdk版本是jdk8. 类加载统计： Loaded：加载class的数量 Bytes：所占用空间大小 Unloaded：未加载数量 Bytes:未加载占用空间 Time：时间 垃圾回收统计 S0C：第一个幸存区的大小 S1C：第二个幸存区的大小 S0U：第一个幸存区的使用大小 S1U：第二个幸存区的使用大小 EC：伊甸园区的大小 EU：伊甸园区的使用大小 OC：老年代大小 OU：老年代使用大小 MC：方法区大小(元空间) MU：方法区使用大小 CCSC:压缩类空间大小 CCSU:压缩类空间使用大小 YGC：年轻代垃圾回收次数 YGCT：年轻代垃圾回收消耗时间 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 堆内存统计 NGCMN：新生代最小容量 NGCMX：新生代最大容量 NGC：当前新生代容量 S0C：第一个幸存区大小 S1C：第二个幸存区的大小 EC：伊甸园区的大小 OGCMN：老年代最小容量 OGCMX：老年代最大容量 OGC：当前老年代大小 OC:当前老年代大小 MCMN:最小元数据容量 MCMX：最大元数据容量 MC：当前元数据空间大小 CCSMN：最小压缩类空间大小 CCSMX：最大压缩类空间大小 CCSC：当前压缩类空间大小 YGC：年轻代gc次数 FGC：老年代GC次数 新生代垃圾回收统计 S0C：第一个幸存区的大小 S1C：第二个幸存区的大小 S0U：第一个幸存区的使用大小 S1U：第二个幸存区的使用大小 TT:对象在新生代存活的次数 MTT:对象在新生代存活的最大次数 DSS:期望的幸存区大小 EC：伊甸园区的大小 EU：伊甸园区的使用大小 YGC：年轻代垃圾回收次数 YGCT：年轻代垃圾回收消耗时间 新生代内存统计 NGCMN：新生代最小容量 NGCMX：新生代最大容量 NGC：当前新生代容量 S0CMX：最大幸存1区大小 S0C：当前幸存1区大小 S1CMX：最大幸存2区大小 S1C：当前幸存2区大小 ECMX：最大伊甸园区大小 EC：当前伊甸园区大小 YGC：年轻代垃圾回收次数 FGC：老年代回收次数 老年代垃圾回收统计 MC：方法区大小 MU：方法区使用大小 CCSC:压缩类空间大小 CCSU:压缩类空间使用大小 OC：老年代大小 OU：老年代使用大小 YGC：年轻代垃圾回收次数 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 老年代内存统计 OGCMN：老年代最小容量 OGCMX：老年代最大容量 OGC：当前老年代大小 OC：老年代大小 YGC：年轻代垃圾回收次数 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 元数据空间统计 MCMN:最小元数据容量 MCMX：最大元数据容量 MC：当前元数据空间大小 CCSMN：最小压缩类空间大小 CCSMX：最大压缩类空间大小 CCSC：当前压缩类空间大小 YGC：年轻代垃圾回收次数 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 S0：幸存1区当前使用比例 S1：幸存2区当前使用比例 E：伊甸园区使用比例 O：老年代使用比例 M：元数据区使用比例 CCS：压缩使用比例 YGC：年轻代垃圾回收次数 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 3.**Jmap** 此命令可以用来查看内存信息。 实例个数以及占用内存大小 打开log.txt，文件内容如下： num：序号 instances：实例数量 bytes：占用空间大小 class name：类名称 堆信息 堆内存dump 也可以设置内存溢出自动导出dump文件(内存很大的时候，可能会导不出来) -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./ （路径） 可以用jvisualvm命令工具导入该dump文件分析 4.**Jstack** 用jstack查找死锁，见如下示例，也可以用jvisualvm查看死锁 ** 5.**远程连接jvisualvm** 启动普通的jar程序JMX端口配置： java -Dcom.sun.management.jmxremote.port=12345 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -jar foo.jar tomcat的JMX配置 JAVA_OPTS=-Dcom.sun.management.jmxremote.port=8999 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false jvisualvm远程连接服务需要在远程服务器上配置host(连接ip 主机名)，并且要关闭防火墙 6.**jstack找出占用cpu最高的堆栈信息** 1，使用命令top -p ，显示你的java进程的内存情况，pid是你的java进程号，比如4977 2，按H，获取每个线程的内存情况 3，找到内存和cpu占用最高的线程tid，比如4977 4，转为十六进制得到 0x1371 ,此为线程id的十六进制表示 5，执行 jstack 4977|grep -A 10 1371，得到线程堆栈信息中1371这个线程所在行的后面10行 6，查看对应的堆栈信息找出可能存在问题的代码 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:49:07 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/jvm/gc.html":{"url":"performance/jvm/gc.html","title":"3.JVM垃圾回收与调优","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.JVM内存分配与回收 1.1 对象优先在Eden区分配 1.2 大对象直接进入老年代 1.3 长期存活的对象将进入老年代 2.如何判断对象可以被回收 2.1 引用计数法 2.2 可达性分析算法 2.3 finalize()方法最终判定对象是否存活 2.4 如何判断一个常量是废弃常量 2.5 如何判断一个类是无用的类 3.垃圾收集算法 3.1 标记-清除算法 3.2 复制算法 3.3 标记-整理算法 3.4 分代收集算法 4.垃圾收集器 4.1 Serial收集器 4.2 ParNew收集器 4.3 Parallel Scavenge收集器 4.4.Serial Old收集器 4.5 Parallel Old收集器 4.6 CMS收集器(-XX:+UseConcMarkSweepGC(主要是old区使用)) 4.7 G1收集器(-XX:+UseG1GC) 5. 如何选择垃圾收集器 6. 实战调优 6.1JVM调优主要就是调整下面两个指标 6.2GC调优步骤 6.3G1调优相关 1.JVM内存分配与回收 1.1 对象优先在Eden区分配 大多数情况下，对象在新生代中 Eden 区分配。当 Eden 区没有足够空间进行分配时，虚拟机将发起一次Minor GC。我们来进行实际测试一下。 在测试之前我们先来看看Minor Gc和Full GC 有什么不同呢？ 新生代GC（Minor GC）:指发生新生代的的垃圾收集动作，Minor GC非常频繁，回收速度一般也比较快。 老年代GC（Major GC/Full GC）:指发生在老年代的GC，出现了Major GC经常会伴随至少一次的Minor GC（并非绝对），Major GC的速度一般会比Minor GC的慢10倍以上。 测试： 通过以下方式运行： 添加的参数：**-XX:+PrintGCDetails** 运行结果： 从上图我们可以看出eden区内存几乎已经被分配完全（即使程序什么也不做，新生代也会使用至少2000多k内存）。假如我们再为allocation2分配内存会出现什么情况呢？ 简单解释一下为什么会出现这种情况：因为给allocation2分配内存的时候eden区内存几乎已经被分配完了，我们刚刚讲了当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC.GC期间虚拟机又发现allocation1无法存入Survior空间，所以只好通过分配担保机制把新生代的对象提前转移到老年代中去，老年代上的空间足够存放allocation1，所以不会出现Full GC。执行Minor GC后，后面分配的对象如果能够存在eden区的话，还是会在eden区分配内存。可以执行如下代码验证： 1.2 大对象直接进入老年代 大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。 为什么要这样呢？ 为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率。 1.3 长期存活的对象将进入老年代 既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别那些对象应放在新生代，那些对象应放在老年代中。为了做到这一点，虚拟机给每个对象一个对象年龄（Age）计数器。 如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为1.对象在 Survivor 中每熬过一次 MinorGC,年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数-XX:MaxTenuringThreshold来设置。 2.如何判断对象可以被回收 堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断那些对象已经死亡（即不能再被任何途径使用的对象）。 2.1 引用计数法 给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加1；当引用失效，计数器就减1；任何时候计数器为0的对象就是不可能再被使用的。 这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。所谓对象之间的相互引用问题，如下面代码所示：除了对象objA 和 objB 相互引用着对方之外，这两个对象之间再无任何引用。但是他们因为互相引用对方，导致它们的引用计数器都不为0，于是引用计数算法无法通知 GC 回收器回收他们。 2.2 可达性分析算法 这个算法的基本思想就是通过一系列的称为“GC Roots”的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。 GC Roots根节点：类加载器、Thread、虚拟机栈的本地变量表、static成员、常量引用、本地方法栈的变量等等 2.3 finalize()方法最终判定对象是否存活 即使在可达性分析算法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历再次标记过程。 标记的前提是对象在进行可达性分析后发现没有与GC Roots相连接的引用链。 1. 第一次标记并进行一次筛选。 筛选的条件是此对象是否有必要执行finalize()方法。 当对象没有覆盖finalize方法，或者finzlize方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”，对象被回收。 2. 第二次标记 如果这个对象被判定为有必要执行finalize（）方法，那么这个对象将会被放置在一个名为：F-Queue的队列之中，并在稍后由一条虚拟机自动建立的、低优先级的Finalizer线程去执行。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束。这样做的原因是，如果一个对象finalize（）方法中执行缓慢，或者发生死循环（更极端的情况），将很可能会导致F-Queue队列中的其他对象永久处于等待状态，甚至导致整个内存回收系统崩溃。 finalize（）方法是对象脱逃死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模标记，如果对象要在finalize（）中成功拯救自己----只要重新与引用链上的任何的一个对象建立关联即可，譬如把自己赋值给某个类变量或对象的成员变量，那在第二次标记时它将移除出“即将回收”的集合。如果对象这时候还没逃脱，那基本上它就真的被回收了。 见示例程序： 2.4 如何判断一个常量是废弃常量 运行时常量池主要回收的是废弃的常量。那么，我们如何判断一个常量是废弃常量呢？ 假如在常量池中存在字符串 \"abc\"，如果当前没有任何String对象引用该字符串常量的话，就说明常量 \"abc\" 就是废弃常量，如果这时发生内存回收的话而且有必要的话，\"abc\" 就会被系统清理出常量池。 2.5 如何判断一个类是无用的类 方法区主要回收的是无用的类，那么如何判断一个类是无用的类的呢？ 判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面3个条件才能算是“无用的类”： 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述3个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。 3.垃圾收集算法 3.1 标记-清除算法 算法分为“标记”和“清除”阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。它是最基础的收集算法，效率也很高，但是会带来两个明显的问题： 效率问题 空间问题（标记清除后会产生大量不连续的碎片） 3.2 复制算法 为了解决效率问题，“复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。 3.3 标记-整理算法 根据老年代的特点特出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一段移动，然后直接清理掉端边界以外的内存。 3.4 分代收集算法 当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将java堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。 比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。 4.垃圾收集器 如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。 虽然我们对各个收集器进行比较，但并非为了挑选出一个最好的收集器。因为直到现在为止还没有最好的垃圾收集器出现，更加没有万能的垃圾收集器，我们能做的就是根据具体应用场景选择适合自己的垃圾收集器。试想一下：如果有一种四海之内、任何场景下都适用的完美收集器存在，那么我们的HotSpot虚拟机就不会实现那么多不同的垃圾收集器了。 4.1 Serial收集器 Serial（串行）收集器收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的“单线程”的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（\"Stop The World\"），直到它收集结束。 新生代采用复制算法，老年代采用标记-整理算法。 虚拟机的设计者们当然知道Stop The World带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续）。 但是Serial收集器有没有优于其他垃圾收集器的地方呢？当然有，它简单而高效（与其他收集器的单线程相比）。Serial收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。 4.2 ParNew收集器 ParNew收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和Serial收集器完全一样。 新生代采用复制算法，老年代采用标记-整理算法。 它是许多运行在Server模式下的虚拟机的首要选择，除了Serial收集器外，只有它能与CMS收集器（真正意义上的并发收集器，后面会介绍到）配合工作。 并行和并发概念补充： 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。适合科学计算、后台处理等弱交互场景。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个CPU上。适合Web应用。4.3 Parallel Scavenge收集器 Parallel Scavenge 收集器类似于ParNew 收集器，是Server 模式（内存大于2G，2个cpu）下的默认收集器，那么它有什么特别之处呢？ Parallel Scavenge收集器关注点是吞吐量（高效率的利用CPU）。CMS等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是CPU中用于运行用户代码的时间与CPU总消耗时间的比值。Parallel Scavenge收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解的话，可以选择把内存管理优化交给虚拟机去完成也是一个不错的选择。 新生代采用复制算法，老年代采用标记-整理算法。 4.4.Serial Old收集器 Serial收集器的老年代版本，它同样是一个单线程收集器。它主要有两大用途：一种用途是在JDK1.5以及以前的版本中与Parallel Scavenge收集器搭配使用，另一种用途是作为CMS收集器的后备方案。 4.5 Parallel Old收集器 Parallel Scavenge收集器的老年代版本。使用多线程和“标记-整理”算法。在注重吞吐量以及CPU资源的场合，都可以优先考虑 Parallel Scavenge收集器和Parallel Old收集器。 4.6 CMS收集器(-XX:+UseConcMarkSweepGC(**主要是old区使用**)) CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它而非常符合在注重用户体验的应用上使用，它是HotSpot虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。 从名字中的Mark Sweep这两个词可以看出，CMS收集器是一种“标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤： 初始标记：暂停所有的其他线程(STW)，并记录下直接与root相连的对象，速度很快 ； 并发标记：同时开启GC和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以GC线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。 重新标记：重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短 并发清除：开启用户线程，同时GC线程开始对未标记的区域做清扫。 从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：并发收集、低停顿。但是它有下面三个明显的缺点： 对CPU资源敏感（会和服务抢资源）； 无法处理浮动垃圾(在java业务程序线程与垃圾收集线程并发执行过程中又产生的垃圾，这种浮动垃圾只能等到下一次gc再清理了)； 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。 CMS的相关参数 -XX:+UseConcMarkSweepGC 启用cms -XX:ConcGCThreads:并发的GC线程数（并非STW时间，而是和服务一起执行的线程数） -XX:+UseCMSCompactAtFullCollection:FullGC之后做压缩（减少碎片） -XX:CMSFullGCsBeforeCompaction:多少次FullGC之后压缩一次（因压缩非常的消耗时间，所以不能每次FullGC都做） -XX:CMSInitiatingOccupancyFraction:触发FulGC条件（默认是92） -XX:+UseCMSInitiatingOccupancyOnly:是否动态调节 -XX:+CMSScavengeBeforeRemark:FullGC之前先做YGC（一般这个参数是打开的） -XX:+CMSClassUnloadingEnabled:启用回收Perm区（jdk1.7及以前）4.7 G1收集器(-XX:+UseG1GC) G1 (Garbage-First)是一款面向服务器的垃圾收集器,**主要针对配备多颗处理器及大容量内存的机器**. 以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征. G1将Java堆划分为多个大小相等的独立区域（Region），虽保留新生代和老年代的概念，但不再是物理隔阂了，它们都是（可以不连续）Region的集合。 分配大对象（直接进Humongous区，专门存放短期巨型对象，不用直接进老年代，避免Full GC的大量开销）不会因为无法找到连续空间而提前触发下一次GC。 被视为JDK1.7中HotSpot虚拟机的一个重要进化特征。它具备以下特点： 并行与并发：G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿时间。部分其他收集器原本需要停顿Java线程来执行GC动作，G1收集器仍然可以通过并发的方式让java程序继续执行。 分代收集：虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但是还是保留了分代的概念。 空间整合：与CMS的“标记--清理”算法不同，G1从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。 可预测的停顿：这是G1相对于CMS的另一个大优势，降低停顿时间是G1 和 CMS 共同的关注点，但G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内完成垃圾收集。 G1收集器的运作大致分为以下几个步骤： 初始标记（initial mark，STW）：在此阶段，G1 GC 对根进行标记。该阶段与常规的 (STW) 年轻代垃圾回收密切相关。 并发标记（Concurrent Marking）：G1 GC 在整个堆中查找可访问的（存活的）对象。 最终标记（Remark，STW）：该阶段是 STW 回收，帮助完成标记周期。 筛选回收（Cleanup，STW）：筛选回收阶段首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。 G1收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的Region(这也就是它的名字Garbage-First的由来)。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了GF收集器在有限时间内可以尽可能高的收集效率。 G1垃圾收集分类 YoungGC 新对象进入Eden区 存活对象拷贝到Survivor区 存活时间达到年龄阈值时，对象晋升到Old区 MixedGC 不是FullGC，回收所有的Young和部分Old(根据期望的GC停顿时间确定old区垃圾收集的优先顺序) global concurrent marking （全局并发标记） Initial marking phase:标记GC Root，STW Root region scanning phase：标记存活Region Concurrent marking phase：标记存活的对象 Remark phase :重新标记,STW Cleanup phase:部分STW 相关参数 G1MixedGCLiveThresholdPercent Old区的region被回收的时候的存活对象占比 G1MixedGCCountTarget：一次global concurrent marking之后，最多执行Mixed GC的次数 G1OldCSetRegionThresholdPercent 一次Mixed GC中能被选入CSet的最多old区的region数量 触发的时机 InitiatingHeapOccupancyPercent:堆占有率达到这个值则触发global concurrent marking，默认45% G1HeapWastePercent:在global concurrent marking结束之后，可以知道区有多少空间要被回收，在每次YGC之后和再次发生Mixed GC之前，会检查垃圾占比是否达到了此参数，只有达到了，下次才会发生Mixed GC5. 如何选择垃圾收集器 优先调整堆的大小让服务器自己来选择 如果内存小于100M，使用串行收集器 如果是单核，并且没有停顿时间的要求，串行或JVM自己选择 如果允许停顿时间超过1秒，选择并行或者JVM自己选 如果响应时间最重要，并且不能超过1秒，使用并发收集器 下图有连线的可以搭配使用，官方推荐使用G1，因为性能高 6. 实战调优 6.1**JVM调优主要就是调整下面两个指标** 停顿时间**: 垃圾收集器做垃圾回收中断应用执行的时间。-XX:MaxGCPauseMillis** 吞吐量**：花在垃圾收集的时间和花在应用时间的占比 -XX:GCTimeRatio=,垃圾收集时间占比：1/(1+n)** 6.2**GC调优步骤** 打印GC日志 -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -Xloggc:./gc.log 分析日志得到关键性指标 分析GC原因，调优JVM参数 1、Parallel Scavenge收集器(默认) 分析parallel-gc.log 第一次调优，设置Metaspace大小：增大元空间大小-XX:MetaspaceSize=64M -XX:MaxMetaspaceSize=64M 第二次调优，添加吞吐量和停顿时间参数：-XX:MaxGCPauseMillis=100 -XX:GCTimeRatio=99 第三次调优，修改动态扩容增量：-XX:YoungGenerationSizeIncrement=30 2、配置CMS收集器 -XX:+UseConcMarkSweepGC 分析cms-gc.log 3、配置G1收集器 -XX:+UseG1GC 分析g1-gc.log 查看发生MixedGC的阈值：jinfo -flag InitiatingHeapOccupancyPercent 进程id 分析工具：gceasy，GCViewer 6.3**G1调优相关** 常用参数 -XX:+UseG1GC 开启G1 -XX:G1HeapRegionSize=n,region的大小，1-32M，2048个 -XX:MaxGCPauseMillis=200 最大停顿时间 -XX:G1NewSizePercent -XX:G1MaxNewSizePercent -XX:G1ReservePercent=10 保留防止to space溢出（） -XX:ParallelGCThreads=n SWT线程数（停止应用程序） -XX:ConcGCThreads=n 并发线程数=1/4*并行 最佳实践 年轻代大小：避免使用-Xmn、-XX:NewRatio等显示设置Young区大小，会覆盖暂停时间目标（常用参数3） 暂停时间目标：暂停时间不要太严苛，其吞吐量目标是90%的应用程序时间和10%的垃圾回收时间，太严苛会直接影响到吞吐量 是否需要切换到G1 50%以上的堆被存活对象占用 对象分配和晋升的速度变化非常大 垃圾回收时间特别长，超过1秒 G1调优目标 6GB以上内存 停顿时间是500ms以内 吞吐量是90%以上 GC常用参数 堆栈设置 -Xss:每个线程的栈大小 -Xms:初始堆大小，默认物理内存的1/64 -Xmx:最大堆大小，默认物理内存的1/4 -Xmn:新生代大小 -XX:NewSize:设置新生代初始大小 -XX:NewRatio:默认2表示新生代占年老代的1/2，占整个堆内存的1/3。 -XX:SurvivorRatio:默认8表示一个survivor区占用1/8的Eden内存，即1/10的新生代内存。 -XX:MetaspaceSize:设置元空间大小 -XX:MaxMetaspaceSize:设置元空间最大允许大小，默认不受限制，JVM Metaspace会进行动态扩展。 垃圾回收统计信息 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:filename 收集器设置 -XX:+UseSerialGC:设置串行收集器 -XX:+UseParallelGC:设置并行收集器 -XX:+UseParallelOldGC:老年代使用并行回收收集器 -XX:+UseParNewGC:在新生代使用并行收集器 -XX:+UseParalledlOldGC:设置并行老年代收集器 -XX:+UseConcMarkSweepGC:设置CMS并发收集器 -XX:+UseG1GC:设置G1收集器 -XX:ParallelGCThreads:设置用于垃圾回收的线程数 并行收集器设置 -XX:ParallelGCThreads:设置并行收集器收集时使用的CPU数。并行收集线程数。 -XX:MaxGCPauseMillis:设置并行收集最大暂停时间 -XX:GCTimeRatio:设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n) CMS收集器设置 -XX:+UseConcMarkSweepGC:设置CMS并发收集器 -XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况。 -XX:ParallelGCThreads:设置并发收集器新生代收集方式为并行收集时，使用的CPU数。并行收集线程数。 -XX:CMSFullGCsBeforeCompaction:设定进行多少次CMS垃圾回收后，进行一次内存压缩 -XX:+CMSClassUnloadingEnabled:允许对类元数据进行回收 -XX:UseCMSInitiatingOccupancyOnly:表示只在到达阀值的时候，才进行CMS回收 -XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况 -XX:ParallelCMSThreads:设定CMS的线程数量 -XX:CMSInitiatingOccupancyFraction:设置CMS收集器在老年代空间被使用多少后触发 -XX:+UseCMSCompactAtFullCollection:设置CMS收集器在完成垃圾收集后是否要进行一次内存碎片的整理 G1收集器设置 -XX:+UseG1GC:使用G1收集器 -XX:ParallelGCThreads:指定GC工作的线程数量 -XX:G1HeapRegionSize:指定分区大小(1MB~32MB，且必须是2的幂)，默认将整堆划分为2048个分区 -XX:GCTimeRatio:吞吐量大小，0-100的整数(默认9)，值为n则系统将花费不超过1/(1+n)的时间用于垃圾收集 -XX:MaxGCPauseMillis:目标暂停时间(默认200ms) -XX:G1NewSizePercent:新生代内存初始空间(默认整堆5%) -XX:G1MaxNewSizePercent:新生代内存最大空间 -XX:TargetSurvivorRatio:Survivor填充容量(默认50%) -XX:MaxTenuringThreshold:最大任期阈值(默认15) -XX:InitiatingHeapOccupancyPercen:老年代占用空间超过整堆比IHOP阈值(默认45%),超过则执行混合收集 -XX:G1HeapWastePercent:堆废物百分比(默认5%) -XX:G1MixedGCCountTarget:参数混合周期的最大总次数(默认8) Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 14:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/mysql/":{"url":"performance/mysql/","title":"mysql","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/mysql/use.html":{"url":"performance/mysql/use.html","title":"1.Mysql安装和使用","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 安装MySQL 1.安装包准备 2.安装MySQL服务器 3.安装MySQL客户端 4.MySQL中user表中主机配置 5.开启bin-log 安装MySQL 注意：一定要用root用户操作如下步骤；先卸载MySQL再安装 1.安装包准备 （1）查看MySQL是否安装 rpm -qa|grep mysql （2）如果安装了MySQL，就先卸载 rpm -e --nodeps mysql-libs-5.1.73-7.el6.x86_64 （3）上传mysql-libs.zip到hadoop102的/opt/software目录，并解压文件到当前目录 unzip mysql-libs.zip （4）进入到mysql-libs文件夹下 ll -rw-r--r--. 1 root root 18509960 3月 26 2015 MySQL-client-5.6.24-1.el6.x86_64.rpm -rw-r--r--. 1 root root 3575135 12月 1 2013 mysql-connector-java-5.1.27.tar.gz -rw-r--r--. 1 root root 55782196 3月 26 2015 MySQL-server-5.6.24-1.el6.x86_64.rpm 2.安装MySQL服务器 （1）安装MySQL服务端 rpm -ivh MySQL-server-5.6.24-1.el6.x86_64.rpm （2）查看产生的随机密码 cat /root/.mysql_secret OEXaQuS8IWkG19Xs （3）查看MySQL状态 service mysql status （4）启动MySQL service mysql start 3.安装MySQL客户端 （1）安装MySQL客户端 rpm -ivh MySQL-client-5.6.24-1.el6.x86_64.rpm （2）链接MySQL（密码替换成产生的随机密码） mysql -uroot -pOEXaQuS8IWkG19Xs （3）修改密码 mysql>SET PASSWORD=PASSWORD('000000'); （4）退出MySQL mysql>exit 4.MySQL中user表中主机配置 配置只要是root用户+密码，在任何主机上都能登录MySQL数据库。 （1）进入MySQL mysql -uroot -p000000 （2）显示数据库 mysql>show databases; （3）使用MySQL数据库 mysql>use mysql; （4）展示MySQL数据库中的所有表 mysql>show tables; （5）展示user表的结构 mysql>desc user; （6）查询user表 mysql>select User, Host, Password from user; （7）修改user表，把Host表内容修改为% mysql>update user set host='%' where host='localhost'; （8）删除root用户的其他host mysql> delete from user where Host='hadoop102'; delete from user where Host='127.0.0.1'; delete from user where Host='::1'; （9）刷新 mysql>flush privileges; （10）退出 mysql>quit; 5.开启bin-log 打开mysql 的配置文件my.ini(别说找不到哦) 在mysqld配置项下面加上log_bin=mysql_bin [mysqld] log_bin = mysql_bin 重启mysql 在次show variables like 'log_bin' Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:14:39 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/mysql/high-use.html":{"url":"performance/mysql/high-use.html","title":"2.Mysql性能优化","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.Mysql架构介绍 1.1Mysql存储引擎 1.2Mysql逻辑架构 1.3Mysql物理文件体系结构 （1）binlog二进制日志文件 （2）redo重做日志文件 （3）共享表空间和独立表空间 （4）undo log （5）临时表空间 （6）error log （7）slow.log 2.InnoDB存储引擎体系结构 2.1缓冲池 2.2change buffer 2.3自适应哈希索引 2.4redo log buffer 2.5double write 2.6InnoDB后台线程 2.6.1InnoDB后台主线程 2.6.2InnoDB后台I/O线程 2.6.3InnoDB脏页刷新线程 2.6.4InnoDB purge线程 2.7redo log 2.8undo log 2.9Query Cache 3.Mysql事务和锁 3.1事务隔离级别 3.2InoDB锁机制介绍 3.3锁等待和死锁 3.3.1锁等待 3.3.2死锁 3.5锁问题的监控 4.Mysql服务器全面优化 4.1Mysql 5.7 InnoDB存储引擎增强特性 4.2硬件层面优化 4.3Linux操作系统层面优化 4.4Mysql配置参数优化 4.5设计规范 1.Mysql架构介绍 1.1Mysql存储引擎 InnoDB 支持行锁,事务 MyISAM 支持表锁,不支持事务 Memory 默认使用hash索引,比b+tree效力高 可通过show engines;命令来查看 1.2Mysql逻辑架构 1.3Mysql物理文件体系结构 （1）binlog二进制日志文件 不管使用的是哪一种存储引擎，都会产生binlog。如果开启了binlog二进制日志，就会有若干个二进制日志文件，如mysql-bin.000001、mysql-bin.000002、mysql-bin.00003等。binlog记录了MySQL对数据库执行更改的所有操作。查看当前binlog文件列表，如图1-7所示。 show master logs ; 。从MySQL 5.1版本开始，MySQL引入了binlog_format参数。这个参数有可选值statement和row：statement就是之前的格式，基于SQL语句来记录；row记录的则是行的更改情况，可以避免之前提到的数据不一致的问题。做MySQL主从复制，statement格式的binlog可能会导致主备不一致，所以要使用row格式。我们还需要借助mysqlbinlog工具来解析和查看binlog中的内容。如果需要用binlog来恢复数据，标准做法是用mysqlbinlog工具把binlog中的内容解析出来，然后把解析结果整个发给MySQL执行。 （2）redo重做日志文件 ib_logfile0、ib_logfile1是InnoDB引擎特有的、用于记录InnoDB引擎下事务的日志，它记录每页更改的物理情况。首先要搞明白的是已经有binlog了为什么还需要redo log，因为两者分工不同。binlog主要用来做数据归档，但是并不具备崩溃恢复的能力，也就是说如果系统突然崩溃，重启后可能会有部分数据丢失。Innodb将所有对页面的修改操作写入一个专门的文件，并在数据库启动时从此文件进行恢复操作，这个文件就是redo log file。redo log的存在可以完美解决这个问题。默认情况下，每个InnoDB引擎至少有一个重做日志组，每组下至少有两个重做日志文件，例如前面提到的ib_logfile0和ib_logfile1。重做日志组中的每个日志文件大小一致且循环写入，也就是说先写iblogfile0，写满了之后写iblogfile1，一旦iblogfile1写满了，就继续写iblogfile0。 （3）共享表空间和独立表空间 在MySQL 5.6.6之前的版本中，InnoDB默认会将所有的数据库InnoDB引擎的表数据存储在一个共享表空间ibdata1中，这样管理起来很困难，增删数据库的时候，ibdata1文件不会自动收缩，单个数据库的备份也将成为问题。为了优化上述问题，在MySQL 5.6.6之后的版本中，独立表空间innodb_file_per_table参数默认开启，每个数据库的每个表都有自已独立的表空间，每个表的数据和索引都会存在自己的表空间中。即便是innnodb表指定为独立表空间，用户自定义数据库中的某些元数据信息、回滚（undo）信息、插入缓冲（change buffer）、二次写缓冲（double write buffer）等还是存放在共享表空间，所以又称为系统表空间。 show variables like 'innodb_data%'; （4）undo log undo log是回滚日志，如果事务回滚，则需要依赖undo日志进行回滚操作。MySQL在进行事务操作的同时，会记录事务性操作修改数据之前的信息，就是undo日志，确保可以回滚到事务发生之前的状态。innodb的undo log存放在ibdata1共享表空间中，当开启事务后，事务所使用的undo log会存放在ibdata1中，即使这个事务被关闭，undo log也会一直占用空间。 show variables like '%undo%'; （5）临时表空间 存储临时对象的空间，比如临时表对象等。如图1-10所示，参数innodb_temp_data_file_path可以看到临时表空间的信息，上限设置为5GB。 show variables like 'innodb_temp_data_file_path%'; （6）error log 错误日志记录了MySQL Server每次启动和关闭的详细信息，以及运行过程中所有较为严重的警告和错误信息。 show variables like 'log_error%'; （7）slow.log 如果配置了MySQL的慢查询日志，MySQL就会将运行过程中的慢查询日志记录到slow_log文件中。MySQL的慢查询日志是MySQL提供的一种日志记录，用来记录在MySQL中响应时间超过阀值的语句，具体指运行时间超过long_query_time值的SQL。 show variables like '%slow_query_log%'; 例如，mysqldumpslow -s r -t 20 /database/mysql/slow-log表示为得到返回记录集最多的20个查询；mysqldumpslow -s t -t 20 -g \"left join\" /database/mysql/slow-log表示得到按照时间排序的前20条里面含有左连接的查询语句。 2.InnoDB存储引擎体系结构 2.1缓冲池 InnoDB存储引擎是基于磁盘存储的。由于CPU速度和磁盘速度之间的鸿沟，InnoDB引擎使用缓冲池技术来提高数据库的整体性能。 show variables like 'innodb_buffer_pool_size%'; ，这个对InnoDB整体性能影响也最大，一般可以设置为50%到80%的内存大小。在专用数据库服务器上，可以将缓冲池大小设置得大些，多次访问相同的数据表数据所需要的磁盘I/O就更少 InnoDB存储引擎的缓存机制和MyISAM的最大区别就在于InnoDB缓冲池不仅仅缓存索引，还会缓存实际的数据。 InnoDB存储引擎的LRU列表中还加入了midpoint位置，即新读取的页并不是直接放到LRU列表首部，而是放到LRU列表的midpoint位置。这个算法在InnoDB存储引擎下称为midpoint insertion strategy，默认该位置在LRU列表长度的5/8处。midpoint的位置可由参数innodb_old_blocks_pct控制 show variables like 'innodb_old_blocks_pct%'; 在图中，innodb_old_blocks_pct默认值为37，表示新读取的页插入到LRU列表尾端37%的位置 MySQL 5.6之后的版本提供了一个新特性来快速预热buffer_pool缓冲池，如图2-4所示。参数innodb_buffer_pool_dump_at_shutdown=ON表示在关闭MySQL时会把内存中的热数据保存在磁盘里ib_buffer_pool文件中，其保存比率由参数innodb_buffer_pool_dump_pct控制，默认为25%。 2.2change buffer change buffer的主要目的是将对二级索引的数据操作缓存下来，以减少二级索引的随机I/O，并达到操作合并的效果。 2.3自适应哈希索引 InnoDB存储引擎会监控对表上二级索引的查找。如果发现某二级索引被频繁访问，二级索引就成为热数据；如果观察到建立哈希索引可以带来速度的提升，则建立哈希索引，所以称之为自适应（adaptive）的，即自适应哈希索引（Adaptive Hash Index，AHI）。 2.4redo log buffer redo log buffer是一块内存区域，存放将要写入redo log文件的数据 2.5double write double write（两次写）技术的引入是为了提高数据写入的可靠性 2.6InnoDB后台线程 2.6.1InnoDB后台主线程 master thread是InnoD存储引擎非常核心的一个在后台运行的主线程，相当重要。它做的主要工作包括但不限于：将缓冲池中的数据异步刷新到磁盘，保证数据的一致性，包括脏页的刷新、合并插入缓冲等。 2.6.2InnoDB后台I/O线程 在InnoDB存储引擎中大量使用了AIO（Async I/O）来处理写I/O请求，这样可以极大地提高数据库的性能。I/O线程的工作主要是负责这些I/O请求的回调（call back）处理。InnoDB 1.0版本之前共有4个I/O线程，分别是write、read、insert buffer和log I/O thread。在Linux平台下，I/O线程的数量不能进行调整，但是在Windows平台下可以通过参数innodb_file_io_threads来增大I/O线程。从InnoDB 1.0.x版本开始，read thread和write thread分别增大到了4个，并且不再使用innodb_file_io_threads参数，而是分别使用innodb_read_io_threads和innodb_write_io_threads参数进行设置，如此调整后，在Linux平台上就可以根据CPU核数来更改相应的参数值了。 2.6.3InnoDB脏页刷新线程 MySQL 5.6版本以前，脏页的清理工作交由master线程处理。page cleaner thread是5.6.2版本引入的一个新线程，实现从master线程中卸下缓冲池刷脏页的工作。为了进一步提升扩展性和刷脏效率，在5.7.4版本里引入了多个page cleaner线程，从而达到并行刷脏的效果。 2.6.4InnoDB purge线程 purge thread负责回收已经使用并分配的undo页 2.7redo log 明确一下InnoDB修改数据的基本流程。当我们想要修改DB上某一行数据的时候，InnoDB是把数据从磁盘读取到内存的缓冲池上进行修改。这个时候数据在内存中被修改，与磁盘中相比就存在了差异，我们称这种有差异的数据为脏页。InnoDB对脏页的处理不是每次生成脏页就将脏页刷新回磁盘，因为这样会产生海量的I/O操作，严重影响InnoDB的处理性能。既然脏页与磁盘中的数据存在差异，那么如果在此期间DB出现故障就会造成数据丢失。为了解决这个问题，redo log就应运而生了。 2.8undo log undo log是InnoDB MVCC事务特性的重要组成部分。当我们对记录做了变更操作时就会产生undo记录，undo记录默认被记录到系统表空间（ibdata）中，但从MySQL 5.6开始，也可以使用独立的undo表空间。 2.9Query Cache 3.Mysql事务和锁 3.1事务隔离级别 数据库提供了4种隔离级别，由低到高依次为read uncommitted（读未提交）、read committed（读已提交）、repeatable read（可重复读取）、serializable（序列化）。 3.2InoDB锁机制介绍 锁机制是事务型数据库中为了保证数据的一致性手段 InnoDB主要使用两种级别的锁机制： 行级锁和表级锁。 InnoDB的行级锁类型主要有共享（S）锁（又称读锁）、排他（X）锁（又称写锁）。共享（S）锁允许持有该锁的事务读取行；排他（X）锁允许持有该锁的事务更新或删除行。 3.3锁等待和死锁 3.3.1锁等待 锁等待是指一个事务过程中产生的锁，其他事务需要等待上一个事务释放它的锁才能占用该资源。如果该事务一直不释放，就需要持续等待下去，直到超过了锁等待时间，会报一个等待超时的错误。在MySQL中通过innodb_lock_wait_timeout参数来控制锁等待时间，单位是秒。如图3-9所示，可以通过语句show variables like '%innodb_lock_wait%'来查看锁等待超时时间 当MySQL发生锁等待情况时，可以通过语句select * from sys.innodb_lock_waits来在线查看， 3.3.2死锁 在MySQL中，两个或两个以上的事务相互持有和请求锁，并形成一个循环的依赖关系，就会产生死锁，也就是锁资源请求产生了死循环现象。InnoDB会自动检测事务死锁，立即回滚其中某个事务，并且返回一个错误。它根据某种机制来选择那个最简单（代价最小）的事务来进行回滚。常见的死锁会报错“ERROR 1213 (40001):deadlock found when trying to get lock; try restarting transaction.”。偶然发生的死锁不必担心，InnoDB存储引擎有一个后台的锁监控线程，该线程负责查看可能的死锁问题，并自动告知用户。 3.5锁问题的监控 我们通过show full processlist是为了查看当前MySQL是否有压力、都在跑什么语句、当前语句耗时多久了，从中可以看到总共有多少链接数、哪些线程有问题，然后把有问题的线程kill掉，临时解决一些突发性的问题。 通过执行show engine innodb status命令来查看是否存在锁表情况，如 MySQL将事务和锁信息记录在了information_schema数据库中，我们只需要查询即可。涉及的表主要有3个，即innodb_trx、innodb_locks、innodb_lock_waits， select * from information_schema.INNODB_TRX; select * from information_schema.INNODB_LOCKS; select * from information_schema.INNODB_LOCK_WAITS; 4.Mysql服务器全面优化 4.1Mysql 5.7 InnoDB存储引擎增强特性 Online Alter Table以及索引 innodb_buffer_pool online change innodb_buffer_pool_dump和load的增强 InnoDB临时表优化 page clean的效率提升 undo log自动清除4.2硬件层面优化 （1）使用SSD或者PCIe SSD设备，至少获得数百倍甚至万倍的IOPS提升。 4.3Linux操作系统层面优化 文件系统选择推荐使用xfs 4.4Mysql配置参数优化 4.5设计规范 库表的设计规范 索引设计规范 sql语句的规范 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:20:32 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/mysql/mysql-index.html":{"url":"performance/mysql/mysql-index.html","title":"3.索引底层数据结构","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.索引到底是什么 2.索引底层数据结构与算法 2.1B-Tree 2.2B+Tree(B-Tree变种) 3.索引最左前缀原理 1.索引到底是什么 索引是帮助MySQL高效获取数据的排好序的数据结构 数据结构教学网站：https://www.cs.usfca.edu/~galles/visualization/Algorithms.html 2.索引底层数据结构与算法 二叉树 红黑树 HASH BTREE 2.1B-Tree 度(Degree)-节点的数据存储个数 叶节点具有相同的深度 叶节点的指针为空 节点中的数据key从左到右递增排列 2.2B+Tree(B-Tree变种) 非叶子节点不存储data，只存储key，可以增大度 叶子节点不存储指针 顺序访问指针，提高区间访问的性能 3.索引最左前缀原理 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:01:37 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/mysql/Explain.html":{"url":"performance/mysql/Explain.html","title":"1.Explain详解","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.explain 中的列 1. id列 1）简单子查询 2）from子句中的子查询 3）union查询 2. select_type列 1）simple：简单查询。查询不包含子查询和union 2）primary：复杂查询中最外层的 select 3）subquery：包含在 select 中的子查询（不在 from 子句中） 4）derived：包含在 from 子句中的子查询。MySQL会将结果存放在一个临时表中，也称为派生表（derived的英文含义） 5）union：在 union 中的第二个和随后的 select 6）union result：从 union 临时表检索结果的 select 3. table列 4. type列 5. possible_keys列 6. key列 7. key_len列 8. ref列 9. rows列 10. Extra列 2.索引最佳实践 1. 全值匹配 2.最佳左前缀法则 3.不在索引列上做任何操作（计算、函数、（自动or手动）类型转换），会导致索引失效而转向全表扫描 4.存储引擎不能使用索引中范围条件右边的列 5.尽量使用覆盖索引（只访问索引的查询（索引列包含查询列）），减少select *语句 6.mysql在使用不等于（！=或者<>）的时候无法使用索引会导致全表扫描 7.is null,is not null 也无法使用索引 8.like以通配符开头（'$abc...'）mysql索引失效会变成全表扫描操作 9.字符串不加单引号索引失效 10.少用or,用它连接时很多情况下索引会失效 使用EXPLAIN关键字可以模拟优化器执行SQL语句，从而知道MySQL是 如何处理你的SQL语句的。分析你的查询语句或是结构的性能瓶颈 下面是使用 explain 的例子： 在 select 语句之前增加 explain 关键字，MySQL 会在查询上设置一个标记，执行查询时，会返回执行计划的信息，而不是执行这条SQL（如果 from 中包含子查询，仍会执行该子查询，将结果放入临时表中） 使用的表 DROP TABLE IF EXISTS `actor`; CREATE TABLE `actor` ( `id` int(11) NOT NULL, `name` varchar(45) DEFAULT NULL, `update_time` datetime DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; INSERT INTO `actor` (`id`, `name`, `update_time`) VALUES (1,'a','2017-12-22 15:27:18'), (2,'b','2017-12-22 15:27:18'), (3,'c','2017-12-22 15:27:18'); DROP TABLE IF EXISTS `film`; CREATE TABLE `film` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(10) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_name` (`name`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; INSERT INTO `film` (`id`, `name`) VALUES (3,'film0'),(1,'film1'),(2,'film2'); DROP TABLE IF EXISTS `film_actor`; CREATE TABLE `film_actor` ( `id` int(11) NOT NULL, `film_id` int(11) NOT NULL, `actor_id` int(11) NOT NULL, `remark` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_film_actor_id` (`film_id`,`actor_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; INSERT INTO `film_actor` (`id`, `film_id`, `actor_id`) VALUES (1,1,1),(2,1,2),(3,2,1); mysql> explain select * from actor; 在查询中的每个表会输出一行，如果有两个表通过 join 连接查询，那么会输出两行。表的意义相当广泛：可以是子查询、一个 union 结果等。 explain 有两个变种： 1）explain extended：会在 explain 的基础上额外提供一些查询优化的信息。紧随其后通过 show warnings 命令可以 得到优化后的查询语句，从而看出优化器优化了什么。额外还有 filtered 列，是一个半分比的值，rows * filtered/100 可以估算出将要和 explain 中前一个表进行连接的行数（前一个表指 explain 中的id值比当前表id值小的表）。 mysql> explain extended select * from film where id = 1; mysql> show warnings; 2）explain partitions：相比 explain 多了个 partitions 字段，如果查询是基于分区表的话，会显示查询将访问的分区。 1.explain 中的列 接下来我们将展示 explain 中每个列的信息。 1. id列 id列的编号是 select 的序列号，有几个 select 就有几个id，并且id的顺序是按 select 出现的顺序增长的。MySQL将 select 查询分为简单查询(SIMPLE)和复杂查询(PRIMARY)。 复杂查询分为三类：简单子查询、派生表（from语句中的子查询）、union 查询。 id列越大执行优先级越高，id相同则从上往下执行，id为NULL最后执行 1）简单子查询 mysql> explain select (select 1 from actor limit 1) from film; 2）from子句中的子查询 mysql> explain select id from (select id from film) as der; 这个查询执行时有个临时表别名为der，外部 select 查询引用了这个临时表 3）union查询 mysql> explain select 1 union all select 1; union结果总是放在一个匿名临时表中，临时表不在SQL中出现，因此它的id是NULL。 2. select_type列 select_type 表示对应行是简单还是复杂的查询，如果是复杂的查询，又是上述三种复杂查询中的哪一种。 1）simple：简单查询。查询不包含子查询和union mysql> explain select * from film where id = 2; 2）primary：复杂查询中最外层的 select 3）subquery：包含在 select 中的子查询（不在 from 子句中） 4）derived：包含在 from 子句中的子查询。MySQL会将结果存放在一个临时表中，也称为派生表（derived的英文含义） 用这个例子来了解 primary、subquery 和 derived 类型 mysql> explain select (select 1 from actor where id = 1) from (select * from film where id = 1) der; 5）union：在 union 中的第二个和随后的 select 6）union result：从 union 临时表检索结果的 select 用这个例子来了解 union 和 union result 类型： mysql> explain select 1 union all select 1; 3. table列 这一列表示 explain 的一行正在访问哪个表。 当 from 子句中有子查询时，table列是 格式，表示当前查询依赖 id=N 的查询，于是先执行 id=N 的查询。 当有 union 时，UNION RESULT 的 table 列的值为，1和2表示参与 union 的 select 行id。 4. type列 这一列表示关联类型或访问类型，即MySQL决定如何查找表中的行，查找数据行记录的大概范围。 依次从最优到最差分别为：system > const > eq_ref > ref > range > index > ALL 一般来说，得保证查询达到range级别，最好达到ref NULL：mysql能够在优化阶段分解查询语句，在执行阶段用不着再访问表或索引。例如：在索引列中选取最小值，可以单独查找索引来完成，不需要在执行时访问表 mysql> explain select min(id) from film; const, system：mysql能对查询的某部分进行优化并将其转化成一个常量（可以看show warnings 的结果）。用于 primary key 或 unique key 的所有列与常数比较时，所以表最多有一个匹配行，读取1次，速度比较快。system是const的特例，表里只有一条元组匹配时为system mysql> explain extended select from (select from film where id = 1) tmp; mysql> show warnings; eq_ref：primary key 或 unique key 索引的所有部分被连接使用 ，最多只会返回一条符合条件的记录。这可能是在 const 之外最好的联接类型了，简单的 select 查询不会出现这种 type。 mysql> explain select * from film_actor left join film on film_actor.film_id = film.id; ref：相比 eq_ref，不使用唯一索引，而是使用普通索引或者唯一性索引的部分前缀，索引要和某个值相比较，可能会找到多个符合条件的行。 简单 select 查询，name是普通索引（非唯一索引） mysql> explain select * from film where name = \"film1\"; 2.关联表查询，idx_film_actor_id是film_id和actor_id的联合索引，这里使用到了film_actor的左边前缀film_id部分。 mysql> explain select film_id from film left join film_actor on film.id = film_actor.film_id; range：范围扫描通常出现在 in(), between ,> ,= 等操作中。使用一个索引来检索给定范围的行。 mysql> explain select * from actor where id > 1; index：扫描全表索引，这通常比ALL快一些。（index是从索引中读取的，而all是从硬盘中读取） mysql> explain select * from film; ALL：即全表扫描，意味着mysql需要从头到尾去查找所需要的行。通常情况下这需要增加索引来进行优化了 mysql> explain select * from actor; 5. possible_keys列 这一列显示查询可能使用哪些索引来查找。 explain 时可能出现 possible_keys 有列，而 key 显示 NULL 的情况，这种情况是因为表中数据不多，mysql认为索引对此查询帮助不大，选择了全表查询。 如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查 where 子句看是否可以创造一个适当的索引来提高查询性能，然后用 explain 查看效果。 6. key列 这一列显示mysql实际采用哪个索引来优化对该表的访问。 如果没有使用索引，则该列是 NULL。如果想强制mysql使用或忽视possible_keys列中的索引，在查询中使用 force index、ignore index。 7. key_len列 这一列显示了mysql在索引里使用的字节数，通过这个值可以算出具体使用了索引中的哪些列。 举例来说，film_actor的联合索引 idx_film_actor_id 由 film_id 和 actor_id 两个int列组成，并且每个int是4字节。通过结果中的key_len=4可推断出查询使用了第一个列：film_id列来执行索引查找。 mysql> explain select * from film_actor where film_id = 2; key_len计算规则如下： 字符串 char(n)：n字节长度 varchar(n)：2字节存储字符串长度，如果是utf-8，则长度 3n + 2 数值类型 tinyint：1字节 smallint：2字节 int：4字节 bigint：8字节 时间类型 date：3字节 timestamp：4字节 datetime：8字节 如果字段允许为 NULL，需要1字节记录是否为 NULL 索引最大长度是768字节，当字符串过长时，mysql会做一个类似左前缀索引的处理，将前半部分的字符提取出来做索引。 8. ref列 这一列显示了在key列记录的索引中，表查找值所用到的列或常量，常见的有：const（常量），字段名（例：film.id） 9. rows列 这一列是mysql估计要读取并检测的行数，注意这个不是结果集里的行数。 10. Extra列 这一列展示的是额外信息。常见的重要值如下： Using index：查询的列被索引覆盖，并且where筛选条件是索引的前导列，是性能高的表现。一般是使用了覆盖索引(索引包含了所有查询的字段)。对于innodb来说，如果是辅助索引性能会有不少提高 mysql> explain select film_id from film_actor where film_id = 1; Using where：查询的列未被索引覆盖，where筛选条件非索引的前导列 mysql> explain select * from actor where name = 'a'; Using where Using index：查询的列被索引覆盖，并且where筛选条件是索引列之一但是不是索引的前导列，意味着无法直接通过索引查找来查询到符合条件的数据 mysql> explain select film_id from film_actor where actor_id = 1; NULL：查询的列未被索引覆盖，并且where筛选条件是索引的前导列，意味着用到了索引，但是部分字段未被索引覆盖，必须通过“回表”来实现，不是纯粹地用到了索引，也不是完全没用到索引 mysql>explain select * from film_actor where film_id = 1; Using index condition：与Using where类似，查询的列不完全被索引覆盖，where条件中是一个前导列的范围； mysql> explain select * from film_actor where film_id > 1; Using temporary：mysql需要创建一张临时表来处理查询。出现这种情况一般是要进行优化的，首先是想到用索引来优化。 actor.name没有索引，此时创建了张临时表来distinct mysql> explain select distinct name from actor; film.name建立了idx_name索引，此时查询时extra是using index,没有用临时表 mysql> explain select distinct name from film; Using filesort：mysql 会对结果使用一个外部索引排序，而不是按索引次序从表里读取行。此时mysql会根据联接类型浏览所有符合条件的记录，并保存排序关键字和行指针，然后排序关键字并按顺序检索行信息。这种情况下一般也是要考虑使用索引来优化的。 actor.name未创建索引，会浏览actor整个表，保存排序关键字name和对应的id，然后排序name并检索行记录 mysql> explain select * from actor order by name; film.name建立了idx_name索引,此时查询时extra是using indexmysql> explain select * from film order by name; 2.索引最佳实践 使用的表 CREATE TABLE `employees` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(24) NOT NULL DEFAULT '' COMMENT '姓名', `age` int(11) NOT NULL DEFAULT '0' COMMENT '年龄', `position` varchar(20) NOT NULL DEFAULT '' COMMENT '职位', `hire_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '入职时间', PRIMARY KEY (`id`), KEY `idx_name_age_position` (`name`,`age`,`position`) USING BTREE ) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8 COMMENT='员工记录表'; INSERT INTO employees(name,age,position,hire_time) VALUES('LiLei',22,'manager',NOW()); INSERT INTO employees(name,age,position,hire_time) VALUES('HanMeimei', 23,'dev',NOW()); INSERT INTO employees(name,age,position,hire_time) VALUES('Lucy',23,'dev',NOW()); 最佳实践 1. 全值匹配 EXPLAIN SELECT * FROM employees WHERE name= 'LiLei'; EXPLAIN SELECT * FROM employees WHERE name= 'LiLei' AND age = 22; EXPLAIN SELECT * FROM employees WHERE name= 'LiLei' AND age = 22 AND position ='manager'; 2.最佳左前缀法则 如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始并且不跳过索引中的列。 EXPLAIN SELECT * FROM employees WHERE age = 22 AND position ='manager'; EXPLAIN SELECT * FROM employees WHERE position = 'manager'; EXPLAIN SELECT * FROM employees WHERE name = 'LiLei'; 3.不在索引列上做任何操作（计算、函数、（自动or手动）类型转换），会导致索引失效而转向全表扫描 EXPLAIN SELECT * FROM employees WHERE name = 'LiLei'; EXPLAIN SELECT * FROM employees WHERE left(name,3) = 'LiLei'; 4.存储引擎不能使用索引中范围条件右边的列 EXPLAIN SELECT * FROM employees WHERE name= 'LiLei' AND age = 22 AND position ='manager'; EXPLAIN SELECT * FROM employees WHERE name= 'LiLei' AND age > 22 AND position ='manager'; 5.尽量使用覆盖索引（只访问索引的查询（索引列包含查询列）），减少select *语句 EXPLAIN SELECT name,age FROM employees WHERE name= 'LiLei' AND age = 23 AND position ='manager'; EXPLAIN SELECT * FROM employees WHERE name= 'LiLei' AND age = 23 AND position ='manager'; 6.mysql在使用不等于（！=或者<>）的时候无法使用索引会导致全表扫描 EXPLAIN SELECT * FROM employees WHERE name != 'LiLei' 7.is null,is not null 也无法使用索引 EXPLAIN SELECT * FROM employees WHERE name is null 8.like以通配符开头（'$abc...'）mysql索引失效会变成全表扫描操作 EXPLAIN SELECT * FROM employees WHERE name like '%Lei' EXPLAIN SELECT * FROM employees WHERE name like 'Lei%' 问题：解决like'%字符串%'索引不被使用的方法？ a）使用覆盖索引，查询字段必须是建立覆盖索引字段 EXPLAIN SELECT name,age,position FROM employees WHERE name like '%Lei%'; b）当覆盖索引指向的字段是varchar(380)及380以上的字段时，覆盖索引会失效！ 9.字符串不加单引号索引失效 EXPLAIN SELECT * FROM employees WHERE name = '1000'; EXPLAIN SELECT * FROM employees WHERE name = 1000; 10.少用or,用它连接时很多情况下索引会失效 EXPLAIN SELECT * FROM employees WHERE name = 'LiLei' or name = 'HanMeimei'; 总结： like KK%相当于=常量，%KK和%KK% 相当于范围 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:01:48 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/mysql/high-index.html":{"url":"performance/mysql/high-index.html","title":"2.索引优化深入","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.创建test表（测试表） 2.创建索引 3.分析以下Case索引使用情况 3.1Case 1： 3.2Case 2： 3.2.1Case 2.1： 3.2.1Case 2.2： 3.3Case 3： 3.3.1Case 3.1： 3.3.2Case 3.2： 3.4Case 4： 3.4.1Case 4.1： 3.4.2Case 4.2： 3.4.3Case 4.3： 3.5Case 5： 3.5.1Case 5.1： 3.6Case 6： 3.7Case 7： 3.8Case 8： 4.总结： 1.order by语句使用索引最左前列。 2.使用where子句与order by子句条件列组合满足索引最左前列。 等价于： 等价于 A表与B表的ID字段应建立索引 1.创建test表（测试表） drop table if exists test; create table test( id int primary key auto_increment, c1 varchar(10), c2 varchar(10), c3 varchar(10), c4 varchar(10), c5 varchar(10) ) ENGINE=INNODB default CHARSET=utf8; insert into test(c1,c2,c3,c4,c5) values('a1','a2','a3','a4','a5'); insert into test(c1,c2,c3,c4,c5) values('b1','b2','b3','b4','b5'); insert into test(c1,c2,c3,c4,c5) values('c1','c2','c3','c4','c5'); insert into test(c1,c2,c3,c4,c5) values('d1','d2','d3','d4','d5'); insert into test(c1,c2,c3,c4,c5) values('e1','e2','e3','e4','e5'); 2.创建索引 3.分析以下Case索引使用情况 3.1Case 1： 分析： ①创建复合索引的顺序为c1,c2,c3,c4。 ②上述四组explain执行的结果都一样：type=ref，key_len=132，ref=const,const,const,const。 结论：在执行常量等值查询时，改变索引列的顺序并不会更改explain的执行结果，因为mysql底层优化器会进行优化，但是推荐按照索引顺序列编写sql语句。 3.2Case 2： 分析： 当出现范围的时候，type=range，key_len=99，比不用范围key_len=66增加了，说明使用上了索引，但对比Case1中执行结果，说明c4上索引失效。 结论：范围右边索引列失效，但是范围当前位置（c3）的索引是有效的，从key_len=99可证明。 3.2.1Case 2.1： 分析： 与上面explain执行结果对比，key_len=132说明索引用到了4个，因为对此sql语句mysql底层优化器会进行优化：范围右边索引列失效（c4右边已经没有索引列了），注意索引的顺序（c1,c2,c3,c4），所以c4右边不会出现失效的索引列，因此4个索引全部用上。 结论：范围右边索引列失效，是有顺序的：c1,c2,c3,c4，如果c3有范围，则c4失效；如果c4有范围，则没有失效的索引列，从而会使用全部索引。 3.2.1Case 2.2： 分析： 如果在c1处使用范围，则type=ALL，key=Null，索引失效，全表扫描，这里违背了最佳左前缀法则，带头大哥已死，因为c1主要用于范围，而不是查询。 解决方式使用覆盖索引。 结论：在最佳左前缀法则中，如果最左前列（带头大哥）的索引失效，则后面的索引都失效。 3.3Case 3： 分析： 利用最佳左前缀法则：中间兄弟不能断，因此用到了c1和c2索引（查找），从key_len=66，ref=const,const，c3索引列用在排序过程中。 3.3.1Case 3.1： 分析： 从explain的执行结果来看：key_len=66，ref=const,const，从而查找只用到c1和c2索引，c3索引用于排序。 3.3.2Case 3.2： 分析： 从explain的执行结果来看：key_len=66，ref=const,const，查询使用了c1和c2索引，由于用了c4进行排序，跳过了c3，出现了Using filesort。 3.4Case 4： 分析： 查找只用到索引c1，c2和c3用于排序，无Using filesort。 3.4.1Case 4.1： 分析： 和Case 4中explain的执行结果一样，但是出现了Using filesort，因为索引的创建顺序为c1,c2,c3,c4，但是排序的时候c2和c3颠倒位置了。 3.4.2Case 4.2： 分析： 在查询时增加了c5，但是explain的执行结果一样，因为c5并未创建索引。 3.4.3Case 4.3： 分析： 与Case 4.1对比，在Extra中并未出现Using filesort，因为c2为常量，在排序中被优化，所以索引未颠倒，不会出现Using filesort。 3.5Case 5： 分析： 只用到c1上的索引，因为c4中间间断了，根据最佳左前缀法则，所以key_len=33，ref=const，表示只用到一个索引。 3.5.1Case 5.1： 分析： 对比Case 5，在group by时交换了c2和c3的位置，结果出现Using temporary和Using filesort，极度恶劣。原因：c3和c2与索引创建顺序相反。 3.6Case 6： 分析： ①在c1,c2,c3,c4上创建了索引，直接在c1上使用范围，导致了索引失效，全表扫描：type=ALL，ref=Null。因为此时c1主要用于排序，并不是查询。 ②使用c1进行排序，出现了Using filesort。 ③解决方法：使用覆盖索引。 3.7Case 7： 分析： 虽然排序的字段列与索引顺序一样，且order by默认升序，这里c2 desc变成了降序，导致与索引的排序方式不同，从而产生Using filesort。 3.8Case 8： EXPLAIN extended select c1 from test where c1 in ('a1','b1') ORDER BY c2,c3; 分析： 对于排序来说，多个相等条件也是范围查询 4.总结： ①MySQL支持两种方式的排序filesort和index，Using index是指MySQL扫描索引本身完成排序。index效率高，filesort效率低。 ②order by满足两种情况会使用Using index。 1.order by语句使用索引最左前列。 2.使用where子句与order by子句条件列组合满足索引最左前列。 ③尽量在索引列上完成排序，遵循索引建立（索引创建的顺序）时的最佳左前缀法则。 ④如果order by的条件不在索引列上，就会产生Using filesort。 ⑤group by与order by很类似，其实质是先排序后分组，遵照索引创建顺序的最佳左前缀法则。注意where高于having，能写在where中的限定条件就不要去having限定了。 通俗理解口诀： 全值匹配我最爱，最左前缀要遵守； 带头大哥不能死，中间兄弟不能断； 索引列上少计算，范围之后全失效； LIKE百分写最右，覆盖索引不写星； 不等空值还有or，索引失效要少用。 补充：in和exsits优化 原则：小表驱动大表，即小的数据集驱动大的数据集 in：当B表的数据集必须小于A表的数据集时，in优于exists select * from A where id in (select id from B) 等价于： for select id from B for select * from A where A.id = B.id exists：当A表的数据集小于B表的数据集时，exists优于in 将主查询A的数据，放到子查询B中做条件验证，根据验证结果（true或false）来决定主查询的数据是否保留 select * from A where exists (select 1 from B where B.id = A.id) 等价于 for select * from A for select * from B where B.id = A.id A表与B表的ID字段应建立索引 1、EXISTS (subquery)只返回TRUE或FALSE,因此子查询中的SELECT * 也可以是SELECT 1或select X,官方说法是实际执行时会忽略SELECT清单,因此没有区别 2、EXISTS子查询的实际执行过程可能经过了优化而不是我们理解上的逐条对比 3、EXISTS子查询往往也可以用JOIN来代替，何种最优需要具体问题具体分析 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:02:03 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/mysql/acid.html":{"url":"performance/mysql/acid.html","title":"3.Mysql锁与事务隔离级别","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 １. 概述 1.1 定义 1.2 锁的分类 2. 锁 2.1 表锁（偏读） 2.1.1 基本操作 2.1.2 案例分析(加读锁） 2.1.3 案例分析(加写锁） 2.1.4 案例结论 2.2 行锁（偏写） 2.2.1 行锁支持事务 2.2.2 行锁案例分析 2.2.3******隔离级别案例分析** 2.2.4 案例结论 2.2.5 行锁分析 2.2.6 死锁 2.2.7 优化建议 １. 概述 1.1 定义 锁是计算机协调多个进程或线程并发访问某一资源的机制。 在数据库中，除了传统的计算资源（如CPU、RAM、I/O等）的争用以外，数据也是一种供需要用户共享的资源。如何保证数据并发访问的一致性、有效性是所有数据库必须解决的一个问题，锁冲突也是影响数据库并发访问性能的一个重要因素。从这个角度来说，锁对数据库而言显得尤其重要，也更加复杂。 1.2 锁的分类 从性能上分为乐观锁(用版本对比来实现)和悲观锁 从对数据库操作的类型分，分为读锁和写锁(都属于悲观锁) 读锁（共享锁）：针对同一份数据，多个读操作可以同时进行而不会互相影响 写锁（排它锁）：当前写操作没有完成前，它会阻断其他写锁和读锁 从对数据操作的粒度分，分为表锁和行锁2. 锁 2.1 表锁（**偏读**） 表锁偏向MyISAM存储引擎，开销小，加锁快，无思索，锁定粒度大，发生锁冲突的概率最高，并发度最低。 2.1.1 基本操作 建表SQL CREATE TABLE `mylock` ( `id` INT (11) NOT NULL AUTO_INCREMENT, `NAME` VARCHAR (20) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE = MyISAM DEFAULT CHARSET = utf8; 插入数据 INSERT INTO`test`.`mylock`(`id`,`NAME`)VALUES('1','a'); INSERT INTO`test`.`mylock`(`id`,`NAME`)VALUES('2','b'); INSERT INTO`test`.`mylock`(`id`,`NAME`)VALUES('3','c'); INSERT INTO`test`.`mylock`(`id`,`NAME`)VALUES('4','d'); 手动增加表锁 lock table表名称read(write),表名称2read(write); 查看表上加过的锁 show opentables; 删除表锁 unlock tables; 2.1.2 案例分析(加读锁） 当前session和其他session都可以读该表 当前session中插入或者更新锁定的表都会报错，其他session插入或更新则会等待 2.1.3 案例分析(加写锁） 当前session对该表的增删改查都没有问题，其他session对该表的所有操作被阻塞 2.1.4 案例结论 MyISAM在执行查询语句(SELECT)前,会自动给涉及的所有表加读锁,在执行增删改操作前,会自动给涉及的表加写锁。 1、对MyISAM表的读操作(加读锁) ,不会阻寒其他进程对同一表的读请求,但会阻赛对同一表的写请求。只有当读锁释放后,才会执行其它进程的写操作。 2、对MylSAM表的写操作(加写锁) ,会阻塞其他进程对同一表的读和写操作,只有当写锁释放后,才会执行其它进程的读写操作 总结： 简而言之，就是读锁会阻塞写，但是不会阻塞读。而写锁则会把读和写都阻塞。 2.2 行锁（**偏写**） 行锁偏向InnoDB存储引擎，开销大，加锁慢，会出现死锁，锁定粒度最小，发生锁冲突的概率最低，并发度也最高。InnoDB与MYISAM的最大不同有两点：一是支持事务（TRANSACTION）；二是采用了行级锁。 2.2.1 行锁支持事务 事务（Transaction）及其ACID属性 事务是由一组SQL语句组成的逻辑处理单元,事务具有以下4个属性,通常简称为事务的ACID属性。 原子性(Atomicity)：事务是一个原子操作单元,其对数据的修改,要么全都执行,要么全都不执行。 一致性(Consistent)：在事务开始和完成时,数据都必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改,以保持数据的完整性;事务结束时,所有的内部数据结构(如B树索引或双向链表)也都必须是正确的。 隔离性(Isolation)：数据库系统提供一定的隔离机制,保证事务在不受外部并发操作影响的“独立”环境执行。这意味着事务处理过程中的中间状态对外部是不可见的,反之亦然。 持久性(Durable)：事务完成之后,它对于数据的修改是永久性的,即使出现系统故障也能够保持。 并发事务处理带来的问题 更新丢失（Lost Update） 当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题–最后的更新覆盖了由其他事务所做的更新。 脏读（Dirty Reads） 一个事务正在对一条记录做修改，在这个事务完成并提交前，这条记录的数据就处于不一致的状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”数据，并据此作进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象的叫做“脏读”。 一句话：事务A读取到了事务B已经修改但尚未提交的数据，还在这个数据基础上做了操作。此时，如果B事务回滚，A读取的数据无效，不符合一致性要求。 不可重读（Non-Repeatable Reads） 一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了！这种现象就叫做“不可重复读”。 一句话：事务A读取到了事务B已经提交的修改数据，不符合隔离性 幻读（Phantom Reads） 一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。 一句话：事务A读取到了事务B提交的新增数据，不符合隔离性 脏读是事务B里面修改了数据 幻读是事务B里面新增了数据 事务隔离级别 脏读”、“不可重复读”和“幻读”,其实都是数据库读一致性问题,必须由数据库提供一定的事务隔离机制来解决。 数据库的事务隔离越严格,并发副作用越小,但付出的代价也就越大,因为事务隔离实质上就是使事务在一定程度上“串行化”进行,这显然与“并发”是矛盾的。 同时,不同的应用对读一致性和事务隔离程度的要求也是不同的,比如许多应用对“不可重复读\"和“幻读”并不敏感,可能更关心数据并发访问的能力。 常看当前数据库的事务隔离级别: show variables like 'tx_isolation'; 设置事务隔离级别：**set tx_isolation='REPEATABLE-READ';** 2.2.2 行锁案例分析 用下面的表演示，需要开启事务，Session_1更新某一行，Session_2更新同一行被阻塞，但是更新其他行正常2.2.3**隔离级别案例分析** CREATE TABLE `account` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) DEFAULT NULL, `balance` int(11) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; INSERT INTO `test`.`account` (`name`, `balance`) VALUES ('lilei', '450'); INSERT INTO `test`.`account` (`name`, `balance`) VALUES ('hanmei', '16000'); INSERT INTO `test`.`account` (`name`, `balance`) VALUES ('lucy', '2400'); 1、读未提交： （1）打开一个客户端A，并设置当前事务模式为read uncommitted（未提交读），查询表account的初始值： set tx_isolation='read-uncommitted'; （2）在客户端A的事务提交之前，打开另一个客户端B，更新表account： （3）这时，虽然客户端B的事务还没提交，但是客户端A就可以查询到B已经更新的数据： （4）一旦客户端B的事务因为某种原因回滚，所有的操作都将会被撤销，那客户端A查询到的数据其实就是脏数据： （5）在客户端A执行更新语句update account set balance = balance - 50 where id =1，lilei的balance没有变成350，居然是400，是不是很奇怪，数据不一致啊，如果你这么想就太天真 了，在应用程序中，我们会用400-50=350，并不知道其他会话回滚了，要想解决这个问题可以采用读已提交的隔离级别 2、读已提交 （1）打开一个客户端A，并设置当前事务模式为read committed（未提交读），查询表account的所有记录： set tx_isolation='read-committed'; （2）在客户端A的事务提交之前，打开另一个客户端B，更新表account： （3）这时，客户端B的事务还没提交，客户端A不能查询到B已经更新的数据，解决了脏读问题： （4）客户端B的事务提交 （5）客户端A执行与上一步相同的查询，结果 与上一步不一致，即产生了不可重复读的问题 3、可重复读 （1）打开一个客户端A，并设置当前事务模式为repeatable read，查询表account的所有记录 set tx_isolation='repeatable-read'; （2）在客户端A的事务提交之前，打开另一个客户端B，更新表account并提交 （3）在客户端A查询表account的所有记录，与步骤（1）查询结果一致，没有出现不可重复读的问题 （4）在客户端A，接着执行update balance = balance - 50 where id = 1，balance没有变成400-50=350，lilei的balance值用的是步骤（2）中的350来算的，所以是300，数据的一致性倒是没有被破坏。可重复读的隔离级别下使用了MVCC机制，select操作不会更新版本号，是快照读（历史版本）；insert、update和delete会更新版本号，是当前读（当前版本）。 （5）重新打开客户端B，插入一条新数据后提交 （6）在客户端A查询表account的所有记录，没有 查出 新增数据，所以没有出现幻读 (7)验证幻读 在客户端A执行update account set balance=888 where id = 4;能更新成功，再次查询能查到客户端B新增的数据 4.串行化 （1）打开一个客户端A，并设置当前事务模式为serializable，查询表account的初始值： set tx_isolation='serializable'; mysql>setsessiontransactionisolationlevelserializable; Query OK,0rows affected (0.00sec) mysql>starttransaction; Query OK,0rows affected (0.00sec) mysql>selectfromaccount;+------+--------+---------+|id|name|balance|+------+--------+---------+|1|lilei|10000||2|hanmei|10000||3|lucy|10000||4|lily|10000|+------+--------+---------+4rowsinset(*0.00sec) （2）打开一个客户端B，并设置当前事务模式为serializable，插入一条记录报错，表被锁了插入失败，mysql中事务隔离级别为serializable时会锁表，因此不会出现幻读的情况，这种隔离级别并发性极低，开发中很少会用到。 mysql>setsessiontransactionisolationlevelserializable; Query OK,0rows affected (0.00sec) mysql>starttransaction; Query OK,0rows affected (0.00sec) mysql>insertintoaccountvalues(5,'tom',0); ERROR1205(HY000): Lock wait timeout exceeded; try restartingtransaction Mysql默认级别是repeatable-read，有办法解决幻读问题吗？ 间隙锁在某些情况下可以解决幻读问题 要避免幻读可以用间隙锁在Session_1下面执行update account set name = 'zhuge' where id > 10 and id 2.2.4 案例结论 Innodb存储引擎由于实现了行级锁定，虽然在锁定机制的实现方面所带来的性能损耗可能比表级锁定会要更高一下，但是在整体并发处理能力方面要远远优于MYISAM的表级锁定的。当系统并发量高的时候，Innodb的整体性能和MYISAM相比就会有比较明显的优势了。 但是，Innodb的行级锁定同样也有其脆弱的一面，当我们使用不当的时候，可能会让Innodb的整体性能表现不仅不能比MYISAM高，甚至可能会更差。 2.2.5 行锁分析 通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况 showstatuslike'innodb_row_lock%'; 对各个状态量的说明如下： Innodb_row_lock_current_waits: 当前正在等待锁定的数量 Innodb_row_lock_time: 从系统启动到现在锁定总时间长度 Innodb_row_lock_time_avg: 每次等待所花平均时间 Innodb_row_lock_time_max：从系统启动到现在等待最长的一次所花时间 Innodb_row_lock_waits:系统启动后到现在总共等待的次数 对于这5个状态变量，比较重要的主要是： Innodb_row_lock_time_avg （等待平均时长） Innodb_row_lock_waits （等待总次数） Innodb_row_lock_time（等待总时长） 尤其是当等待次数很高，而且每次等待时长也不小的时候，我们就需要分析系统中为什么会有如此多的等待，然后根据分析结果着手制定优化计划。 2.2.6 死锁 set tx_isolation='repeatable-read'; Session_1执行：select * from account where id=1 for update; Session_2执行：select * from account where id=2 for update; Session_1执行：select * from account where id=2 for update; Session_2执行：select * from account where id=1 for update; 查看近期死锁日志信息：show engine innodb status\\G; 大多数情况mysql可以自动检测死锁并回滚产生死锁的那个事务，但是有些情况mysql没法自动检测死锁 2.2.7 优化建议 尽可能让所有数据检索都通过索引来完成，避免无索引行锁升级为表锁 合理设计索引，尽量缩小锁的范围 尽可能减少检索条件，避免间隙锁 尽量控制事务大小，减少锁定资源量和时间长度 尽可能低级别事务隔离 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:18:12 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/nginx/":{"url":"performance/nginx/","title":"nginx","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/nginx/Nginx-config.html":{"url":"performance/nginx/Nginx-config.html","title":"1.Nginx核心模块与配置实践","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、Nginx 简介与安装 知识点： 1、Nginx简介： 2、编译与安装 二、Nginx 架构说明 三、Nginx 配置与使用 知识点 1、配置文件的语法格式： 2、配置第一个静态WEB服务 3、日志配置： 主讲：鲁班 时间：2018/10/12 概要： Nginx 简介 Nginx 架构说明 Nginx 基础配置与使用一、Nginx 简介与安装 知识点： Nginx 简介 Nginx 编译与安装1、Nginx简介： Nginx是一个高性能WEB服务器，除它之外Apache、Tomcat、Jetty、IIS，它们都是Web服务器，或者叫做WWW（World Wide Web）服务器，相应地也都具备Web服务器的基本功能。Nginx 相对基它WEB服务有什么优势呢？ Tomcat、Jetty 面向java语言，先天就是重量级的WEB服务器，其性能与Nginx没有可比性。 IIS只能在Windows操作系统上运行。Windows作为服务器在稳定性与其他一些性能上都不如类UNIX操作系统，因此，在需要高性能Web服务器的场合下IIS并不占优。 Apache的发展时期很长，而且是目前毫无争议的世界第一大Web服务器，其有许多优点，如稳定、开源、跨平台等，但它出现的时间太长了，在它兴起的年代，互联网的产业规模远远比不上今天，所以它被设计成了一个重量级的、不支持高并发的Web服务器。在Apache服务器上，如果有数以万计的并发HTTP请求同时访问，就会导致服务器上消耗大量内存，操作系统内核对成百上千的Apache进程做进程间切换也会消耗大量CPU资源，并导致HTTP请求的平均响应速度降低，这些都决定了Apache不可能成为高性能Web服务器，这也促使了Lighttpd和Nginx的出现。 下图可以看出07年到17 年强劲增长势头。 2、编译与安装 安装环境准备： （1）linux 内核2.6及以上版本: 只有2.6之后才支持epool ，在此之前使用select或pool多路复用的IO模型，无法解决高并发压力的问题。通过命令uname -a 即可查看。 #查看 linux 内核 uname -a （2）GCC编译器 GCC（GNU Compiler Collection）可用来编译C语言程序。Nginx不会直接提供二进制可执行程序,只能下载源码进行编译。 （3）PCRE库 PCRE（Perl Compatible Regular Expressions，Perl兼容正则表达式）是由Philip Hazel开发的函数库，目前为很多软件所使用，该库支持正则表达式。 （4）zlib库 zlib库用于对HTTP包的内容做gzip格式的压缩，如果我们在nginx.conf里配置了gzip on，并指定对于某些类型（content-type）的HTTP响应使用gzip来进行压缩以减少网络传输量。 （5）OpenSSL开发库 如果我们的服务器不只是要支持HTTP，还需要在更安全的SSL协议上传输HTTP，那么就需要拥有OpenSSL了。另外，如果我们想使用MD5、SHA1等散列函数，那么也需要安装它。 上面几个库都是Nginx 基础功能所必需的，为简单起见我们可以通过yum 命令统一安装。 #yum 安装nginx 环境 yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel pcre pcre-devel 源码获取： nginx 下载页：http://nginx.org/en/download.html 。 # 下载nginx 最新稳定版本 wget http://nginx.org/download/nginx-1.14.0.tar.gz #解压 tar -zxvf nginx-1.14.0.tar.gz 最简单的安装： # 全部采用默认安装 ./configure make && make install 执行完成之后 nginx 运行文件 就会被安装在 /usr/local/nginx 下。 基于参数构建 ./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module --with-debug 控制命令： #默认方式启动： ./sbin/nginx #指定配置文件启动 ./sbing/nginx -c /tmp/nginx.conf #指定nginx程序目录启动 ./sbin/nginx -p /usr/local/nginx/ #快速停止 ./sbin/nginx -s stop #优雅停止 ./sbin/nginx -s quit # 热装载配置文件 ./sbin/nginx -s reload # 重新打开日志文件 ./sbin/nginx -s reopen 模块更新： 二、Nginx 架构说明 Nginx 架构图: 架构说明： 1）nginx启动时，会生成两种类型的进程，一个是主进程（Master），一个（windows版本的目前只有一个）和多个工作进程（Worker）。主进程并不处理网络请求，主要负责调度工作进程，也就是图示的三项：加载配置、启动工作进程及非停升级。所以，nginx启动以后，查看操作系统的进程列表，我们就能看到至少有两个nginx进程。 2）服务器实际处理网络请求及响应的是工作进程（worker），在类unix系统上，nginx可以配置多个worker，而每个worker进程都可以同时处理数以千计的网络请求。 3）模块化设计。nginx的worker，包括核心和功能性模块，核心模块负责维持一个运行循环（run-loop），执行网络请求处理的不同阶段的模块功能，如网络读写、存储读写、内容传输、外出过滤，以及将请求发往上游服务器等。而其代码的模块化设计，也使得我们可以根据需要对功能模块进行适当的选择和修改，编译成具有特定功能的服务器。 4）事件驱动、异步及非阻塞，可以说是nginx得以获得高并发、高性能的关键因素，同时也得益于对Linux、Solaris及类BSD等操作系统内核中事件通知及I/O性能增强功能的采用，如kqueue、epoll及event ports。 Nginx 核心模块： 三、Nginx 配置与使用 知识点 配置文件语法格式 配置第一个静态WEB服务 配置案例 动静分离实现 防盗链 多域名站点 下载限速 IP 黑名单 基于user-agent分流 日志配置1、配置文件的语法格式： 先来看一个简单的nginx 配置worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 80; server_name localhost; location / { root html; index index.html index.htm; } location /nginx_status { stub_status on; access_log off; } } } 上述配置中的events、http、server、location、upstream等属于配置项块。而worker_processes 、worker_connections、include、listen 属于配置项块中的属性。 /nginx_status 属于配置块的特定参数参数。其中server块嵌套于http块，其可以直接继承访问Http块当中的参数。 | 配置块 | 名称开头用大口号包裹其对应属性 | |:----|:----| | 属性 | 基于空格切分属性名与属性值，属性值可能有多个项 都以空格进行切分 如： access_log logs/host.access.log main | | 参数 | 其配置在 块名称与大括号间，其值如果有多个也是通过空格进行拆 | 注意 如果配置项值中包括语法符号，比如空格符，那么需要使用单引号或双引号括住配置项值，否则Nginx会报语法错误。例如： log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; 2、配置第一个静态WEB服务 基础站点演示： [ ] 创建站点目录 mkdir -p /usr/www/luban [ ] 编写静态文件 [ ] 配置 nginx.conf [ ] 配置server [ ] 配置location 基本配置介绍说明： （1）监听端口 语法：listen address： 默认：listen 80; 配置块：server （2）主机名称 语法：server_name name[……]; 默认：server_name \"\"; 配置块：server server_name后可以跟多个主机名称，如server_name www.testweb.com、download.testweb.com;。 支持通配符与正则 （3）location 语法：location[=|～|～*|^～|@]/uri/{……} 配置块：server / 基于uri目录匹配 =表示把URI作为字符串，以便与参数中的uri做完全匹配。 ～表示正则匹配URI时是字母大小写敏感的。 ～*表示正则匹配URI时忽略字母大小写问题。 ^～表示正则匹配URI时只需要其前半部分与uri参数匹配即可。 动静分离演示： [ ] 创建静态站点 [ ] 配置 location /static [ ] 配置 ~* .(gif|png|css|js)$ 基于目录动静分离 server { listen 80; server_name *.luban.com; root /usr/www/luban; location / { index luban.html; } location /static { alias /usr/www/static; } } 基于正则动静分离 location ~* \\.(gif|jpg|png|css|js)$ { root /usr/www/static; } 防盗链配置演示： # 加入至指定location 即可实现 valid_referers none blocked *.luban.com; if ($invalid_referer) { return 403; } 下载限速： location /download { limit_rate 1m; limit_rate_after 30m; } 创建IP黑名单 # 创建黑名单文件 echo 'deny 192.168.0.132;' >> balck.ip #http 配置块中引入 黑名单文件 include black.ip; 3、日志配置： 日志格式： log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log logs/access.log main; #基于域名打印日志 access_log logs/$host.access.log main; error日志的设置 语法：error_log /path/file level; 默认：error_log logs/error.log error; level是日志的输出级别，取值范围是debug、info、notice、warn、error、crit、alert、emerg， 针对指定的客户端输出debug级别的日志 语法：debug_connection[IP|CIDR] events { debug_connection 192.168.0.147; debug_connection 10.224.57.0/200; } nginx.conf Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/nginx/Nginx-In-actual-combat.html":{"url":"performance/nginx/Nginx-In-actual-combat.html","title":"2.Nginx 性能优化实践","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、Nginx 反向代理实现 知识点： 2.负载均衡配置与参数解析 3.upstream 负载均衡算法介绍 二、Nginx 高速缓存 知识点： 1、案例分析： 2.Nginx 静态缓存基本配置 3.缓存的清除： 三、Nginx 性能参数调优 主讲：鲁班 时间：2018/10/14 概要： Nginx 反向代理与负载均衡 Nginx 实现高速缓存 Nginx 性能参数调优 一、Nginx 反向代理实现 知识点： 反向代理基本配置 负载均衡配置与参数解析 负载均衡算法详解 反向代理基本配置 提问：什么是反向代理其与正向代理有什么区别？ 正向代理的概念： 正向代理是指客户端与目标服务器之间增加一个代理服务器，客户端直接访问代理服务器，在由代理服务器访问目标服务器并返回客户端并返回 。这个过程当中客户端需要知道代理服务器地址，并配置连接。 反向代理的概念： 反向代理是指 客户端访问目标服务器，在目标服务内部有一个统一接入网关将请求转发至后端真正处理的服务器并返回结果。这个过程当中客户端不需要知道代理服务器地址，代理对客户端而言是透明的。 反向代理与正向代理的区别 | | 正向代理 | 反向代理 | |:----|:----|:----| | 代理服务器位置 | 客户端与服务都能连接的们位置 | 目标服务器内部 | | 主要作用 | 屏蔽客户端IP、集中式缓存、解决客户端不能直连服务端的问题。 | 屏蔽服务端内部实现、负载均衡、缓存。 | | 应用场景 | 爬虫、翻墙、maven 的nexus 服务 | Nginx 、Apache负载均衡应用 | Nginx代理基本配置 Nginx 代理只需要配置 location 中配置proxy_pass 属性即可。其指向代理的服务器地址。 # 正向代理到baidu 服务 location = /baidu.html { proxy_pass http://www.baidu.com; } # 反向代理至 本机的8010服务 location /luban/ { proxy_pass http://127.0.0.1:8010; } 代理相关参数： proxy_pass # 代理服务 proxy_redirect off; # 是否允许重定向 proxy_set_header Host $host; # 传 header 参数至后端服务 proxy_set_header X-Forwarded-For $remote_addr; # 设置request header 即客户端IP 地址 proxy_connect_timeout 90; # 连接代理服务超时时间 proxy_send_timeout 90; # 请求发送最大时间 proxy_read_timeout 90; # 读取最大时间 proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; 2.负载均衡配置与参数解析 通过proxy_pass 可以把请求代理至后端服务，但是为了实现更高的负载及性能， 我们的后端服务通常是多个， 这个是时候可以通过upstream 模块实现负载均衡。 演示upstream 的实现。 upstream backend { server 127.0.0.1:8010 weight=1; server 127.0.0.1:8080 weight=2; } location / { proxy_pass http://backend; } upstream 相关参数: service 反向服务地址 加端口 weight 权重 max_fails 失败多少次 认为主机已挂掉则，踢出 fail_timeout 踢出后重新探测时间 backup 备用服务 max_conns 允许最大连接数 slow_start 当节点恢复，不立即加入,而是等待 slow_start 后加入服务对列。3.upstream 负载均衡算法介绍 ll+weight： 轮询加权重 (默认) ip_hash : 基于Hash 计算 ,用于保持session 一至性 url_hash: 静态资源缓存,节约存储，加快速度（第三方） least_conn ：最少链接（第三方） least_time ：最小的响应时间,计算节点平均响应时间，然后取响应最快的那个，分配更高权重（第三方）二、Nginx 高速缓存 知识点： 缓存案例分析 Nginx 静态缓存基本配置 缓存更新 1、案例分析： 某电商平台商品详情页需要实现 700+ QPS，如何着手去做？ 首先为分析一下一个商品详情页有哪些信息 从中得出 商品详情页依懒了 对于商品详情页涉及了如下主要服务： 商品详情页HTML页面渲染 价格服务 促销服务 库存状态/配送至服务 广告词服务 预售/秒杀服务 评价服务 试用服务 推荐服务 商品介绍服务 各品类相关的一些特殊服务 解决方案： 采用Ajax 动态加载 价格、广告、库存等服务 采用key value 缓存详情页主体html。 方案架构： 问题： 当达到500QPS 的时候很难继续压测上去。 分析原因：一个详情页html 主体达平均150 kb 那么在500QPS 已接近千M局域网宽带极限。必须减少内网通信。 基于Nginx 静态缓存的解决方案： 2.Nginx 静态缓存基本配置 一、在http元素下添加缓存区声明。 #proxy_cache_path 缓存路径 #levels 缓存层级及目录位数 #keys_zone 缓存区内存大小 #inactive 有效期 #max_size 硬盘大小 proxy_cache_path /data/nginx/cache_luban levels=1:2 keys_zone=cache_luban:500m inactive=20d max_size=1g; 二、为指定location 设定缓存策略。 # 指定缓存区 proxy_cache cache_luban; #以全路径md5值做做为Key proxy_cache_key $host$uri$is_args$args; #对不同的HTTP状态码设置不同的缓存时间 proxy_cache_valid 200 304 12h; 演示缓存生效过程 [ ] 配置声明缓存路径 [ ] 为location 配置缓存策略 [ ] 重启nginx（修改了） [ ] 查看缓存目录生成 缓存参数详细说明| 父元素 | 名称 | 描述 | |:----|:----|:----| | http | proxy_cache_path | 指定缓存区的根路径 | | | levels | 缓存目录层级最高三层，每层1~2个字符表示。如1:1:2 表示三层。 | | | keys_zone | 缓存块名称 及内存块大小。如 cache_item:500m 。表示声明一个名为cache_item 大小为500m。超出大小后最早的数据将会被清除。 | | | inactive | 最长闲置时间 如:10d 如果一个数据被闲置10天将会被清除 | | | max_size | 缓存区硬盘最大值。超出闲置数据将会被清除 | | location | proxy_cache | 指定缓存区，对应keys_zone 中设置的值 | | | proxy_cache_key | 通过参数拼装缓存key 如：$host$uri$is_args$args 则会以全路径md5值做做为Key | | | proxy_cache_valid | 为不同的状态码设置缓存有效期 | 3.缓存的清除： 该功能可以采用第三方模块 ngx_cache_purge 实现。 为nginx 添加 ngx_cache_purge 模块 #下载ngx_cache_purge 模块包 ,这里nginx 版本为1.6.2 purge 对应2.0版 wget http://labs.frickle.com/files/ngx_cache_purge-2.3.tar.gz #查看已安装模块 ./sbin/nginx -V #进入nginx安装包目录 重新安装 --add-module为模块解压的全路径 ./configure --prefix=/root/svr/nginx --with-http_stub_status_module --with-http_ssl_module --add-module=/root/svr/nginx/models/ngx_cache_purge-2.0 #重新编译 make #拷贝 安装目录/objs/nginx 文件用于替换原nginx 文件 #检测查看安装是否成功 nginx -t 清除配置： location ~ /clear(/.*) { #允许访问的IP allow 127.0.0.1; allow 192.168.0.193; #禁止访问的IP deny all; #配置清除指定缓存区和路径(与proxy_cache_key一至) proxy_cache_purge cache_item $host$1$is_args$args; } 配置好以后 直接访问 ： # 访问生成缓存文件 http://www.luban.com/?a=1 # 清除生成的缓存,如果指定缓存不存在 则会报404 错误。 http://www.luban.com/clear/?a=1 三、Nginx 性能参数调优 worker_processes number; 每个worker进程都是单线程的进程，它们会调用各个模块以实现多种多样的功能。如果这些模块确认不会出现阻塞式的调用，那么，有多少CPU内核就应该配置多少个进程；反之，如果有可能出现阻塞式调用，那么需要配置稍多一些的worker进程。例如，如果业务方面会致使用户请求大量读取本地磁盘上的静态资源文件，而且服务器上的内存较小，以至于大部分的请求访问静态资源文件时都必须读取磁盘（磁头的寻址是缓慢的），而不是内存中的磁盘缓存，那么磁盘I/O调用可能会阻塞住worker进程少量时间，进而导致服务整体性能下降。 每个worker 进程的最大连接数 语法：worker_connections number; 默认：worker_connections 1024 worker_cpu_affinity cpumask[cpumask……] 绑定Nginx worker进程到指定的CPU内核 为什么要绑定worker进程到指定的CPU内核呢？假定每一个worker进程都是非常繁忙的，如果多个worker进程都在抢同一个CPU，那么这就会出现同步问题。反之，如果每一个worker进程都独享一个CPU，就在内核的调度策略上实现了完全的并发。 例如，如果有4颗CPU内核，就可以进行如下配置： worker_processes 4; worker_cpu_affinity 1000 0100 0010 0001; 注意 worker_cpu_affinity配置仅对Linux操作系统有效。 Nginx worker 进程优先级设置 语法：worker_priority nice; 默认：worker_priority 0; 优先级由静态优先级和内核根据进程执行情况所做的动态调整（目前只有±5的调整）共同决定。nice值是进程的静态优先级，它的取值范围是–20～+19，–20是最高优先级，+19是最低优先级。因此，如果用户希望Nginx占有更多的系统资源，那么可以把nice值配置得更小一些，但不建议比内核进程的nice值（通常为–5）还要小 Nginx worker进程可以打开的最大句柄描述符个数 语法： worker_rlimit_nofile limit; 默认：空 更改worker进程的最大打开文件数限制。如果没设置的话，这个值为操作系统的限制。设置后你的操作系统和Nginx可以处理比“ulimit -a”更多的文件，所以把这个值设高，这样nginx就不会有“too many open files”问题了。 是否打开accept锁 语法：accept_mutex[on|off] 默认：accept_mutext on; accept_mutex是Nginx的负载均衡锁，当某一个worker进程建立的连接数量达到worker_connections配置的最大连接数的7/8时，会大大地减小该worker进程试图建立新TCP连接的机会，accept锁默认是打开的，如果关闭它，那么建立TCP连接的耗时会更短，但worker进程之间的负载会非常不均衡，因此不建议关闭它。 使用accept锁后到真正建立连接之间的延迟时间 语法：accept_mutex_delay Nms; 默认：accept_mutex_delay 500ms; 在使用accept锁后，同一时间只有一个worker进程能够取到accept锁。这个accept锁不是堵塞锁，如果取不到会立刻返回。如果只有一个worker进程试图取锁而没有取到，他至少要等待accept_mutex_delay定义的时间才能再次试图取锁。 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/tomcat/":{"url":"performance/tomcat/","title":"tomcat","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"performance/tomcat/Tomcat-pro-use.html":{"url":"performance/tomcat/Tomcat-pro-use.html","title":"1.Tomcat生产环境应用","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、Tomcat各组件认知 2.Tomcat 各组件及关系 3.Tomcat启动参数说明 二、Tomcat server.xml 配置详解 三、Tomcat IO模型介绍 1、Tomcat支持的IO模型说明 2、BIO 与NIO有什么区别 概要： Tomcat各核心组件认知 Tomcat server.xml 配置详解 Tomcat IO模型介绍 一、Tomcat各组件认知 知识点： Tomcat架构说明 Tomcat组件及关系详情介绍 Tomcat启动参数说明 Tomcat架构说明 Tomcat是一个基于JAVA的WEB容器，其实现了JAVA EE中的 Servlet 与 jsp 规范，与Nginx apache 服务器不同在于一般用于动态请求处理。在架构设计上采用面向组件的方式设计。即整体功能是通过组件的方式拼装完成。另外每个组件都可以被替换以保证灵活性。 那么是哪些组件组成了Tomcat呢？ 2.Tomcat 各组件及关系 Server 和 Service Connector 连接器 HTTP 1.1 SSL https AJP（ Apache JServ Protocol） apache 私有协议，用于apache 反向代理Tomcat Container Engine 引擎 catalina Host 虚拟机 基于域名 分发请求 Context 隔离各个WEB应用 每个Context的 ClassLoader都是独立 Component Manager （管理器） logger （日志管理） loader （载入器） pipeline (管道) valve （管道中的阀） 3.Tomcat启动参数说明 我们平时启动Tomcat过程是怎么样的？ 复制WAR包至Tomcat webapp 目录。 执行starut.bat 脚本启动。 启动过程中war 包会被自动解压装载。 但是我们在Eclipse 或idea 中启动WEB项目的时候 也是把War包复杂至webapps 目录解压吗？显然不是，其真正做法是在Tomcat程序文件之外创建了一个部署目录，在一般生产环境中也是这么做的 即：Tomcat 程序目录和部署目录分开 。 我们只需要在启动时指定CATALINA_HOME 与 CATALINA_BASE 参数即可实现。 启动参数 描述说明 JAVA_OPTS jvm 启动参数 , 设置内存 编码等 -Xms100m -Xmx200m -Dfile.encoding=UTF-8 JAVA_HOME 指定jdk 目录，如果未设置从java 环境变量当中去找。 CATALINA_HOME Tomcat 程序根目录 CATALINA_BASE 应用部署目录，默认为$CATALINA_HOME CATALINA_OUT 应用日志输出目录：默认$CATALINA_BASE/log CATALINA_TMPDIR 应用临时目录：默认：$CATALINA_BASE/temp 可以编写一个脚本 来实现自定义配置： 演示自定义启动Tomcat [ ] 下载并解压Tomcat [ ] 创建并拷贝应用目录 [ ] 创建Tomcat.sh [ ] 编写Tomcat.sh [ ] chmod +x tomcat.sh 添加执行权限 [ ] 拷贝conf 、webapps 、logs至应用目录。 [ ] 执行启动测试。 ```powershell!/bin/bash export JAVA_OPTS=\"-Xms100m -Xmx200m\" export JAVA_HOME=/root/svr/jdk/ export CATALINA_HOME=/usr/local/apache-tomcat-8.5.34 export CATALINA_BASE=\"pwd\" case $1 in start) $CATALINA_HOME/bin/catalina.sh start echo start success!! ;; stop) $CATALINA_HOME/bin/catalina.sh stop echo stop success!! ;; restart) $CATALINA_HOME/bin/catalina.sh stop echo stop success!! sleep 2 $CATALINA_HOME/bin/catalina.sh start echo start success!! ;; version) $CATALINA_HOME/bin/catalina.sh version ;; configtest) $CATALINA_HOME/bin/catalina.sh configtest ;; esac exit 0 ## 二、Tomcat server.xml 配置详解 --- Server 的基本基本配置： ```xml 元素说明： server root元素：server 的顶级配置 主要属性: port：执行关闭命令的端口号 shutdown：关闭命令 [ ] 演示shutdown的用法#基于telent 执行SHUTDOWN 命令即可关闭 telent 127.0.0.1 8005 SHUTDOWN service 服务：将多个connector 与一个Engine组合成一个服务，可以配置多个服务。 Connector 连接器：用于接收 指定协议下的连接 并指定给唯一的Engine 进行处理。 主要属性： protocol 监听的协议，默认是http/1.1 port 指定服务器端要创建的端口号 minThread 服务器启动时创建的处理请求的线程数 maxThread 最大可以创建的处理请求的线程数 enableLookups 如果为true，则可以通过调用request.getRemoteHost()进行DNS查询来得到远程客户端的实际主机名，若为false则不进行DNS查询，而是返回其ip地址 redirectPort 指定服务器正在处理http请求时收到了一个SSL传输请求后重定向的端口号 acceptCount 指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理 connectionTimeout 指定超时的时间数(以毫秒为单位) SSLEnabled 是否开启 sll 验证，在Https 访问时需要开启。 [ ] 演示配置多个Connector Engine 引擎：用于处理连接的执行器，默认的引擎是catalina。一个service 中只能配置一个Engine。 主要属性：name 引擎名称 defaultHost 默认host Host 虚拟机：基于域名匹配至指定虚拟机。类似于nginx 当中的server,默认的虚拟机是localhost. 主要属性： [ ] 演示配置多个Host Context 应用上下文：一个host 下可以配置多个Context ，每个Context 都有其独立的classPath。相互隔离，以免造成ClassPath 冲突。 主要属性： [ ] 演示配置多个Context Valve 阀门：可以理解成request 的过滤器，具体配置要基于具体的Valve 接口的子类。以下即为一个访问日志的Valve. 三、Tomcat IO模型介绍 知识点： Tomcat支持的IO模型说明 BIO 与NIO的区别 IO模型源码解读1、Tomcat支持的IO模型说明 | | 描述 | |:----|:----| | BIO | 阻塞式IO，即Tomcat使用传统的java.io进行操作。该模式下每个请求都会创建一个线程，对性能开销大，不适合高并发场景。优点是稳定，适合连接数目小且固定架构。 | | NIO | 非阻塞式IO，jdk1.4 之后实现的新IO。该模式基于多路复用选择器监测连接状态在通知线程处理，从而达到非阻塞的目的。比传统BIO能更好的支持并发性能。Tomcat 8.0之后默认采用该模式 | | APR | 全称是 Apache Portable Runtime/Apache可移植运行库)，是Apache HTTP服务器的支持库。可以简单地理解为，Tomcat将以JNI的形式调用Apache HTTP服务器的核心动态链接库来处理文件读取或网络传输操作。使用需要编译安装APR 库 | | AIO | 异步非阻塞式IO，jdk1.7后之支持 。与nio不同在于不需要多路复用选择器，而是请求处理线程执行完程进行回调调知，已继续执行后续操作。Tomcat 8之后支持。 | | | | 使用指定IO模型的配置方式: 配置 server.xml 文件当中的 修改即可。 默认配置 8.0 protocol=“HTTP/1.1” 8.0 之前是 BIO 8.0 之后是NIO BIO protocol=“org.apache.coyote.http11.Http11Protocol“ NIO protocol=”org.apache.coyote.http11.Http11NioProtocol“ AIO protocol=”org.apache.coyote.http11.Http11Nio2Protocol“ APR protocol=”org.apache.coyote.http11.Http11AprProtocol“ 2、BIO 与NIO有什么区别 分别演示在高并发场景下BIO与NIO的线程数的变化？ 演示数据： | | 每秒提交数 | BIO执行线程 | NIO执行线程 | | |:----|:----|:----|:----|:----| | 预测 | 200 | 200 | 50 | | | 实验环境 | 200 | 48 | 37 | | | 生产环境 | 200 | 419 | 23 | | 结论： BIO 线程模型讲解 NIO 线程模型讲解 BIO 源码解读 Http11Protocol Http BIO协议解析器 JIoEndpoint Acceptor implements Runnable SocketProcessor implements Runnable Http11NioProtocol Http Nio协议解析器 NioEndpoint Acceptor implements Runnable Poller implements Runnable SocketProcessor implements Runnable Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/":{"url":"distributed/","title":"五、分布式框架专题","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/zookeeper/":{"url":"distributed/zookeeper/","title":"zookeeper","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/zookeeper/zookeeper-base-use.html":{"url":"distributed/zookeeper/zookeeper-base-use.html","title":"1.特性与节点说明","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、zookeeper概要、背景及作用 zookeeper产生背景： zookeeper概要： znode 节点 二、部署与常规配置 版本说明： 常规配置文件说明： 客户端命令： 三、Zookeeper节点介绍 知识点： 节点类型 节点属性 节点的监听： acl权限设置 主题概要 zookeeper概要、背景及作用 部署与常规配置 节点类型 一、zookeeper概要、背景及作用 zookeeper产生背景： 项目从单体到分布式转变之后，将会产生多个节点之间协同的问题。如： 每天的定时任务由谁哪个节点来执行？ RPC调用时的服务发现? 如何保证并发请求的幂等 .... 这些问题可以统一归纳为多节点协调问题，如果靠节点自身进行协调这是非常不可靠的，性能上也不可取。必须由一个独立的服务做协调工作，它必须可靠，而且保证性能。 zookeeper概要： ZooKeeper是用于分布式应用程序的协调服务。它公开了一组简单的API，分布式应用程序可以基于这些API用于同步，节点状态、配置等信息、服务注册等信息。其由JAVA编写，支持JAVA 和C两种语言的客户端。 znode 节点 zookeeper 中数据基本单元叫节点，节点之下可包含子节点，最后以树级方式程现。每个节点拥有唯一的路径path。客户端基于PATH上传节点数据，zookeeper 收到后会实时通知对该路径进行监听的客户端。 二、部署与常规配置 zookeeper 基于JAVA开发，下载后只要有对应JVM环境即可运行。其默认的端口号是2181运行前得保证其不冲突。 版本说明： 2019年5月20日发行的3.5.5是3.5分支的第一个稳定版本。此版本被认为是3.4稳定分支的后续版本，可以用于生产。基于3.4它包含以下新功能 动态重新配置 本地会议 新节点类型：容器，TTL 原子广播协议的SSL支持 删除观察者的能力 多线程提交处理器 升级到Netty 4.1 Maven构建 另请注意：建议的最低JDK版本为1.8 文件说明： apache-zookeeper-xxx-tar.gz 代表源代码 apache-zookeeper-xxx-bin.tar.gz 运行版本 下载地址：https://zookeeper.apache.org/releases.html#download 具体部署流程： #下载 wget https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/current/apache-zookeeper-3.5.5-bin.tar.gz #解压 tar -zxvf apache-zookeeper-3.5.5-bin.tar.gz #拷贝默认配置 cd {zookeeper_home}/conf cp zoo_sample.cfg zoo.cfg #启动 {zookeeper_home}/bin/zkServer.sh 常规配置文件说明： # zookeeper时间配置中的基本单位 (毫秒) tickTime=2000 # 允许follower初始化连接到leader最大时长，它表示tickTime时间倍数 即:initLimit*tickTime initLimit=10 # 允许follower与leader数据同步最大时长,它表示tickTime时间倍数 syncLimit=5 #zookeper 数据存储目录 dataDir=/tmp/zookeeper #对客户端提供的端口号 clientPort=2181 #单个客户端与zookeeper最大并发连接数 maxClientCnxns=60 # 保存的数据快照数量，之外的将会被清除 autopurge.snapRetainCount=3 #自动触发清除任务时间间隔，小时为单位。默认为0，表示不自动清除。 autopurge.purgeInterval=1 客户端命令： 基本命令列表 close 关闭当前会话 connect host:port 重新连接指定Zookeeper服务 create [-s] [-e] [-c] [-t ttl] path [data] [acl] 创建节点 delete [-v version] path 删除节点，(不能存在子节点） deleteall path 删除路径及所有子节点 setquota -n|-b val path 设置节点限额 -n 子节点数 -b 字节数 listquota path 查看节点限额 delquota [-n|-b] path 删除节点限额 get [-s] [-w] path 查看节点数据 -s 包含节点状态 -w 添加监听 getAcl [-s] path ls [-s] [-w] [-R] path 列出子节点 -s状态 -R 递归查看所有子节点 -w 添加监听 printwatches on|off 是否打印监听事件 quit 退出客户端 history 查看执行的历史记录 redo cmdno 重复 执行命令，history 中命令编号确定 removewatches path [-c|-d|-a] [-l] 删除指定监听 set [-s] [-v version] path data 设置值 setAcl [-s] [-v version] [-R] path acl 为节点设置ACL权限 stat [-w] path 查看节点状态 -w 添加监听 sync path 强制同步节点 node数据的增删改查 # 列出子节点 ls / #创建节点 create /luban \"luban is good man\" # 查看节点 get /luban # 创建子节点 create /luban/sex \"man\" # 删除节点 delete /luban/sex # 删除所有节点 包括子节点 deleteall /luban 三、Zookeeper节点介绍 知识点： 节点类型 节点的监听(watch) 节点属性说明(stat) 权限设置(acl) zookeeper 中节点叫znode存储结构上跟文件系统类似，以树级结构进行存储。不同之外在于znode没有目录的概念，不能执行类似cd之类的命令。znode结构包含如下： path:唯一路径 childNode：子节点 stat:状态属性 type:节点类型 节点类型 | 类型 | 描述 | |:----|:----| | PERSISTENT | 持久节点 | | PERSISTENT_SEQUENTIAL | 持久序号节点 | | EPHEMERAL | 临时节点(不可在拥有子节点) | | EPHEMERAL_SEQUENTIAL | 临时序号节点(不可在拥有子节点) | PERSISTENT（持久节点） 持久化保存的节点，也是默认创建的 #默认创建的就是持久节点 create /test PERSISTENT_SEQUENTIAL(持久序号节点) 创建时zookeeper 会在路径上加上序号作为后缀，。非常适合用于分布式锁、分布式选举等场景。创建时添加 -s 参数即可。 #创建序号节点 create -s /test #返回创建的实际路径 Created /test0000000001 create -s /test #返回创建的实际路径2 Created /test0000000002 EPHEMERAL（临时节点） 临时节点会在客户端会话断开后自动删除。适用于心跳，服务发现等场景。创建时添加参数-e 即可。 #创建临时节点， 断开会话 在连接将会自动删除 create -e /temp EPHEMERAL_SEQUENTIAL（临时序号节点） 与持久序号节点类似，不同之处在于EPHEMERAL_SEQUENTIAL是临时的会在会话断开后删除。创建时添加 -e -s create -e -s /temp/seq 节点属性 # 查看节点属性 stat /luban 其属性说明如下表： #创建节点的事物ID cZxid = 0x385 #创建时间 ctime = Tue Sep 24 17:26:28 CST 2019 #修改节点的事物ID mZxid = 0x385 #最后修改时间 mtime = Tue Sep 24 17:26:28 CST 2019 # 子节点变更的事物ID pZxid = 0x385 #这表示对此znode的子节点进行的更改次数（不包括子节点） cversion = 0 # 数据版本，变更次数 dataVersion = 0 #权限版本，变更次数 aclVersion = 0 #临时节点所属会话ID ephemeralOwner = 0x0 #数据长度 dataLength = 17 #子节点数(不包括子子节点) numChildren = 0 节点的监听： 客户添加 -w 参数可实时监听节点与子节点的变化，并且实时收到通知。非常适用保障分布式情况下的数据一至性。其使用方式如下： | 命令 | 描述 | |:----|:----| | ls -w path | 监听子节点的变化（增，删） | | get -w path | 监听节点数据的变化 | | stat -w path | 监听节点属性的变化 | | printwatches on|off | 触发监听后，是否打印监听事件(默认on) | acl权限设置 ACL全称为Access Control List（访问控制列表），用于控制资源的访问权限。ZooKeeper使用ACL来控制对其znode的防问。基于scheme:id:permission的方式进行权限控制。scheme表示授权模式、id模式对应值、permission即具体的增删改权限位。 scheme:认证模型 | 方案 | 描述 | |:----|:----| | world | 开放模式，world表示全世界都可以访问（这是默认设置） | | ip | ip模式，限定客户端IP防问 | | auth | 用户密码认证模式，只有在会话中添加了认证才可以防问 | | digest | 与auth类似，区别在于auth用明文密码，而digest 用sha-1+base64加密后的密码。在实际使用中digest 更常见。 | permission权限位 | 权限位 | 权限 | 描述 | |:----|:----|:----| | c | CREATE | 可以创建子节点 | | d | DELETE | 可以删除子节点（仅下一级节点） | | r | READ | 可以读取节点数据及显示子节点列表 | | w | WRITE | 可以设置节点数据 | | a | ADMIN | 可以设置节点访问控制列表权限 | acl 相关命令： | 命令 | 使用方式 | 描述 | |:----|:----|:----| | getAcl | getAcl | 读取ACL权限 | | setAcl | setAcl | 设置ACL权限 | | addauth | addauth | 添加认证用户 | world权限**示例** 语法： setAcl world:anyone: 注：world模式中anyone是唯一的值,表示所有人 查看默认节点权限： #创建一个节点 create -e /testAcl #查看节点权限 getAcl /testAcl #返回的默认权限表示 ，所有人拥有所有权限。 'world,'anyone: cdrwa 修改默认权限为 读写 #设置为rw权限 setAcl /testAcl world:anyone:rw # 可以正常读 get /testAcl # 无法正常创建子节点 create -e /testAcl/t \"hi\" # 返回没有权限的异常 Authentication is not valid : /testAcl/t IP权限示例： 语法： setAcl ip:: auth模式示例: 语法： setAcl auth::: addauth digest : digest 权限示例： 语法： setAcl digest ::: addauth digest : 注1：密钥 通过sha1与base64组合加密码生成，可通过以下命令生成 echo -n : | openssl dgst -binary -sha1 | openssl base64 注2：为节点设置digest 权限后，访问前必须执行addauth，当前会话才可以防问。 设置digest 权限 #先 sha1 加密，然后base64加密 echo -n luban:123456 | openssl dgst -binary -sha1 | openssl base64 #返回密钥 2Rz3ZtRZEs5RILjmwuXW/wT13Tk= #设置digest权限 setAcl /luban digest:luban:2Rz3ZtRZEs5RILjmwuXW/wT13Tk=:cdrw 查看节点将显示没有权限 #查看节点 get /luban #显示没有权限访问 org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /luban 给当前会话添加认证后在次查看 #给当前会话添加权限帐户 addauth digest luban:123456 #在次查看 get /luban #获得返回结果 luban is good man ACL的特殊说明： 权限仅对当前节点有效，不会让子节点继承。如限制了IP防问A节点，但不妨碍该IP防问A的子节点 /A/B。 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/zookeeper/zookeeper-client-use.html":{"url":"distributed/zookeeper/zookeeper-client-use.html","title":"2.客户端使用与集群特性","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、客户端API常规应用 2.创建、查看节点 3.监听节点 4.设置节点ACL权限 5.第三方客户端ZkClient 二、Zookeeper集群 3.选举机制 5.四字运维命令 主要内容： 客户端 zookeeper客户端简介，C客户端 客户端连接参数说明 客户端CRUD 客户端监听 集群 集群架构说明 集群配置及参数说明 选举投票机制 主从复制机制一、客户端API常规应用 zookeeper 提供了java与C两种语言的客户端。我们要学习的就是java客户端。引入最新的maven依赖： org.apache.zookeeper zookeeper 3.5.5 知识点： 初始连接 创建、查看节点 监听节点 设置节点权限 第三方客户端ZkClient 初始连接： 常规的客户端类是 org.apache.zookeeper.ZooKeeper，实例化该类之后将会自动与集群建立连接。构造参数说明如下： | 参数名称 | 类型 | 说明 | |:----|:----|:----|:----:| | connectString | String | 连接串，包括ip+端口 ,集群模式下用逗号隔开 192.168.0.149:2181,192.168.0.150:2181 | | sessionTimeout | int | 会话超时时间，该值不能超过服务端所设置的 minSessionTimeout 和maxSessionTimeout | | watcher | Watcher | 会话监听器，服务端事件将会触该监听 | | sessionId | long | 自定义会话ID | | sessionPasswd | byte[] | 会话密码 | | canBeReadOnly | boolean | 该连接是否为只读的 | | hostProvider | HostProvider | 服务端地址提供者，指示客户端如何选择某个服务来调用，默认采用StaticHostProvider实现 | 2.创建、查看节点 创建节点 通过org.apache.zookeeper.ZooKeeper#create()即可创建节点，其参数说明如下： | 参数名称 | 类型 | 说明 | |:----|:----|:----| | path | String | | | data | byte[] | | | acl | List | | | createMode | CreateMode | | | cb | StringCallback | | | ctx | Object | | 查看节点： 通过org.apache.zookeeper.ZooKeeper#getData()即可创建节点，其参数说明如下： | 参数名称 | 类型 | 说明 | |:----|:----|:----| | path | String | | | watch | boolean | | | watcher | Watcher | | | cb | DataCallback | | | ctx | Object | | 查看子节点： 通过org.apache.zookeeper.ZooKeeper#getChildren()即可获取子节点，其参数说明如下： | 参数名称 | 类型 | 说明 | |:----:|:----:|:----| | path | String | | | watch | boolean | | | watcher | Watcher | | | cb | Children2Callback | | | ctx | Object | | 3.监听节点 在getData() 与getChildren()两个方法中可分别设置监听数据变化和子节点变化。通过设置watch为true，当前事件触发时会调用zookeeper()构建函数中Watcher.process()方法。也可以添加watcher参数来实现自定义监听。一般采用后者。 注：所有的监听都是一次性的，如果要持续监听需要触发后在添加一次监听。 4.设置节点ACL权限 ACL包括结构为scheme:id:permission（有关ACL的介绍参照第一节课关于ACL的讲解） 客户端中由org.apache.zookeeper.data.ACL 类表示，类结构如下： ACL Id scheme // 对应权限模式scheme id // 对应模式中的id值 perms // 对应权限位permission 关于权限位的表示方式： 每个权限位都是一个唯一数字，将其合时通过或运行生成一个全新的数字即可 @InterfaceAudience.Public public interface Perms { int READ = 1 5.第三方客户端ZkClient zkClient 是在zookeeper客户端基础之上封装的，使用上更加友好。主要变化如下： 可以设置持久监听，或删除某个监听 可以插入JAVA对象，自动进行序列化和反序列化 简化了基本的增删改查操作。 二、Zookeeper集群 知识点： 集群部署 集群角色说明 选举机制 数据提交机制 集群配置说明 zookeeper集群的目的是为了保证系统的性能承载更多的客户端连接设专门提供的机制。通过集群可以实现以下功能： 读写分离：提高承载，为更多的客户端提供连接，并保障性能。 主从自动切换：提高服务容错性，部分节点故障不会影响整个服务集群。 半数以上运行机制说明： 集群至少需要三台服务器，并且强烈建议使用奇数个服务器。因为zookeeper 通过判断大多数节点的存活来判断整个服务是否可用。比如3个节点，挂掉了2个表示整个集群挂掉，而用偶数4个，挂掉了2个也表示其并不是大部分存活，因此也会挂掉。 集群部署 配置语法： server.=:: 节点**ID**：服务id手动指定1至125之间的数字，并写到对应服务节点的 {dataDir}/myid 文件中。 IP地址：节点的远程IP地址，可以相同。但生产环境就不能这么做了，因为在同一台机器就无法达到容错的目的。所以这种称作为伪集群。 数据同步端口：主从同时数据复制端口，（做伪集群时端口号不能重复）。 远举端口：主从节点选举端口，（做伪集群时端口号不能重复）。 配置文件示例： tickTime=2000 dataDir=/var/lib/zookeeper/ clientPort=2181 initLimit=5 syncLimit=2 #以下为集群配置，必须配置在所有节点的zoo.cfg文件中 server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 集群配置流程： 分别创建3个data目录用于存储各节点数据mkdir data mkdir data/1 mkdir data/3 mkdir data/3 编写myid文件echo 1 > data/1/myid echo 3 > data/3/myid echo 2 > data/2/myid 3、编写配置文件 conf/zoo1.cfg tickTime=2000 initLimit=10 syncLimit=5 dataDir=data/1 clientPort=2181 #集群配置 server.1=127.0.0.1:2887:3887 server.2=127.0.0.1:2888:3888 server.3=127.0.0.1:2889:3889 conf/zoo2.cfg tickTime=2000 initLimit=10 syncLimit=5 dataDir=data/2 clientPort=2182 #集群配置 server.1=127.0.0.1:2887:3887 server.2=127.0.0.1:2888:3888 server.3=127.0.0.1:2889:3889 conf/zoo3.cfg tickTime=2000 initLimit=10 syncLimit=5 dataDir=data/3 clientPort=2183 #集群配置 server.1=127.0.0.1:2887:3887 server.2=127.0.0.1:2888:3888 server.3=127.0.0.1:2889:3889 4.分别启动 ./bin/zkServer.sh start conf/zoo1.cfg ./bin/zkServer.sh start conf/zoo2.cfg ./bin/zkServer.sh start conf/zoo3.cfg 5.分别查看状态 ./bin/zkServer.sh status conf/zoo1.cfg Mode: follower ./bin/zkServer.sh status conf/zoo2.cfg Mode: leader ./bin/zkServer.sh status conf/zoo3.cfg Mode: follower 检查集群复制情况： 1、分别连接指定节点 zkCli.sh 后加参数-server 表示连接指定IP与端口。 ./bin/zkCli.sh -server 127.0.0.1:2181 ./bin/zkCli.sh -server 127.0.0.1:2182 ./bin/zkCli.sh -server 127.0.0.1:2183 [ ] 任意节点中创建数据，查看其它节点已经同步成功。 注意： -server参数后同时连接多个服务节点，并用逗号隔开 127.0.0.1:2181,127.0.0.1:2182 集群角色说明 zookeeper 集群中总共有三种角色，分别是leader（主节点）follower(子节点) observer（次级子节点） | 角色 | 描述 | |:----|:----| | leader | 主节点，又名领导者。用于写入数据，通过选举产生，如果宕机将会选举新的主节点。 | | follower | 子节点，又名追随者。用于实现数据的读取。同时他也是主节点的备选节点，并用拥有投票权。 | | observer | 次级子节点，又名观察者。用于读取数据，与fllower区别在于没有投票权，不能选为主节点。并且在计算集群可用状态时不会将observer计算入内。 | observer配置： 只要在集群配置中加上observer后缀即可，示例如下： server.3=127.0.0.1:2889:3889:observer 3.选举机制 通过 ./bin/zkServer.sh status 命令可以查看到节点状态 ./bin/zkServer.sh status conf/zoo1.cfg Mode: follower ./bin/zkServer.sh status conf/zoo2.cfg Mode: leader ./bin/zkServer.sh status conf/zoo3.cfg Mode: follower 可以发现中间的2182 是leader状态.其选举机制如下图： 投票机制说明： 第一轮投票全部投给自己 第二轮投票给myid比自己大的相邻节点 如果得票超过半数，选举结束。 选举触发： 当集群中的服务器出现已下两种情况时会进行Leader的选举 服务节点初始化启动 半数以上的节点无法和Leader建立连接 当节点初始起动时会在集群中寻找Leader节点，如果找到则与Leader建立连接，其自身状态变化follower或observer。如果没有找到Leader，当前节点状态将变化LOOKING，进入选举流程。 在集群运行其间如果有follower或observer节点宕机只要不超过半数并不会影响整个集群服务的正常运行。但如果leader宕机，将暂停对外服务，所有follower将进入LOOKING 状态，进入选举流程。 数据同步机制 zookeeper 的数据同步是为了保证各节点中数据的一至性，同步时涉及两个流程，一个是正常的客户端数据提交，另一个是集群某个节点宕机在恢复后的数据同步。 客户端写入请求： 写入请求的大至流程是，收leader接收客户端写请求，并同步给各个子节点。如下图： 但实际情况要复杂的多，比如client 它并不知道哪个节点是leader 有可能写的请求会发给follower ，由follower在转发给leader进行同步处理 客户端写入流程说明： client向zk中的server发送写请求，如果该server不是leader，则会将该写请求转发给leader server，leader将请求事务以proposal形式分发给follower； 当follower收到收到leader的proposal时，根据接收的先后顺序处理proposal； 当Leader收到follower针对某个proposal过半的ack后，则发起事务提交，重新发起一个commit的proposal Follower收到commit的proposal后，记录事务提交，并把数据更新到内存数据库； 当写成功后，反馈给client。 服务节点初始化同步： 在集群运行过程当中如果有一个follower节点宕机，由于宕机节点没过半，集群仍然能正常服务。当leader 收到新的客户端请求，此时无法同步给宕机的节点。造成数据不一至。为了解决这个问题，当节点启动时，第一件事情就是找当前的Leader，比对数据是否一至。不一至则开始同步,同步完成之后在进行对外提供服务。 如何比对Leader的数据版本呢，这里通过ZXID事物ID来确认。比Leader就需要同步。 ZXID说明： ZXID是一个长度64位的数字，其中低32位是按照数字递增，任何数据的变更都会导致,低32位的数字简单加1。高32位是leader周期编号，每当选举出一个新的leader时，新的leader就从本地事物日志中取出ZXID,然后解析出高32位的周期编号，进行加1，再将低32位的全部设置为0。这样就保证了每次新选举的leader后，保证了ZXID的唯一性而且是保证递增的。 思考题： 如果leader 节点宕机，在恢复后它还能被选为leader吗？ 5.四字运维命令 ZooKeeper响应少量命令。每个命令由四个字母组成。可通过telnet或nc向ZooKeeper发出命令。 这些命令默认是关闭的，需要配置4lw.commands.whitelist来打开，可打开部分或全部示例如下： #打开指定命令 4lw.commands.whitelist=stat, ruok, conf, isro #打开全部 4lw.commands.whitelist=* 安装Netcat工具，已使用nc命令 #安装Netcat 工具 yum install -y nc #查看服务器及客户端连接状态 echo stat | nc localhost 2181 命令列表 conf：3.3.0中的新增功能：打印有关服务配置的详细信息。 缺点：3.3.0中的新增功能：列出了连接到该服务器的所有客户端的完整连接/会话详细信息。包括有关已接收/已发送的数据包数量，会话ID，操作等待时间，最后执行的操作等信息。 crst：3.3.0中的新增功能：重置所有连接的连接/会话统计信息。 dump：列出未完成的会话和临时节点。这仅适用于领导者。 envi：打印有关服务环境的详细信息 ruok：测试服务器是否以非错误状态运行。如果服务器正在运行，它将以imok响应。否则，它将完全不响应。响应“ imok”不一定表示服务器已加入仲裁，只是服务器进程处于活动状态并绑定到指定的客户端端口。使用“ stat”获取有关状态仲裁和客户端连接信息的详细信息。 srst：重置服务器统计信息。 srvr：3.3.0中的新功能：列出服务器的完整详细信息。 stat：列出服务器和连接的客户端的简要详细信息。 wchs：3.3.0中的新增功能：列出有关服务器监视的简要信息。 wchc：3.3.0中的新增功能：按会话列出有关服务器监视的详细信息。这将输出具有相关监视（路径）的会话（连接）列表。请注意，根据手表的数量，此操作可能会很昂贵（即影响服务器性能），请小心使用。 dirs：3.5.1中的新增功能：以字节为单位显示快照和日志文件的总大小 wchp：3.3.0中的新增功能：按路径列出有关服务器监视的详细信息。这将输出具有关联会话的路径（znode）列表。请注意，根据手表的数量，此操作可能会很昂贵（即影响服务器性能），请小心使用。 mntr：3.4.0中的新增功能：输出可用于监视集群运行状况的变量列表。 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/zookeeper/zookeeper-sence-use.html":{"url":"distributed/zookeeper/zookeeper-sence-use.html","title":"3.典型使用场景实践","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、 分布式集群管理 分布式集群管理的需求： 架构设计： 功能实现： 二 、分布式注册中心 Dubbo 对zookeeper的使用 Dubbo Zookeeper注册中心存储结构： 示例演示： 三、分布式JOB 分布式JOB需求： 架构设计： 四、分布式锁 锁的的基本概念： 锁的获取： 关于羊群效应： 示例演示： 课程概要： 分布式集群管理 分布式注册中心 分布式JOB 分布式锁 一、 分布式集群管理 分布式集群管理的需求： 主动查看线上服务节点 查看服务节点资源使用情况 服务离线通知 服务资源（CPU、内存、硬盘）超出阀值通知架构设计： 节点结构： tuling-manger // 根节点 server00001 : //服务节点 1 server00002 ://服务节点 2 server........n ://服务节点 n 服务状态信息: ip cpu memory disk功能实现： 数据生成与上报： 创建临时节点： 定时变更节点状态信息： 主动查询： 1、实时查询 zookeeper 获取集群节点的状态信息。 被动通知： 监听根节点下子节点的变化情况,如果CPU 等硬件资源低于警告位则发出警报。 关键示例代码： package com.tuling; import com.fasterxml.jackson.core.JsonProcessingException; import com.fasterxml.jackson.databind.ObjectMapper; import com.tuling.os.CPUMonitorCalc; import com.tuling.os.OsBean; import org.I0Itec.zkclient.IZkChildListener; import org.I0Itec.zkclient.ZkClient; import java.io.IOException; import java.lang.instrument.Instrumentation; import java.lang.management.ManagementFactory; import java.lang.management.MemoryUsage; import java.net.InetAddress; import java.net.UnknownHostException; import java.util.ArrayList; import java.util.List; import java.util.stream.Collectors; /** * @author Tommy * Created by Tommy on 2019/9/22 **/ public class Agent { private String server = \"192.168.0.149:2181\"; ZkClient zkClient; private static Agent instance; private static final String rootPath = \"/tuling-manger\"; private static final String servicePath = rootPath + \"/service\"; private String nodePath; private Thread stateThread; List list = new ArrayList<>(); public static void premain(String args, Instrumentation instrumentation) { instance = new Agent(); if (args != null) { instance.server = args; } instance.init(); } // 初始化连接 public void init() { zkClient = new ZkClient(server, 5000, 10000); System.out.println(\"zk连接成功\" + server); buildRoot(); createServerNode(); stateThread = new Thread(() -> { while (true) { updateServerNode(); try { Thread.sleep(5000); } catch (InterruptedException e) { e.printStackTrace(); } } }, \"zk_stateThread\"); stateThread.setDaemon(true); stateThread.start(); } // 构建根节点 public void buildRoot() { if (!zkClient.exists(rootPath)) { zkClient.createPersistent(rootPath); } } // 生成服务节点 public void createServerNode() { nodePath = zkClient.createEphemeralSequential(servicePath, getOsInfo()); System.out.println(\"创建节点:\" + nodePath); } // 监听服务节点状态改变 public void updateServerNode() { zkClient.writeData(nodePath, getOsInfo()); } // 更新服务节点状态 public String getOsInfo() { OsBean bean = new OsBean(); bean.lastUpdateTime = System.currentTimeMillis(); bean.ip = getLocalIp(); bean.cpu = CPUMonitorCalc.getInstance().getProcessCpu(); MemoryUsage memoryUsag = ManagementFactory.getMemoryMXBean().getHeapMemoryUsage(); bean.usableMemorySize = memoryUsag.getUsed() / 1024 / 1024; bean.usableMemorySize = memoryUsag.getMax() / 1024 / 1024; ObjectMapper mapper = new ObjectMapper(); try { return mapper.writeValueAsString(bean); } catch (JsonProcessingException e) { throw new RuntimeException(e); } } public void updateNode(String path, Object data) { if (zkClient.exists(path)) { zkClient.writeData(path, data); } else { zkClient.createEphemeral(path, data); } } public static String getLocalIp() { InetAddress addr = null; try { addr = InetAddress.getLocalHost(); } catch (UnknownHostException e) { throw new RuntimeException(e); } return addr.getHostAddress(); } } 实现效果图： 二 、分布式注册中心 在单体式服务中，通常是由多个客户端去调用一个服务，只要在客户端中配置唯一服务节点地址即可，当升级到分布式后，服务节点变多，像阿里一线大厂服务节点更是上万之多，这么多节点不可能手动配置在客户端，这里就需要一个中间服务，专门用于帮助客户端发现服务节点，即许多技术书籍经常提到的服务发现。 一个完整的注册中心涵盖以下功能特性： 服务注册：提供者上线时将自提供的服务提交给注册中心。 服务注销：通知注册心提供者下线。 服务订阅：动态实时接收服务变更消息。 可靠：注册服务本身是集群的，数据冗余存储。避免单点故障，及数据丢失。 容错：当服务提供者出现宕机，断电等极情况时，注册中心能够动态感知并通知客户端服务提供者的状态。Dubbo 对zookeeper的使用 阿里著名的开源项目Dubbo 是一个基于JAVA的RCP框架，其中必不可少的注册中心可基于多种第三方组件实现，但其官方推荐的还是Zookeeper做为注册中心服务。 Dubbo Zookeeper注册中心存储结构： 节点说明： | 类别 | 属性 | 说明 | |:----|:----|:----| | Root | 持久节点 | 根节点名称，默认是 \"dubbo\" | | Service | 持久节点 | 服务名称，完整的服务类名 | | type | 持久节点 | 可选值：providers(提供者)、consumers（消费者）、configurators(动态配置)、routers | | URL | 临时节点 | url名称 包含服务提供者的 IP 端口 及配置等信息。 | 流程说明： 服务提供者启动时: 向 /dubbo/com.foo.BarService/providers 目录下写入自己的 URL 地址 服务消费者启动时: 订阅 /dubbo/com.foo.BarService/providers 目录下的提供者 URL 地址。并向 /dubbo/com.foo.BarService/consumers 目录下写入自己的 URL 地址 监控中心启动时: 订阅 /dubbo/com.foo.BarService 目录下的所有提供者和消费者 URL 地址。示例演示： 服务端代码： package com.tuling.zk.dubbo; import com.alibaba.dubbo.config.ApplicationConfig; import com.alibaba.dubbo.config.ProtocolConfig; import com.alibaba.dubbo.config.RegistryConfig; import com.alibaba.dubbo.config.ServiceConfig; import java.io.IOException; /** * @author Tommy * Created by Tommy on 2019/10/8 **/ public class Server { public void openServer(int port) { // 构建应用 ApplicationConfig config = new ApplicationConfig(); config.setName(\"simple-app\"); // 通信协议 ProtocolConfig protocolConfig = new ProtocolConfig(\"dubbo\", port); protocolConfig.setThreads(200); ServiceConfig serviceConfig = new ServiceConfig(); serviceConfig.setApplication(config); serviceConfig.setProtocol(protocolConfig); serviceConfig.setRegistry(new RegistryConfig(\"zookeeper://192.168.0.149:2181\")); serviceConfig.setInterface(UserService.class); UserServiceImpl ref = new UserServiceImpl(); serviceConfig.setRef(ref); //开始提供服务 开张做生意 serviceConfig.export(); System.out.println(\"服务已开启!端口:\"+serviceConfig.getExportedUrls().get(0).getPort()); ref.setPort(serviceConfig.getExportedUrls().get(0).getPort()); } public static void main(String[] args) throws IOException { new Server().openServer(-1); System.in.read(); } } 客户端代码： package com.tuling.zk.dubbo; import com.alibaba.dubbo.config.ApplicationConfig; import com.alibaba.dubbo.config.ReferenceConfig; import com.alibaba.dubbo.config.RegistryConfig; import java.io.IOException; /** * @author Tommy * Created by Tommy on 2018/11/20 **/ public class Client { UserService service; // URL 远程服务的调用地址 public UserService buildService(String url) { ApplicationConfig config = new ApplicationConfig(\"young-app\"); // 构建一个引用对象 ReferenceConfig referenceConfig = new ReferenceConfig<>(); referenceConfig.setApplication(config); referenceConfig.setInterface(UserService.class); // referenceConfig.setUrl(url); referenceConfig.setRegistry(new RegistryConfig(\"zookeeper://192.168.0.149:2181\")); referenceConfig.setTimeout(5000); // 透明化 this.service = referenceConfig.get(); return service; } static int i = 0; public static void main(String[] args) throws IOException { Client client1 = new Client(); client1.buildService(\"\"); String cmd; while (!(cmd = read()).equals(\"exit\")) { UserVo u = client1.service.getUser(Integer.parseInt(cmd)); System.out.println(u); } } private static String read() throws IOException { byte[] b = new byte[1024]; int size = System.in.read(b); return new String(b, 0, size).trim(); } } 查询zk 实际存储内容： /dubbo /dubbo/com.tuling.zk.dubbo.UserService /dubbo/com.tuling.zk.dubbo.UserService/configurators /dubbo/com.tuling.zk.dubbo.UserService/routers /dubbo/com.tuling.zk.dubbo.UserService/providers /dubbo/com.tuling.zk.dubbo.UserService/providers/dubbo://192.168.0.132:20880/com.tuling.zk.dubbo.UserService?anyhost=true&application=simple-app&dubbo=2.6.2&generic=false&interface=com.tuling.zk.dubbo.UserService&methods=getUser&pid=11128&side=provider&threads=200&timestamp=1570518302772 /dubbo/com.tuling.zk.dubbo.UserService/providers/dubbo://192.168.0.132:20881/com.tuling.zk.dubbo.UserService?anyhost=true&application=simple-app&dubbo=2.6.2&generic=false&interface=com.tuling.zk.dubbo.UserService&methods=getUser&pid=12956&side=provider&threads=200&timestamp=1570518532382 /dubbo/com.tuling.zk.dubbo.UserService/providers/dubbo://192.168.0.132:20882/com.tuling.zk.dubbo.UserService?anyhost=true&application=simple-app&dubbo=2.6.2&generic=false&interface=com.tuling.zk.dubbo.UserService&methods=getUser&pid=2116&side=provider&threads=200&timestamp=1570518537021 /dubbo/com.tuling.zk.dubbo.UserService/consumers /dubbo/com.tuling.zk.dubbo.UserService/consumers/consumer://192.168.0.132/com.tuling.zk.dubbo.UserService?application=young-app&category=consumers&check=false&dubbo=2.6.2&interface=com.tuling.zk.dubbo.UserService&methods=getUser&pid=9200&side=consumer&timeout=5000&timestamp=1570518819628 三、分布式JOB 分布式JOB需求： 多个服务节点只允许其中一个主节点运行JOB任务。 当主节点挂掉后能自动切换主节点，继续执行JOB任务。架构设计： node结构： tuling-master server0001:master server0002:slave server000n:slave 选举流程： 服务启动： 在tuling-maste下创建server子节点，值为slave 获取所有tuling-master 下所有子节点 判断是否存在master 节点 如果没有设置自己为master节点 子节点删除事件触发： 获取所有tuling-master 下所有子节点 判断是否存在master 节点 如果没有设置最小值序号为master 节点四、分布式锁 锁的的基本概念： 开发中锁的概念并不陌生，通过锁可以实现在多个线程或多个进程间在争抢资源时，能够合理的分配置资源的所有权。在单体应用中我们可以通过 synchronized 或ReentrantLock 来实现锁。但在分布式系统中，仅仅是加synchronized 是不够的，需要借助第三组件来实现。比如一些简单的做法是使用 关系型数据行级锁来实现不同进程之间的互斥，但大型分布式系统的性能瓶颈往往集中在数据库操作上。为了提高性能得采用如Redis、Zookeeper之内的组件实现分布式锁。 共享锁：也称作只读锁，当一方获得共享锁之后，其它方也可以获得共享锁。但其只允许读取。在共享锁全部释放之前，其它方不能获得写锁。 排它锁：也称作读写锁，获得排它锁后，可以进行数据的读写。在其释放之前，其它方不能获得任何锁。 锁的获取： 某银行帐户，可以同时进行帐户信息的读取，但读取其间不能修改帐户数据。其帐户ID为:888 获得读锁流程： 1、基于资源ID创建临时序号读锁节点 /lock/888.R0000000002 Read 2、获取 /lock 下所有子节点，判断其最小的节点是否为读锁，如果是则获锁成功 3、最小节点不是读锁，则阻塞等待。添加lock/ 子节点变更监听。 4、当节点变更监听触发，执行第2步 数据结构： 获得写锁： 1、基于资源ID创建临时序号写锁节点 /lock/888.R0000000002 Write 2、获取 /lock 下所有子节点，判断其最小的节点是否为自己，如果是则获锁成功 3、最小节点不是自己，则阻塞等待。添加lock/ 子节点变更监听。 4、当节点变更监听触发，执行第2步 释放锁： 读取完毕后，手动删除临时节点，如果获锁期间宕机，则会在会话失效后自动删除。 关于羊群效应： 在等待锁获得期间，所有等待节点都在监听 Lock节点，一但lock 节点变更所有等待节点都会被触发，然后在同时反查Lock 子节点。如果等待对例过大会使用Zookeeper承受非常大的流量压力。 为了改善这种情况，可以采用监听链表的方式，每个等待对列只监听前一个节点，如果前一个节点释放锁的时候，才会被触发通知。这样就形成了一个监听链表。 示例演示： package com.tuling.zookeeper.lock; import org.I0Itec.zkclient.IZkDataListener; import org.I0Itec.zkclient.ZkClient; import java.util.List; import java.util.stream.Collectors; /** * @author Tommy * Created by Tommy on 2019/9/23 **/ public class ZookeeperLock { private String server = \"192.168.0.149:2181\"; private ZkClient zkClient; private static final String rootPath = \"/tuling-lock\"; public ZookeeperLock() { zkClient = new ZkClient(server, 5000, 20000); buildRoot(); } // 构建根节点 public void buildRoot() { if (!zkClient.exists(rootPath)) { zkClient.createPersistent(rootPath); } } public Lock lock(String lockId, long timeout) { Lock lockNode = createLockNode(lockId); lockNode = tryActiveLock(lockNode);// 尝试激活锁 if (!lockNode.isActive()) { try { synchronized (lockNode) { lockNode.wait(timeout); } } catch (InterruptedException e) { throw new RuntimeException(e); } } if (!lockNode.isActive()) { throw new RuntimeException(\" lock timeout\"); } return lockNode; } public void unlock(Lock lock) { if (lock.isActive()) { zkClient.delete(lock.getPath()); } } // 尝试激活锁 private Lock tryActiveLock(Lock lockNode) { // 判断当前是否为最小节点 List list = zkClient.getChildren(rootPath) .stream() .sorted() .map(p -> rootPath + \"/\" + p) .collect(Collectors.toList()); String firstNodePath = list.get(0); if (firstNodePath.equals(lockNode.getPath())) { lockNode.setActive(true); } else { String upNodePath = list.get(list.indexOf(lockNode.getPath()) - 1); zkClient.subscribeDataChanges(upNodePath, new IZkDataListener() { @Override public void handleDataChange(String dataPath, Object data) throws Exception { } @Override public void handleDataDeleted(String dataPath) throws Exception { // 事件处理 与心跳 在同一个线程，如果Debug时占用太多时间，将导致本节点被删除，从而影响锁逻辑。 System.out.println(\"节点删除:\" + dataPath); Lock lock = tryActiveLock(lockNode); synchronized (lockNode) { if (lock.isActive()) { lockNode.notify(); } } zkClient.unsubscribeDataChanges(upNodePath, this); } }); } return lockNode; } public Lock createLockNode(String lockId) { String nodePath = zkClient.createEphemeralSequential(rootPath + \"/\" + lockId, \"lock\"); return new Lock(lockId, nodePath); } } Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/zookeeper/zookeeper-zab.html":{"url":"distributed/zookeeper/zookeeper-zab.html","title":"4.ZAB协议实现源码分析","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、启动流程 1.工程结构介绍 2.启动宏观流程图： 3.集群启动详细流程 4.netty 服务启动流程： 二、快照与事务日志存储结构 概要: 存储结构: 快照相关配置： 快照装载流程： 课程概要： 启动流程源码分析 快照与事物日志的存储结构一、启动流程 知识点： 工程结构介绍 启动流程宏观图 集群启动详细流程 netty 服务工作机制1.工程结构介绍 项目地址:https://github.com/apache/zookeeper.git 分支tag ：3.5.5 zookeeper-recipes: 示例源码 zookeeper-client: C语言客户端 zookeeper-server：主体源码 2.启动宏观流程图： [ ] 启动示例演示： 服务端：ZooKeeperServerMain 客户端：ZooKeeperMain 3.集群启动详细流程 装载配置： # zookeeper 启动流程堆栈 >QuorumPeerMain#initializeAndRun //启动工程 >QuorumPeerConfig#parse // 加载config 配置 >QuorumPeerConfig#parseProperties// 解析config配置 >new DatadirCleanupManager // 构造一个数据清器 >DatadirCleanupManager#start // 启动定时任务 清除过期的快照 代码堆栈 ： >QuorumPeerMain#main //启动main方法 >QuorumPeerConfig#parse // 加载zoo.cfg 文件 >QuorumPeerConfig#parseProperties // 解析配置 >DatadirCleanupManager#start // 启动定时任务清除日志 >QuorumPeerConfig#isDistributed // 判断是否为集群模式 >ServerCnxnFactory#createFactory() // 创建服务默认为NIO，推荐netty //***创建 初始化集群管理器**/ >QuorumPeerMain#getQuorumPeer >QuorumPeer#setTxnFactory >new FileTxnSnapLog // 数据文件管理器，用于检测快照与日志文件 /** 初始化数据库*/ >new ZKDatabase >ZKDatabase#createDataTree //创建数据树，所有的节点都会存储在这 // 启动集群：同时启动线程 > QuorumPeer#start // > QuorumPeer#loadDataBase // 从快照文件以及日志文件 加载节点并填充到dataTree中去 > QuorumPeer#startServerCnxnFactory // 启动netty 或java nio 服务，对外开放2181 端口 > AdminServer#start// 启动管理服务，netty http服务，默认端口是8080 > QuorumPeer#startLeaderElection // 开始执行选举流程 > quorumPeer.join() // 防止主进程退出 流程说明: main方法启动 加载zoo.cfg 配置文件 解析配置 创建服务工厂 创建集群管理线程 设置数据库文件管理器 设置数据库 ....设置设置 start启动集群管理线程 加载数据节点至内存 启动netty 服务，对客户端开放端口 启动管理员Http服务，默认8080端口 启动选举流程 join 管理线程，防止main 进程退出 4.netty 服务启动流程： 服务UML类图 设置netty启动参数 -Dzookeeper.serverCnxnFactory=org.apache.zookeeper.server.NettyServerCnxnFactory 初始化： 关键代码： #初始化管道流 #channelHandler 是一个内部类是具体的消息处理器。 protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); if (secure) { initSSL(pipeline); } pipeline.addLast(\"servercnxnfactory\", channelHandler); } channelHandler 类结构 执行堆栈： NettyServerCnxnFactory#NettyServerCnxnFactory // 初始化netty服务工厂 > NettyUtils.newNioOrEpollEventLoopGroup // 创建IO线程组 > NettyUtils#newNioOrEpollEventLoopGroup() // 创建工作线程组 >ServerBootstrap#childHandler(io.netty.channel.ChannelHandler) // 添加管道流 >NettyServerCnxnFactory#start // 绑定端口，并启动netty服务 创建连接： 每当有客户端新连接进来，就会进入该方法 创建 NettyServerCnxn对象。并添加至cnxns对例 执行堆栈 CnxnChannelHandler#channelActive >new NettyServerCnxn // 构建连接器 >NettyServerCnxnFactory#addCnxn // 添加至连接器，并根据客户端IP进行分组 >ipMap.get(addr) // 基于IP进行分组 读取消息： 执行堆栈 CnxnChannelHandler#channelRead >NettyServerCnxn#processMessage // 处理消息 >NettyServerCnxn#receiveMessage // 接收消息 >ZooKeeperServer#processPacket //处理消息包 >org.apache.zookeeper.server.Request // 封装request 对象 >org.apache.zookeeper.server.ZooKeeperServer#submitRequest // 提交request >org.apache.zookeeper.server.RequestProcessor#processRequest // 处理请求 二、快照与事务日志存储结构 概要: ZK中所有的数据都是存储在内存中，即zkDataBase中。但同时所有对ZK数据的变更都会记录到事物日志中，并且当写入到一定的次数就会进行一次快照的生成。已保证数据的备份。其后缀就是ZXID（唯一事物ID）。 事物日志：每次增删改，的记录日志都会保存在文件当中 快照日志：存储了在指定时间节点下的所有的数据存储结构: zkDdataBase 是zk数据库基类，所有节点都会保存在该类当中，而对Zk进行任何的数据变更都会基于该类进行。zk数据的存储是通过DataTree 对象进行，其用了一个map 来进行存储。 UML 类图： 读取快照日志： org.apache.zookeeper.server.SnapshotFormatter 读取事物日志： org.apache.zookeeper.server.LogFormatter 快照相关配置： dataLogDir 事物日志目录 zookeeper.preAllocSize 预先开辟磁盘空间，用于后续写入事务日志，默认64M zookeeper.snapCount 每进行snapCount次事务日志输出后，触发一次快照，默认是100,000 autopurge.snapRetainCount 自动清除时 保留的快照数 autopurge.purgeInterval 清除时间间隔，小时为单位 -1 表示不自动清除。 快照装载流程： >ZooKeeperServer#loadData // 加载数据 >FileTxnSnapLog#restore // 恢复数据 >FileSnap#deserialize() // 反序列化数据 >FileSnap#findNValidSnapshots // 查找有效的快照 >Util#sortDataDir // 基于后缀排序文件 >persistence.Util#isValidSnapshot // 验证是否有效快照文件 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/netty/":{"url":"distributed/netty/","title":"netty","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/netty/shell.html":{"url":"distributed/netty/shell.html","title":"1.启停脚本","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 ! /bin/bash #! /bin/bash case $1 in \"start\"){ for i in hadoop101 hadoop102 hadoop103 do echo \" --------启动 $i Kafka-------\" # 用于KafkaManager监控 ssh $i \"export JMX_PORT=9988 && /usr/local/software/kafka_2.12-2.6.0/bin/kafka-server-start.sh -daemon /usr/local/software/kafka_2.12-2.6.0/config/server.properties \" done };; \"stop\"){ for i in hadoop101 hadoop102 hadoop103 do echo \" --------停止 $i Kafka-------\" ssh $i \"/usr/local/software/kafka_2.12-2.6.0/bin/kafka-server-stop.sh stop\" done };; esac Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:36:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/netty/netty.html":{"url":"distributed/netty/netty.html","title":"2.分布式之netty","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.Java IO 与 NIO 1.1Linux I/O 模型介绍 1.1.1Linux I/O 流程 1.1.2 将 I/O 模型划分为以下五种类型： 1.1.3 各种 I/O 模型的比较 1.2Java I/O 1.3Java NIO 1.3.1java io 和 java nio 对比 1.3.2Java NIO 主要由3 部分核心组件组成 1.3.3NIO 带来了什么 2.Netty 编程实践 2.1Netty 介绍 2.1.1特性 2.2Netty 主要组件介绍 2.2.1Bootstrap 和 ServerBootstrap 2.2.2Transport Channel 2.2.3EventLoop和EventLoopGroup 2.2.4ChannelHandler和ChannelPipeline 2.2.5ByteBuf 2.3Netty 编程示例 3.Netty 线程模型解析 3.1Reactor 模式及其与 Netty 的对应关系 3.1.1单线程Reactor 3.1.2多线程Reactor 3.1.3Multiple Reactor 3.1.4主从Reactor 3.2Netty EventLoop 源码解析 3.2.1NioEventLoopGroup整体结构 3.2.2NioEventLoop创建分析 3.2.3NioEventLoop启动流程分析 3.2.4NioEventLoop执行流程分析 4.Netty 编解码编程实战 4.1 半包粘包问题示例与分析 4.2Netty 半包粘包问题解决 4.2.1LineBasedFrameDecoder（\\n, \\r\\n) 4.2.2DelimiterBasedFrameDecoder 4.2.3FixedLengthFrameDecoder 4.2.4LengthFieldBasedFrameDecoder 4.3Netty 编解码器分析 5.基于 Netty 实现高性能弹幕系统 5.1 弹幕系统概要设计 5.1.1弹幕系统特点 5.1.2弹幕系统架构设计 5.2Netty 对 Http 协议解析实现 5.2.1http报文解析方案： 5.2.2netty关于http 的解决方案： 5.2.3Netty Http的请求处理流程 5.3WebScoket 协议解析实现 5.3.1webSocket 协议简介： 5.3.2webSocket特点如下： 5.3.3WebSocket 协议报文格式： 6.基于 Netty 实现 RPC 框架 6.1RPC构建需要考虑的主要因素 6..1.2RPC框架 1.Java IO 与 NIO 1.1Linux I/O 模型介绍 1.1.1Linux I/O 流程 1.1.2 将 I/O 模型划分为以下五种类型： 阻塞式 I/O 模型 非阻塞式 I/O 模型 I/O 复用 信号驱动式 I/O 异步 I/O 1.1.3 各种 I/O 模型的比较 1.2Java I/O 1.3Java NIO 1.3.1java io 和 java nio 对比 1.3.2Java NIO 主要由3 部分核心组件组成 a. Buffer 一个 Buffer 本质上是内存中的一块， 可以将数据写入这块内存， 从这块内存获取数据 java.nio 定义了以下几个 Buffer 的实现 Java NIO Buffer 三大核心概念：position、limit、capacity 最好理解的当然是 capacity，它代表这个缓冲区的容量，一旦设定就不可以更改。比如 capacity 为 1024 的 IntBuffer，代表其一次可以存放 1024 个 int 类型的值。 一旦 Buffer 的容量达到 capacity，需要清空 Buffer，才能重新写入值。 b. Channel 所有的 NIO 操作始于通道，通道是数据来源或数据写入的目的地，主要地，java.nio 包中主要实现的以下几个 Channel： c. Selector Selector 是 Java NIO 中的一个组件，用于检查一个或多个 NIO Channel 的状态是否处于可读、可写 如此可以实现单线程管理多个 channels,也就是可以管理多个网络链接 1.3.3NIO 带来了什么 事件驱动模型 避免多线程 单线程处理多任务 非阻塞 IO,IO 读写不再阻塞,而是返回 0 基于 block 的传输,通常比基于流的传输更高效 更高级的 IO 函数,zero-copy IO 多路复用大大提高了 java 网络应用的可伸缩性和实用性 注意 使用NIO = 高性能 NIO不一定更快的场景 客户端应用 连接数 并发程度不高 局域网环境下 NIO完全屏蔽了平台差异(Linux poll/select/epoll, FreeBSD Kqueue) NIO仍然是基于各个OS平台的IO系统实现的,差异仍然存在 使用NIO做网络编程很容易 离散的事件驱动模型，编程困难2.Netty 编程实践 2.1Netty 介绍 2.1.1特性 设计 统一的API,适用于不同的协议(阻塞和非阻塞) 基于灵活、可扩展的事件驱动模型（SEDA） 高度可定制的线程模型 可靠的无连接数据Socket支持(UDP) 性能 更好的吞吐量,低延迟 更省资源 尽量减少不必要的内存拷贝 安全 完整的SSL/ TLS和STARTTLS的支持 易用 完善的Java doc,用户指南和样例 仅依赖于JDK1.6（netty 4.x)2.2Netty 主要组件介绍 2.2.1Bootstrap 和 ServerBootstrap Netty Server启动主要流程： 设置服务端ServerBootStrap启动参数 group(parentGroup, childGroup): channel(NioServerSocketChannel): 设置通道类型 handler()：设置NioServerSocketChannel的ChannelHandlerPipeline childHandler(): 设置NioSocketChannel的ChannelHandlerPipeline 通过ServerBootStrap的bind方法启动服务端，bind方法会在parentGroup中注册NioServerScoketChannel，监听客户端的连接请求 会创建一个NioServerSocketChannel实例，并将其在parentGroup中进行注册 Netty Server执行主要流程： Client发起连接CONNECT请求，parentGroup中的NioEventLoop不断轮循是否有新的客户端请求，如果有，ACCEPT事件触发 ACCEPT事件触发后，parentGroup中NioEventLoop会通过NioServerSocketChannel获取到对应的代表客户端的NioSocketChannel，并将其注册到childGroup中 childGroup中的NioEventLoop不断检测自己管理的NioSocketChannel是否有读写事件准备好 2.2.2Transport Channel 提供了统一的API，支持不同类型的传输层： OIO -阻塞IO NIO - Java NIO Epoll - Linux Epoll(JNI) Local Transport - IntraVM调用 Embedded Transport - 供测试使用的嵌入传输 UDS - Unix套接字的本地传输 2.2.3EventLoop和EventLoopGroup EventLoopGroup 包括多个EventLoop 多个EventLoop之间不交互 EventLoop： 每个EventLoop对应一个线程 所有连接(channel)都将注册到一个EventLoop，并且只注册到一个，整个生命周期中都不会变化 每个EventLoop管理着多个连接(channel) EventLoop来处理连接(Channel)上的读写事件 ServerBootstrap包括2个不同类型的EventLoopGroup: Parent EventLoop:负责处理Accept事件，接收请求 Child EventLoop：负责处理读写事件 ByteBuf通过两个索引（reader index、writer index）划分为三个区域： reader index前面的数据是已经读过的数据，这些数据可以丢弃 从reader index开始，到writer index之前的数据是可读数据 从writer index开始，为可写区域2.2.4ChannelHandler和ChannelPipeline ChannelHandler - 业务处理核心逻辑，用户自定义 Netty 提供2个重要的 ChannelHandler 子接口： ChannelInboundHandler - 处理进站数据和所有状态更改事件 ChannelOutboundHandler - 处理出站数据，允许拦截各种操作 ChannelPipeline 是ChannelHandler容器 包括一系列的ChannelHandler 实例,用于拦截流经一个 Channel 的入站和出站事件 每个Channel都有一个其ChannelPipeline 可以修改 ChannelPipeline 通过动态添加和删除 ChannelHandler 定义了丰富的API调用来回应入站和出站事件 ChannelHandlerContext表示 ChannelHandler 和ChannelPipeline 之间的关联 在 ChannelHandler 添加到 ChannelPipeline 时创建 ChannelHandlerContext表示 ChannelHandler 和ChannelPipeline 之间的关联 2.2.5ByteBuf 相比JDK ByteBuffer， 更加易于使用： 为读/写分别维护单独的指针，不需要通过flip()进行读/写模式切换 容量自动伸缩（类似于 ArrayList，StringBuilder） Fluent API (链式调用） 更好的性能： 通过内置的CompositeBuffer来减少数据拷贝（Zero copy） 支持内存池，减少GC压力2.3Netty 编程示例 3.Netty 线程模型解析 3.1Reactor 模式及其与 Netty 的对应关系 3.1.1单线程Reactor 3.1.2多线程Reactor 3.1.3Multiple Reactor 3.1.4主从Reactor 3.2Netty EventLoop 源码解析 3.2.1NioEventLoopGroup整体结构 3.2.2NioEventLoop创建分析 3.2.3NioEventLoop启动流程分析 3.2.4NioEventLoop执行流程分析 4.Netty 编解码编程实战 4.1 半包粘包问题示例与分析 4.2Netty 半包粘包问题解决 4.2.1LineBasedFrameDecoder（\\n, \\r\\n) 回车换行解码器 配合StringDecoder 4.2.2DelimiterBasedFrameDecoder 分隔符解码器 4.2.3FixedLengthFrameDecoder 固定长度解码器 4.2.4LengthFieldBasedFrameDecoder 基于'长度'解码器(私有协议最常用) 4.3Netty 编解码器分析 5.基于 Netty 实现高性能弹幕系统 5.1 弹幕系统概要设计 5.1.1弹幕系统特点 1.实时性高：你发我收， 毫秒之差 2.并发量大：一人吐槽，万人观看 5.1.2弹幕系统架构设计 业务架构 实现方案一 实现方案二 5.2Netty 对 Http 协议解析实现 request 报文 response 报文 5.2.1http报文解析方案： 1：请求行的边界是CRLF(回车)，如果读取到CRLF(回车)，则意味着请求行的信息已经读取完成。 2：Header的边界是CRLF，如果连续读取两个CRLF，则意味着header的信息读取完成。 3：body的长度是有Content-Length 来进行确定。 5.2.2netty关于http 的解决方案： // 解析请求 很多http server的实现都是基于servlet标准，但是netty对http实现并没有基于servlet。所以在使用上比Servlet复杂很多。比如在servlet 中直接可以通过 HttpServletRequest 获取 请求方法、请求头、请求参数。而netty 确需要通过如下对象自行解析获取。 HttpMethod：主要是对method的封装，包含method序列化的操作 HttpVersion: 对version的封装，netty包含1.0和1.1的版本 QueryStringDecoder: 主要是对urI进行解析，解析path和url上面的参数。 HttpPostRequestDecoder：对post 中body 内容进行解析获取 form 参数。 HttpHeaders：包含对header的内容进行封装及操作 HttpContent：是对body进行封装，本质上就是一个ByteBuf。如果ByteBuf的长度是固定的，则请求的body过大，可能包含多个HttpContent，其中最后一个为LastHttpContent(空的HttpContent),用来说明body的结束。 HttpRequest：主要包含对Request Line和Header的组合 FullHttpRequest： 主要包含对HttpRequest和httpContent的组合 5.2.3Netty Http的请求处理流程 从图中可以看出做为服务端的Netty 就是在做 编码和解码操作。其分别通过以下两个ChannelHandler对象实现： HttpRequestDecoder :用于从byteBuf 获取数据并解析封装成HttpRequest 对象 HttpResponseEncoder：用于将业务返回数据编码成 Response报文并发送到ByteBuf。 将以上两个对象添加进 Netty 的 pipeline 即可实现最简单的http 服务。 Decoder 流程 encode 流程 5.3WebScoket 协议解析实现 5.3.1webSocket 协议简介： webSocket 是html5 开始提供的一种浏览器与服务器间进行全双工二进制通信协议，其基于TCP双向全双工作进行消息传递，同一时刻即可以发又可以接收消息，相比Http的半双工协议性能有很大的提升， 5.3.2webSocket特点如下： 1.单一TCP长连接，采用全双工通信模式 2.对代理、防火墙透明 3.无头部信息、消息更精简 4.通过ping/pong 来保活 5.服务器可以主动推送消息给客户端，不在需要客户轮询 5.3.3WebSocket 协议报文格式： 我们知道，任何应用协议都有其特有的报文格式，比如Http协议通过 空格 换行组成其报文。如http 协议不同在于WebSocket属于二进制协议，通过规范进二进位来组成其报文。具体组成如下图： 通过javaScript 中的API可以直接操作WebSocket 对象，其示例如下： var ws = new WebSocket(“ws://localhost:8080”); ws.onopen = function()// 建立成功之后触发的事件 { console.log(“打开连接”); ws.send(\"ddd\"); // 发送消息 }; ws.onmessage = function(evt) { // 接收服务器消息 console.log(evt.data); }; ws.onclose = function(evt) { console.log(“WebSocketClosed!”); // 关闭连接 }; ws.onerror = function(evt) { console.log(“WebSocketError!”); // 连接异常 }; 6.基于 Netty 实现 RPC 框架 6.1RPC构建需要考虑的主要因素 通信协议 文本协议或二进制协议（RESTful with JSON or RPC with Binary Encoding） 支持的调用方式：单向、双向、Streaming API容错、可伸缩性6..1.2RPC框架 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:27:02 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/dubbo/":{"url":"distributed/dubbo/","title":"dubbo","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/dubbo/dubbo-introduce.html":{"url":"distributed/dubbo/dubbo-introduce.html","title":"1.从0到1整体认知分布式系统","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、分布式架构的发展历史与背景 架构的发展历史： 分布式架构所带来的成本与风险: 二、如何选型分布式架构 基于反向代理的集中式分布式架构 嵌入应用内部的去中心化架构 基于独立代理进程的架构(Service Mesh) 三种架构的比较 **三、Dubbo 架构与设计说明 ** dubbo架构简要讲解 Dubbo 整体设计 Dubbo 中的SPI机制 概要： 分布式架构的发展历史与背景 如何着手架构一套分布示式系统 Dubbo 架构与设计说明 一、分布式架构的发展历史与背景 场景一： 一家做政务OA系统的公司老板发现跟竞争对手比发现自己的系统的架构不是分布示的，找到技术负责人问，把系统架构升级成分布示架构要多长时间？技术负责人网上查了查 dubbo官网看了看 Demo 这不很简单吗，拍着胸脯一个月能升级好。 现在我的问题是：这位技术理在改造过程中可能会遇到什么风险和问题？ 新功能和旧BUG的问题 业务完整性的问题 团队协作方式转变 开发人员技能提升 系统交付方式转变 这些问题解决涉及业务部门及整个技术部门（开发、测试、运维）协商与工作标准的制定。业务相关问题暂不做讨论,技术架构上应该要清楚自己的职责是，如何通过技术手段把业务波动降至最低、开发成本最低、实施风险最低？ 架构的发展历史： 单体式架构： 垂直架构: 分布示架构： 分布式架构所带来的成本与风险: 分布式事物： 分布式事物是指一个操作，分成几个小操作在多个服务器上执行，要么多成功，要么多失败这些分布事物要做的 不允许服务有状态（**stateless service**） 无状态服务是指对单次请求的处理，不依赖其他请求，也就是说，处理一次请求所需的全部信息，要么都包含在这个请求里，要么可以从外部获取到（比如说数据库），服务器本身不存储任何信息。 服务依懒关系复杂 服务 A --> B--> C 那和服务C 的修改 就可能会影响 B 和C，事实上当服务越来 越多的时候，C的变动将会越来越困难。 部署运维成本增加 不用说了，相比之前几个节点，运维成本的增加必须的。 源码管理成本增加： 原本一套或几套源码现在拆分成几十个源码库，其中分支、tag都要进行相应管理。 如何保证系统的伸缩性： 伸缩性是指,当前服务器硬件升级后或新增服务器处理能力就能相对应的提升。 分布式会话： 此仅针对应用层服务，不能将Session 存储在一个服务器上。 分布式JOB 通常定时任务只需要在一台机器上触发执行，分布式的情况下在哪台执行呢？ 最后通过一张图直观感受一下 单体到分布式的区别： 二、如何选型分布式架构 提问：实现一个分布示框架最核心功能是什么? RPC远程调用技术： 大家知道的 有哪些远程调用的 方式？拿几个大家比较熟悉的来举例：RMI 、Web Service、Http | 协议 | 描述 | 优点 | 缺点 | |:----|:----|:----|:----| | RMI | JAVA 远程方法调用、使用原生二进制方式进行序列化 | 简单易用、SDK支持，提高开发效率 | 不支持跨语言 | | Web Service | 比较早系统调用解决方案 ，跨语言, 其基于WSDL 生成 SOAP 进行消息的传递。 | SDK支持、跨语言 | 实现较重，发布繁琐 | | Http | 采用htpp +json 实现 | 简单、轻量、跨语言 | 不支持SDK | 基于比较上述比较，大家会选择哪个方案，综合考虑 RMI是比较合适的方案，基本没有学习成本。而跨语言问题基本可以勿略。 如果服务端不是单个的话，这个方案差点我就用了。实际上服务端是多个的 ，好了新的问题又来了。 负载均衡：这么多个机器调用哪一台? 服务发现：样发现新的服务地址呢？ 健康检测：服务关宕机或恢复后怎么办？ 容错：如果调用其中一台调用出错了怎么办？ 这些功能怎么解决呢？一个一个的去编码实现么？。有没有现成的方案可以直接借鉴呢？ 分布式架构的三种解决方案： 基于反向代理的中心化架构 嵌入应用内部的去中心化架构 基于独立代理进程的Service Mesh架构基于反向代理的集中式分布式架构 这是最简单和传统做法，在服务消费者和生产者之间，代理作为独立一层集中部署，由独立团队(一般是运维或框架)负责治理和运维。常用的集中式代理有硬件负载均衡器(如F5)，或者软件负载均衡器(如Nginx)，这种软硬结合两层代理也是业内常见做法，兼顾配置的灵活性(Nginx比F5易于配置)。 Http+Nginx 方案总结： 优点：简单快速、几乎没有学习成本 适用场景：轻量级分布式系统、局部分布式架构。 瓶颈：Nginx中心负载、Http传输、JSON序列化、开发效率、运维效率。 嵌入应用内部的去中心化架构 这是很多互联网公司比较流行的一种做法，代理(包括服务发现和负载均衡逻辑)以客户库的形式嵌入在应用程序中。这种模式一般需要独立的服务注册中心组件配合，服务启动时自动注册到注册中心并定期报心跳，客户端代理则发现服务并做负载均衡。我们所熟悉的 duboo 和spring cloud Eureka +Ribbon/'rɪbən/ 都是这种方式实现。 相比第一代架构它有以下特点几点： 去中心化，客户端直连服务端 动态注册和发现服务 高效稳定的网络传输 高效可容错的序列化基于独立代理进程的架构(Service Mesh) 这种做法是上面两种模式的一个折中，代理既不是独立集中部署，也不嵌入在客户应用程序中，而是作为独立进程部署在每一个主机上，一个主机上的多个消费者应用可以共用这个代理，实现服务发现和负载均衡，如下图所示。这个模式一般也需要独立的服务注册中心组件配合，作用同第二代架构。 三种架构的比较 模式 优点 缺点 适应场景 案例 集中式负载架构 简单 集中式治理 与语言无关 配置维护成本高 多了一层IO 单点问题 大部分公司都适用，对运维有要求 亿贝、携程、早期互联网公司 客户端嵌入式架构 无单点 性能更好 客户端复杂 语言栈要求 中大规模公司、语言栈统一 Dubbo 、 Twitter finagle、 Spring Cloud Ribbon 独立进程代理架构 无单点 性能更好 与语言无关 运维部署复杂 开发联调复杂 中大规模公司 对运维有要求 Smart Stack Service Mesh 三、Dubbo 架构与设计说明 dubbo架构简要讲解 架构图 流程说明： Provider(提供者)绑定指定端口并启动服务 指供者连接注册中心，并发本机IP、端口、应用信息和提供服务信息发送至注册中心存储 Consumer(消费者），连接注册中心 ，并发送应用信息、所求服务信息至注册中心 注册中心根据 消费 者所求服务信息匹配对应的提供者列表发送至Consumer 应用缓存。 Consumer 在发起远程调用时基于缓存的消费者列表择其一发起调用。 Provider 状态变更会实时通知注册中心、在由注册中心实时推送至Consumer 这么设计的意义： Consumer 与Provider 解偶，双方都可以横向增减节点数。 注册中心对本身可做对等集群，可动态增减节点，并且任意一台宕掉后，将自动切换到另一台 去中心化，双方不直接依懒注册中心，即使注册中心全部宕机短时间内也不会影响服务的调用 服务提供者无状态，任意一台宕掉后，不影响使用 Dubbo 整体设计 config 配置层：对外配置接口，以 ServiceConfig, ReferenceConfig 为中心，可以直接初始化配置类，也可以通过 spring 解析配置生成配置类 proxy 服务代理层：服务接口透明代理，生成动态代理 扩展接口为 ProxyFactory registry 注册中心层：封装服务地址的注册与发现，以服务 URL 为中心，扩展接口为 RegistryFactory, Registry, RegistryService cluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster, Directory, Router, LoadBalance monitor 监控层：RPC 调用次数和调用时间监控，以 Statistics 为中心，扩展接口为 MonitorFactory, Monitor, MonitorService protocol 远程调用层：封装 RPC 调用，以 Invocation, Result 为中心，扩展接口为 Protocol, Invoker, Exporter exchange 信息交换层：封装请求响应模式，同步转异步，以 Request, Response 为中心，扩展接口为 Exchanger, ExchangeChannel, ExchangeClient, ExchangeServer transport 网络传输层：抽象 mina 和 netty 为统一接口，以 Message 为中心，扩展接口为 Channel, Transporter, Client, Server, Codec serialize 数据序列化层：可复用的一些工具，扩展接口为 Serialization, ObjectInput, ObjectOutput, ThreadPool 其协作流程如下： Dubbo 中的SPI机制 在了解Dubbo的spi之前 先来了解一下 JAVA自带的SPI java spi的具体约定为:当服务的提供者，提供了服务接口的一种实现之后，在jar包的META-INF/services/目录里同时创建一个以服务接口命名的文件。该文件里就是实现该服务接口的具体实现类。而当外部程序装配这个模块的时候，就能通过该jar包META-INF/services/里的配置文件找到具体的实现类名，并装载实例化，完成模块的注入。 基于这样一个约定就能很好的找到服务接口的实现类，而不需要再代码里制定。jdk提供服务实现查找的一个工具类java.util.ServiceLoader 演示JAVA SPI机制 [ ] 编写接口 [ ] 编写实现类 [ ] 编辑META-INF/services/xxx 文件 [ ] 演示spi 实现 spi 目录文件： META-INF/services/tuling.dubbo.server.UserService 中的值： tuling.dubbo.server.impl.UserServiceImpl2 装载获取SPI实现类： public static void main(String[] args) { Iterator services = ServiceLoader.load(UserService.class).iterator(); UserService service = null; while (services.hasNext()) { service = services.next(); } System.out.println(service.getUser(111)); } Dubbo的SPI机制： dubbo spi 在JAVA自带的SPI基础上加入了扩展点的功能，即每个实现类都会对应至一个扩展点名称，其目的是 应用可基于此名称进行相应的装配。 演示Dubbo SPI机制： [ ] 编写Filter 过滤器 [ ] 编写 dubbo spi 配置文件 [ ] 装配自定义Filter dubbo spi 目录文件 dubbo spi 文件内容： luban=tuling.dubbo.server.LubanFilter 装配自定义Filter Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/dubbo/dubbo-base-use.html":{"url":"distributed/dubbo/dubbo-base-use.html","title":"2.快速掌握Dubbo常规应用","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、Dubbo 快速入门 Dubbo核心功能解释 快速演示Dubbo的远程调用 基于Dubbo实现服务集群： 二、Dubbo常规配置说明 Dubbo配置的整体说明： dubbo 配置的一些套路: 一般建议配置示例： Copyright &copy ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 概要： Dubbo 快速入门 Dubbo 常规配置说明一、Dubbo 快速入门 Dubbo核心功能解释 dubbo 阿里开源的一个SOA服务治理框架，从目前来看把它称作是一个RPC远程调用框架更为贴切。单从RPC框架来说，功能较完善，支持多种传输和序列化方案。所以想必大家已经知道他的核心功能了：就是远程调用。 快速演示Dubbo的远程调用 实现步骤 [ ] 创建服务端项目 [ ] 引入dubbo 依赖 [ ] 编写服务端代码 [ ] 创建客户端项目 [ ] 引入dubbo 依赖 [ ] 编写客户端调用代码 dubbo 引入： com.alibaba dubbo 2.6.2 dubbo 默认依懒： 客户端代码： static String remoteUrl = \"dubbo://127.0.0.1:12345/tuling.dubbo.server.UserService\"; // 构建远程服务对象 public UserService buildRemoteService(String remoteUrl) { ApplicationConfig application = new ApplicationConfig(); application.setName(\"young-app\"); ReferenceConfig referenceConfig = new ReferenceConfig<>(); referenceConfig.setApplication(application); referenceConfig.setInterface(UserService.class); referenceConfig.setUrl(remoteUrl); UserService userService = referenceConfig.get(); return userService; } 服务端代码： public void openServer(int port) { ApplicationConfig config = new ApplicationConfig(); config.setName(\"simple-app\"); ProtocolConfig protocolConfig=new ProtocolConfig(); protocolConfig.setName(\"dubbo\"); protocolConfig.setPort(port); protocolConfig.setThreads(20); ServiceConfig serviceConfig=new ServiceConfig(); serviceConfig.setApplication(config); serviceConfig.setProtocol(protocolConfig); serviceConfig.setRegistry(new RegistryConfig(RegistryConfig.NO_AVAILABLE)); serviceConfig.setInterface(UserService.class); serviceConfig.setRef(new UserServiceImpl()); serviceConfig.export(); } 基于Dubbo实现服务集群： 在上一个例子中如多个服务的集群？即当有多个服务同时提供的时候，客户端该调用哪个？以什么方式进行调用以实现负载均衡？ 一个简单的办法是将多个服务的URL同时设置到客户端并初始化对应的服务实例，然后以轮询的方式进行调用。 但如果访问增大，需要扩容服务器数量，那么就必须增加配置重启客户端实例。显然这不是我们愿意看到的。Dubbo引入了服务注册中的概念，可以解决动态扩容的问题。 演示基于注册中心实现服集群： [ ] 修改服务端代码，添加multicast 注册中心。 [ ] 修改客户端代码，添加multicast 注册中心。 [ ] 观察 多个服务时，客户端如何调用。 [ ] 观察 动态增减服务，客户端的调用。 # 服务端连接注册中心 serviceConfig.setRegistry(new RegistryConfig(\"multicast://224.1.1.1:2222\")); # 客户端连接注册中心 referenceConfig.setRegistry(new RegistryConfig(\"multicast://224.1.1.1:2222\")); #查看 基于UDP 占用的2222 端口 netstat -ano|findstr 2222 基于spring IOC维护Dubbo 实例 在前面两个例子中 出现了,ApplicationConfig、ReferenceConfig、RegistryConfig、com.alibaba.dubbo.config.ServiceConfig等实例 ，很显然不需要每次调用的时候都去创建该实例那就需要一个IOC 容器去管理这些实例，spring 是一个很好的选择。 提供者配置---------------------------------- 提供者服务暴露代码： ApplicationContext context = new ClassPathXmlApplicationContext(\"/spring-provide.xml\"); ((ClassPathXmlApplicationContext) context).start(); System.in.read(); 消费者配置--------------------------------------- 消费者调用代码： ApplicationContext context = new ClassPathXmlApplicationContext(\"/spring-consumer.xml\"); UserService userService = context.getBean(UserService.class); UserVo u = userService.getUser(1111); System.out.println(u); 二、Dubbo常规配置说明 Dubbo配置的整体说明： 标签 用途 解释 公共 用于配置当前应用信息，不管该应用是提供者还是消费者 公共 用于配置连接注册中心相关信息 服务 用于配置提供服务的协议信息，协议由提供方指定，消费方被动接受 服务 用于暴露一个服务，定义服务的元信息，一个服务可以用多个协议暴露，一个服务也可以注册到多个注册中心 服务 当 ProtocolConfig 和 ServiceConfig 某属性没有配置时，采用此缺省值，可选 引用 当 ReferenceConfig 某属性没有配置时，采用此缺省值，可选 引用 用于创建一个远程服务代理，一个引用可以指向多个注册中心 公共 用于 ServiceConfig 和 ReferenceConfig 指定方法级的配置信息 公共 用于指定方法参数配置 配置关系图： 配置分类 所有配置项分为三大类。 服务发现：表示该配置项用于服务的注册与发现，目的是让消费方找到提供方。 服务治理：表示该配置项用于治理服务间的关系，或为开发测试提供便利条件。 性能调优：表示该配置项用于调优性能，不同的选项对性能会产生影响。dubbo 配置的一些套路: 先来看一个简单配置 通过字面了解 timeout即服务的执行超时时间。但当服务执行真正超时的时候 报的错跟timeout并没有半毛钱的关系，其异常堆栈如下： 可以看到错误表达的意思是 因为Channel 关闭导致 无法返回 Response 消息。 出现这情况的原因在于 虽然timeout 配置在服务端去是用在客户端，其表示的是客户端调用超时间，而非服务端方法的执行超时。当我们去看客户端的日志时候就能看到timeout异常了 类似这种配在服务端用在客户端的配置还有很多，如retries/riː'traɪ/(重试次数)、async/əˈsɪŋk/（是否异步）、loadbalance(负载均衡)。。。等。 套路一：*服务端配置客户端来使用*。 注：其参数传递机制是 服务端所有配置都会封装到URL参数，在通过注册中心传递到客户端 如果需要暴露多个服务的时候，每个服务都要设置其超时时间，貌似有点繁琐。Dubbo中可以通过 来实现服务端缺省配置。它可以同时为 和 两个标签提供缺省配置。如： #相当于每个服务提供者设置了超时时间 和重试次数 同样客户端也有缺省配置标签：，这些缺省设置可以配置多个 通过 ,如果没指定就用第一个。 、 套路二：与 ，与傻傻分不清楚 在服务端配置timeout 之后 所有客户端都会采用该方超时时间，其客户端可以自定义超时时间吗？通过 可以设定或者在 也可以设定 甚至可以设定到方法级别 。加上服务端的配置，超时总共有6处可以配置。如果6处都配置了不同的值，最后肯定只会有一个超时值生效，其优先级如下： 小提示：通过DefaultFuture的get 方法就可观测到实际的超时设置。 com.alibaba.dubbo.remoting.exchange.support.DefaultFuture 套路三：同一属性到处配置，优先级要小心。 一般建议配置示例： 提供端：--------------------------- 消费端示例：-------------------- Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/dubbo/dubbo-high-use.html":{"url":"distributed/dubbo/dubbo-high-use.html","title":"3.Dubbo企业级应用进阶","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、分布式项目开发与联调 接口暴露与引用 自动化构建与协作 接口平滑升级： 开发联调： 二、Dubbo控制管理后台使用 Dubbo 控制后台版本说明： Dubbo 控制后台的安装： 三、Dubbo注册中心详解 注册中心的作用 Dubbo所支持的注册中心 Redis 注册中心 Zookeeper 注册中心 课程概要： 分布式项目开发与联调 控制管理后台使用 Dubbo注册中心详解 一、分布式项目开发与联调 接口暴露与引用 在一个RPC场景中 ，调用方是通过接口来调用服务端，传入参数并获得返回结果。这样服务端的接口和模型必须暴露给调用方项目。服务端如何暴露呢？客户端如何引用呢？ 接口信息 、模型信息 、异常 暴露接口的通常做法是 接口与实现分离，服务端将 接口、模型、异常 等统一放置于一个模块，实现置于另一个模块。调用方通过Maven进行引用。 自动化构建与协作 当项目越来越多，服务依懒关系越发复杂的时候，为了提高协作效率，必须采用自动化工具 完成 接口从编写到构建成JAR包，最后到引用的整个过程。 流程描述： 服务提供者项目发人员编写Client 接口 push 至远程仓库 jenkins 构建指定版本 jenkins Deploye 至私服仓库 nexus 服务消费者项目开发人员基于maven 从私服务仓库下载接口平滑升级： 在项目迭代过程当中， 经常会有多个项目依懒同一个接口，如下图 项目B、C都依懒了项目A当中的接口1，此时项目B业务需要，需要接口1多增加一个参数，升级完成后。项目B能正确构建上线，项目C却不行。 解决办法与原则： 接口要做到向下兼容：接口参数尽量以对象形式进行封装。Model属性只增不删，如果需要作废，可以添加@Deprecated 标识。 如果出现了不可兼容的变更，则必须通知调用方整改，并制定上线计划。 开发联调： 在项目开发过程当中，一个开发或测试环境的注册中心很有可能会同时承载着多个服务，如果两组服务正在联调，如何保证调用的是目标服务呢？ 1、基于临时分组联调 group 分组 在reference 和server 当中采用相同的临时组 ,通过group 进行设置 2、直连提供者： 在reference 中指定提供者的url即可做到直连 3、只注册： 一个项目有可能同是为即是服务提供者又消费者，在测试时需要调用某一服务同时又不希望正在开发的服务影响到其它订阅者如何实现？ 通过修改 register=false 即可实现 二、Dubbo控制管理后台使用 Dubbo 控制后台版本说明： dubbo 在2.6.0 以前 使用dubbo-admin 作为管理后台，2.6 以后已经去掉dubbo-admin 并采用 incubator-dubbo-ops 作为新的管理后台，目前该后台还在开发中还没有发布正式的版本 ，所以本节课还是采用的旧版的dubbo-admin 来演示。 Dubbo 控制后台的安装： #从github 中下载dubbo 项目 git clone https://github.com/apache/incubator-dubbo.git #更新项目 git fetch #临时切换至 dubbo-2.5.8 版本 git checkout dubbo-2.5.8 #进入 dubbo-admin 目录 cd dubbo-admin #mvn 构建admin war 包 mvn clean pakcage -DskipTests #得到 dubbo-admin-2.5.8.war 即可直接部署至Tomcat #修改 dubbo.properties 配置文件 dubbo.registry.address=zookeeper://127.0.0.1:2181 注：如果实在懒的构建 可直接下载已构建好的： 链接：https://pan.baidu.com/s/1zJFNPgwNVgZZ-xobAfi5eQ 提取码：gjtv 控制后台基本功能介绍 ： 服务查找： 服务关系查看: 服务权重调配： 服务路由： 服务禁用 三、Dubbo注册中心详解 注册中心的作用 为了到达服务集群动态扩容的目的，注册中心存储了服务的地址信息与可用状态信息，并实时推送给订阅了相关服务的客户端。 一个完整的注册中心需要实现以下功能： 接收服务端的注册与客户端的引用，即将引用与消费建立关联，并支持多对多。 当服务非正常关闭时能即时清除其状态 当注册中心重启时，能自动恢复注册数据，以及订阅请求 注册中心本身的集群 Dubbo所支持的注册中心 Multicast 注册中心 基于组网广播技术，只能用在局域网内，一般用于简单的测试服务 Zookeeper 注册中心(**推荐**) Zookeeper 是 Apacahe Hadoop 的子项目，是一个树型的目录服务，支持变更推送，适合作为 Dubbo 服务的注册中心，工业强度较高，可用于生产环境，并推荐使用 Redis 注册中心 基于Redis的注册中心 Simple 注册中心 基于本身的Dubbo服务实现（SimpleRegistryService），不支持集群可作为自定义注册中心的参考，但不适合直接用于生产环境。 Redis 注册中心 关于Redis注册中心我们需要了解两点， 如何存储服务的注册与订阅关系 是当服务状态改变时如何即时更新 演示使用Redis 做为注册中心的使用。 [ ] 启动Redis服务 [ ] 服务端配置注册中心 [ ] 启动两个服务端 [ ] 通过RedisClient 客户端观察Redis中的数据 redis 注册中心配置： 当我们启动两个服务端后发现，Reids中增加了一个Hash 类型的记录，其key为/dubbo/tuling.dubbo.server.UserService/providers。Value中分别存储了两个服务提供者的URL和有效期。 同样消费者也是类似其整体结构如下： //服务提供者注册信息 /dubbbo/com.tuling.teach.service.DemoService/providers dubbo://192.168.246.1:20880/XXX.DemoService=1542619052964 dubbo://192.168.246.2:20880/XXX.DemoService=1542619052964 //服务消费订阅信息 /dubbbo/com.tuling.teach.service.DemoService/consumers dubbo://192.168.246.1:20880/XXX.DemoService=1542619788641 主 Key 为服务名和类型 Map 中的 Key 为 URL 地址 Map 中的 Value 为过期时间，用于判断脏数据，脏数据由监控中心删除 接下来回答第二个问题 当提供者突然 宕机状态能即里变更吗？ 这里Dubbo采用的是定时心跳的机制 来维护服务URL的有效期，默认每30秒更新一次有效期。即URL对应的毫秒值。具体代码参见：com.alibaba.dubbo.registry.redis.RedisRegistry#expireExecutor com.alibaba.dubbo.registry.redis.RedisRegistry#deferExpired com.alibaba.dubbo.registry.integration.RegistryDirectory com.alibaba.dubbo.registry.support.ProviderConsumerRegTable Zookeeper 注册中心 关于Zookeeper 注册中心同样需要了解其存储结构和更新机制。 Zookeper是一个树型的目录服务，本身支持变更推送相比redis的实现Publish/Subscribe功能更稳定。 结构： 失败重连 com.alibaba.dubbo.registry.support.FailbackRegistry 提供者突然断开： 基于Zookeeper 临时节点机制实现，在客户端会话超时后 Zookeeper会自动删除所有临时节点，默认为40秒。 // 创建临时节点 com.alibaba.dubbo.remoting.zookeeper.curator.CuratorZookeeperClient#createEphemeral 提问： 在zookeeper 断开的40秒内 如果 有客户端加入 会调用 已失效的提供者连接吗？ 答：不会，提供者宕机后 ，其与客户端的链接也随即断开，客户端在调用前会检测长连接状态。 // 检测连接是否有效 com.alibaba.dubbo.rpc.protocol.dubbo.DubboInvoker#isAvailable 创建 configurators与routers 会创建持久节点 // 创建持久节点 com.alibaba.dubbo.remoting.zookeeper.curator.CuratorZookeeperClient#createPersistent 服务订阅机制实现： // 注册目录 com.alibaba.dubbo.registry.integration.RegistryDirectory 源码解析： com.alibaba.dubbo.registry.integration.RegistryDirectory Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/dubbo/dubbo-module-detail.html":{"url":"distributed/dubbo/dubbo-module-detail.html","title":"2.Dubb调用模块详解","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、Dubbo 调用模块基本组成 Dubbo调用模块概述： 透明代理： 负载均衡 TODO 一至性hash 演示 容错 异步调用 过滤器 TODO 演示添加日志访问过滤: 二 、Dubbo 调用非典型使用场景 泛化提供&引用 TODO 示例演示 隐示传参 令牌验证 三、调用通信内部实现源码分析 网络传输的实现组成 Dubbo 长连接实现与配置 dubbo传输uml类图: Dubbo 传输协作线程 概要： 一、Dubbo 调用模块基本组成 二 、Dubbo 调用非典型使用场景 三、调用通信内部实现源码分析 一、Dubbo 调用模块基本组成 Dubbo调用模块概述： dubbo调用模块核心功能是发起一个远程方法的调用并顺利拿到返回结果，其体系组成如下： 透明代理：通过动态代理技术，屏蔽远程调用细节以提高编程友好性。 负载均衡：当有多个提供者是，如何选择哪个进行调用的负载算法。 容错机制：当服务调用失败时采取的策略 调用方式：支持同步调用、异步调用 透明代理： 参见源码： com.alibaba.dubbo.config.ReferenceConfig#createProxy com.alibaba.dubbo.common.bytecode.ClassGenerator com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory 负载均衡 Dubbo 目前官方支持以下负载均衡策略： 随机(random)：按权重设置随机概率。此为默认算法. 轮循 (roundrobin):按公约后的权重设置轮循比率。 最少活跃调用数(leastactive):相同活跃数的随机，活跃数指调用前后计数差。 一致性Hash(consistenthash ):相同的参数总是发到同一台机器 设置方式支持如下四种方式设置，优先级由低至高 TODO 一至性hash 演示 [ ] 配置loadbalance [ ] 配置需要hash 的参数与虚拟节点数 [ ] 发起远程调用 一至性hash 算法详解： 容错 Dubbo 官方目前支持以下容错策略： 失败自动切换：调用失败后基于retries=“2” 属性重试其它服务器 快速失败：快速失败，只发起一次调用，失败立即报错。 勿略失败：失败后勿略，不抛出异常给客户端。 失败重试：失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作 并行调用: 只要一个成功即返回，并行调用指定数量机器，可通过 forks=\"2\" 来设置最大并行数。 广播调用：广播调用所有提供者，逐个调用，任意一台报错则报错 设置方式支持如下两种方式设置，优先级由低至高 注：容错机制 在基于 API设置时无效 如 referenceConfig.setCluster(\"failback\"); 经测试不启作用 异步调用 异步调用是指发起远程调用之后获取结果的方式。 同步等待结果返回（默认） 异步等待结果返回 不需要返回结果 Dubbo 中关于异步等待结果返回的实现流程如下图： 异步调用配置: 注：在进行异步调用时 容错机制不能为 cluster=\"forking\" 或 cluster=\"broadcast\" 异步获取结果演示： [ ] 编写异步调用代码 [ ] 编写同步调用代码 [ ] 分别演示同步调用与异步调用耗时 异步调用结果获取Demo demoService.sayHello1(\"han\"); Future future1 = RpcContext.getContext().getFuture(); demoService.sayHello2(\"han2\"); Future future2 = RpcContext.getContext().getFuture(); Object r1 = null, r2 = null; // wait 直到拿到结果 获超时 r1 = future1.get(); // wait 直到拿到结果 获超时 r2 = future2.get(); 过滤器 类似于 WEB 中的Filter ，Dubbo本身提供了Filter 功能用于拦截远程方法的调用。其支持自定义过滤器与官方的过滤器使用： TODO 演示添加日志访问过滤: 以上配置 就是 为 服务提供者 添加 日志记录过滤器， 所有访问日志将会集中打印至 accesslog 当中 二 、Dubbo 调用非典型使用场景 泛化提供&引用 泛化提供 是指不通过接口的方式直接将服务暴露出去。通常用于Mock框架或服务降级框架实现。 TODO 示例演示 public static void doExportGenericService() { ApplicationConfig applicationConfig = new ApplicationConfig(); applicationConfig.setName(\"demo-provider\"); // 注册中心 RegistryConfig registryConfig = new RegistryConfig(); registryConfig.setProtocol(\"zookeeper\"); registryConfig.setAddress(\"192.168.0.147:2181\"); ProtocolConfig protocol=new ProtocolConfig(); protocol.setPort(-1); protocol.setName(\"dubbo\"); GenericService demoService = new MyGenericService(); ServiceConfig service = new ServiceConfig(); // 弱类型接口名 service.setInterface(\"com.tuling.teach.service.DemoService\"); // 指向一个通用服务实现 service.setRef(demoService); service.setApplication(applicationConfig); service.setRegistry(registryConfig); service.setProtocol(protocol); // 暴露及注册服务 service.export(); } 泛化引用 是指不通过常规接口的方式去引用服务，通常用于测试框架。 ApplicationConfig applicationConfig = new ApplicationConfig(); applicationConfig.setName(\"demo-provider\"); // 注册中心 RegistryConfig registryConfig = new RegistryConfig(); registryConfig.setProtocol(\"zookeeper\"); registryConfig.setAddress(\"192.168.0.147:2181\"); // 引用远程服务 ReferenceConfig reference = new ReferenceConfig(); // 弱类型接口名 reference.setInterface(\"com.tuling.teach.service.DemoService\"); // 声明为泛化接口 reference.setGeneric(true); reference.setApplication(applicationConfig); reference.setRegistry(registryConfig); // 用com.alibaba.dubbo.rpc.service.GenericService可以替代所有接口引用 GenericService genericService = reference.get(); Object result = genericService.$invoke(\"sayHello\", new String[]{\"java.lang.String\"}, new Object[]{\"world\"}); 隐示传参 是指通过非常方法参数传递参数，类似于http 调用当中添加cookie值。通常用于分布式追踪框架的实现。使用方式如下 ： //客户端隐示设置值 RpcContext.getContext().setAttachment(\"index\", \"1\"); // 隐式传参，后面的远程调用都会隐 //服务端隐示获取值 String index = RpcContext.getContext().getAttachment(\"index\"); 令牌验证 通过令牌验证在注册中心控制权限，以决定要不要下发令牌给消费者，可以防止消费者绕过注册中心访问提供者，另外通过注册中心可灵活改变授权方式，而不需修改或升级提供者 使用： 三、调用通信内部实现源码分析 网络传输的实现组成 IO模型： BIO 同步阻塞 NIO 同步非阻塞 AIO 异步非阻塞 连接模型： 长连接 短连接 线程分类： IO线程 服务端业务线程 客户端调度线程 客户端结果exchange线程。 保活心跳线程 重连线程 线程池模型： 固定数量线程池 缓存线程池 有限线程池Dubbo 长连接实现与配置 初始连接： 引用服务增加提供者==>获取连接===》是否获取共享连接==>创建连接客户端==》开启心跳检测状态检查定时任务===》开启连接状态检测 源码见：com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol#getClients 心跳发送： 在创建一个连接客户端同时也会创建一个心跳客户端，客户端默认基于60秒发送一次心跳来保持连接的存活，可通过 heartbeat 设置。 源码见：com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeClient#startHeatbeatTimer 断线重连： 每创建一个客户端连接都会启动一个定时任务每两秒中检测一次当前连接状态，如果断线则自动重连。 源码见：com.alibaba.dubbo.remoting.transport.AbstractClient#initConnectStatusCheckCommand 连接销毁: 基于注册中心通知，服务端断开后销毁 源码见：com.alibaba.dubbo.remoting.transport.AbstractClient#close() dubbo传输uml类图: Dubbo 传输协作线程 客户端调度线程：用于发起远程方法调用的线程。 客户端结果**Exchange**线程：当远程方法返回response后由该线程填充至指定ResponseFuture，并叫醒等待的调度线程。 客户端IO线程：由传输框架实现，用于request 消息流发送、response 消息流读取与解码等操作。 服务端IO线程：由传输框架实现，用于request消息流读取与解码 与Response发送。 业务执行线程：服务端具体执行业务方法的线程 客户端线程协作流程： 调度线程 调用远程方法 对request 进行协议编码 发送request 消息至IO线程 等待结果的获取 IO线程 读取response流 response 解码 提交Exchange 任务 Exchange线程 填写response值 至 ResponseFuture 唤醒调度线程，通知其获取结果 调用调试： 客户端的执行线程: 1、业务线程 1) DubboInvoker#doInvoke(隐示传公共参数、获取客户端、异步、单向、同步（等待返回结果）) 2)AbstractPeer#send// netty Client客户端发送消息 写入管道 3)DubboCodec#encodeRequestData // Request 协议编码 2、IO线程 DubboCodec#decodeBody //Response解码 AllChannelHandler#received //// 派发消息处理线程 3、调度线程 DefaultFuture#doReceived // 设置返回结果 服务端线程协作： IO线程： request 流读取 request 解码 提交业务处理任务 业务线程： 业务方法执行 response 编码 回写结果至channel 线程池 fixed：固定线程池,此线程池启动时即创建固定大小的线程数，不做任何伸缩， cached：缓存线程池,此线程池可伸缩，线程空闲一分钟后回收，新请求重新创建线程 Limited：有限线程池,此线程池一直增长，直到上限，增长后不收缩。 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/dubbo/dubbo-proto-detail.html":{"url":"distributed/dubbo/dubbo-proto-detail.html","title":"3.Dubbo协议模块源码剖析","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 RPC协议基本组成 RPC 协议名词解释 协议基本组成： Dubbo中所支持RPC协议使用 协议的使用与配置: TODO 演示采用其它协议来配置Dubbo Hessian 序列化： 三 、RPC协议报文编码与实现详解 RPC 传输实现： 拆包与粘包产生的原因： 拆包与粘包解决办法： Dubbo 协议报文编码： Dubbo协议的编解码过程： 主讲：鲁班 时间：2018/12/2 8:10 地址：腾讯课堂图灵学院 课程概要： RPC协议基本组成 RPC协议报文编码与实现详解 Dubbo中所支持RPC协议与使用 RPC协议基本组成 RPC 协议名词解释 在一个典型RPC的使用场景中，包含了服务发现、负载、容错、网络传输、序列化等组件，其中RPC协议就指明了程序如何进行网络传输和序列化 。也就是说一个RPC协议的实现就等于一个非透明的远程调用实现，如何做到的的呢？ 协议基本组成： 地址：服务提供者地址 端口：协议指定开放的端口 报文编码：协议报文编码 ，分为请求头和请求体两部分。 序列化方式：将请求体序列化成对象 Hessian2Serialization、 DubboSerialization、 JavaSerialization JsonSerialization 运行服务: 网络传输实现 netty mina RMI 服务 servlet 容器（jetty、Tomcat、Jboss） Dubbo中所支持RPC协议使用 dubbo 支持的RPC协议列表 | 名称 | 实现描述 | 连接描述 | 适用场景 | |:----|:----|:----|:----| | dubbo | 传输服务: mina, netty(默认), grizzy序列化: hessian2(默认), java, fastjson自定义报文 | 单个长连接NIO异步传输 | 1、常规RPC调用2、传输数据量小3、提供者少于消费者 | | rmi | 传输：java rmi 服务序列化：java原生二进制序列化 | 多个短连接BIO同步传输 | 1、常规RPC调用2、与原RMI客户端集成3、可传少量文件4、不支持防火墙穿透 | | hessian | 传输服务：servlet容器序列化：hessian二进制序列化 | 基于Http 协议传输，依懒servlet容器配置 | 1、提供者多于消费者2、可传大字段和文件3、跨语言调用 | | http | 传输服务：servlet容器序列化：java原生二进制序列化 | 依懒servlet容器配置 | 1、数据包大小混合 | | thrift | 与thrift RPC 实现集成，并在其基础上修改了报文头 | 长连接、NIO异步传输 | | 关于RMI不支持防火墙穿透的补充说明： 原因在于RMI 底层实现中会有两个端口，一个是固定的用于服务发现的注册端口，另外会生成一个随机端口用于网络传输。因为这个随机端口就不能在防火墙中提前设置开放开。所以存在防火墙穿透问题 协议的使用与配置: Dubbo框架配置协议非常方便，用户只需要在 provider 应用中 配置 元素即可。 TODO 演示采用其它协议来配置Dubbo [ ] dubbo 协议采用 json 进行序列化 (源码参见：com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol) [ ] 采用RMI协议 (源码参见：com.alibaba.dubbo.rpc.protocol.rmi.RmiProtocol) [ ] 采用Http协议 (源码参见：com.alibaba.dubbo.rpc.protocol.http.HttpProtocol.InternalHandler) [ ] 采用Heason协议 (源码参见:com.alibaba.dubbo.rpc.protocol.hessian.HessianProtocol.HessianHandler) netstat -aon|findstr \"17732\" 序列化： | | 特点 | |:----|:----| | fastjson | 文本型：体积较大，性能慢、跨语言、可读性高 | | fst | 二进制型：体积小、兼容 JDK 原生的序列化。要求 JDK 1.7 支持。 | | hessian2 | 二进制型：跨语言、容错性高、体积小 | | java | 二进制型：在JAVA原生的基础上 可以写入Null | | compactedjava | 二进制型：与java 类似，内容做了压缩 | | nativejava | 二进制型：原生的JAVA 序列化 | | kryo | 二进制型：体积比hessian2 还要小，但容错性 没有hessian2 好 | Hessian 序列化： 参数及返回值需实现 Serializable 接口 参数及返回值不能自定义实现 List, Map, Number, Date, Calendar 等接口，只能用 JDK 自带的实现，因为 hessian 会做特殊处理，自定义实现类中的属性值都会丢失。 Hessian 序列化，只传成员属性值和值的类型，不传方法或静态变量，兼容情况 [1][2]： | 数据通讯 | 情况 | 结果 | |:----|:----|:----| | A->B | 类A多一种 属性（或者说类B少一种 属性） | 不抛异常，A多的那 个属性的值，B没有， 其他正常 | | A->B | 枚举A多一种 枚举（或者说B少一种 枚举），A使用多 出来的枚举进行传输 | 抛异常 | | A->B | 枚举A多一种 枚举（或者说B少一种 枚举），A不使用 多出来的枚举进行传输 | 不抛异常，B正常接 收数据 | | A->B | A和B的属性 名相同，但类型不相同 | 抛异常 | | A->B | serialId 不相同 | 正常传输 | 接口增加方法，对客户端无影响，如果该方法不是客户端需要的，客户端不需要重新部署。输入参数和结果集中增加属性，对客户端无影响，如果客户端并不需要新属性，不用重新部署。 输入参数和结果集属性名变化，对客户端序列化无影响，但是如果客户端不重新部署，不管输入还是输出，属性名变化的属性值是获取不到的。 总结：服务器端和客户端对领域对象并不需要完全一致，而是按照最大匹配原则。 [ ] 演示Hession2 序列化的容错性 三 、RPC协议报文编码与实现详解 RPC 传输实现： RPC的协议的传输是基于 TCP/IP 做为基础使用Socket 或Netty、mina等网络编程组件实现。但有个问题是TCP是面向字节流的无边边界协议，其只管负责数据传输并不会区分每次请求所对应的消息，这样就会出现TCP协义传输当中的拆包与粘包问题 拆包与粘包产生的原因： 我们知道tcp是以流动的方式传输数据，传输的最小单位为一个报文段（segment）。tcp Header中有个Options标识位，常见的标识为mss(Maximum Segment Size)指的是，连接层每次传输的数据有个最大限制MTU(Maximum Transmission Unit)，一般是1500比特，超过这个量要分成多个报文段，mss则是这个最大限制减去TCP的header，光是要传输的数据的大小，一般为1460比特。换算成字节，也就是180多字节。 tcp为提高性能，发送端会将需要发送的数据发送到缓冲区，等待缓冲区满了之后，再将缓冲中的数据发送到接收方。同理，接收方也有缓冲区这样的机制，来接收数据。这时就会出现以下情况： 应用程序写入的数据大于MSS大小，这将会发生拆包。 应用程序写入数据小于MSS大小，这将会发生粘包。 接收方法不及时读取套接字缓冲区数据，这将发生粘包。拆包与粘包解决办法： 设置定长消息，服务端每次读取既定长度的内容作为一条完整消息。 {\"type\":\"message\",\"content\":\"hello\"}\\n 使用带消息头的协议、消息头存储消息开始标识及消息长度信息，服务端获取消息头的时候解析出消息长度，然后向后读取该长度的内容。 比如：Http协议 heade 中的 Content-Length 就表示消息体的大小。 (注①：http 报文编码) Dubbo 协议报文编码： 注②Dubbo 协议报文编码： | | 0-7 | 8-15 | 16-20 | 21 | 22 | 23 | 24-31 | | |:----|:----|:----|:----|:----|:----|:----|:----|:----| | | | 1 | 1 | | | | | | | 32-95 | | | | | | | | | | 96-127 | | | | | | | | | magic：类似java字节码文件里的魔数，用来判断是不是dubbo协议的数据包。魔数是常量0xdabb,用于判断报文的开始。 flag：标志位, 一共8个地址位。低四位用来表示消息体数据用的序列化工具的类型（默认hessian），高四位中，第一位为1表示是request请求，第二位为1表示双向传输（即有返回response），第三位为1表示是心跳ping事件。 status：状态位, 设置请求响应状态，dubbo定义了一些响应的类型。具体类型见 com.alibaba.dubbo.remoting.exchange.Response invoke id：消息id, long 类型。每一个请求的唯一识别id（由于采用异步通讯的方式，用来把请求request和返回的response对应上） body length：消息体 body 长度, int 类型，即记录Body Content有多少个字节。 （注：相关源码参见 com.alibaba.dubbo.rpc.protocol.dubbo.DubboCodec**） Dubbo协议的编解码过程： Dubbo 协议编解码实现过程 (源码来源于**dubbo2.5.8 ) 1、DubboCodec.encodeRequestData() 116L // 编码request 2、DecodeableRpcInvocation.decode() 89L // 解码request 3、DubboCodec.encodeResponseData() 184L // 编码response 4、DecodeableRpcResult.decode() 73L // 解码response Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/rocketmq/":{"url":"distributed/rocketmq/","title":"rocketmq","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/rocketmq/shell.html":{"url":"distributed/rocketmq/shell.html","title":"1.启停脚本","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 ! /bin/bash #! /bin/bash case $1 in \"start\"){ for i in hadoop101 hadoop102 hadoop103 do echo \" --------启动 $i Kafka-------\" # 用于KafkaManager监控 ssh $i \"export JMX_PORT=9988 && /usr/local/software/kafka_2.12-2.6.0/bin/kafka-server-start.sh -daemon /usr/local/software/kafka_2.12-2.6.0/config/server.properties \" done };; \"stop\"){ for i in hadoop101 hadoop102 hadoop103 do echo \" --------停止 $i Kafka-------\" ssh $i \"/usr/local/software/kafka_2.12-2.6.0/bin/kafka-server-stop.sh stop\" done };; esac Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:36:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/rocketmq/rocketmq.html":{"url":"distributed/rocketmq/rocketmq.html","title":"2.分布式之RockeqMq","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.概述 1.1 简介 1.2 特点 1.3 场景 1.4 架构 1.5 工作原理 2.环境搭建 2.1 版本 2.2 主机规划 2.3 下载 2.4 单机启动 2.4.1启动NameServer 2.4.2启动Broker 2.4.3测试RocketMQ 2.5集群部署 2.5.1服务器环境 2.5.2 Host添加信息 2.5.3 防火墙配置 2.5.4环境变量配置 2.5.5 创建消息存储路径 2.5.6broker配置文件 1）master1 2）slave2 3）master2 4）slave1 2.5.7 修改启动脚本文件 1）runbroker.sh 2）runserver.sh 2.5.8 服务启动 1）启动NameServe集群 2）启动Broker集群 2.5.9 查看进程状态 2.5.10 查看日志 3.快速入门 3.1 普通消息 3.2 定时消息 3.3 顺序消息 3.4 事务消息 4.深入了解 4.1Consumer端 4.1.1消费模型 4.1.2消费选择 4.1.3消息重复幂等： 4.1.4消息过滤： 4.2Namesrv端 4.3Broker端 5.优化 5.1 5.2 5.3 1.概述 1.1 简介 1.2 特点 1.3 场景 解耦 异步 肖锋1.4 架构 1.5 工作原理 2.环境搭建 2.1 版本 组件 版本 备注 centos 64 位 7.x 以上 jdk 1.8 rocketmq 4.x 2.2 主机规划 ip host 安装软件 192.168.62.130 hadoop102 rocketmq jdk 192.168.62.131 hadoop103 rocketmq jdk 2.3 下载 https://github.com/apache/rocketmq/ 2.4 单机启动 2.4.1启动NameServer # 1.启动NameServer nohup sh bin/mqnamesrv & # 2.查看启动日志 tail -f ~/logs/rocketmqlogs/namesrv.log 2.4.2启动Broker # 1.启动Broker nohup sh bin/mqbroker -n localhost:9876 & # 2.查看启动日志 tail -f ~/logs/rocketmqlogs/broker.log 问题描述： RocketMQ默认的虚拟机内存较大，启动Broker如果因为内存不足失败，需要编辑如下两个配置文件，修改JVM内存大小# 编辑runbroker.sh和runserver.sh修改默认JVM大小 vi runbroker.sh vi runserver.sh 参考设置： JAVA_OPT=\"${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m\" 2.4.3测试RocketMQ 发送消息 # 1.设置环境变量 export NAMESRV_ADDR=localhost:9876 # 2.使用安装包的Demo发送消息 sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer 接收消息 # 1.设置环境变量 export NAMESRV_ADDR=localhost:9876 # 2.接收消息 sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer 关闭RocketMQ # 1.关闭NameServer sh bin/mqshutdown namesrv # 2.关闭Broker sh bin/mqshutdown broker 2.5集群部署 2.5.1服务器环境 序号 IP 角色 架构模式 1 192.168.62.130 nameserver、brokerserver Master1、Slave2 2 192.168.62.131 nameserver、brokerserver Master2、Slave1 2.5.2 Host添加信息 vim /etc/hosts 配置如下: # nameserver 192.168.62.130 rocketmq-nameserver1 192.168.62.131 rocketmq-nameserver2 # broker 192.168.62.130 rocketmq-master1 192.168.62.130 rocketmq-slave2 192.168.62.131 rocketmq-master2 192.168.62.131 rocketmq-slave1 # nameserver sudo echo '192.168.62.130 rocketmq-nameserver1' >>/etc/hosts echo '192.168.62.131 rocketmq-nameserver2' >>/etc/hosts # broker echo '192.168.62.130 rocketmq-master1' >>/etc/hosts echo '192.168.62.130 rocketmq-slave2' >>/etc/hosts echo '192.168.62.131 rocketmq-master2' >>/etc/hosts echo '192.168.62.131 rocketmq-slave1' >>/etc/hosts 配置完成后, 重启网卡 systemctl restart network 2.5.3 防火墙配置 宿主机需要远程访问虚拟机的rocketmq服务和web服务，需要开放相关的端口号，简单粗暴的方式是直接关闭防火墙 # 关闭防火墙 systemctl stop firewalld.service # 查看防火墙的状态 firewall-cmd --state # 禁止firewall开机启动 systemctl disable firewalld.service 或者为了安全，只开放特定的端口号，RocketMQ默认使用3个端口：9876 、10911 、11011 。如果防火墙没有关闭的话，那么防火墙就必须开放这些端口： nameserver默认使用 9876 端口 master默认使用 10911 端口 slave默认使用11011 端口 执行以下命令： # 开放name server默认端口 firewall-cmd --remove-port=9876/tcp --permanent # 开放master默认端口 firewall-cmd --remove-port=10911/tcp --permanent # 开放slave默认端口 (当前集群模式可不开启) firewall-cmd --remove-port=11011/tcp --permanent # 重启防火墙 firewall-cmd --reload 2.5.4环境变量配置 vim /etc/profile 在profile文件的末尾加入如下命令 #set rocketmq ROCKETMQ_HOME=/usr/local/software/rocketmq PATH=$PATH:$ROCKETMQ_HOME/bin export ROCKETMQ_HOME PATH #set rocketmq echo 'ROCKETMQ_HOME=/usr/local/rocketmq/rocketmq-all-4.4.0-bin-release' >>/etc/profile echo 'PATH=$PATH:$ROCKETMQ_HOME/bin' >>/etc/profile echo 'export ROCKETMQ_HOME PATH' >>/etc/profile 输入:wq! 保存并退出， 并使得配置立刻生效： source /etc/profile 2.5.5 创建消息存储路径 sudo mkdir -p /usr/local/rocketmq/store sudo mkdir -p /usr/local/rocketmq/store/commitlog sudo mkdir -p /usr/local/rocketmq/store/consumequeue sudo mkdir -p /usr/local/rocketmq/store/index sudo mkdir -p /usr/local/rocketmqs/store sudo mkdir -p /usr/local/rocketmqs/store/commitlog sudo mkdir -p /usr/local/rocketmqs/store/consumequeue sudo mkdir -p /usr/local/rocketmqs/store/index 2.5.6broker配置文件 1）master1 服务器：192.168.62.130 vim /usr/local/software/rocketmq/conf/2m-2s-sync/broker-a.properties 修改配置如下： #所属集群名字 brokerClusterName=rocketmq-cluster #broker名字，注意此处不同的配置文件填写的不一样 brokerName=broker-a #0 表示 Master，>0 表示 Slave brokerId=0 #nameServer地址，分号分割 namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876 #在发送消息时，自动创建服务器不存在的topic，默认创建的队列数 defaultTopicQueueNums=4 #是否允许 Broker 自动创建Topic，建议线下开启，线上关闭 autoCreateTopicEnable=true #是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭 autoCreateSubscriptionGroup=true #Broker 对外服务的监听端口 listenPort=10911 #删除文件时间点，默认凌晨 4点 deleteWhen=04 #文件保留时间，默认 48 小时 fileReservedTime=120 #commitLog每个文件的大小默认1G mapedFileSizeCommitLog=1073741824 #ConsumeQueue每个文件默认存30W条，根据业务情况调整 mapedFileSizeConsumeQueue=300000 #destroyMapedFileIntervalForcibly=120000 #redeleteHangedFileInterval=120000 #检测物理文件磁盘空间 diskMaxUsedSpaceRatio=88 #存储路径 storePathRootDir=/usr/local/rocketmq/store #commitLog 存储路径 storePathCommitLog=/usr/local/rocketmq/store/commitlog #消费队列存储路径存储路径 storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue #消息索引存储路径 storePathIndex=/usr/local/rocketmq/store/index #checkpoint 文件存储路径 storeCheckpoint=/usr/local/rocketmq/store/checkpoint #abort 文件存储路径 abortFile=/usr/local/rocketmq/store/abort #限制的消息大小 maxMessageSize=65536 #flushCommitLogLeastPages=4 #flushConsumeQueueLeastPages=2 #flushCommitLogThoroughInterval=10000 #flushConsumeQueueThoroughInterval=60000 #Broker 的角色 #- ASYNC_MASTER 异步复制Master #- SYNC_MASTER 同步双写Master #- SLAVE brokerRole=SYNC_MASTER #刷盘方式 #- ASYNC_FLUSH 异步刷盘 #- SYNC_FLUSH 同步刷盘 flushDiskType=SYNC_FLUSH #checkTransactionMessageEnable=false #发消息线程池数量 #sendMessageThreadPoolNums=128 #拉消息线程池数量 #pullMessageThreadPoolNums=128 2）slave2 服务器：192.168.62.130 vim /usr/local/software/rocketmq/conf/2m-2s-sync/broker-b-s.properties 修改配置如下： #所属集群名字 brokerClusterName=rocketmq-cluster #broker名字，注意此处不同的配置文件填写的不一样 brokerName=broker-b #0 表示 Master，>0 表示 Slave brokerId=1 #nameServer地址，分号分割 namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876 #在发送消息时，自动创建服务器不存在的topic，默认创建的队列数 defaultTopicQueueNums=4 #是否允许 Broker 自动创建Topic，建议线下开启，线上关闭 autoCreateTopicEnable=true #是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭 autoCreateSubscriptionGroup=true #Broker 对外服务的监听端口 listenPort=11011 #删除文件时间点，默认凌晨 4点 deleteWhen=04 #文件保留时间，默认 48 小时 fileReservedTime=120 #commitLog每个文件的大小默认1G mapedFileSizeCommitLog=1073741824 #ConsumeQueue每个文件默认存30W条，根据业务情况调整 mapedFileSizeConsumeQueue=300000 #destroyMapedFileIntervalForcibly=120000 #redeleteHangedFileInterval=120000 #检测物理文件磁盘空间 diskMaxUsedSpaceRatio=88 #存储路径 storePathRootDir=/usr/local/rocketmqs/store #commitLog 存储路径 storePathCommitLog=/usr/local/rocketmqs/store/commitlog #消费队列存储路径存储路径 storePathConsumeQueue=/usr/local/rocketmqs/store/consumequeue #消息索引存储路径 storePathIndex=/usr/local/rocketmqs/store/index #checkpoint 文件存储路径 storeCheckpoint=/usr/local/rocketmqs/store/checkpoint #abort 文件存储路径 abortFile=/usr/local/rocketmqs/store/abort #限制的消息大小 maxMessageSize=65536 #flushCommitLogLeastPages=4 #flushConsumeQueueLeastPages=2 #flushCommitLogThoroughInterval=10000 #flushConsumeQueueThoroughInterval=60000 #Broker 的角色 #- ASYNC_MASTER 异步复制Master #- SYNC_MASTER 同步双写Master #- SLAVE brokerRole=SLAVE #刷盘方式 #- ASYNC_FLUSH 异步刷盘 #- SYNC_FLUSH 同步刷盘 flushDiskType=ASYNC_FLUSH #checkTransactionMessageEnable=false #发消息线程池数量 #sendMessageThreadPoolNums=128 #拉消息线程池数量 #pullMessageThreadPoolNums=128 3）master2 服务器：192.168.62.131 vim /usr/local/software/rocketmq/conf/2m-2s-sync/broker-b.properties 修改配置如下： #所属集群名字 brokerClusterName=rocketmq-cluster #broker名字，注意此处不同的配置文件填写的不一样 brokerName=broker-b #0 表示 Master，>0 表示 Slave brokerId=0 #nameServer地址，分号分割 namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876 #在发送消息时，自动创建服务器不存在的topic，默认创建的队列数 defaultTopicQueueNums=4 #是否允许 Broker 自动创建Topic，建议线下开启，线上关闭 autoCreateTopicEnable=true #是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭 autoCreateSubscriptionGroup=true #Broker 对外服务的监听端口 listenPort=10911 #删除文件时间点，默认凌晨 4点 deleteWhen=04 #文件保留时间，默认 48 小时 fileReservedTime=120 #commitLog每个文件的大小默认1G mapedFileSizeCommitLog=1073741824 #ConsumeQueue每个文件默认存30W条，根据业务情况调整 mapedFileSizeConsumeQueue=300000 #destroyMapedFileIntervalForcibly=120000 #redeleteHangedFileInterval=120000 #检测物理文件磁盘空间 diskMaxUsedSpaceRatio=88 #存储路径 storePathRootDir=/usr/local/rocketmq/store #commitLog 存储路径 storePathCommitLog=/usr/local/rocketmq/store/commitlog #消费队列存储路径存储路径 storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue #消息索引存储路径 storePathIndex=/usr/local/rocketmq/store/index #checkpoint 文件存储路径 storeCheckpoint=/usr/local/rocketmq/store/checkpoint #abort 文件存储路径 abortFile=/usr/local/rocketmq/store/abort #限制的消息大小 maxMessageSize=65536 #flushCommitLogLeastPages=4 #flushConsumeQueueLeastPages=2 #flushCommitLogThoroughInterval=10000 #flushConsumeQueueThoroughInterval=60000 #Broker 的角色 #- ASYNC_MASTER 异步复制Master #- SYNC_MASTER 同步双写Master #- SLAVE brokerRole=SYNC_MASTER #刷盘方式 #- ASYNC_FLUSH 异步刷盘 #- SYNC_FLUSH 同步刷盘 flushDiskType=SYNC_FLUSH #checkTransactionMessageEnable=false #发消息线程池数量 #sendMessageThreadPoolNums=128 #拉消息线程池数量 #pullMessageThreadPoolNums=128 4）slave1 服务器：192.168.62.131 vim /usr/local/software/rocketmq/conf/2m-2s-sync/broker-a-s.properties 修改配置如下： #所属集群名字 brokerClusterName=rocketmq-cluster #broker名字，注意此处不同的配置文件填写的不一样 brokerName=broker-a #0 表示 Master，>0 表示 Slave brokerId=1 #nameServer地址，分号分割 namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876 #在发送消息时，自动创建服务器不存在的topic，默认创建的队列数 defaultTopicQueueNums=4 #是否允许 Broker 自动创建Topic，建议线下开启，线上关闭 autoCreateTopicEnable=true #是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭 autoCreateSubscriptionGroup=true #Broker 对外服务的监听端口 listenPort=11011 #删除文件时间点，默认凌晨 4点 deleteWhen=04 #文件保留时间，默认 48 小时 fileReservedTime=120 #commitLog每个文件的大小默认1G mapedFileSizeCommitLog=1073741824 #ConsumeQueue每个文件默认存30W条，根据业务情况调整 mapedFileSizeConsumeQueue=300000 #destroyMapedFileIntervalForcibly=120000 #redeleteHangedFileInterval=120000 #检测物理文件磁盘空间 diskMaxUsedSpaceRatio=88 #存储路径 storePathRootDir=/usr/local/rocketmqs/store #commitLog 存储路径 storePathCommitLog=/usr/local/rocketmqs/store/commitlog #消费队列存储路径存储路径 storePathConsumeQueue=/usr/local/rocketmqs/store/consumequeue #消息索引存储路径 storePathIndex=/usr/local/rocketmqs/store/index #checkpoint 文件存储路径 storeCheckpoint=/usr/local/rocketmqs/store/checkpoint #abort 文件存储路径 abortFile=/usr/local/rocketmqs/store/abort #限制的消息大小 maxMessageSize=65536 #flushCommitLogLeastPages=4 #flushConsumeQueueLeastPages=2 #flushCommitLogThoroughInterval=10000 #flushConsumeQueueThoroughInterval=60000 #Broker 的角色 #- ASYNC_MASTER 异步复制Master #- SYNC_MASTER 同步双写Master #- SLAVE brokerRole=SLAVE #刷盘方式 #- ASYNC_FLUSH 异步刷盘 #- SYNC_FLUSH 同步刷盘 flushDiskType=ASYNC_FLUSH #checkTransactionMessageEnable=false #发消息线程池数量 #sendMessageThreadPoolNums=128 #拉消息线程池数量 #pullMessageThreadPoolNums=128 2.5.7 修改启动脚本文件 1）runbroker.sh vim /usr/local/software/rocketmq/bin/runbroker.sh 需要根据内存大小进行适当的对JVM参数进行调整： #=================================================== # 开发环境配置 JVM Configuration JAVA_OPT=\"${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m\" 2）runserver.sh vim /usr/local/software/rocketmq/bin/runserver.sh JAVA_OPT=\"${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m\" 2.5.8 服务启动 1）启动NameServe集群 分别在192.168.25.135和192.168.25.138启动NameServer cd /usr/local/software/rocketmq/bin nohup sh mqnamesrv & 2）启动Broker集群 在192.168.62.130上启动master1和slave2 master1： cd /usr/local/software/rocketmq/bin nohup sh mqbroker -c /usr/local/software/rocketmq/conf/2m-2s-sync/broker-a.properties & slave2： cd /usr/local/software/rocketmq/bin nohup sh mqbroker -c /usr/local/software/rocketmq/conf/2m-2s-sync/broker-b-s.properties & 在192.168.62.131上启动master2和slave2 master2 cd /usr/local/software/rocketmq/bin nohup sh mqbroker -c /usr/local/software/rocketmq/conf/2m-2s-sync/broker-b.properties & slave1 /usr/local/software/rocketmq/bin nohup sh mqbroker -c /usr/local/software/rocketmq/conf/2m-2s-sync/broker-a-s.properties & 2.5.9 查看进程状态 启动后通过JPS查看启动进程 2.5.10 查看日志 # 查看nameServer日志 tail -500f ~/logs/rocketmqlogs/namesrv.log # 查看broker日志 tail -500f ~/logs/rocketmqlogs/broker.log 3.快速入门 3.1 普通消息 3.2 定时消息 3.3 顺序消息 3.4 事务消息 4.深入了解 4.1Consumer端 RocketMQ提供了两种消费模式：PUSH（pull进行监听）和PULL（长轮训） Push 方式：rocketmq 已经提供了很全面的实现， consumer 通过长轮询拉取消息后回调 MessageListener 接口实现完成消费， 应用系统只要 MessageListener 完成业务逻辑即可 Pull 方式：完全由业务系统去控制，定时拉取消息，指定队列消费等等， 当然这里需要业务系统 根据自己的业务需求去实现。 这两种模式分别对应的是DefaultMQPushConsumer类和DefaultMQPullConsumer类 org.apache.rocketmq.client.impl.consumer.PullMessageService#run 4.1.1消费模型 org.apache.rocketmq.common.protocol.heartbeat.MessageModel#BROADCASTING org.apache.rocketmq.common.protocol.heartbeat.MessageModel#CLUSTERING 4.1.2消费选择 org.apache.rocketmq.common.consumer.ConsumeFromWhere#CONSUME_FROM_LAST_OFFSET 第一次启动从队列最后位置消费，后续再启动接着上次消费的进度开始消费 org.apache.rocketmq.common.consumer.ConsumeFromWhere#CONSUME_FROM_FIRST_OFFSET 第一次启动从队列初始位置消费，后续再启动接着上次消费的进度开始消费 org.apache.rocketmq.common.consumer.ConsumeFromWhere#CONSUME_FROM_TIMESTAMP 第一次启动从指定时间点位置消费，后续再启动接着上次消费的进度开始消费 以上所说的第一次启动是指从来没有消费过的消费者，如果该消费者消费过，那么会在broker端记录该消费者的消费位置，如果该消费者挂了再启动，那么自动从上次消费的进度开始 4.1.3消息重复幂等： RocketMQ无法避免消息重复，所以如果业务对消费重复非常敏感，务必要在业务层面去重 Ps：见开发文档 接口幂等性处理 redis incr 4.1.4消息过滤： enablePropertyFilter=true Status=1 消费 status=2不需要 4.2Namesrv端 Namesrv 名称服务，是没有状态可集群横向扩展。可以理解为一个注册中心, 整个Namesrv的代码非常简单，主要包含两块功能： 1、管理一些 KV 的配置 2、管理一些 Topic、Broker的注册信息 大致提供服务为： 每个 broker 启动的时候会向 namesrv 注册 Producer 发送消息的时候根据 topic 获取路由到 broker 的信息 Consumer 根据 topic 到 namesrv 获取 topic 的路由到 broker 的信息 4.3Broker端 5.优化 5.1 5.2 5.3 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:34:40 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/rabbitmq/":{"url":"distributed/rabbitmq/","title":"rabbitmq","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/kafka/":{"url":"distributed/kafka/","title":"kafka","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/kafka/shell.html":{"url":"distributed/kafka/shell.html","title":"1.集群启动停止脚本","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 ! /bin/bash #! /bin/bash case $1 in \"start\"){ for i in hadoop101 hadoop102 hadoop103 do echo \" --------启动 $i Kafka-------\" # 用于KafkaManager监控 ssh $i \"export JMX_PORT=9988 && /usr/local/software/kafka_2.12-2.6.0/bin/kafka-server-start.sh -daemon /usr/local/software/kafka_2.12-2.6.0/config/server.properties \" done };; \"stop\"){ for i in hadoop101 hadoop102 hadoop103 do echo \" --------停止 $i Kafka-------\" ssh $i \"/usr/local/software/kafka_2.12-2.6.0/bin/kafka-server-stop.sh stop\" done };; esac Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:36:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/kafka/kafka.html":{"url":"distributed/kafka/kafka.html","title":"2.大数据技术之Kafka","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.概述 1.1 简介 1.2 特点 1.3 场景 1.4 架构 2.kafka 环境搭建 1）解压安装包 2）在kafka_2.12-2.6.0 目录下创建 logs 文件夹 3）修改配置文件 4）分发安装包 5）分别在 hadoop102 和 hadoop103 上修改配置文件 config/server.properties 中的 broker.id=1、broker.id=2 8）启动集群 9）关闭集群 3.Kafka shell 使用 1）查看当前服务器中的所有 topic 2）创建 topic 3）删除 topic 4）发送消息 5）消费消息 6）查看某个 Topic 的详情 4. Kafka API 实战 4.1 环境准备 4.2 Kafka 生产者 Java API 4.2.1 创建生产者（过时的 API） 4.2.2 创建生产者（新 API） 4.2.3 创建生产者带回调函数（新 API） 4.2.4 自定义分区生产者 4.3 Kafka 消费者 Java API 4.3.1 高级 API 4.3.2 低级 API 5. Kafka producer 拦截器(interceptor) 5.1 拦截器原理 6. Kafka 工作流程分析 3.1 Kafka 生产过程分析 3.1.1 写入方式 3.1.2 分区（Partition） 3.1.3 副本（Replication） 3.1.4 写入流程 3.2 Broker 保存消息 3.2.1 存储方式 3.2.2 存储策略 3.2.3 Zookeeper 存储结构 3.3 Kafka 消费过程分析 3.3.1 高级 API 3.3.2 低级 API 3.3.3 消费者组 3.3.4 消费方式 3.3.5 消费者组案例 7. 扩展 7.1 Kafka 与 Flume 比较 7.2 Flume 与 kafka 集成 7.3 Kafka 配置信息 7.3.1 Broker 配置信息 7.3.2 Producer 配置信息 7.3.3 Consumer 配置信息 1.概述 1.1 简介 Apache Kafka 是一个分布式消息系统，由Scala写成。是由 Apache 软件基金会开发的一个开源消息系统项目 1.2 特点 高吞吐量：Kafka 每秒可以生产约 25 万消息（50 MB），每秒处理 55 万消息（110 MB） 持久化数据存储：可进行持久化操作。将消息持久化到磁盘，因此可用于批量消费，例如 ETL，以及实时应用程序。通过将数据持久化到硬盘以及 replication 防止数据丢失。 分布式系统易于扩展：所有的 producer、broker 和 consumer 都会有多个，均为分布式的。无需停机即可扩展机器。 客户端状态维护：消息被处理的状态是在 consumer 端维护，而不是由 server 端维护。当失败时能自动平衡。 1.3 场景 大数据日志收集缓存 1.4 架构 2.kafka 环境搭建 1）解压安装包 tar -zxvf kafka_2.12-2.6.0.tgz -C /usr/local/software 2）在kafka_2.12-2.6.0 目录下创建 logs 文件夹 cd kafka_2.12-2.6.0 && mkdir logs 3）修改配置文件 vim server.properties 输入以下内容： #broker 的全局唯一编号，不能重复 broker.id=0 #删除 topic 功能使能 delete.topic.enable=true #处理网络请求的线程数量 num.network.threads=3 #用来处理磁盘 IO 的现成数量 num.io.threads=8 #发送套接字的缓冲区大小 socket.send.buffer.bytes=102400 #接收套接字的缓冲区大小 socket.receive.buffer.bytes=102400 #请求套接字的缓冲区大小 socket.request.max.bytes=104857600 #kafka 运行日志存放的路径 log.dirs=/usr/local/software/kafka_2.12-2.6.0/logs #topic 在当前 broker 上的分区个数 num.partitions=1 #用来恢复和清理 data 下数据的线程数量 num.recovery.threads.per.data.dir=1 #segment 文件保留的最长时间，超时将被删除 log.retention.hours=168 #配置连接 Zookeeper 集群地址 zookeeper.connect=hadoop101:2181,hadoop102:2181,hadoop103:2181 broker.id=0 log.dirs=/usr/local/software/kafka_2.12-2.6.0/logs zookeeper.connect=hadoop101:2181,hadoop102:2181,hadoop103:2181 4）分发安装包 xsync kafka_2.12-2.6.0 注意：分发之后记得配置其他机器的环境变量 5）分别在 hadoop102 和 hadoop103 上修改配置文件 config/server.properties 中的 broker.id=1、broker.id=2 注：broker.id 不得重复 8）启动集群 依次在 hadoop101、hadoop102、hadoop103 节点上启动 kafka bin/kafka-server-start.sh config/server.properties & 9）关闭集群 依次在 hadoop101、hadoop102、hadoop103 节点上关闭 kafka bin/kafka-server-stop.sh stop 3.Kafka shell 使用 1）查看当前服务器中的所有 topic bin/kafka-topics.sh --zookeeper hadoop101:2181 --list 2）创建 topic bin/kafka-topics.sh --zookeeper hadoop101:2181 --create --replication-factor 1 --partitions 1 --topic first 选项说明： --topic 定义 topic 名 --replication-factor 定义副本数 --partitions 定义分区数 bin/kafka-topics.sh --create --topic quickstart-events --bootstrap-server hadoop101:9092 3）删除 topic bin/kafka-topics.sh --zookeeper hadoop101:2181 --delete --topic first 需要 server.properties 中设置 delete.topic.enable=true 否则只是标记删除或者直接重启。 4）发送消息 bin/kafka-console-producer.sh --broker-list hadoop101:9092 --topic first hello world bin/kafka-console-producer.sh --topic quickstart-events --bootstrap-server hadoop101:9092 5）消费消息 bin/kafka-console-consumer.sh --zookeeper hadoop101:2181 --from-beginning --topic first --from-beginning：会把 first 主题中以往所有的数据都读取出来。根据业务场景选择是否增加该配置。 bin/kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server hadoop101:9092 6）查看某个 Topic 的详情 bin/kafka-topics.sh --zookeeper hadoop101:2181 --describe --topic first bin/kafka-topics.sh --describe --topic quickstart-events --bootstrap-server hadoop101:9092 4. Kafka API 实战 4.1 环境准备 1）启动 zk 和 kafka 集群，在 kafka 集群中打开一个消费者 bin/kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server hadoop101:9092 2）导入 pom 依赖 org.apache.kafka kafka-clients 0.11.0.0 org.apache.kafka kafka_2.12 0.11.0.0 4.2 Kafka 生产者 Java API 4.2.1 创建生产者（过时的 API） import java.util.Properties; import kafka.javaapi.producer.Producer; import kafka.producer.KeyedMessage; import kafka.producer.ProducerConfig; public class OldProducer { public static void main(String[] args) { Properties properties = new Properties(); properties.put(\"metadata.broker.list\", \"hadoop102:9092\"); properties.put(\"request.required.acks\", \"1\"); properties.put(\"serializer.class\", \"kafka.serializer.StringEncoder\"); Producer producer = new Producer(new ProducerConfig(properties)); KeyedMessage message = new KeyedMessage(\"first\", \"hello world\"); producer.send(message ); } } 4.2.2 创建生产者（新 API） import java.util.Properties; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.Producer; import org.apache.kafka.clients.producer.ProducerRecord; public class NewProducer { public static void main(String[] args) { Properties props = new Properties(); // Kafka 服务端的主机名和端口号 props.put(\"bootstrap.servers\", \"hadoop103:9092\"); // 等待所有副本节点的应答 props.put(\"acks\", \"all\"); // 消息发送最大尝试次数 props.put(\"retries\", 0); // 一批消息处理大小 props.put(\"batch.size\", 16384); // 请求延时 props.put(\"linger.ms\", 1); // 发送缓存区内存大小 props.put(\"buffer.memory\", 33554432); // key 序列化 props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); // value 序列化 props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); Producer producer = new KafkaProducer<>(props); for (int i = 0; i (\"first\", Integer.toString(i), \"hello world-\" + i)); } producer.close(); } } 4.2.3 创建生产者带回调函数（新 API） import java.util.Properties; import org.apache.kafka.clients.producer.Callback; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.clients.producer.RecordMetadata; public class CallBackProducer { public static void main(String[] args) { Properties props = new Properties(); // Kafka 服务端的主机名和端口号 props.put(\"bootstrap.servers\", \"hadoop103:9092\"); // 等待所有副本节点的应答 props.put(\"acks\", \"all\"); // 消息发送最大尝试次数 props.put(\"retries\", 0); // 一批消息处理大小 props.put(\"batch.size\", 16384); // 增加服务端请求延时 props.put(\"linger.ms\", 1); // 发送缓存区内存大小 props.put(\"buffer.memory\", 33554432); // key 序列化 props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); // value 序列化 props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); KafkaProducer kafkaProducer = new KafkaProducer<>(props); for (int i = 0; i (\"first\", \"hello\" + i), new Callback() { @Override public void onCompletion(RecordMetadata metadata, Exception exception) { if (metadata != null) { System.err.println(metadata.partition() + \"---\" + metadata.offset()); } } }); } kafkaProducer.close(); } } 4.2.4 自定义分区生产者 0）需求：将所有数据存储到 topic 的第 0 号分区上 1）定义一个类实现 Partitioner 接口，重写里面的方法（过时 API） import java.util.Map; import kafka.producer.Partitioner; public class CustomPartitioner implements Partitioner { public CustomPartitioner() { super(); } @Override public int partition(Object key, int numPartitions) { // 控制分区 return 0; } } 2）自定义分区（新 API） import java.util.Map; import org.apache.kafka.clients.producer.Partitioner; import org.apache.kafka.common.Cluster; public class CustomPartitioner implements Partitioner { @Override public void configure(Map configs) { } @Override public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) { // 控制分区 return 0; } @Override public void close() { } } 3）在代码中调用 import java.util.Properties; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.Producer; import org.apache.kafka.clients.producer.ProducerRecord; public class PartitionerProducer { public static void main(String[] args) { Properties props = new Properties(); // Kafka 服务端的主机名和端口号 props.put(\"bootstrap.servers\", \"hadoop103:9092\"); // 等待所有副本节点的应答 props.put(\"acks\", \"all\"); // 消息发送最大尝试次数 props.put(\"retries\", 0); // 一批消息处理大小 props.put(\"batch.size\", 16384); // 增加服务端请求延时 props.put(\"linger.ms\", 1); // 发送缓存区内存大小 props.put(\"buffer.memory\", 33554432); // key 序列化 props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); // value 序列化 props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); // 自定义分区 props.put(\"partitioner.class\", \"com.haha.kafka.CustomPartitioner\"); Producer producer = new KafkaProducer<>(props); producer.send(new ProducerRecord(\"first\", \"1\", \"haha\")); producer.close(); } } 4）测试 （1）在 hadoop102 上监控/opt/module/kafka/logs/目录下 first 主题 3 个分区的 log 日志动态变化情况 tail -f 00000000000000000000.log （2）发现数据都存储到指定的分区了。 4.3 Kafka 消费者 Java API 4.3.1 高级 API 0）在控制台创建发送者 bin/kafka-console-producer.sh \\ --broker-list hadoop102:9092 --topic first >hello world 1）创建消费者（过时 API） import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Properties; import kafka.consumer.Consumer; import kafka.consumer.ConsumerConfig; import kafka.consumer.ConsumerIterator; import kafka.consumer.KafkaStream; import kafka.javaapi.consumer.ConsumerConnector; public class CustomConsumer { public static void main(String[] args) { Properties properties = new Properties(); properties.put(\"zookeeper.connect\", \"hadoop102:2181\"); properties.put(\"group.id\", \"g1\"); properties.put(\"zookeeper.session.timeout.ms\", \"500\"); properties.put(\"zookeeper.sync.time.ms\", \"250\"); properties.put(\"auto.commit.interval.ms\", \"1000\"); // 创建消费者连接器 ConsumerConnector consumer = Consumer.createJavaConsumerConnector(new ConsumerConfig(properties)); HashMap topicCount = new HashMap<>(); topicCount.put(\"first\", 1); Map>> consumerMap = consumer.createMessageStreams(topicCount); KafkaStream stream = consumerMap.get(\"first\").get(0); ConsumerIterator it = stream.iterator(); while (it.hasNext()) { System.out.println(new String(it.next().message())); } } } 2）官方提供案例（自动维护消费情况）（新 API） import java.util.Arrays; import java.util.Properties; import org.apache.kafka.clients.consumer.ConsumerRecord; import org.apache.kafka.clients.consumer.ConsumerRecords; import org.apache.kafka.clients.consumer.KafkaConsumer; public class CustomNewConsumer { public static void main(String[] args) { Properties props = new Properties(); // 定义 kakfa 服务的地址，不需要将所有 broker 指定上 props.put(\"bootstrap.servers\", \"hadoop102:9092\"); // 制定 consumer group props.put(\"group.id\", \"test\"); // 是否自动确认 offset props.put(\"enable.auto.commit\", \"true\"); // 自动确认 offset 的时间间隔 props.put(\"auto.commit.interval.ms\", \"1000\"); // key 的序列化类 props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); // value 的序列化类 props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); // 定义 consumer KafkaConsumer consumer = new KafkaConsumer<>(props); // 消费者订阅的 topic, 可同时订阅多个 consumer.subscribe(Arrays.asList(\"first\", \"second\",\"third\")); while (true) { // 读取数据，读取超时时间为 100ms ConsumerRecords records = consumer.poll(100); for (ConsumerRecord record : records) System.out.printf(\"offset = %d, key = %s, value = %s%n\", record.offset(), record.key(), record.value()); } } } 4.3.2 低级 API 实现使用低级 API 读取指定 topic，指定 partition,指定 offset 的数据。 1）消费者使用低级 API 的主要步骤： 步骤 主要工作 1 根据指定的分区从主题元数据中找到主副本 2 获取分区最新的消费进度 3 从主副本拉取分区的消息 4 识别主副本的变化，重试 2）方法描述： findLeader() 客户端向种子节点发送主题元数据，将副本集加入备用节点 getLastOffset() 消费者客户端发送偏移量请求，获取分区最近的偏移量 run() 消费者低级 AP I 拉取消息的主要方法 findNewLeader() 当分区的主副本节点发生故障，客户将要找出新的主副本 3）代码： import java.nio.ByteBuffer; import java.util.ArrayList; import java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; import kafka.api.FetchRequest; import kafka.api.FetchRequestBuilder; import kafka.api.PartitionOffsetRequestInfo; import kafka.cluster.BrokerEndPoint; import kafka.common.ErrorMapping; import kafka.common.TopicAndPartition; import kafka.javaapi.FetchResponse; import kafka.javaapi.OffsetResponse; import kafka.javaapi.PartitionMetadata; import kafka.javaapi.TopicMetadata; import kafka.javaapi.TopicMetadataRequest; import kafka.javaapi.consumer.SimpleConsumer; import kafka.message.MessageAndOffset; public class SimpleExample { private List m_replicaBrokers = new ArrayList<>(); public SimpleExample() { m_replicaBrokers = new ArrayList<>(); } public static void main(String args[]) { SimpleExample example = new SimpleExample(); // 最大读取消息数量 long maxReads = Long.parseLong(\"3\"); // 要订阅的 topic String topic = \"test1\"; // 要查找的分区 int partition = Integer.parseInt(\"0\"); // broker 节点的 ip List seeds = new ArrayList<>(); seeds.add(\"192.168.9.102\"); seeds.add(\"192.168.9.103\"); seeds.add(\"192.168.9.104\"); // 端口 int port = Integer.parseInt(\"9092\"); try { example.run(maxReads, topic, partition, seeds, port); } catch (Exception e) { System.out.println(\"Oops:\" + e); e.printStackTrace(); } } public void run(long a_maxReads, String a_topic, int a_partition, List a_seedBrokers, int a_port) throws Exception { // 获取指定 Topic partition 的元数据 PartitionMetadata metadata = findLeader(a_seedBrokers, a_port, a_topic, a_partition); if (metadata == null) { System.out.println(\"Can't find metadata for Topic and Partition. Exiting\"); return; } if (metadata.leader() == null) { System.out.println(\"Can't find Leader for Topic and Partition. Exiting\"); return; } String leadBroker = metadata.leader().host(); String clientName = \"Client\" + a_topic + \"\" + a_partition; SimpleConsumer consumer = new SimpleConsumer(leadBroker, a_port, 100000, 64 * 1024, clientName); long readOffset = getLastOffset(consumer, a_topic, a_partition, kafka.api.OffsetRequest.EarliestTime(), clientName); int numErrors = 0; while (a_maxReads > 0) { if (consumer == null) { consumer = new SimpleConsumer(leadBroker, a_port, 100000, 64 * 1024, clientName); } FetchRequest req = new FetchRequestBuilder().clientId(clientName).addFetch(a_topic, a_partition, readOffset, 100000).build(); FetchResponse fetchResponse = consumer.fetch(req); if (fetchResponse.hasError()) { numErrors++; // Something went wrong! short code = fetchResponse.errorCode(a_topic, a_partition); System.out.println(\"Error fetching data from the Broker:\" + leadBroker + \" Reason: \" + code); if (numErrors > 5) break; if (code == ErrorMapping.OffsetOutOfRangeCode()) { // We asked for an invalid offset. For simple case ask for // the last element to reset readOffset = getLastOffset(consumer, a_topic, a_partition, kafka.api.OffsetRequest.LatestTime(), clientName); continue; } consumer.close(); consumer = null; leadBroker = findNewLeader(leadBroker, a_topic, a_partition, a_port); continue; } numErrors = 0; long numRead = 0; for (MessageAndOffset messageAndOffset : fetchResponse.messageSet(a_topic, a_partition)) { long currentOffset = messageAndOffset.offset(); if (currentOffset System.out.println(\"Found an old offset: \" + currentOffset + \" Expecting: \" + readOffset); continue; } readOffset = messageAndOffset.nextOffset(); ByteBuffer payload = messageAndOffset.message().payload(); byte[] bytes = new byte[payload.limit()]; payload.get(bytes); System.out.println(String.valueOf(messageAndOffset.offset()) + \": \" + new String(bytes, \"UTF-8\")); numRead++; a_maxReads--; } if (numRead == 0) { try { Thread.sleep(1000); } catch (InterruptedException ie) { } } } if (consumer != null) consumer.close(); } public static long getLastOffset(SimpleConsumer consumer, String topic, int partition, long whichTime, String clientName) { TopicAndPartition topicAndPartition = new TopicAndPartition(topic, partition); Map requestInfo = new HashMap(); requestInfo.put(topicAndPartition, new PartitionOffsetRequestInfo(whichTime, 1)); kafka.javaapi.OffsetRequest request = new kafka.javaapi.OffsetRequest(requestInfo, kafka.api.OffsetRequest.CurrentVersion(), clientName); OffsetResponse response = consumer.getOffsetsBefore(request); if (response.hasError()) { System.out.println(\"Error fetching data Offset Data the Broker. Reason: \" + response.errorCode(topic, partition)); return 0; } long[] offsets = response.offsets(topic, partition); return offsets[0]; } private String findNewLeader(String a_oldLeader, String a_topic, int a_partition, int a_port) throws Exception { for (int i = 0; i boolean goToSleep = false; PartitionMetadata metadata = findLeader(m_replicaBrokers, a_port, a_topic, a_partition); if (metadata == null) { goToSleep = true; } else if (metadata.leader() == null) { goToSleep = true; } else if (a_oldLeader.equalsIgnoreCase(metadata.leader().host()) && i == 0) { // first time through if the leader hasn't changed give // ZooKeeper a second to recover // second time, assume the broker did recover before failover, // or it was a non-Broker issue // goToSleep = true; } else { return metadata.leader().host(); } if (goToSleep) { Thread.sleep(1000); } } System.out.println(\"Unable to find new leader after Broker failure. Exiting\"); throw new Exception(\"Unable to find new leader after Broker failure. Exiting\"); } private PartitionMetadata findLeader(List a_seedBrokers, int a_port, String a_topic, int a_partition) { PartitionMetadata returnMetaData = null; loop: for (String seed : a_seedBrokers) { SimpleConsumer consumer = null; try { consumer = new SimpleConsumer(seed, a_port, 100000, 64 * 1024, \"leaderLookup\"); List topics = Collections.singletonList(a_topic); TopicMetadataRequest req = new TopicMetadataRequest(topics); kafka.javaapi.TopicMetadataResponse resp = consumer.send(req); List metaData = resp.topicsMetadata(); for (TopicMetadata item : metaData) { for (PartitionMetadata part : item.partitionsMetadata()) { if (part.partitionId() == a_partition) { returnMetaData = part; break loop; } } } } catch (Exception e) { System.out.println(\"Error communicating with Broker [\" + seed + \"] to find Leader for [\" + a_topic + \", \" + a_partition + \"] Reason: \" + e); } finally { if (consumer != null) consumer.close(); } } if (returnMetaData != null) { m_replicaBrokers.clear(); for (BrokerEndPoint replica : returnMetaData.replicas()) { m_replicaBrokers.add(replica.host()); } } return returnMetaData; } } 5. Kafka producer 拦截器(interceptor) 5.1 拦截器原理 Producer 拦截器(interceptor)是在 Kafka 0.10 版本被引入的，主要用于实现 clients 端的定制化控制逻辑。 对于 producer 而言，interceptor 使得用户在消息发送前以及 producer 回调逻辑前有机会对消息做一些定制化需求，比如修改消息等。同时，producer 允许用户指定多个 interceptor 按序作用于同一条消息从而形成一个拦截链(interceptor chain)。Intercetpor 的实现接口是 org.apache.kafka.clients.producer.ProducerInterceptor，其定义的方法包括： （1）configure(configs) 获取配置信息和初始化数据时调用。 （2）onSend(ProducerRecord)： 该方法封装进 KafkaProducer.send 方法中，即它运行在用户主线程中。Producer 确保在消息被序列化以及计算分区前调用该方法。用户可以在该方法中对消息做任何操作，但最好保证不要修改消息所属的 topic 和分区，否则会影响目标分区的计算 （3）onAcknowledgement(RecordMetadata, Exception)： 该方法会在消息被应答或消息发送失败时调用，并且通常都是在 producer 回调逻辑触发之前。onAcknowledgement 运行在 producer 的 IO 线程中，因此不要在该方法中放入很重的逻辑，否则会拖慢 producer 的消息发送效率 （4）close： 关闭 interceptor，主要用于执行一些资源清理工作 如前所述，interceptor 可能被运行在多个线程中，因此在具体实现时用户需要自行确保线程安全。另外倘若指定了多个 interceptor，则 producer 将按照指定顺序调用它们，并仅仅是捕获每个 interceptor 可能抛出的异常记录到错误日志中而非在向上传递。这在使用过程中要特别留意。 5.2 拦截器案例 1）需求： 实现一个简单的双 interceptor 组成的拦截链。第一个 interceptor 会在消息发送前将时间戳信息加到消息 value 的最前部；第二个 interceptor 会在消息发送后更新成功发送消息数或失败发送消息数。 2）案例实操 （1）增加时间戳拦截器 import java.util.Map; import org.apache.kafka.clients.producer.ProducerInterceptor; import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.clients.producer.RecordMetadata; public class TimeInterceptor implements ProducerInterceptor { @Override public void configure(Map configs) { } @Override public ProducerRecord onSend(ProducerRecord record) { // 创建一个新的 record，把时间戳写入消息体的最前部 return new ProducerRecord(record.topic(), record.partition(), record.timestamp(), record.key(), System.currentTimeMillis() + \",\" + record.value().toString()); } @Override public void onAcknowledgement(RecordMetadata metadata, Exception exception) { } @Override public void close() { } } （2）统计发送消息成功和发送失败消息数，并在 producer 关闭时打印这两个计数器 import java.util.Map; import org.apache.kafka.clients.producer.ProducerInterceptor; import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.clients.producer.RecordMetadata; public class CounterInterceptor implements ProducerInterceptor{ private int errorCounter = 0; private int successCounter = 0; @Override public void configure(Map configs) { } @Override public ProducerRecord onSend(ProducerRecord record) { return record; } @Override public void onAcknowledgement(RecordMetadata metadata, Exception exception) { // 统计成功和失败的次数 if (exception == null) { successCounter++; } else { errorCounter++; } } @Override public void close() { // 保存结果 System.out.println(\"Successful sent: \" + successCounter); System.out.println(\"Failed sent: \" + errorCounter); } } （3）producer 主程序 import java.util.ArrayList; import java.util.List; import java.util.Properties; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.Producer; import org.apache.kafka.clients.producer.ProducerConfig; import org.apache.kafka.clients.producer.ProducerRecord; public class InterceptorProducer { public static void main(String[] args) throws Exception { // 1 设置配置信息 Properties props = new Properties(); props.put(\"bootstrap.servers\", \"hadoop102:9092\"); props.put(\"acks\", \"all\"); props.put(\"retries\", 0); props.put(\"batch.size\", 16384); props.put(\"linger.ms\", 1); props.put(\"buffer.memory\", 33554432); props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); // 2 构建拦截链 List interceptors = new ArrayList<>(); interceptors.add(\"com.atguigu.kafka.interceptor.TimeInterceptor\"); interceptors.add(\"com.atguigu.kafka.interceptor.CounterInterceptor\"); props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors); String topic = \"first\"; Producer producer = new KafkaProducer<>(props); // 3 发送消息 for (int i = 0; i record = new ProducerRecord<>(topic, \"message\" + i); producer.send(record); } // 4 一定要关闭 producer，这样才会调用 interceptor 的 close 方法 producer.close(); } } 3）测试 （1）在 kafka 上启动消费者，然后运行客户端 java 程序。 bin/kafka-console-consumer.sh \\ --zookeeper hadoop102:2181 --from-beginning --topic first 1501904047034,message0 1501904047225,message1 1501904047230,message2 1501904047234,message3 1501904047236,message4 1501904047240,message5 1501904047243,message6 1501904047246,message7 1501904047249,message8 1501904047252,message9 （2）观察 java 平台控制台输出数据如下： Successful sent: 10 Failed sent: 0 6. Kafka 工作流程分析 3.1 Kafka 生产过程分析 3.1.1 写入方式 producer 采用推（push）模式将消息发布到 broker，每条消息都被追加（append）到分区（patition）中，属于顺序写磁盘（顺序写磁盘效率比随机写内存要高，保障 kafka 吞吐率）。 3.1.2 分区（Partition） 消息发送时都被发送到一个 topic，其本质就是一个目录，而 topic 是由一些 Partition Logs(分区日志)组成，其组织结构如下图所示： 我们可以看到，每个 Partition 中的消息都是有序的，生产的消息被不断追加到 Partition log 上，其中的每一个消息都被赋予了一个唯一的 offset 值。 1）分区的原因 （1）方便在集群中扩展，每个 Partition 可以通过调整以适应它所在的机器，而一个 topic 又可以有多个 Partition 组成，因此整个集群就可以适应任意大小的数据了； （2）可以提高并发，因为可以以 Partition 为单位读写了。 2）分区的原则 （1）指定了 patition，则直接使用； （2）未指定 patition 但指定 key，通过对 key 的 value 进行 hash 出一个 patition； （3）patition 和 key 都未指定，使用轮询选出一个 patition。 DefaultPartitioner 类 public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) { List partitions = cluster.partitionsForTopic(topic); int numPartitions = partitions.size(); if (keyBytes == null) { int nextValue = nextValue(topic); List availablePartitions = cluster.availablePartitionsForTopic(topic); if (availablePartitions.size() > 0) { int part = Utils.toPositive(nextValue) % availablePartitions.size(); return availablePartitions.get(part).partition(); } else { // no partitions are available, give a non-available partition return Utils.toPositive(nextValue) % numPartitions; } } else { // hash the keyBytes to choose a partition return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions; } } 3.1.3 副本（Replication） 同一个 partition 可能会有多个 replication（对应 server.properties 配置中的 default.replication.factor=N）。没有 replication 的情况下，一旦 broker 宕机，其上所有 patition 的数据都不可被消费，同时 producer 也不能再将数据存于其上的 patition。引入 replication 之后，同一个 partition 可能会有多个 replication，而这时需要在这些 replication 之间选出一个 leader，producer 和 consumer 只与这个 leader 交互，其它 replication 作为 follower 从 leader 中复制数据。 3.1.4 写入流程 producer 写入消息流程如下： 1）producer 先从 zookeeper 的 \"/brokers/.../state\"节点找到该 partition 的 leader 2）producer 将消息发送给该 leader 3）leader 将消息写入本地 log 4）followers 从 leader pull 消息，写入本地 log 后向 leader 发送 ACK 5）leader 收到所有 ISR 中的 replication 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset）并向 producer 发送 ACK 3.2 Broker 保存消息 3.2.1 存储方式 物理上把 topic 分成一个或多个 patition（对应 server.properties 中的 num.partitions=3 配置），每个 patition 物理上对应一个文件夹（该文件夹存储该 patition 的所有消息和索引文件），如下： ll drwxrwxr-x. 2 atguigu atguigu 4096 8 月 6 14:37 first-0 drwxrwxr-x. 2 atguigu atguigu 4096 8 月 6 14:35 first-1 drwxrwxr-x. 2 atguigu atguigu 4096 8 月 6 14:37 first-2 cd first-0 ll -rw-rw-r--. 1 atguigu atguigu 10485760 8 月 6 14:33 00000000000000000000.index -rw-rw-r--. 1 atguigu atguigu 219 8 月 6 15:07 00000000000000000000.log -rw-rw-r--. 1 atguigu atguigu 10485756 8 月 6 14:33 00000000000000000000.timeindex -rw-rw-r--. 1 atguigu atguigu 8 8 月 6 14:37 leader-epoch-checkpoint 3.2.2 存储策略 无论消息是否被消费，kafka 都会保留所有消息。有两种策略可以删除旧数据： 1）基于时间：log.retention.hours=168 2）基于大小：log.retention.bytes=1073741824 需要注意的是，因为 Kafka 读取特定消息的时间复杂度为 O(1)，即与文件大小无关，所以这里删除过期文件与提高 Kafka 性能无关。 3.2.3 Zookeeper 存储结构 注意：producer 不在 zk 中注册，消费者在 zk 中注册。 3.3 Kafka 消费过程分析 kafka 提供了两套 consumer API：高级 Consumer API 和低级 Consumer API。 3.3.1 高级 API 1）高级 API 优点 高级 API 写起来简单 不需要自行去管理 offset，系统通过 zookeeper 自行管理。 不需要管理分区，副本等情况，.系统自动管理。 消费者断线会自动根据上一次记录在 zookeeper 中的 offset 去接着获取数据（默认设置 1 分钟更新一下 zookeeper 中存的 offset） 可以使用 group 来区分对同一个 topic 的不同程序访问分离开来（不同的 group 记录不同的 offset，这样不同程序读取同一个 topic 才不会因为 offset 互相影响） 2）高级 API 缺点 不能自行控制 offset（对于某些特殊需求来说） 不能细化控制如分区、副本、zk 等 3.3.2 低级 API 1）低级 API 优点 能够让开发者自己控制 offset，想从哪里读取就从哪里读取。 自行控制连接分区，对分区自定义进行负载均衡 对 zookeeper 的依赖性降低（如：offset 不一定非要靠 zk 存储，自行存储 offset 即可，比如存在文件或者内存中） 2）低级 API 缺点 太过复杂，需要自行控制 offset，连接哪个分区，找到分区 leader 等。 3.3.3 消费者组 消费者是以 consumer group 消费者组的方式工作，由一个或者多个消费者组成一个组，共同消费一个 topic。每个分区在同一时间只能由 group 中的一个消费者读取，但是多个 group 可以同时消费这个 partition。在图中，有一个由三个消费者组成的 group，有一个消费者读取主题中的两个分区，另外两个分别读取一个分区。某个消费者读取某个分区，也可以叫做某个消费者是某个分区的拥有者。 在这种情况下，消费者可以通过水平扩展的方式同时读取大量的消息。另外，如果一个消费者失败了，那么其他的 group 成员会自动负载均衡读取之前失败的消费者读取的分区。 3.3.4 消费方式 consumer 采用 pull（拉）模式从 broker 中读取数据。 push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成 consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而 pull 模式则可以根据 consumer 的消费能力以适当的速率消费消息。 对于 Kafka 而言，pull 模式更合适，它可简化 broker 的设计，consumer 可自主控制消费消息的速率，同时 consumer 可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。 pull 模式不足之处是，如果 kafka 没有数据，消费者可能会陷入循环中，一直等待数据到达。为了避免这种情况，我们在我们的拉请求中有参数，允许消费者请求在等待数据到达的“长轮询”中进行阻塞（并且可选地等待到给定的字节数，以确保大的传输大小）。 3.3.5 消费者组案例 1）需求：测试同一个消费者组中的消费者，同一时刻只能有一个消费者消费。 2）案例实操 （1）在 hadoop102、hadoop103 上修改/opt/module/kafka/config/consumer.properties 配置文件中的 group.id 属性为任意组名。 vi consumer.properties group.id=atguigu （2）在 hadoop102、hadoop103 上分别启动消费者 bin/kafka-console-consumer.sh \\ --zookeeper hadoop102:2181 --topic first --consumer.config config/consumer.properties bin/kafka-console-consumer.sh --zookeeper hadoop102:2181 --topic first --consumer.config config/consumer.properties （3）在 hadoop104 上启动生产者 bin/kafka-console-producer.sh \\ --broker-list hadoop102:9092 --topic first >hello world （4）查看 hadoop102 和 hadoop103 的接收者。 同一时刻只有一个消费者接收到消息。 7. 扩展 7.1 Kafka 与 Flume 比较 在企业中必须要清楚流式数据采集框架 flume 和 kafka 的定位是什么： flume：cloudera 公司研发: 适合多个生产者； 适合下游数据消费者不多的情况； 适合数据安全性要求不高的操作； 适合与 Hadoop 生态圈对接的操作。 kafka：linkedin 公司研发: 适合数据下游消费众多的情况； 适合数据安全性要求较高的操作，支持 replication。 因此我们常用的一种模型是： 线上数据 --> flume --> kafka --> flume(根据情景增删该流程) --> HDFS 7.2 Flume 与 kafka 集成 1）配置 flume(flume-kafka.conf) # define a1.sources = r1 a1.sinks = k1 a1.channels = c1 # source a1.sources.r1.type = exec a1.sources.r1.command = tail -F -c +0 /opt/module/datas/flume.log a1.sources.r1.shell = /bin/bash -c # sink a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink a1.sinks.k1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092 a1.sinks.k1.kafka.topic = first a1.sinks.k1.kafka.flumeBatchSize = 20 a1.sinks.k1.kafka.producer.acks = 1 a1.sinks.k1.kafka.producer.linger.ms = 1 # channel a1.channels.c1.type = memory a1.channels.c1.capacity = 1000 a1.channels.c1.transactionCapacity = 100 # bind a1.sources.r1.channels = c1 a1.sinks.k1.channel = c1 2） 启动 kafkaIDEA 消费者 3） 进入 flume 根目录下，启动 flume bin/flume-ng agent -c conf/ -n a1 -f jobs/flume-kafka.conf 4） 向 /opt/module/datas/flume.log 里追加数据，查看 kafka 消费者消费情况 $ echo hello > /opt/module/datas 7.3 Kafka 配置信息 7.3.1 Broker 配置信息 属性 默认值 描述 broker.id 必填参数，broker 的唯一标识 log.dirs /tmp/kafka-logs Kafka 数据存放的目录。可以指定多个目录，中间用逗号分隔，当新 partition 被创建的时会被存放到当前存放 partition 最少的目录。 port 9092 BrokerServer 接受客户端连接的端口号 zookeeper.connect null Zookeeper 的连接串，格式为：hostname1:port1,hostname2:port2,hostname3:port3。可以填一个或多个，为了提高可靠性，建议都填上。注意，此配置允许我们指定一个 zookeeper 路径来存放此 kafka 集群的所有数据，为了与其他应用集群区分开，建议在此配置中指定本集群存放目录，格式为：hostname1:port1,hostname2:port2,hostname3:port3/chroot/path。需要注意的是，消费者的参数要和此参数一致。 message.max.bytes 1000000 服务器可以接收到的最大的消息大小。注意此参数要和 consumer 的 maximum.message.size 大小一致，否则会因为生产者生产的消息太大导致消费者无法消费。 num.io.threads 8 服务器用来执行读写请求的 IO 线程数，此参数的数量至少要等于服务器上磁盘的数量。 queued.max.requests 500 I/O 线程可以处理请求的队列大小，若实际请求数超过此大小，网络线程将停止接收新的请求。 socket.send.buffer.bytes 100 * 1024 The SO_SNDBUFF buffer the server prefers for socket connections. socket.receive.buffer.bytes 100 * 1024 The SO_RCVBUFF buffer the server prefers for socket connections. socket.request.max.bytes 100 1024 1024 服务器允许请求的最大值， 用来防止内存溢出，其值应该小于 Java heap size. num.partitions 1 默认 partition 数量，如果 topic 在创建时没有指定 partition 数量，默认使用此值，建议改为 5 log.segment.bytes 1024 1024 1024 Segment 文件的大小，超过此值将会自动新建一个 segment，此值可以被 topic 级别的参数覆盖。 log.roll.{ms,hours} 24 * 7 hours 新建 segment 文件的时间，此值可以被 topic 级别的参数覆盖。 log.retention.{ms,minutes,hours} 7 days Kafka segment log 的保存周期，保存周期超过此时间日志就会被删除。此参数可以被 topic 级别参数覆盖。数据量大时，建议减小此值。 log.retention.bytes -1 每个 partition 的最大容量，若数据量超过此值，partition 数据将会被删除。注意这个参数控制的是每个 partition 而不是 topic。此参数可以被 log 级别参数覆盖。 log.retention.check.interval.ms 5 minutes 删除策略的检查周期 auto.create.topics.enable true 自动创建 topic 参数，建议此值设置为 false，严格控制 topic 管理，防止生产者错写 topic。 default.replication.factor 1 默认副本数量，建议改为 2。 replica.lag.time.max.ms 10000 在此窗口时间内没有收到 follower 的 fetch 请求，leader 会将其从 ISR(in-sync replicas)中移除。 replica.lag.max.messages 4000 如果 replica 节点落后 leader 节点此值大小的消息数量，leader 节点就会将其从 ISR 中移除。 replica.socket.timeout.ms 30 * 1000 replica 向 leader 发送请求的超时时间。 replica.socket.receive.buffer.bytes 64 * 1024 The socket receive buffer for network requests to the leader for replicating data. replica.fetch.max.bytes 1024 * 1024 The number of byes of messages to attempt to fetch for each partition in the fetch requests the replicas send to the leader. replica.fetch.wait.max.ms 500 The maximum amount of time to wait time for data to arrive on the leader in the fetch requests sent by the replicas to the leader. num.replica.fetchers 1 Number of threads used to replicate messages from leaders. Increasing this value can increase the degree of I/O parallelism in the follower broker. fetch.purgatory.purge.interval.requests 1000 The purge interval (in number of requests) of the fetch request purgatory. zookeeper.session.timeout.ms 6000 ZooKeeper session 超时时间。如果在此时间内 server 没有向 zookeeper 发送心跳，zookeeper 就会认为此节点已挂掉。 此值太低导致节点容易被标记死亡；若太高，.会导致太迟发现节点死亡。 zookeeper.connection.timeout.ms 6000 客户端连接 zookeeper 的超时时间。 zookeeper.sync.time.ms 2000 H ZK follower 落后 ZK leader 的时间。 controlled.shutdown.enable true 允许 broker shutdown。如果启用，broker 在关闭自己之前会把它上面的所有 leaders 转移到其它 brokers 上，建议启用，增加集群稳定性。 auto.leader.rebalance.enable true If this is enabled the controller will automatically try to balance leadership for partitions among the brokers by periodically returning leadership to the “preferred” replica for each partition if it is available. leader.imbalance.per.broker.percentage 10 The percentage of leader imbalance allowed per broker. The controller will rebalance leadership if this ratio goes above the configured value per broker. leader.imbalance.check.interval.seconds 300 The frequency with which to check for leader imbalance. offset.metadata.max.bytes 4096 The maximum amount of metadata to allow clients to save with their offsets. connections.max.idle.ms 600000 Idle connections timeout: the server socket processor threads close the connections that idle more than this. num.recovery.threads.per.data.dir 1 The number of threads per data directory to be used for log recovery at startup and flushing at shutdown. unclean.leader.election.enable true Indicates whether to enable replicas not in the ISR set to be elected as leader as a last resort, even though doing so may result in data loss. delete.topic.enable false 启用 deletetopic 参数，建议设置为 true。 offsets.topic.num.partitions 50 The number of partitions for the offset commit topic. Since changing this after deployment is currently unsupported, we recommend using a higher setting for production (e.g., 100-200). offsets.topic.retention.minutes 1440 Offsets that are older than this age will be marked for deletion. The actual purge will occur when the log cleaner compacts the offsets topic. offsets.retention.check.interval.ms 600000 The frequency at which the offset manager checks for stale offsets. offsets.topic.replication.factor 3 The replication factor for the offset commit topic. A higher setting (e.g., three or four) is recommended in order to ensure higher availability. If the offsets topic is created when fewer brokers than the replication factor then the offsets topic will be created with fewer replicas. offsets.topic.segment.bytes 104857600 Segment size for the offsets topic. Since it uses a compacted topic, this should be kept relatively low in order to facilitate faster log compaction and loads. offsets.load.buffer.size 5242880 An offset load occurs when a broker becomes the offset manager for a set of consumer groups (i.e., when it becomes a leader for an offsets topic partition). This setting corresponds to the batch size (in bytes) to use when reading from the offsets segments when loading offsets into the offset manager’s cache. offsets.commit.required.acks -1 The number of acknowledgements that are required before the offset commit can be accepted. This is similar to the producer’s acknowledgement setting. In general, the default should not be overridden. offsets.commit.timeout.ms 5000 The offset commit will be delayed until this timeout or the required number of replicas have received the offset commit. This is similar to the producer request timeout. 7.3.2 Producer 配置信息 属性 默认值 描述 metadata.broker.list 启动时 producer 查询 brokers 的列表，可以是集群中所有 brokers 的一个子集。注意，这个参数只是用来获取 topic 的元信息用，producer 会从元信息中挑选合适的 broker 并与之建立 socket 连接。格式是：host1:port1,host2:port2。 request.required.acks 0 参见 3.2 节介绍 request.timeout.ms 10000 Broker 等待 ack 的超时时间，若等待时间超过此值，会返回客户端错误信息。 producer.type sync 同步异步模式。async 表示异步，sync 表示同步。如果设置成异步模式，可以允许生产者以 batch 的形式 push 数据，这样会极大的提高 broker 性能，推荐设置为异步。 serializer.class kafka.serializer.DefaultEncoder 序列号类，.默认序列化成 byte[] 。 key.serializer.class Key 的序列化类，默认同上。 partitioner.class kafka.producer.DefaultPartitioner Partition 类，默认对 key 进行 hash。 compression.codec none 指定 producer 消息的压缩格式，可选参数为： “none”, “gzip” and “snappy”。关于压缩参见 4.1 节 compressed.topics null 启用压缩的 topic 名称。若上面参数选择了一个压缩格式，那么压缩仅对本参数指定的 topic 有效，若本参数为空，则对所有 topic 有效。 message.send.max.retries 3 Producer 发送失败时重试次数。若网络出现问题，可能会导致不断重试。 retry.backoff.ms 100 Before each retry, the producer refreshes the metadata of relevant topics to see if a new leader has been elected. Since leader election takes a bit of time, this property specifies the amount of time that the producer waits before refreshing the metadata. topic.metadata.refresh.interval.ms 600 * 1000 The producer generally refreshes the topic metadata from brokers when there is a failure (partition missing, leader not available…). It will also poll regularly (default: every 10min so 600000ms). If you set this to a negative value, metadata will only get refreshed on failure. If you set this to zero, the metadata will get refreshed after each message sent (not recommended). Important note: the refresh happen only AFTER the message is sent, so if the producer never sends a message the metadata is never refreshed queue.buffering.max.ms 5000 启用异步模式时，producer 缓存消息的时间。比如我们设置成 1000 时，它会缓存 1 秒的数据再一次发送出去，这样可以极大的增加 broker 吞吐量，但也会造成时效性的降低。 queue.buffering.max.messages 10000 采用异步模式时 producer buffer 队列里最大缓存的消息数量，如果超过这个数值，producer 就会阻塞或者丢掉消息。 queue.enqueue.timeout.ms -1 当达到上面参数值时 producer 阻塞等待的时间。如果值设置为 0，buffer 队列满时 producer 不会阻塞，消息直接被丢掉。若值设置为-1，producer 会被阻塞，不会丢消息。 batch.num.messages 200 采用异步模式时，一个 batch 缓存的消息数量。达到这个数量值时 producer 才会发送消息。 send.buffer.bytes 100 * 1024 Socket write buffer size client.id “” The client id is a user-specified string sent in each request to help trace calls. It should logically identify the application making the request. 7.3.3 Consumer 配置信息 属性 默认值 描述 group.id Consumer 的组 ID，相同 goup.id 的 consumer 属于同一个组。 zookeeper.connect Consumer 的 zookeeper 连接串，要和 broker 的配置一致。 consumer.id null 如果不设置会自动生成。 socket.timeout.ms 30 * 1000 网络请求的 socket 超时时间。实际超时时间由 max.fetch.wait + socket.timeout.ms 确定。 socket.receive.buffer.bytes 64 * 1024 The socket receive buffer for network requests. fetch.message.max.bytes 1024 * 1024 查询 topic-partition 时允许的最大消息大小。consumer 会为每个 partition 缓存此大小的消息到内存，因此，这个参数可以控制 consumer 的内存使用量。这个值应该至少比 server 允许的最大消息大小大，以免 producer 发送的消息大于 consumer 允许的消息。 num.consumer.fetchers 1 The number fetcher threads used to fetch data. auto.commit.enable true 如果此值设置为 true，consumer 会周期性的把当前消费的 offset 值保存到 zookeeper。当 consumer 失败重启之后将会使用此值作为新开始消费的值。 auto.commit.interval.ms 60 * 1000 Consumer 提交 offset 值到 zookeeper 的周期。 queued.max.message.chunks 2 用来被 consumer 消费的 message chunks 数量， 每个 chunk 可以缓存 fetch.message.max.bytes 大小的数据量。 auto.commit.interval.ms 60 * 1000 Consumer 提交 offset 值到 zookeeper 的周期。 queued.max.message.chunks 2 用来被 consumer 消费的 message chunks 数量， 每个 chunk 可以缓存 fetch.message.max.bytes 大小的数据量。 fetch.min.bytes 1 The minimum amount of data the server should return for a fetch request. If insufficient data is available the request will wait for that much data to accumulate before answering the request. fetch.wait.max.ms 100 The maximum amount of time the server will block before answering the fetch request if there isn’t sufficient data to immediately satisfy fetch.min.bytes. rebalance.backoff.ms 2000 Backoff time between retries during rebalance. refresh.leader.backoff.ms 200 Backoff time to wait before trying to determine the leader of a partition that has just lost its leader. auto.offset.reset largest What to do when there is no initial offset in ZooKeeper or if an offset is out of range ;smallest : automatically reset the offset to the smallest offset; largest : automatically reset the offset to the largest offset;anything else: throw exception to the consumer consumer.timeout.ms -1 若在指定时间内没有消息消费，consumer 将会抛出异常。 exclude.internal.topics true Whether messages from internal topics (such as offsets) should be exposed to the consumer. zookeeper.session.timeout.ms 6000 ZooKeeper session timeout. If the consumer fails to heartbeat to ZooKeeper for this period of time it is considered dead and a rebalance will occur. zookeeper.connection.timeout.ms 6000 The max time that the client waits while establishing a connection to zookeeper. zookeeper.sync.time.ms 2000 How far a ZK follower can be behind a ZK leader Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:36:39 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/mongo/":{"url":"distributed/mongo/","title":"mongo","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/mongo/mongoDb-data.html":{"url":"distributed/mongo/mongoDb-data.html","title":"1.准备数据","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.职工信息 2. 学生信息 3. 学生科目 4. 课程项目 1.职工信息 db.emp.insert([ {_id:1101,name:'鲁班' ,job:'讲师' ,dep:'讲师部',salary:10000}, {_id:1102,name:'悟空' ,job:'讲师' ,dep:'讲师部',salary:10000}, {_id:1103,name:'诸葛' ,job:'讲师' ,dep:'讲师部',salary:10000}, {_id:1105,name:'赵云' ,job:'讲师' ,dep:'讲师部',salary:8000}, {_id:1106,name:'韩信',job:'校长' ,dep:'校办',salary:20000}, {_id:1107,name:'貂蝉' ,job:'班主任' ,dep:'客服部',salary:8000}, {_id:1108,name:'安其' ,job:'班主任' ,dep:'客服部',salary:8000}, {_id:1109,name:'李白' ,job:'教务' ,dep:'教务处',salary:8000}, {_id:1110,name:'默子' ,job:'教务',dep:'教务处',salary:8000}, {_id:1111,name:'大乔',job:'助教' ,dep:'客服部',salary:5000}, {_id:1112,name:'小乔' ,job:'助教' ,dep:'客服部',salary:3000}, ]); 2. 学生信息 db.student.insertMany([ {_id:\"001\",name:\"陈霸天\",age:5,grade:{redis:87,zookeper:85,dubbo:90}}, {_id:\"002\",name:\"张明明\",age:3,grade:{redis:86,zookeper:82,dubbo:59}}, {_id:\"003\",name:\"肖炎炎\",age:2,grade:{redis:81,zookeper:94,dubbo:88}}, {_id:\"004\",name:\"李鬼才\",age:6,grade:{redis:48,zookeper:87,dubbo:48}} ]) 3. 学生科目 db.subject.insertMany([ {_id:\"001\",name:\"陈霸天\",subjects:[\"redis\",\"zookeper\",\"dubbo\"]}, {_id:\"002\",name:\"张明明\",subjects:[\"redis\",\"Java\",\"mySql\"]}, {_id:\"003\",name:\"肖炎炎\",subjects:[\"mySql\",\"zookeper\",\"bootstrap\"]}, {_id:\"004\",name:\"李鬼才\",subjects:[\"Java\",\"dubbo\",\"Java\"]}, ]) db.subject2.insertMany([ {_id:\"001\",name:\"陈霸天\",subjects:[{name:\"redis\",hour:12},{name:\"dubbo\",hour:120},{name:\"zookeper\",hour:56}]}, {_id:\"002\",name:\"张明明\",subjects:[{name:\"java\",hour:120},{name:\"mysql\",hour:10},{name:\"oracle\",hour:30}]}, {_id:\"003\",name:\"肖炎炎\",subjects:[{name:\"mysql\",hour:12},{name:\"html5\",hour:120},{name:\"netty\",hour:56}]}, {_id:\"004\",name:\"李鬼才\",subjects:[{name:\"redis\",hour:12},{name:\"dubbo\",hour:120},{name:\"netty\",hour:56}]} ]) 4. 课程项目 db.project.insert([ { _id: 1, name: \"Java Script\", description: \"name is js and jquery\" }, { _id: 2, name: \"Git\", description: \"Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency\" }, { _id: 3, name: \"Apache dubbo\", description: \"Apache Dubbo is a high-performance, java based open source RPC framework.阿里 开源 项目\" }, { _id: 4, name: \"Redis\", description: \"Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker. It supports data structures\" }, { _id: 5, name: \"Apache ZooKeeper\", description: \"Apache ZooKeeper is an effort to develop and maintain an open-source server which enables highly reliable distributed coordination\" } ]) Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/mongo/mongoDb-quick-start.html":{"url":"distributed/mongo/mongoDb-quick-start.html","title":"2.快速上手","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、MongoDb的体系结构 1、NoSql的概念 2、NoSql的应用场景 3、MongoDb的逻辑组成 二、MongoDb安装配置与基础命令 2.mongoDb启动参数说明 3.客户端Shell 的使用及参数说明 4.数据库与集合的基础操作 三、MongoDB CRUD与全文索引 2、数据的查询 排序与分页： 修改 3、数据的修改与删除 4、全文索引 大纲： 1、MongoDb的体系结构 2、MongoDb安装配置与基础命令 3、MongoDB CRUD与全文索引 数据脚本.txt 一、MongoDb的体系结构 概要： NoSql的概念 NoSql的应用场景 MongoDb的逻辑组成 1、NoSql的概念 NoSQL(NoSQL = Not Only SQL )，意即“不仅仅是 [SQL](https://baike.baidu.com/item/SQL) ”，互联网的早期我们的数据大多以关系型数据库来存储的。其特点是规范的数据结构（预定义模式）、强一至性、表与表之间通过外键进行关联，这些特征使我们对数据的管理更加清晰和严谨，但随着互联网的发展数据成爆炸式的增长我们对数据库需要更好的灵活性和更快的速度。这就是NoSql可以做到的。它不需要预先定义模式，没有主外键关联、支持分片、支持复本。 NoSql的分类： 键值(Key-Value)存储数据库 这一类数据库主要会使用到一个哈希表，这个表中有一个特定的键和一个指针指向特定的数据。Key/value模型对于IT系统来说的优势在于简单、易部署。但是如果DBA只对部分值进行查询或更新的时候，Key/value就显得效率低下了。举例如：Tokyo Cabinet/Tyrant, Redis, Voldemort, Oracle BDB. 列存储数据库。 这部分数据库通常是用来应对分布式存储的海量数据。键仍然存在，但是它们的特点是指向了多个列。这些列是由列家族来安排的。如：Cassandra, HBase, Riak. 文档型数据库 文档型数据库的灵感是来自于Lotus Notes办公软件的，而且它同第一种键值存储相类似。该类型的数据模型是版本化的文档，半结构化的文档以特定的格式存储，比如JSON。文档型数据库可 以看作是键值数据库的升级版，允许之间嵌套键值。而且文档型数据库比键值数据库的查询效率更高。如：CouchDB, MongoDb. 国内也有文档型数据库SequoiaDB，已经开源。 图形(Graph)数据库 图形结构的数据库同其他行列以及刚性结构的SQL数据库不同，它是使用灵活的图形模型，并且能够扩展到多个服务器上。NoSQL数据库没有标准的查询语言(SQL)，因此进行数据库查询需要制定数据模型。许多NoSQL数据库都有REST式的数据接口或者查询API。如：Neo4J, InfoGrid, Infinite Graph. 2、NoSql的应用场景 NoSQL数据库在以下的这几种情况下比较适用： 1、数据模型比较简单； 2、需要灵活性更强的IT系统； 3、对数据库性能要求较高； 4、不需要高度的数据一致性； [ ] 基于豆瓣电影举例说明NoSQL的应用场景 [ ] 电影基本信息分析 [ ] 电影与明星关系存储 3、MongoDb的逻辑组成 体系结构： 逻辑结构与关系数据库的对比： | 关系型数据库 | MongoDb | |:----|:----| | database(数据库) | database（数据库） | | table （表） | collection（ 集合） | | row（ 行） | document（ BSON 文档） | | column （列） | field （字段） | | index（唯一索引、主键索引） | index （全文索引） | | join （主外键关联） | embedded Document (嵌套文档) | | primary key(指定1至N个列做主键) | primary key (指定_id field做为主键) | | aggreation(groupy) | aggreation (pipeline mapReduce) | 二、MongoDb安装配置与基础命令 概要： mongoDb版本说明 mongoDb启动参数说明 客户端Shell 的使用及参数说明 数据库与集合的基础操作 mongoDb社区版说明 下载地址：https://www.mongodb.com/download-center/community #下载 wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.5.tgz # 解压 tar -zxvf mongodb-linux-x86_64-4.0.5.tgz 2.mongoDb启动参数说明 mongoDb 由C++编写，下载下来的包可以直接启动 #创建数据库目录 mkdir -p /data/mongo # 启动mongo ./bin/mongod --dbpath=/data/mongo/ 常规参数 | 参数 | 说明 | |:----|:----| | dbpath | 数据库目录，默认/data/db | | bind_ip | 监听IP地址，默认全部可以访问 | | port | 监听的端口，默认27017 | | logpath | 日志路径 | | logappend | 是否追加日志 | | auth | 是开启用户密码登陆 | | fork | 是否已后台启动的方式登陆 | | config | 指定配置文件 | 配置文件示例 vim mongo.conf 内容： dbpath=/data/mongo/ port=27017 bind_ip=0.0.0.0 fork=true logpath = /data/mongo/mongodb.log logappend = true auth=false 已配置文件方式启动 ./bin/mongod -f mongo.conf 3.客户端Shell 的使用及参数说明 #启动客户端 连接 本机的地的默认端口 ./bin/mongo # 指定IP和端口 ./bin/mongo --host=127.0.0.1 --port=27017 mongo shell 是一个js 控台，可以执行js 相关运算如: > 1+1 2 > var i=123; > print(i) 123 > 4.数据库与集合的基础操作 #查看数据库 show dbs; #切换数据库 use luban; #创建数据库与集合，在插入数据时会自动 创建数据库与集和 db.friend.insertOne({name:\"wukong\"，sex:\"man\"}); #查看集合 show tables; show collections; #删除集合 db.friend.drop(); #删除数据库 db.dropDatabase(); 三、MongoDB CRUD与全文索引 概要： 数据的新增的方式 数据的查询 数据的修改删除 全文索引查询 数据的新增的方式 关于Mongodb数据插入的说明 数据库的新增不需要序先设计模型结构，插入数据时会自动创建。 同一个集合中不同数据字段结构可以不一样 插入相关方法： //插入单条 db.friend.insertOne({name:\"wukong\"，sex:\"man\"}); // 插入多条 db.friend.insertMany([ {name:\"wukong\",sex:\"man\"},{name:\"diaocan\",sex:\"woman\",age:18,birthday:new Date(\"1995-11-02\")},{name:\"zixiao\",sex:\"woman\"} ]); // 指定ID db.friend.insert([ {_id:1,name:\"wokong\",sex:\"man\",age:1}, {_id:2,name:\"diaocan\",sex:\"women\",birthday:new Date(\"1988-11- 11\")} ]) 2、数据的查询 概要： 基于条件的基础查询 $and、$or、$in、$gt、$gte、$lt、$lte 运算符 基于 sort skip limit 方法实现排序与分页 嵌套查询 数组查询 数组嵌套查询 基础查询： #基于ID查找 db.emp.find({_id:1101}) #基于属性查找 db.emp.find({\"name\":\"鲁班\"}) # && 运算 与大于 运算 db.emp.find({\"job\":\"讲师\",\"salary\":{$gt:8000}}) # in 运算 db.emp.find({\"job\":{$in:[\"讲师\",\"客服部\"]}}) # or 运算 db.emp.find({$or:[{job:\"讲师\" },{job:\"客服部\"}] }) 排序与分页： // sort skip limit db.emp.find().sort({dep:1,salary:-1}).skip(5).limit(2) 嵌套查询： # 错误示例：无结果 db.student.find({grade:{redis:87,dubbo:90 }); #错误示例：无结果 db.student.find({grade:{redis:87,dubbo:90,zookeper:85} }) # 基于复合属性查找 时必须包含其所有的值 并且顺序一至 db.student.find({grade:{redis:87,zookeper:85,dubbo:90} }) #基于复合属性当中的指定值 查找。注：名称必须用双引号 db.student.find({\"grade.redis\":87}); db.student.find({\"grade.redis\":{\"$gt\":80}}); 数组查询： db.subject.insertMany([ {_id:\"001\",name:\"陈霸天\",subjects:[\"redis\",\"zookeper\",\"dubbo\"]}, {_id:\"002\",name:\"张明明\",subjects:[\"redis\",\"Java\",\"mySql\"]}, {_id:\"003\",name:\"肖炎炎\",subjects:[\"mySql\",\"zookeper\",\"bootstrap\"]}, {_id:\"004\",name:\"李鬼才\",subjects:[\"Java\",\"dubbo\",\"Java\"]}, ]) #无结果 db.subject.find({subjects:[\"redis\",\"zookeper\"]}) #无结果 db.subject.find({subjects:[\"zookeper\",\"redis\",\"dubbo\"]}) # 与嵌套查询一样，必须是所有的值 并且顺序一至 db.subject.find({subjects:[\"redis\",\"zookeper\",\"dubbo\"]}) # $all 匹配数组中包含该两项的值。注：顺序不作要求 db.subject.find({subjects:{\"$all\": [\"redis\",\"zookeper\"]}}) 注： # 简化数组查询 db.subject.find({subjects:\"redis\"}) # 简化数组查询 ，匹配数组中存在任意一值。与$all相对应 db.subject.find({subjects:{$in: [\"redis\",\"zookeper\"]}}) 数组嵌套查询： #基础查询 ，必须查询全部，且顺序一至 db.subject2.find({subjects:{name:\"redis\",hour:12} }) #指定查询第一个数组 课时大于12 db.subject2.find({\"subjects.0.hour\":{$gt:12}}) #查询任科目 课时大于12 db.subject2.find({\"subjects.hour\":{$gt:12}}) # $elemMatch 元素匹配，指定属性满足，且不要求顺序一至 db.subject2.find({subjects:{$elemMatch:{name:\"redis\",hour:12}}}) # 数组中任意元素匹配 不限定在同一个对象当中 db.subject2.find({\"subjects.name\":\"mysql\",\"subjects.hour\":120}) 修改 #设置值 db.emp.update({_id:1101} ,{ $set:{salary:10300} }) #自增 db.emp.update({_id:1101} ,{ $inc:{salary:200}}) #基于条件 更新多条数据 # 只会更新第一条 db.emp.update({\"dep\":\"客服部\"},{$inc:{salary:100}}) # 更新所有 匹配的条件 db.emp.updateMany({\"dep\":\"客服部\"},{$inc:{salary:100}}) 3、数据的修改与删除 修改 #设置值 db.emp.update({_id:1101} ,{ $set:{salary:10300} }) #自增 db.emp.update({_id:1101} ,{ $inc:{salary:200}}) #基于条件 更新多条数据 # 只会更新第一条 db.emp.update({\"dep\":\"客服部\"},{$inc:{salary:100}}) # 更新所有 匹配的条件 db.emp.updateMany({\"dep\":\"客服部\"},{$inc:{salary:100}}) 删除： // 基于查找删除 db.emp.deleteOne({_id:1101}) // 删除整个集合 db.project.drop() // 删除库 db.dropDatabase() 4、全文索引 索引的创建 db.project.createIndex({name:\"text\",description:\"text\"}) 基于索引分词进行查询 db.project.find({$text:{$search:\"java jquery\"}}) 基于索引 短语 db.project.find({$text:{$search:\"\\\"Apache ZooKeeper\\\"\"}}) 过滤指定单词 db.project.find({$text:{$search:\"java apache -阿里\"}}) 查看执行计划 db.project.find({$text:{$search:\"java -阿里\"}}).explain(\"executionStats\") Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/mongo/mongoDb-enterprise.html":{"url":"distributed/mongo/mongoDb-enterprise.html","title":"3.企业应用","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 一、 mongoDB的聚合操作 1.pipeline 聚合 2.mapRedurce 聚合 3.在聚合中使用索引 二、mongodb 的主从复制机制 1.复制集群的架构 2.复制集群搭建基础示例 子节点配置2 3.复制集群选举操作 三、mongodb 中的分片机制 1.为什么需要分片？ 1.mongodb 中的分片架构 2.分片示例流程： 节点1 config1-37017.conf 节点2 config2-37018.conf 配置 shard 节点集群============== 节点 route-27017.conf 四、用户管理与数据集验证 概要： mongoDB的聚合操作 mongodb 集群：复制 mongodb 集群：分片 一、 mongoDB的聚合操作 知识点： pipeline 聚合 mapRedurce 聚合 在聚合中使用索引 1.pipeline 聚合 pipeline相关运算符： $match ：匹配过滤聚合的数据 $project：返回需要聚合的字段 $group：统计聚合数据 示例： # $match 与 $project使用 db.emp.aggregate( {$match:{\"dep\":{$eq:\"客服部\"}}}, {$project:{name:1,dep:1,salary:1}} ); # $group 与 $sum 使用 db.emp.aggregate( {$project:{dep:1,salary:1}}, {$group:{\"_id\":\"$dep\",total:{$sum:\"$salary\"}}} ); # 低于4000 忽略 db.emp.aggregate( {$match:{salary:{$gt:4000}}}, {$project:{dep:1,salary:1}}, {$group:{\"_id\":\"$dep\",total:{$sum:\"$salary\"}}} ); # 基于多个字段 进行组合group 部门+职位进行统计 db.emp.aggregate( {$project:{dep:1,job:1,salary:1}}, {$group:{\"_id\":{\"dep\":\"$dep\",\"job\":\"$job\"},total:{$sum:\"$salary\"}}} ); 二次过滤 db.emp.aggregate( {$project:{dep:1,job:1,salary:1}}, {$group:{\"_id\":{\"dep\":\"$dep\",\"job\":\"$job\"},total:{$sum:\"$salary\"}}}， {$match:{\"$total\":{$gt:10000}}} ); 2.mapRedurce 聚合 mapRedurce 说明： 为什么需要 MapReduce？ (1) 海量数据在单机上处理因为硬件资源限制，无法胜任 (2) 而一旦将单机版程序扩展到集群来分布式运行，将极大增加程序的复杂度和开发难度 (3) 引入 MapReduce 框架后，开发人员可以将绝大部分工作集中在业务逻辑的开发上，而将 分布式计算中的复杂性交由框架来处理 mongodb中mapRedurce的使用流程 创建Map函数， 创建Redurce函数 将map、Redurce 函数添加至集合中，并返回新的结果集 查询新的结果集 示例操作 // 创建map 对象 var map1=function (){ emit(this.job,1); } // 创建reduce 对象 var reduce1=function(job,count){ return Array.sum(count); } // 执行mapReduce 任务 并将结果放到新的集合 result 当中 db.emp.mapReduce(map1,reduce1,{out:\"result\"}) // 查询新的集合 db.result.find() # 使用复合对象作为key var map2=function (){ emit({\"job\":this.job,\"dep\":this.dep},1); } var reduce2=function(key,values){ return values.length; } db.emp.mapReduce(map2,reduce2,{out:\"result2\"}).find() mapRedurce的原理 在map函数中使用emit函数添加指定的 key 与Value ，相同的key 将会发给Redurce进行聚合操作，所以Redurce函数中第二个参数 就是 所有集的数组。return 的显示就是聚合要显示的值。 3.在聚合中使用索引 通过$Math内 可以包合对$text 的运算 示例： db.project.aggregate( {$match:{$text:{$search:\"apache\"}}}, {$project:{\"name\":1,\"price\":1}}, {$group:{_id:\"$name\",price:{$sum:\"$price\"}}} ) 关于索引 除了全文索引之外，还有单键索引。即整个字段的值作为索引。单键索引用值1和-1表示，分别代表正序和降序索引。 示例： de 创建单键索引 db.emp.createIndex({\"dep\":1}) 查看基于索引的执行计划 db.emp.find({\"dep\":\"客服部\"}).explain() 除了单键索引外还可以创建联合索引如下： db.emp.createIndex({\"dep\":1,\"job\":-1}) 查看 复合索引的执行计划 db.emp.find({\"dep\":\"ddd\"}).explain() 查看索引在排序当中的使用 db.emp.find().sort({\"job\":-1,\"dep\":1}).explain() 二、mongodb 的主从复制机制 知识点： 复制集群的架构 复制集群搭建 复制集群的选举配置 1.复制集群的架构 2.复制集群搭建基础示例 主节点配置 dbpath=/data/mongo/master port=27017 fork=true logpath=master.log replSet=tulingCluster 从节点配置 dbpath=/data/mongo/slave port=27018 fork=true logpath=slave.log replSet=tulingCluster 子节点配置2 dbpath=/data/mongo/slave2 port=27019 fork=true logpath=slave2.log replSet=tulingCluster [ ] 分别启动三个节点 [ ] 进入其中一个节点 集群复制配置管理 #查看复制集群的帮助方法 rs.help() 添加配置 // 声明配置变量 var cfg ={\"_id\":\"tulingCluster\", \"members\":[ {\"_id\":0,\"host\":\"127.0.0.1:27017\"}, {\"_id\":1,\"host\":\"127.0.0.1:27018\"} ] } // 初始化配置 rs.initiate(cfg) // 查看集群状态 rs.status() 变更节点示例： // 插入新的复制节点 rs.add(\"127.0.0.1:27019\") // 删除slave 节点 rs.remove(\"127.0.0.1:27019\") [ ] 演示复制状态 [ ] 进入主节点客户端 [ ] 插入数据 [ ] 进入从节点查看数据 [ ] 尝试在从节点下插入数据 注：默认节点下从节点不能读取数据。调用 rs.slaveOk() 解决。 3.复制集群选举操作 为了保证高可用，在集群当中如果主节点挂掉后，会自动 在从节点中选举一个 重新做为主节点。 [ ] 演示节点的切换操作 [ ] kill 主节点 [ ] 进入从节点查看集群状态 。rs.status() 选举的原理： 在mongodb 中通过在 集群配置中的 rs.属性值大小来决定选举谁做为主节点，通时也可以设置arbiterOnly 为true 表示 做为裁判节点用于执行选举操作，该配置下的节点 永远不会被选举为主节点和从节点。 示例： 重新配置节点 var cfg ={\"_id\":\"tulingCluster\", \"protocolVersion\" : 1, \"members\":[ {\"_id\":0,\"host\":\"127.0.0.1:27017\",\"priority\":10}, {\"_id\":1,\"host\":\"127.0.0.1:27018\",\"priority\":2}, {\"_id\":2,\"host\":\"127.0.0.1:27019\",\"arbiterOnly\":true} ] } // 重新装载配置，并重新生成集群节点。 rs.reconfig(cfg) //重新查看集群状态 rs.status() 节点说明： PRIMARY 节点： 可以查询和新增数据 SECONDARY 节点：只能查询 不能新增 基于priority 权重可以被选为主节点 RBITER 节点： 不能查询数据 和新增数据 ，不能变成主节点 三、mongodb 中的分片机制 知识点： 分片的概念 mongodb 中的分片架构 分片示例 1.为什么需要分片？ 随着数据的增长，单机实例的瓶颈是很明显的。可以通过复制的机制应对压力，但mongodb中单个集群的 节点数量限制到了12个以内，所以需要通过分片进一步横向扩展。此外分片也可节约磁盘的存储。 1.mongodb 中的分片架构 分片中的节点说明： 路由节点(mongos)：用于分发用户的请求，起到反向代理的作用。 配置节点(config)：用于存储分片的元数据信息，路由节基于元数据信息 决定把请求发给哪个分片。（3.4版本之后，该节点，必须使用复制集。） 分片节点(shard):用于实际存储的节点，其每个数据块默认为64M，满了之后就会产生新的数据库。 2.分片示例流程： 配置 并启动config 节点集群 配置集群信息 配置并启动2个shard 节点 配置并启动路由节点 添加shard 节点 添加shard 数据库 添加shard 集合 插入测试数据 检查数据的分布 插入大批量数据查看shard 分布 设置shard 数据块为一M 插入10万条数据 配置 并启动config 节点集群 节点1 config1-37017.conf dbpath=/data/mongo/config1 port=37017 fork=true logpath=logs/config1.log replSet=configCluster configsvr=true 节点2 config2-37018.conf dbpath=/data/mongo/config2 port=37018 fork=true logpath=logs/config2.log replSet=configCluster configsvr=true 进入shell 并添加 config 集群配置： var cfg ={\"_id\":\"configCluster\", \"protocolVersion\" : 1, \"members\":[ {\"_id\":0,\"host\":\"127.0.0.1:37017\"}, {\"_id\":1,\"host\":\"127.0.0.1:37018\"} ] } // 重新装载配置，并重新生成集群。 rs.initiate(cfg) 配置 shard 节点集群============== # 节点1 shard1-47017.conf dbpath=/data/mongo/shard1 port=47017 fork=true logpath=logs/shard1.log shardsvr=true # 节点2 shard2-47018.conf dbpath=/data/mongo/shard2 port=47018 fork=true logpath=logs/shard2.log shardsvr=true 配置 路由节点 mongos ============== 节点 route-27017.conf port=27017 bind_ip=0.0.0.0 fork=true logpath=logs/route.log configdb=configCluster/127.0.0.1:37017,127.0.0.1:37018 // 添加分片节点 sh.status() sh.addShard(\"127.0.0.1:47017\"); sh.addShard(\"127.0.0.1:47018\"); 为数据库开启分片功能 sh.enableSharding(\"tuling\") 为指定集合开启分片功能 sh.shardCollection(\"tuling.emp\",{\"_id\":1}) 修改分片大小 use config db.settings.find() db.settings.save({_id:\"chunksize\",value:1}) 尝试插入1万条数据： for(var i=1;i 四、用户管理与数据集验证 // 创建管理员用户 use admin; db.createUser({\"user\":\"admin\",\"pwd\":\"123456\",\"roles\":[\"root\"]}) #验证用户信息 db.auth(\"admin\",\"123456\") #查看用户信息 db.getUsers() # 修改密码 db.changeUserPassword(\"admin\",\"123456\") 以auth 方式启动mongod，需要添加auth=true 参数 ，mongdb 的权限体系才会起作用： #以auth 方向启动mongod （也可以在mongo.conf 中添加auth=true 参数） ./bin/mongod -f conf/mongo.conf --auth # 验证用户 use admin; db.auth(\"admin\",\"123456\") 创建只读用户 db.createUser({\"user\":\"dev\",\"pwd\":\"123456\",\"roles\":[\"read\"]}) 重新登陆 验证用户权限 use luban ; db.auth(\"dev\",\"123456\") [ ] 演示查看数据 [ ] 演示插入数据 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/redis/":{"url":"distributed/redis/","title":"redis","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/redis/shell.html":{"url":"distributed/redis/shell.html","title":"1.启停脚本","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 ! /bin/bash #! /bin/bash case $1 in \"start\"){ for i in hadoop101 hadoop102 hadoop103 do echo \" --------启动 $i Kafka-------\" # 用于KafkaManager监控 ssh $i \"export JMX_PORT=9988 && /usr/local/software/kafka_2.12-2.6.0/bin/kafka-server-start.sh -daemon /usr/local/software/kafka_2.12-2.6.0/config/server.properties \" done };; \"stop\"){ for i in hadoop101 hadoop102 hadoop103 do echo \" --------停止 $i Kafka-------\" ssh $i \"/usr/local/software/kafka_2.12-2.6.0/bin/kafka-server-stop.sh stop\" done };; esac Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:36:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/redis/redis.html":{"url":"distributed/redis/redis.html","title":"2.分布式之Redis","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.概述 1.1 简介 1.2 特点 1.3 场景 1.4 架构 1.5 工作原理 2.环境搭建 2.1redis 集群方案比较 2.1.1 哨兵模式 2.1.2 高可用集群模式 2.2 版本(高可用集群模式搭建) 2.2 主机规划 2.3 下载 2.4 配置环境 2.4.1redis 安装 2.4.2redis 集群搭建 3.快速入门 3.1Redis 基础数据结构 3.2Java 操作 redis 集群 3.3 4.深入了解 4.1Redis 的单线程和高性能 4.2 持久化 4.2.1RDB 快照（snapshot） save 60 1000 4.2.2AOF（append-only file） appendonly yes 4.2.3RDB 和 AOF，我应该用哪一个？ 4.2.4Redis 4.0 混合持久化 aof-use-rdb-preamble yes 4.3 六种缓存淘汰策略 4.4Redis 集群原理分析 4.4.1 槽位定位算法 4.4.2 跳转重定位 4.4.3 网络抖动 4.5Redis集群选举原理分析 5.优化 5.1 5.2 5.3 1.概述 1.1 简介 1.2 特点 1.3 场景 1.4 架构 1.5 工作原理 2.环境搭建 2.1redis 集群方案比较 2.1.1 哨兵模式 在 redis3.0 以前的版本要实现集群一般是借助哨兵 sentinel 工具来监控 master 节点的状态，如果 master 节点异常，则会做主从切换，将某一台 slave 作为 master，哨兵的配置略微复杂，并且性能和高可用性等各方面表现一般，特别是在主从切换的瞬间存在访问瞬断的情况，而且哨兵模式只有一个主节点对外提供服务，没法支持很高的并发，且单个主节点内存也不宜设置得过大，否则会导致持久化文件过大，影响数据恢复或主从同步的效率 2.1.2 高可用集群模式 redis 集群是一个由多个主从节点群组成的分布式服务器群，它具有复制、高可用和分片特性。Redis 集群不需要 sentinel 哨兵也能完成节点移除和故障转移的功能。需要将每个节点设置成集群模式，这种集群模式没有中心节点，可水平扩展，据官方文档称可以线性扩展到上万个节点(官方推荐不超过 1000 个节点)。redis 集群的性能和高可用性均优于之前版本的哨兵模式，且集群配置非常简单 2.2 版本(高可用集群模式搭建) 组件 版本 备注 centos 64 位 7.x 以上 redis 5.0 gcc xxx 2.2 主机规划 ip host 安装软件 127.0.0.1 hadoop101 redis gcc 2.3 下载 http://download.redis.io/releases/redis-5.0.2.tar.gz tar xzf redis-5.0.2.tar.gz 2.4 配置环境 2.4.1redis 安装 进入到解压好的 redis-5.0.2 目录下，进行编译与安装 make & make install 启动并指定配置文件 src/redis-server redis.conf（注意要使用后台启动，所以修改 redis.conf 里的daemonize 改为 yes) 验证启动是否成功 ps -ef | grep redis 进入 redis 客户端 /usr/local/redis/bin/redis-cli 退出客户端 quit 退出 redis 服务： （1）pkill redis-server （2）kill 进程号 （3）src/redis-cli shutdown 2.4.2redis 集群搭建 redis 集群需要至少要三个 master 节点，我们这里搭建三个 master 节点，并且给每个 master 再搭建一个 slave 节点，总共 6 个 redis 节点，这里用三台机器部署 6 个 redis 实例，每台机器一主一从，搭建集群的步骤如下： 第一步：在第一台机器的/usr/local 下创建文件夹 redis-cluster，然后在其下面分别创建 2 个文件夾如下: （1）mkdir -p /usr/local/redis-cluster （2）mkdir 8001、mkdir 8004 第二步：把之前的 redis.conf 配置文件 copy 到 8001 下，修改如下内容： （1）daemonize yes （2）port 8001（分别对每个机器的端口号进行设置） （3）dir /usr/local/redis-cluster/8001/（指定数据文件存放位置，必须要指定不同的目录位置，不然会丢失数据） （4）cluster-enabled yes（启动集群模式） （5）cluster-config-file nodes-8001.conf（集群节点信息文件，这里 800x 最好和 port 对应上） （6）cluster-node-timeout 5000 (7) # bind 127.0.0.1（去掉 bind 绑定访问 ip 信息） (8) protected-mode no （关闭保护模式） （9）appendonly yes 如果要设置密码需要增加如下配置： （10）requirepass zhuge (设置 redis 访问密码) （11）masterauth zhuge (设置集群节点间访问密码，跟上面一致) 第三步：把修改后的配置文件，copy 到 8002，修改第 2、3、5 项里的端口号，可以用批量替换： :%s/源字符串/目的字符串/g 第四步：另外两台机器也需要做上面几步操作，第二台机器用 8002 和 8005，第三台机器用 8003 和 8006 第五步：分别启动 6 个 redis 实例，然后检查是否启动成功 （1）/usr/local/redis-5.0.2/src/redis-server /usr/local/redis-cluster/800*/redis.conf （2）ps -ef | grep redis 查看是否启动成功 第六步：用 redis-cli 创建整个 redis 集群(redis5 以前的版本集群是依靠 ruby 脚本 redis-trib.rb 实现)（1）/usr/local/redis-5.0.2/src/redis-cli -a zhuge --cluster create --cluster-replicas 1 192.168.0.61:8001 192.168.0.62:8002 192.168.0.63:8003 192.168.0.61:8004 192.168.0.62:8005 192.168.0.63:8006 代表为每个创建的主服务器节点创建一个从服务器节点第七步：验证集群： （1）连接任意一个客户端即可：./redis-cli -c -h -p (-a 访问服务端密码，-c 表示集群模式，指定 ip 地址和端口号）如：/usr/local/redis-5.0.2/src/redis-cli -a zhuge -c -h 192.168.0.61 -p 800* （2）进行验证：cluster info（查看集群信息）、cluster nodes（查看节点列表） （3）进行数据操作验证 （4）关闭集群则需要逐个进行关闭，使用命令： /usr/local/redis/bin/redis-cli -a zhuge -c -h 192.168.0.60 -p 800* shutdown 3.快速入门 3.1Redis 基础数据结构 Redis 有 5 种基础数据结构，分别为：string (字符串)、list (列表)、set (集合)、hash (哈希) 和 zset (有序集合)。 3.2Java 操作 redis 集群 借助 redis 的 java 客户端 jedis 可以操作以上集群，引用 jedis 版本的 maven 坐标如下： redis.clients jedis 2.9.0 Java 编写访问 redis 集群的代码非常简单，如下所示： import java.io.IOException; import java.util.HashSet; import java.util.Set; import redis.clients.jedis.HostAndPort; import redis.clients.jedis.JedisCluster; import redis.clients.jedis.JedisPoolConfig; /** * 访问 redis 集群 */ public class RedisCluster { public static void main(String[] args) throws IOException{ Set jedisClusterNode = new HashSet(); jedisClusterNode.add(new HostAndPort(\"192.168.0.61\", 8001)); jedisClusterNode.add(new HostAndPort(\"192.168.0.62\", 8002)); jedisClusterNode.add(new HostAndPort(\"192.168.0.63\", 8003)); jedisClusterNode.add(new HostAndPort(\"192.168.0.61\", 8004)); jedisClusterNode.add(new HostAndPort(\"192.168.0.62\", 8005)); jedisClusterNode.add(new HostAndPort(\"192.168.0.63\", 8006)); JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(100); config.setMaxIdle(10); config.setTestOnBorrow(true); //connectionTimeout：指的是连接一个 url 的连接等待时间 //soTimeout：指的是连接上一个 url，获取 response 的返回等待时间 JedisCluster jedisCluster = new JedisCluster(jedisClusterNode, 6000, 5000, 10, \"zhuge\", config); System.out.println(jedisCluster.set(\"student\", \"zhuge\")); System.out.println(jedisCluster.set(\"age\", \"19\")); System.out.println(jedisCluster.get(\"student\")); System.out.println(jedisCluster.get(\"age\")); jedisCluster.close(); } } 3.3 4.深入了解 4.1Redis 的单线程和高性能 Redis 单线程为什么还能这么快？ 因为它所有的数据都在内存中，所有的运算都是内存级别的运算，而且单线程避免了多线程的切换性能损耗问题。正因为 Redis 是单线程，所以要小心使用 Redis 指令，对于那些耗时的指令(比如 keys)，一定要谨慎使用，一不小心就可能会导致 Redis 卡顿。 Redis 单线程如何处理那么多的并发客户端连接？ Redis 的 IO 多路复用：redis 利用 epoll 来实现 IO 多路复用，将连接信息和事件放到队列中，依次放到文件事件分派器，事件分派器将事件分发给事件处理器。 Nginx 也是采用 IO 多路复用原理解决 C10K 问题 4.2 持久化 4.2.1RDB 快照（snapshot） 在默认情况下，Redis 将内存数据库快照保存在名字为 dump.rdb 的二进制文件中。 你可以对 Redis 进行设置， 让它在“ N 秒内数据集至少有 M 个改动”这一条件被满足时， 自动保存一次数据集。 比如说，以下设置会让 Redis 在满足“ 60 秒内有至少有 1000 个键被改动”这一条件时， 自动保存一次数据集： save 60 1000 4.2.2AOF（append-only file） 快照功能并不是非常耐久（durable）：如果 Redis 因为某些原因而造成故障停机， 那么服务器将丢失最近写入、且仍未保存到快照中的那些数据。从 1.1 版本开始，Redis 增加了一种完全耐久的持久化方式：AOF 持久化，将修改的每一条指令记录进文件 你可以通过修改配置文件来打开 AOF 功能： appendonly yes 从现在开始， 每当 Redis 执行一个改变数据集的命令时（比如 SET）， 这个命令就会被追加到 AOF 文件的末尾。 这样的话， 当 Redis 重新启时， 程序就可以通过重新执行 AOF 文件中的命令来达到重建数据集的目的。 你可以配置 Redis 多久才将数据 fsync 到磁盘一次。 有三个选项：  每次有新命令追加到 AOF 文件时就执行一次 fsync ：非常慢，也非常安全。  每秒 fsync 一次：足够快（和使用 RDB 持久化差不多），并且在故障时只会丢失 1 秒钟的数据。  从不 fsync ：将数据交给操作系统来处理。更快，也更不安全的选择。 推荐（并且也是默认）的措施为每秒 fsync 一次， 这种 fsync 策略可以兼顾速度和安全性。 4.2.3RDB 和 AOF，我应该用哪一个？ 如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化。 有很多用户都只使用 AOF 持久化， 但我们并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快。 4.2.4Redis 4.0 混合持久化 重启 Redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。AOF在重写(aof文件里可能有太多没用指令，所以aof会定期根据内存的最新数据生成aof文件)时将重写这一刻之前的内存rdb快照文件的内容和增量的 AOF修改内存数据的命令日志文件存在一起，都写入新的aof文件，新的文件一开始不叫appendonly.aof，等到重写完新的AOF文件才会进行改名，原子的覆盖原有的AOF文件，完成新旧两个AOF文件的替换； AOF 根据配置规则在后台自动重写，也可以人为执行命令 bgrewriteaof 重写 AOF。 于是在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。 开启混合持久化： aof-use-rdb-preamble yes 混合持久化 aof 文件结构 4.3 六种缓存淘汰策略 当 Redis 内存超出物理内存限制时，内存的数据会开始和磁盘产生频繁的交换 (swap)。交换会让 Redis 的性能急剧下降，对于访问量比较频繁的 Redis 来说，这样龟速的存取效率基本上等于不可用。 在生产环境中我们是不允许 Redis 出现交换行为的，为了限制最大使用内存，Redis 提供了配置参数 maxmemory 来限制内存超出期望大小。 当实际内存超出 maxmemory 时，Redis 提供了几种可选策略 (maxmemory-policy) 来让用户自己决定该如何腾出新的空间以继续提供读写服务。 noeviction不会继续服务写请求 (DEL 请求可以继续服务)，读请求可以继续进行。这样可以保证不会丢失数据，但是会让线上的业务不能持续进行。这是默认的淘汰策略。 volatile-lru尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。没有设置过期时间的 key 不会被淘汰，这样可以保证需要持久化的数据不会突然丢失。 volatile-ttl跟上面一样，除了淘汰的策略不是 LRU，而是 key 的剩余寿命 ttl 的值，ttl 越小越优先被淘汰。 volatile-random跟上面一样，不过淘汰的 key 是过期 key 集合中随机的 key。 allkeys-lru区别于 volatile-lru，这个策略要淘汰的 key 对象是全体的 key 集合，而不只是过期的 key 集合。这意味着没有设置过期时间的 key 也会被淘汰。 allkeys-random跟上面一样，不过淘汰的策略是随机的 key。 volatile-xxx策略只会针对带过期时间的 key 进行淘汰，allkeys-xxx 策略会对所有的 key 进行淘汰。如果你只是拿 Redis 做缓存，那应该使用 allkeys-xxx，客户端写缓存时不必携带过期时间。如果你还想同时使用 Redis 的持久化功能，那就使用 volatile-xxx 策略，这样可以保留没有设置过期时间的 key，它们是永久的 key 不会被 LRU 算法淘汰。 4.4Redis 集群原理分析 Redis Cluster 将所有数据划分为16384 的 slots(槽位)，每个节点负责其中一部分槽位。槽位的信息存储于每个节点中，。 当 Redis Cluster 的客户端来连接集群时，它也会得到一份集群的槽位配置信息并将其缓存在客户端本地。这样当客户端要查找某个 key 时，可以直接定位到目标节点。同时因为槽位的信息可能会存在客户端与服务器不一致的情况，还需要纠正机制来实现槽位信息的校验调整。 4.4.1 槽位定位算法 Cluster 默认会对 key 值使用 crc16 算法进行 hash 得到一个整数值，然后用这个整数值对 16384 进行取模来得到具体槽位。 HASH_SLOT = CRC16(key) mod 16384 4.4.2 跳转重定位 当客户端向一个错误的节点发出了指令，该节点会发现指令的 key 所在的槽位并不归自己管理，这时它会向客户端发送一个特殊的跳转指令携带目标操作的节点地址，告诉客户端去连这个节点去获取数据。客户端收到指令后除了跳转到正确的节点上去操作，还会同步更新纠正本地的槽位映射表缓存，后续所有 key 将使用新的槽位映射表。 4.4.3 网络抖动 真实世界的机房网络往往并不是风平浪静的，它们经常会发生各种各样的小问题。比如网络抖动就是非常常见的一种现象，突然之间部分连接变得不可访问，然后很快又恢复正常。 为解决这种问题，Redis Cluster 提供了一种选项 cluster-node-timeout，表示当某个节点持续 timeout 的时间失联时，才可以认定该节点出现故障，需要进行主从切换。如果没有这个选项，网络抖动会导致主从频繁切换 (数据的重新复制)。 4.5Redis集群选举原理分析 当slave发现自己的master变为FAIL状态时，便尝试进行Failover，以期成为新的master。由于挂掉的master可能会有多个slave，从而存在多个slave竞争成为master节点的过程， 其过程如下： 1.slave发现自己的master变为FAIL 2.将自己记录的集群currentEpoch加1，并广播FAILOVER_AUTH_REQUEST 信息 3.其他节点收到该信息，只有master响应，判断请求者的合法性，并发送FAILOVER_AUTH_ACK，对每一个epoch只发送一次ack 4.尝试failover的slave收集FAILOVER_AUTH_ACK 5.超过半数后变成新Master 6.广播Pong通知其他集群节点。 从节点并不是在主节点一进入 FAIL 状态就马上尝试发起选举，而是有一定延迟，一定的延迟确保我们等待FAIL状态在集群中传播，slave如果立即尝试选举，其它masters或许尚未意识到FAIL状态，可能会拒绝投票 •延迟计算公式： DELAY = 500ms + random(0 ~ 500ms) + SLAVE_RANK * 1000ms •SLAVE_RANK表示此slave已经从master复制数据的总量的rank。Rank越小代表已复制的数据越新。这种方式下，持有最新数据的slave将会首先发起选举（理论上）。 5.优化 5.1 5.2 5.3 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:38:25 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/shardingsphere/":{"url":"distributed/shardingsphere/","title":"shardingsphere","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/elk/":{"url":"distributed/elk/","title":"elk","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 13:18:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/elk/shell.html":{"url":"distributed/elk/shell.html","title":"1.启停脚本","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 ! /bin/bash #! /bin/bash case $1 in \"start\"){ for i in hadoop101 hadoop102 hadoop103 do echo \" --------启动 $i Kafka-------\" # 用于KafkaManager监控 ssh $i \"export JMX_PORT=9988 && /usr/local/software/kafka_2.12-2.6.0/bin/kafka-server-start.sh -daemon /usr/local/software/kafka_2.12-2.6.0/config/server.properties \" done };; \"stop\"){ for i in hadoop101 hadoop102 hadoop103 do echo \" --------停止 $i Kafka-------\" ssh $i \"/usr/local/software/kafka_2.12-2.6.0/bin/kafka-server-stop.sh stop\" done };; esac Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:36:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed/elk/elk.html":{"url":"distributed/elk/elk.html","title":"2.分布式之ELK","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.Elasticsearch 1.1配置文件elasticsearch.yml 1.2启动 1.3访问 2.Logstash 2.1创建配置文件logstash.conf 2.2启动 3.Kibana 3.1配置kibana.yml 3.2启动 3.3访问 1.Elasticsearch 1.1配置文件elasticsearch.yml (如果是单机测试可以不用配置直接默认启动就可以了) 配置集群名称，保证每个节点的名称相同，如此就能都处于一个集群之内了 cluster.name: elasticsearch-cluster # 每一个节点的名称，必须不一样 node.name: es-node1 # http端口（使用默认即可） http.port: 9200 # 主节点，作用主要是用于来管理整个集群，负责创建或删除索引，管理其他非master节点（相当于企业老总） node.master: true # 数据节点，用于对文档数据的增删改查 node.data: true # 集群列表 discovery.seed_hosts: [\"192.168.0.100\", \"192.168.0.101\", \"192.168.0.102\"] # 启动的时候使用一个master节点 cluster.initial_master_nodes: [\"es-node1\"] 1.2启动 ./bin/elasticSearch –d 启动。-d表示后台启动 1.3访问 127.0.0.1:9200 2.Logstash 2.1创建配置文件logstash.conf input { file { type => \"log\" path => [\"/export/home/tomcat/domains/*/*/logs/*.out\"] start_position => \"end\" ignore_older => 0 codec=> multiline { //配置log换行问题 pattern => \"^%{TIMESTAMP_ISO8601}\" negate => true what => \"previous\" } } beats { port => 5044 } } output { if [type] == \"log\" { elasticsearch { hosts => [\"http://127.0.0.1:9200\"] index => \"log-%{+YYYY.MM}\" } } } 2.2启动 ./logstash -f ../config/logstash.conf 后台启动：nohup ./bin/logstash -f config/log.conf > log.log & 配置多个文件：./logstash -f ../config 指定启动目录，然后启动目录下配置多个*.conf文件。里面指定不同的logpath。 3.Kibana 3.1配置kibana.yml elasticsearch.url: http://localhost:9200 server.host: 0.0.0.0 3.2启动 启动命令：./kibana 后台启动：nohup ./bin/kibana & 3.3访问 http://localhost:5601 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 15:55:52 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"micro/":{"url":"micro/","title":"六、微服务框架专题","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"project/":{"url":"project/","title":"七、项目实战专题","keywords":"","body":"Introduction Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-13 09:07:24 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"project/SystemArchitecture.html":{"url":"project/SystemArchitecture.html","title":"1.系统架构","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.电商演变 2.运行效果 3.环境详解 4.架构详解 1.电商演变 2.运行效果 项目下载地址：http://git.jiagouedu.com/java-vip/tuling-shop.git 前端：wukong/ aaa111 后端：admin/123456 前提条件：Redis、mysql、zookeeper 创建数据库脚本 代码下载来之后编译。 启动顺序：shop-goods、shop-member、shop-trade、shop-pay、 shop-admin、shop-web 3.环境详解 192.168.0.15：base 服务 192.168.0.16：app 服务 Depoly.sh 下载、解压 env-set.sh 赋值、杀进程、启动 Pom.sh 每次解压会从 app-conf 目录下 copy 环境的配置 第三方 jar 包如何上传到私服。 mvn deploy:deploy-file -DgroupId=com.alipay -DartifactId=alipay-sdk-java -Dversion=3.3.0 -Dpackaging=jar -Dfile=F:\\workspace\\vipdev\\tuling-shop\\alipay-sdk-java-3.3.0.jar -Durl=http://192.168.0.15:7777/nexus/content/repositories/thirdparty/ 4.架构详解 新增加能： 1、完善部分模块(shop-web 和 shop-admin) 2、冗余代码 3、模块分离（shop-admin、shop-web） 4、支付功能（shop-pay、shop-pay-client） 5、分布式事务 6、版本模块 Jeeshop 开源网站改过来的 单体应用 半个时间 分布式网站 秒杀、商品详细、库存、分库分表、分布式事务。 *Client 都是 dubbo 对外暴露接口 问题？为什么要这么设计？解耦 对外接口（不需要业务） 并且我们接口升级之后 不会影响我们的服务 Dubbo 所有接口模块 不同的业务按不同的 dubbo 模块 优点：解耦，不会暴露给调用方具体的业务代码、职责单一。 缺点：带来一定工作量 繁琐 拆的还不够细。 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 16:08:59 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"project/member.html":{"url":"project/member.html","title":"2.商品&会员模块","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.商品中心 1.1分类+商品（1对多） 1.2分类+商品+品牌： 1.3分类+商品+品牌+属性： 1.4分类+商品+品牌+属性+规格： 1.5技术点 2.会员中心 2.1t_account会员表 2.2t_accountRank会员级别表 2.3t_address配送地址信息表 1.商品中心 商品中心： 1.1分类+商品（1对多） t_catalog商品分类表 参数 名称 类型 备注 id 自增长 int 唯一 name 分类名称 String code 编码，简码 String 唯一 pid 父ID Int order1 排序 Int type 类型 String 类型，a:文章目录；p:产品目录 showInNav 是否显示在首页的导航条上 String y:显示,n:不显示；默认n。仅对type=p有效 t_product商品表 字段名 数据类型 默认值 描述 id int 唯一，商品ID catalogID varchar 商品类别catalog表id name varchar 商品名称 introduce text 商品简介 price DECIMAL(9,2) 定价 nowPrice DECIMAL(9,2) 现价 picture String 小图片地址 score Int 0 赠送积分 maxPicture String 大图片地址 isnew String n 是否新品。n：否，y：是 sale String n 是否特价。n：否，y：是 activityID String 绑定的活动ID giftID String 绑定的礼品ID hit int 0 浏览次数 unit String 商品单位。默认“item:件” createAccount String 录入人账号 createtime datetime 录入时间 updateAccount String 最后修改人账号 updatetime String 最后修改时间 isTimePromotion String n 是否限时促销。n：否，y：是 status Int 0 商品状态。1：新增，2：已上架，3：已下架 productHTML LONGTEXT 商品介绍 images String 商品多张图片集合，逗号分割 sellcount Int 销售数量 默认：0 stock Int 剩余库存数 默认：0 searchKey String 搜索关键词 title String 页面标题 description String 页面描述 keywords String 页面关键词 1.2分类+商品+品牌： 我要查看苹果所有的产品（手机苹果、电脑苹果）需求 1.3分类+商品+品牌+属性： 更加快速找到我们想购买的商品 t_attribute商品属性(参数)表 参数 名称 类型 备注 id 自增长 int 唯一 name 属性/参数名称 String catalogID 类别ID Int pid 父ID Int 该字段具有双重含义。0表示属性大类，一般情况下产品只有两层attribute，一层为属性名称类别，一层为属性；-1：参数 order1 排序 Int t_attribute_link商品属性(参数)中间表 参数 名称 类型 备注 id 自增长 int 唯一 attrID 属性(参数)ID Int productID 商品ID Int value 商品参数值 String 名称从属性表中取得 1.4分类+商品+品牌+属性+规格： t_spec商品规格表 字段名 数据类型 默认值 描述 id int 唯一 productID String 商品ID specColor String 颜色 specSize String 尺寸 specStock Int 此规格的商品库存数 specPrice Double 此规格的商品价格 specStatus String y:显示规格；n:不显示规格 SPU ：SPU(Standard Product Unit)：标准化产品单元。是商品信息聚合的最小单位，是一组可复用、易检索的标准化信息的集合，该集合描述了一个产品的特性。通俗点讲，属性值、特性相同的商品就可以称为一个SPU。 举例：Iphone6 SKU： SKU=Stock Keeping Unit（库存量单位）。即库存进出计量的基本单元，可以是以件，盒，托盘等为单位。 举例：Iphone6+土豪金+32G C2C店铺 1.5技术点 商品检索：ES、SOLR （数据源来自数据库，那就意味着同步）、分词 商品展示：商品+图片+库存+店铺+商品相关的信息 图片：GFS、TFS、FastDFs底层原理？特点：文件小、图片小 并发下问题 缓存：查询的速度、内存》硬盘（数据源来自数据库，那就意味着同步） 增量：增加、修改、下架 全量：预热数据（某个活动所有商品加载缓存中） 静态化: 把html+CDN 缺点:更新上需要更新HTML 2.会员中心 会员基础服务：登录、注册、购物、评价、晒单 会员成长体系：购物、评价、晒单 会员等级（注册会员、铜牌会员、银牌会员、金牌会员、钻石会员 ） 2.1t_account会员表 字段名 数据类型 主键 唯一 描述 id int Y 会员ID nickname varchar y 昵称 account varchar y 用户名out当前时间戳 password varchar 密码 accountType String 会员类型。qq,sinawb,alipay trueName String 真实姓名 sex String 性别。m:男,f：女,s:保密 birthday Date 出生年月日 province String 省份 city varchar 所在城市 address varchar 联系地址 postcode varchar 邮政编码 cardNO varchar 证件号码 cardType varchar 证件类型 grade int 等级 amount money 消费额 tel varchar 电话 email varchar y Email地址 emailIsActive String 邮箱是否已激活。y:已激活,n:未激活。默认n freeze String 是否冻结 n：未冻结，y：已冻结；默认n freezeStartdate Date 冻结的开始日期 freezeEnddate Date 冻结的结束日期 lastLoginTime Date 最后登录时间 lastLoginIp String 最后登录IP lastLoginArea String 最后登陆地点 diffAreaLogin String 是否是异地登陆y:是,n:否 regeistDate Date 注册日期 addressID Int 配送信息ID openId String y QQ登陆返回 accessToken String QQ登陆返回 alipayUseId String y 支付宝快捷登陆返回的用户ID sinaWeiboID String y 新浪微博登陆返回的用户ID rank String 会员等级。和t_accountType.code进行挂钩。默认R1 score Int 会员积分。默认0 2.2t_accountRank会员级别表 字段名 数据类型 是否主键 描述 id int 是 自增 code String 级别编码R1：普通会员，0-499R2：铜牌会员，积分范围500-999R3：银牌会员，1000-1999R4：金牌会员，2000-4000R5：钻石会员，大于4000 name String 级别名称 minScore Int 最小积分 maxScore Int 最大积分 remark String 备注 2.3t_address配送地址信息表 字段名 数据类型 是否主键 描述 id Int 是 自增 account String 会员账号 name String 收货人姓名 province String 省份 city String 城市 area String 区域 pcadetail String 省市区的地址中文合并 address String 收货人详细地址 zip String 收货人邮编 phone String 收货人电话号码 mobile String 收货人手机号码 isdefault String 默认n 是否默认；n=不是,y=默认 技术点： 单点登录、业务功能、会员迁移（分库分表） Login.jd.com item.jd.com 分布式会话解决方案 分库：hash取模、list、range 16个库（800万数据量） hash、不好扩展 1.28亿用户 均匀（解决热点数据） 分库分库 如何设计一个不扩容方案。 可视化的黑客小工具 调式bug比较有用 测试排查问题（查看最新0代码） 系统比较庞大 不需要重启 Admin admin 会员部门 xxx部门 非常非常简单 原理 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 16:09:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"project/order.html":{"url":"project/order.html","title":"3.交易&营销模块","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.交易模块 1.1t_order 订单表 1.2t_orderdetail订单明细表 1.3t_discount折扣表 1.4t_orderpay 支付记录表 1.5t_ordership 订单配送表 1.6t_orderlog订单日志表 1.7t_express快递配送表 2.营销 交易中心 交易中心业务 技术难点 营销 营销中心业务 技术难点1.交易模块 1.1t_order 订单表 字段名 数据类型 是否主键 描述 id int 是 订单编号。 account String 账号 payType varchar 付款方式 carry varchar 运送方式 rebate DECIMAL(9,2) 折扣 createdate datetime 创建日期 remark varchar 备注、支付宝的WIDsubject status String init:未审核；pass:已审核；send：已发货；sign：已签收；cancel:已取消；file:已归档；finish：交易完成； refundStatus String 退款状态(直接借用了支付宝的退款状态)。WAIT_SELLER_AGREE：等待卖家同意退款；WAIT_BUYER_RETURN_GOODS：卖家同意退款，等待买家退货；WAIT_SELLER_CONFIRM_GOODS：买家已退货，等待卖家收到退货；REFUND_SUCCESS：卖家收到退货，退款成功，交易关闭 paystatus String n:未支付；p:部分支付；y:全部支付 lowStocks String n:库存不足；y:库存充足。默认n amount Double 订单总金额 amountExchangeScore Int 订单总兑换积分 fee Double 运费总金额 ptotal Double 商品总金额 quantity Int 商品总数量 updateAmount String n:没有修改过；y:修改过；默认:n expressCode String 配送方式编码 expressName String 配送方式名称 expressNo String 快递运单号 expressCompanyName String 快递公司名称 confirmSendProductRemark String 确认发货备注 otherRequirement String 客户的附加要求 closedComment String 此订单的所有订单项对应的商品都进行了评论，则此值为y，表示此订单的评论功能已经关闭，默认为null，在订单状态为已发货后，则用户可以对订单进行评价。 score Int 订单获赠的积分 1.2t_orderdetail订单明细表 字段名 数据类型 是否主键 描述 ID int 是 ID号 orderID int 与t_order表的id字段关联 orderdetailID String 订单项ID productID int 商品ID giftID String 商品赠品ID productName String 商品名称 price money 价格 number int 数量 total0 Double 总金额（数量*价格） fee Double 配送费 isComment String 是否评价过。n:未评价,y:已评价；默认n lowStocks String n:库存不足；y:库存充足。默认n s String 商品规格信息 1.3t_discount折扣表 字段名 数据类型 是否主键 描述 ID int 是 ID号 discount decimal(9,1) 折扣,比如9.5折 name String 折扣宣传名称 1.4t_orderpay 支付记录表 字段名 数据类型 是否主键 描述 id int 是 自增 orderid String 订单ID paystatus String 支付状态。y:支付成功,n:支付失败 payamount Double 支付金额 createtime String 支付时间 paymethod String 支付方式 confirmdate String 确认日期 confirmuser String 确认人 remark String 备注 tradeNo String 支付宝交易号，以后用来发货 1.5t_ordership 订单配送表 字段名 数据类型 是否主键 描述 id int 是 自增 orderid String 订单ID shipname String 收货人姓名 shipaddress String 收货人详细地址 provinceCode String 省份代码 province String 省份 cityCode String 城市代码 city String 城市 areaCode String 区域代码 area String 区域 phone String 手机 tel String 座机 zip String 邮编 sex String 性别 remark String 备注 1.6t_orderlog订单日志表 字段名 数据类型 允许为空 描述 id int 自增 orderid String 订单ID account String 操作人 createdate date 记录时间，默认是当前时间 content String 日志内容 accountType String w:会员;m:后台管理人员;p:第三方支付系统异步通知 1.7t_express快递配送表 参数 名称 类型 备注 id 自增长 int 唯一 code 快递编码 String 三个值可选：EXPRESS（快递）、POST（平邮）、EMS（EMS） name 快递名称 String fee 物流费用 Double order1 排序 Int 交易中 库存（超卖）、重复支付、唯一主键、秒杀（库存） 、购物车 库存超卖、秒杀：锁、队列 for update 重复支付：幂等性（前端通知、后端通知）（下单 通知多次 调用多次 ）Redis incr 唯一主键：雪花算法、redis、数据库特性、UUID等等（分库分表实战） 下单：RPC调用 显示状态 订单状态 支付状态 发货状态 已付款 活动订单 已支付 未发货 已发货 活动订单 已支付 已发货 待自提 活动订单 已支付 自提点签收 已签收 活动订单 已支付 用户签收 已拒收 活动订单 已支付 用户拒收 配送成功 活动订单 已支付 配送成功 配送失败 活动订单 已支付 配送失败 交易成功 已完成 已支付 配送成功 交易失败 已完成 已支付 配送失败 取消中 取消中 已支付 未发货 已取消 订单取消 未发货 消息中间件：异步、解耦 购物车-技术点 面试题：不未登入时，购物车redis key该怎么做？ Userid+goodsid+shopid ?goodsid+shopid 未登录商品 购物车 Redis 同一台电脑上 跟换游览器没有关系 时序图 存储在redis+mysql redis存储的（shopid+goodsid） 增加一个商品购物车 插入一次数据库。 Userid xxxx id pc ios rpc调用goodsid 商品服务 下单 购物车清空 购物车数据结构：B2C(跨店铺) com.jiagouedu.web.action.front.orders.CartInfo com.jiagouedu.web.action.front.orders. CartGroup(一个店铺catgroup) cartPkg(一个店铺下可能会产生多个包裹) List(商品明细) 2个技术点： 排序的问题 排序（put数据）重写排序算法 实时性的问题 10点 5% 10：1 10% xxx奶粉 囤货 1千奶粉 羊毛党（抓）结算 查一次海关系统（下单） 拆单 业务上问题 2个iphone 长沙 仓库武汉（库存 1 个）（河南 1个 广州 1个） Goodsid+shopid+userid pkg（包裹） JD 充值 100 95 （9.5折）99. 总结： 师，上节课的 黑科技上传了麽 上传了 技术难点说了一大堆，解决方案一个没有 库存锁定、扣减 下单： U l 扣减 10 1 0 支付： 9 0 1 ERP系统 30分钟支付时间 锁定 2.营销 商品级别、订单级别、全站级别。 技术实现？ 营销活动存储（下节课 技术点） 数据的回滚 ，用户手上 订单 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 16:09:21 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"project/pay.html":{"url":"project/pay.html","title":"4.支付模块","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.营销系统 2.支付宝对接 3.微信对接 4.技术注意点： 4.1接口的幂等性 4.2后台系统 4.2.1t_user用户表 4.2.2t_role角色表 4.2.3t_privilege权限表 4.2.4t_systemsetting系统设置表 4.2.5t_systemlog系统日志表 1.营销系统 技术如何去实现？ 一个商品会对应多个活动 购物车N个商品N个活动 100个商品 300个活动（300条记录 数据库查询） 100个悟空人 3w条记录 缓存？Redis mysql Jvm map 数据同步的 在分布式下 不同的jvm 缓存数据不一样？ 活动优先级问题：怎么解决？权重 jvm 也是内存 redis也是内存 那就不要redis了 将来发生 job 执行的 计划 时间 2.支付宝对接 https://openhome.alipay.com/platform/demoManage.htm#/alipay.trade.pay 3.微信对接 4.技术注意点： 4.1接口的幂等性 4.2后台系统 后台管理： 电商没有关系、很多系统的权限这块 公共。 权限系统一般有：账号、角色、权限、资源。 权限可以分为三种：页面权限，操作权限，数据权限。 页面权限： 控制你可以看到哪个页面，看不到哪个页面。 很多系统都只做到了控制页面这一层级，它实现起来比较简单，一些系统会这样设计，但是比较古板，控制的权限不精细，难以在页面上对权限进行更下一层级的划分。 If else 操作权限： 则控制你可以在页面上操作哪些按妞。 延伸：当我们进入一个页面，我们的目的无非是在这个页面上进行增删改查，那在页面上对应的操作可能是：查询，删除，编辑，新增四个按钮。 可能你在某个页面上，只能查询数据，而不能修改数据。 数据权限： 数据权限则是控制你可以看到哪些数据，比如市场A部的人只能看到或者修改A部创建的数据，他看不到或者不能修改B部的数据。 延伸：数据的控制我们一般通过部门去实现，每条记录都有一个创建人，而每一个创建人都属于某个部门，因此部门分的越细，数据的控制层级也就越精细，这里是否有其他好的方式除了部门这个维度还有其他什么方式可以控制数据权限。 4.2.1t_user用户表 t_user用户表 参数 名称 类型 备注 id 自增长 int 唯一 username 帐号 String 唯一 password 密码 string MD5加密 createtime 创建时间 String createAccount 创建人 String updatetime 最后修改时间 String updateAccount 最后修改人 String status 状态 String y:启用,n:禁用；默认y rid 角色ID Int nickname 昵称 String email 邮箱 String 4.2.2t_role角色表 t_role角色表 参数 名称 类型 备注 id 自增长 int 唯一 role_name 角色名称 String role_desc 角色描述 string role_dbPrivilege 数据库权限 String status 角色状态，如果角色被禁用，则该角色下的所有的账号都不能使用，除非角色被解禁。 String y:启用，n:禁用；默认y 4.2.3t_privilege权限表 参数 名称 类型 备注 id 自增长 int 唯一 rid 角色ID int mid 资源ID int t_menu资源表 参数 名称 类型 备注 id 自增长 int 唯一 pid 父ID Int url 资源 String name 资源名称 string orderNum 序号 int type 功能类型 String module：模块page：页面button：功能 4.2.4t_systemsetting系统设置表 字段名 数据类型 允许为空 描述 基本设置 id int ID号 systemCode String 系统代号 name String 网站名称 www String 门户地址根http路径 manageHttp String 后台地址根http路径 log String 网站门户的Log图标地址 title String 网站标题 description String 网站的描述 keywords String 网站的关键字 shortcuticon String 网站的图标 address String 联系地址 tel String 联系电话 email String 邮箱 qqHelpHtml String Qq沟通组建的HTML内容 icp String 备案号 isopen String 是否开放网站。y:开放,n不开放 closeMsg String 网站关闭消息 qq String Qq号码 statisticsCode String 站长统计代码 version String 系统版本相关信息 显示设置 openResponsive String y:启用响应式；n:禁用响应式。默认y imageRootPath String 图片根路径，以后可以专门弄个图片服务器，图片和项目分离，提高站点访问速度。 defaultProductImg String 商品的默认图片 images 图集 String 多张图片之间用分号分割。如果广告的useImagesRandom为n，则优先显示html；否则显示images图集的图片，每一次都会从图集中随机选取一张图片来显示。 manageLeftTreeLeafIcon String 后台左侧菜单叶子节点的图标 4.2.5t_systemlog系统日志表 字段名 数据类型 允许为空 描述 id int 自增 title String 日志标题 content String 日志内容 type Int 日志类型。1：登陆日志，2：版本日志， createdate date 记录时间，默认是当前时间 account String 操作人 loginIP String 登陆人IP地址 logintime String 登陆时间 loginArea String 登陆区域 diffAreaLogin String 是否是异地登陆y:是;n:否 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 16:09:32 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"project/Depots-table-1.html":{"url":"project/Depots-table-1.html","title":"5.分库分表一","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.数据库的压力 2.如何优化？有什么方式 3.问题 4.如何优化：散列+增量（数据热点+扩容） 5.总结 1.数据库的压力 订单相关表都已经是超大表，最大表的数据量已经是几十亿，数据库处理能力已经到了极限； 单库包含多个超大表，占用的硬盘空间已经接近了服务器的硬盘极限，很快将无空间可用； 过度解决：我们可以考虑到最直接的方式是增加大容量硬盘，或者对IO有更高要求，还可以考虑增加SSD硬盘来解决容量的问题。此方法无法解决单表数据量问题。 可以对数据表历史数据进行归档，但也需要频繁进行归档操作，而且不能解决性能问题 硬件上（大小）、单表容量（性能） 2.如何优化？有什么方式 读写分离、换mysql》oracle、分库分表。 分库分表： 散列hash：hashmap可以很好的去解决数据热点的问题，但是扩容 短板 Range增量：他的库容很多好，但是他就是没法解决数据热点的问题。 实战： 老的版本：不支持spring管理（分布式主键） 新的版本:支持（分布式主键） 3.问题 表增加是可以通过创建，但是有一个地方我们改了也会有问题 面对这两种方案都是比较难的处境，shard扩容显得难了、 扩容的问题？ 分库扩容理想状态： 最好不数据迁移（给团队带来的工作压力） 可以达到1的要求，并且数据热点的问题。 根据硬件资源设置不同阈值（判定） 4.如何优化：散列+增量（数据热点+扩容） 热点：解决数据热点的问题（因为我们局部用了散列） 扩容： 5.总结 多查一次数据库（字典表） 依赖全局的ID生成（美团+业务ID在区间自增） 其他： 前端：吞吐量高、并发高、相应速度快、但是业务简单（我） 我的订单 全部订单（我） userid=1 商品表（shopid） 后端：(并发不高、业务逻辑复杂、相应不快) 后台（另外）业务复杂、吞吐量不高 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 16:09:43 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"project/Depots-table-2.html":{"url":"project/Depots-table-2.html","title":"6.分库分表二","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 1.分库分表难点 2.分布式唯一ID解决方案 2.1Uuid: 2.2Snowflke 2.3Mysql 2.4Redis: 3.分布式事务解决方案 1.分库分表难点 分布式事务。 分布式主键。 跨库的查询。 数据迁移的问题。2.分布式唯一ID解决方案 2.1Uuid: 通用唯一识别码 组成部分：当前日期和时间+时钟序列+全局唯一网卡 mac 地址获取 执行任务数：10000 所有线程共耗时：91.292 s 并发执行完耗时：1.221 s 单任务平均耗时：9.1292 ms 单线程最小耗时：0.0 ms 单线程最大耗时：470.0 ms 优点： 代码实现简单、不占用宽带、数据迁移不影响 缺点： 无序、无法保证趋势递增、字符存储、传输、查询慢 2.2Snowflke snowflake 是 Twitter 开源的分布式 ID 生成算法。 传统数据库软件开发中，主键自动生成技术是基本需求。而各个数据库对于该需求也提供了相应的支持，比如 MySQL 的自增键，Oracle 的自增序列等。 数据分片后，不同数据节点生成全局唯一主键是非常棘手的问题。同一个逻辑表内的不同实际表之间的自增键由于无法互相感知而产生重复主键。 虽然可通过约束自增主键初始值和步长的方式避免碰撞，但需引入额外的运维规则，使解决方案缺乏完整性和可扩展性。 io.shardingsphere.core.keygen.DefaultKeyGenerator 执行任务数：10000 所有线程共耗时：15.111 s 并发执行完耗时：217.0 ms 单任务平均耗时：1.5111 ms 单线程最小耗时：0.0 ms 单线程最大耗时：97.0 ms 优点： 不占用宽带、本地生成、高位是毫秒，低位递增 缺点： 强依赖时钟，如果时间回拨，数据递增不安全 2.3Mysql 利用数据库的步长来做的。 CREATE TABLE bit_table ( id varchar(255) NOT NULL,//字符 PRIMARY KEY (id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; CREATE TABLE bit_num ( id bigint(11) NOT NULL AUTO_INCREMENT, KEY (id) USING BTREE ) ENGINE=InnoDB auto_increment=1 DEFAULT CHARSET=utf8; SET global auto_increment_offset=1; --初始化 SET global auto_increment_increment=100; --初始步长 show global variables; 缺点: 受限数据库、单点故障、扩展麻烦 优点： 性能可以、可读性强、数字排序 2.4Redis: redis 原子性：对存储在指定 key 的数值执行原子的加 1 操作。如果指定的 key 不存在，那么在执行 incr 操作之前，会先将它的值设定为 0 组成部分：年份+当天当年第多少天+天数+小时+redis 自增 执行任务数：10000 所有线程共耗时：746.767 s 并发执行完耗时：9.381 s 单任务平均耗时：74.6767 ms 单线程最小耗时：0.0 ms 单线程最大耗时：4.119 s 优点： 有序递增、可读性强、符合刚才我们那个扩容方案的 id 缺点： 占用宽带（网络）、依赖第三方、redis 一个小时内生产 99 万的订单 ？ 场景： 名称 场景 适用指数 Uuid Token、图片 id ★★ Snowflake ELK、MQ、业务系统 ★★★★ 数据库 非大型电商系统 ★★★ Redis 大型系统 ★★★★★ 3.分布式事务解决方案 Copyright © ohter.com 2021 all right reserved，powered by Gitbook该文件修订时间： 2021-04-19 16:09:57 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"}}